[
 {
  "repo": "Project-MONAI/MONAI",
  "language": "Python",
  "readme_contents": "<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/Project-MONAI/MONAI/dev/docs/images/MONAI-logo-color.png\" width=\"50%\" alt='project-monai'>\n</p>\n\n**M**edical **O**pen **N**etwork for **AI**\n\n![Supported Python versions](https://raw.githubusercontent.com/Project-MONAI/MONAI/dev/docs/images/python.svg)\n[![License](https://img.shields.io/badge/license-Apache%202.0-green.svg)](https://opensource.org/licenses/Apache-2.0)\n[![PyPI version](https://badge.fury.io/py/monai.svg)](https://badge.fury.io/py/monai)\n[![docker](https://img.shields.io/badge/docker-pull-green.svg?logo=docker&logoColor=white)](https://hub.docker.com/r/projectmonai/monai)\n[![conda](https://img.shields.io/conda/vn/conda-forge/monai?color=green)](https://anaconda.org/conda-forge/monai)\n\n[![premerge](https://github.com/Project-MONAI/MONAI/actions/workflows/pythonapp.yml/badge.svg?branch=dev)](https://github.com/Project-MONAI/MONAI/actions/workflows/pythonapp.yml)\n[![postmerge](https://img.shields.io/github/checks-status/project-monai/monai/dev?label=postmerge)](https://github.com/Project-MONAI/MONAI/actions?query=branch%3Adev)\n[![docker](https://github.com/Project-MONAI/MONAI/actions/workflows/docker.yml/badge.svg?branch=dev)](https://github.com/Project-MONAI/MONAI/actions/workflows/docker.yml)\n[![Documentation Status](https://readthedocs.org/projects/monai/badge/?version=latest)](https://docs.monai.io/en/latest/)\n[![codecov](https://codecov.io/gh/Project-MONAI/MONAI/branch/dev/graph/badge.svg?token=6FTC7U1JJ4)](https://codecov.io/gh/Project-MONAI/MONAI)\n\nMONAI is a [PyTorch](https://pytorch.org/)-based, [open-source](https://github.com/Project-MONAI/MONAI/blob/dev/LICENSE) framework for deep learning in healthcare imaging, part of [PyTorch Ecosystem](https://pytorch.org/ecosystem/).\nIts ambitions are:\n- developing a community of academic, industrial and clinical researchers collaborating on a common foundation;\n- creating state-of-the-art, end-to-end training workflows for healthcare imaging;\n- providing researchers with the optimized and standardized way to create and evaluate deep learning models.\n\n\n## Features\n> _Please see [the technical highlights](https://docs.monai.io/en/latest/highlights.html) and [What's New](https://docs.monai.io/en/latest/whatsnew.html) of the milestone releases._\n\n- flexible pre-processing for multi-dimensional medical imaging data;\n- compositional & portable APIs for ease of integration in existing workflows;\n- domain-specific implementations for networks, losses, evaluation metrics and more;\n- customizable design for varying user expertise;\n- multi-GPU multi-node data parallelism support.\n\n\n## Installation\n\nTo install [the current release](https://pypi.org/project/monai/), you can simply run:\n\n```bash\npip install monai\n```\n\nPlease refer to [the installation guide](https://docs.monai.io/en/latest/installation.html) for other installation options.\n\n## Getting Started\n\n[MedNIST demo](https://colab.research.google.com/drive/1wy8XUSnNWlhDNazFdvGBHLfdkGvOHBKe) and [MONAI for PyTorch Users](https://colab.research.google.com/drive/1boqy7ENpKrqaJoxFlbHIBnIODAs1Ih1T) are available on Colab.\n\nExamples and notebook tutorials are located at [Project-MONAI/tutorials](https://github.com/Project-MONAI/tutorials).\n\nTechnical documentation is available at [docs.monai.io](https://docs.monai.io).\n\n## Citation\n\nIf you have used MONAI in your research, please cite us! The citation can be exported from: https://arxiv.org/abs/2211.02701.\n\n## Model Zoo\n[The MONAI Model Zoo](https://github.com/Project-MONAI/model-zoo) is a place for researchers and data scientists to share the latest and great models from the community.\nUtilizing [the MONAI Bundle format](https://docs.monai.io/en/latest/bundle_intro.html) makes it easy to [get started](https://github.com/Project-MONAI/tutorials/tree/main/model_zoo) building workflows with MONAI.\n\n## Contributing\nFor guidance on making a contribution to MONAI, see the [contributing guidelines](https://github.com/Project-MONAI/MONAI/blob/dev/CONTRIBUTING.md).\n\n## Community\nJoin the conversation on Twitter [@ProjectMONAI](https://twitter.com/ProjectMONAI) or join our [Slack channel](https://forms.gle/QTxJq3hFictp31UM9).\n\nAsk and answer questions over on [MONAI's GitHub Discussions tab](https://github.com/Project-MONAI/MONAI/discussions).\n\n## Links\n- Website: https://monai.io/\n- API documentation (milestone): https://docs.monai.io/\n- API documentation (latest dev): https://docs.monai.io/en/latest/\n- Code: https://github.com/Project-MONAI/MONAI\n- Project tracker: https://github.com/Project-MONAI/MONAI/projects\n- Issue tracker: https://github.com/Project-MONAI/MONAI/issues\n- Wiki: https://github.com/Project-MONAI/MONAI/wiki\n- Test status: https://github.com/Project-MONAI/MONAI/actions\n- PyPI package: https://pypi.org/project/monai/\n- conda-forge: https://anaconda.org/conda-forge/monai\n- Weekly previews: https://pypi.org/project/monai-weekly/\n- Docker Hub: https://hub.docker.com/r/projectmonai/monai\n"
 },
 {
  "repo": "GoogleCloudPlatform/healthcare",
  "language": "Jupyter Notebook",
  "readme_contents": "# Cloud Healthcare\n\nThis respository contains utilities used for Cloud Healthcare applications.\n"
 },
 {
  "repo": "kakoni/awesome-healthcare",
  "language": null,
  "readme_contents": "# Awesome Health [![Awesome](https://cdn.jsdelivr.net/gh/sindresorhus/awesome@d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)\n\nCurated list of awesome open source healthcare software, libraries, tools and resources. Each link has been vetted to ensure the project is active and provides value to healthcare facilities, providers, developers, policy experts, and/or research scientists.\n\n## Contents\n\n- [EHR](#ehr)\n- [Specifications](#specifications)\n- [Prescribing](#prescribing)\n- [Nursing](#nursing)\n- [Imaging](#imaging)\n- [Dental](#dental)\n- [Laboratory](#laboratory)\n- [Libraries](#libraries)\n- [Frameworks](#frameworks)\n- [Applications](#applications)\n- [Personal Health Record](#phr)\n- [Integration](#integration)\n- [Research](#research)\n- [Hardware](#hardware)\n- [Bioinformatics](#bioinformatics)\n- [Data](#data)\n- [Datasets](#datasets)\n- [Enterprise Master Patient Index](#empi)\n- [Machine Learning](#machine-learning)\n- [Compliance](#compliance)\n- [Asset Management](#asset-management)\n- [Logistics](#logistics)\n- [Analytics](#analytics)\n\n### EHR\n  * [Bahmni](https://www.bahmni.org) - Electronic Medical Record and hospital system.\n  * [Cottage Med](https://cottagemed.org/p/26/Download-Cottage-Med) - Electronic Medical Record software designed by physicians.\n  * [GNU Health](https://www.gnuhealth.org) - Electronic Medical Record, Hospital Management, and Health Information System.\n  * [GNUmed](https://www.gnumed.de/documentation/) - Electronic Medical Record software.\n  * [EHRBase](https://ehrbase.org) OpenEHR Clinical Data Repository.\n  * [EHRServer](https://github.com/ppazos/cabolabs-ehrserver) - CaboLabs EHRServer.\n  * [ERPNext](https://erpnext.com/open-source-healthcare) - Modules that help manage patients, appointments, consultations, lab tests, and billing.\n  * [FreeMedForms EMR](https://freemedforms.com/fr/start) - Electronic Medical Record software.\n  * [HospitalRun](https://hospitalrun.io) - Helps provide the most modern Hospital Information System possible to the least resourced environments.\n  * [HOSxP](https://hosxp.net/joomla25/) - Thai Hospital Information System that aims to ease the healthcare workflow of health centers and central hospitals.\n  * [LibreHealth EHR](https://librehealth.io/projects/lh-ehr/) - Clinically-focused Electronic Health Record System.\n  * [MedinTux](https://medintux.org/) - French Medical Practice Management System.\n  * [Medplum](https://github.com/medplum/medplum) - Developer platform that enables flexible and rapid development of healthcare apps.\n  * [Odoo Medical](https://github.com/OCA/vertical-medical) - Universal Health and Hospital Information System.\n  * [OpenClinic](https://github.com/jact/openclinic) - Medical Records System.\n  * [OpenEMR](https://www.open-emr.org) - Electronic Health Records and Medical Practice Management application.\n  * [OpenEyes](https://openeyes.apperta.org) - Electronic Medical Record application for ophthalmology.\n  * [Open Hospital](https://sourceforge.net/projects/openhospital/) - Electronic Medical Record software for underprivileged rural hospitals.\n  * [openMAXIMS](https://github.com/IMS-MAXIMS/openMAXIMS) - Full Patient Administration System designed for the NHS.\n  * [OpenMRS](https://openmrs.org) - Enterprise Electronic Medical Record System platform.\n  * [OSCAR EMR](https://bitbucket.org/oscaremr/oscar) - OSCAR McMaster Project.\n  * [Ozone HIS](https://www.ozone-his.com) - The entreprise-grade integrated health information system built with OpenMRS 3\n  * [Ripple](https://www.ripple.foundation) -  NHS-funded, community led initiative working towards an integrated Digital Care Record Platform.\n\n### Specifications\n  * [FHIR](https://www.hl7.org/fhir/) - Fast Health Interoperability Resources.\n  * [OpenEHR](https://www.openehr.org) - Open specification upon which software can be built.\n  * [Open mHealth](https://www.openmhealth.org) - Open Standard For Mobile Health Data.\n  * [SMART on FHIR](https://docs.smarthealthit.org/) - Open standards based technology platform.\n  * [StandardHealthRecord](http://standardhealthrecord.org/) - Open specification for health record format, aiming to be more precise than existing formats.\n  * [Continuity of Care Document](https://www.hl7.org/implement/standards/product_brief.cfm?product_id=7) - Continuity of Care Document specifications (free account required).\n  * [Continuity of Care Record](httsp://hitsp.org/ConstructSet_Details.aspx?&PrefixAlpha=4&PrefixNumeric=32) - Specifications for the older form of CCD - sometimes called a \"C32\".\n  * [HL7 Version 2](https://www.hl7.org/implement/standards/product_brief.cfm?product_id=185) - Specifications for all versions of HL7v2 (free account required).\n  * [OHDSI OMOP Common Data Model](https://www.ohdsi.org/data-standardization/) - Standardized data model for many healthcare concepts, awesome Github presence including scripts for many major relational databases.\n  * [Standard Health Record Collaborative](http://standardhealthrecord.org/shr/) - High quality, computable source of patient information provided by establishing a single target for health data standardization.\n  * [DICOM Standards Browser](https://dicom.innolitics.com/ciods) - Provides an effective way to learn the DICOM standard and inspect DICOM attributes.\n  \n### Prescribing\n  * [OpenEP](https://github.com/ehrscape/examples/tree/master/openep) - Suite of medicines management apps that improve the safety and efficiency of prescribing and medicines management.\n\n### Nursing\n  * [open-eObs](https://openeobs.github.io/) - Observation and clinical assessment platform that offers a real-time view of all patients across a ward.\n\n### Imaging\n  * [3D Slicer](https://www.slicer.org) - Cross-platform application for analyzing, visualizing and understanding medical image data.\n  * [Cornerstone](https://github.com/cornerstonejs/cornerstone) - Open source project with a goal to deliver a complete web based medical imaging platform.\n  * [dcm4che](https://www.dcm4che.org/) - Clinical Image and Object Management.\n  * [Dicoogle](https://github.com/bioinformatics-ua/dicoogle) - Dicoogle is an extensible, platform-independent and open-source PACS\n  * [Drishti](https://github.com/nci/drishti/wiki) - Tomography and electron-microscopy data visualizer for both scientists and lay people.\n  * [DICOMcloud](https://github.com/DICOMcloud/DICOMcloud) - A standalone DICOMweb server with RESTful implementation of the DICOMweb/WADO services.\n  * [DICOM Server](https://github.com/microsoft/dicom-server) - OSS Implementation of DICOMweb standard.\n  * [DICOM Web Viewer](https://ivmartel.github.io/dwv/) - JavaScript/HTML5-based DICOM viewer with standard tools and a focus on supporting various screen sizes.\n  * [Fiji](https://imagej.net/software/fiji/) - Open-source platform for biological-image analysis.\n  * [Horos](https://horosproject.org) - Medical image viewer.\n  * [InVesalius](https://invesalius.github.io) - Open source software for reconstruction of computed tomography and magnetic ressonance images.\n  * [ITK](https://itk.org/) - Toolkit used for the development of image segmentation and image registration programs with leading-edge algorithms in 2 and 3 dimensions.\n  * [ITK-SNAP](http://www.itksnap.org/pmwiki/pmwiki.php) - Interactive software for 3 dimensional image navigation, annotation, and automatic segmentation with an emphasis on user-friendliness.\n  * [LibreHealth Radiology](https://librehealth.io/projects/lh-radiology/) - Customized version of LibreHealth Toolkit with additional tools for radiology and imaging professionals.\n  * [Kaapana](https://github.com/kaapana/kaapana) - Open source toolkit for state of the art platform provisioning in the field of medical data analysis.\n  * [Kheops](https://kheops.online) - Open source platform for sharing medical images\n  * [OHIF](https://github.com/OHIF/Viewers) - OHIF zero-footprint DICOM viewer and oncology specific Lesion Tracker.\n  * [Omero](https://github.com/ome/openmicroscopy) - open source client/server system written in Java for visualizing, managing, and annotating microscope images and metadata\n  * [OpenREM](https://openrem.org/) - Radiation Exposure Monitoring for physicists.\n  * [OpenSlide](https://github.com/openslide/openslide) - is a C library for reading whole slide image files.\n  * [Orthanc](https://www.orthanc-server.com) - Lightweight DICOM server for healthcare and medical research.\n  * [Papaya](https://github.com/rii-mango/Papaya) - Pure JavaScript medical research image viewer.\n  * [Slim](https://github.com/ImagingDataCommons/slim) - Interoperable web viewer and annotation tool for computational pathology.\n  * [Viv](https://github.com/hms-dbmi/viv) - multiscale visualization of high-resolution multiplexed bioimaging data on the web.\n  * [VTK](https://vtk.org) - 3 dimensional visualization toolkit supporting a variety of algorithms and modeling techniques.\n\n### Dental\n  * [Open Dental](https://www.opendental.com) - Dental Practice Management Software.\n  * [OpenMolar](https://openmolar.com/) - Dental Practice Management Software. \n\n### Laboratory\n  * [OpenELIS](https://sites.google.com/site/openelisglobal/) - Laboratory Information System for Global Health.\n  * [SENAITE](https://www.senaite.com) - Laboratory Information Management System.\n\n### Frameworks\n  * [API Server](https://github.com/smart-on-fhir/api-server) - FHIR Server to support patient- and clinician-facing apps.\n  * [Blaze](https://github.com/samply/blaze) - A FHIR Store with internal, fast CQL Evaluation Engine\n  * [CareKit](https://github.com/carekit-apple/CareKit/) - Open source software framework for creating apps that help people better understand and manage their health.\n  * [Clinical Meteor project](https://github.com/clinical-meteor) - Meteor for FDA, HIPAA, and HL7 compliant applications.\n  * [Clinical Quality Language](https://github.com/cqframework/clinical_quality_language) - Clinical Quality Language is a HL7 standard for the expression of clinical knowledge.\n  * [FHIRBase](https://fhirbase.github.io) - Storage based on the FHIR Standard.\n  * [FHIR Proxy](https://github.com/microsoft/fhir-proxy) - secure application that acts as an intermediary in the transfer of FHIR data to and from Azure API.\n  * [FHIR Works on AWS](https://github.com/awslabs/fhir-works-on-aws-deployment) - FHIR Works on AWS deployment.\n  * [FHIR Server for Azure](https://github.com/Microsoft/fhir-server) - A .NET Core implementation of the FHIR standard.\n  * [Intervention Engine FHIR Server](https://github.com/intervention-engine/fhir) - Generic FHIR server implementation in GoLang.\n  * [LinuxForHealth FHIR Server](https://github.com/LinuxForHealth/FHIR) - Modular Java implementation of version 4 of the HL7 FHIR specification.\n  * [Medblocks UI](https://github.com/medblocks/medblocks-ui) - Web Components for rapid development of openEHR and FHIR systems.\n  * [Opal](https://opal.openhealthcare.org.uk/) - Framework for building clinical applications.\n  * [ResearchKit](https://github.com/ResearchKit/ResearchKit) - Software framework that makes it easy to create apps for medical research or for other research projects.\n  * [Spark](https://github.com/FirelyTeam/spark) - Public domain FHIR server developed in C#.\n  * [Sushi](https://github.com/FHIR/sushi) - a reference implementation command-line interpreter/compiler for FHIR\n  * [Swift-SMART](https://github.com/smart-on-fhir/Swift-SMART) - Swift SMART on FHIR framework for iOS and OS X.\n\n### Libraries\n  * [Android FHIR SDK](https://github.com/google/android-fhir) - The Android FHIR SDK \n  * [Archie](https://github.com/openehr/archie) - OpenEHR Library written in Java.\n  * [Asymmetrik FHIR API Server](https://github.com/bluehalo/node-fhir-server-core) - A secure REST implementation for the HL7 FHIR Specification.\n  * [Datamol](https://github.com/datamol-io/datamol) - Molecular Manipulation Made Easy. A light Python wrapper build on top of RDKit.\n  * [DCMTK](https://dicom.offis.de/dcmtk.php.en) - DICOM Toolkit.\n  * [dicom](https://github.com/suyashkumar/dicom) - High Performance DICOM Medical Image Parser in GoLang.\n  * [ehrapy](https://github.com/theislab/ehrapy/) - Electronic Health Record analysis in Python.\n  * [Evil-DICOM](https://github.com/rexcardan/Evil-DICOM) - C# DICOM Library.\n  * [Fellow Oak DICOM](https://github.com/fo-dicom/fo-dicom) - DICOM for .NET, .NET Core, Universal Windows, Android, iOS, Mono, and Unity.\n  * [FHIRKit Client](https://github.com/Vermonster/fhir-kit-client) - Node FHIR client library.\n  * [FHIRModels](https://github.com/apple/FHIRModels) - FHIRModels is a Swift library for FHIR resource data models.\n  * [FHIR .NET API](https://github.com/FirelyTeam/firely-net-sdk) - The official .NET API for HL7 FHIR.\n  * [fhir.js](https://github.com/FHIR/fhir.js) - JavaScript client for FHIR.\n  * [FHIR protocol buffers](https://github.com/google/fhir) - A Google implementation of protocol buffers for FHIR.\n  * [Graphir](https://github.com/microsoft/graphir) - GraphQL interface over FHIR API\n  * [HAPI FHIR](https://github.com/hapifhir/hapi-fhir) - Java API for HL7 FHIR Clients and Servers.\n  * [Hearth](https://github.com/jembi/hearth) - A fast FHIR-compliant server focused on longitudinal data stores.\n  * [Health data standards](https://github.com/projectcypress/health-data-standards) - Ruby library for generating and consuming various healthcare related formats. These include HITSP C32, QRDA Category I, and QRDA Category III.\n  * [Hermes](https://github.com/wardle/hermes) - a SNOMED CT terminology server. \n  * [MITK](https://www.mitk.org/wiki/The_Medical_Imaging_Interaction_Toolkit_(MITK)) - The Medical Imaging Interaction Toolkit.\n  * [Node HL7](https://github.com/MatthewVita/node-hl7-complete) - Node module that is bridged with the Java Hapi HL7 library.\n  * [Node-hl7-parser](https://github.com/RedoxEngine/redox-hl7-v2) - Open source version of Redox's HL7 v2 to schema-fied JSON parser.\n  * [php-fhir](https://github.com/dcarbone/php-fhir) - Tools for creating PHP classes from the HL7 FHIR Specification.\n  * [pynetdicom](https://github.com/pydicom/pynetdicom) - A Python implementation of the DICOM networking protocol.\n  * [Python HL7](https://github.com/johnpaulett/python-hl7) - Simple library for parsing messages of HL7 version 2.x into Python objects.\n  * [Python SMART on FHIR client](https://github.com/smart-on-fhir/client-py) - Flexible Python client for FHIR servers supporting the SMART on FHIR protocol.\n  * [Python 835 Parser](https://github.com/keironstoddart/edi-835-parser) - A simple-to-use Python interface to EDI 835 Health Care Claim Payment and Remittance Advice files.\n  * [Ruby FHIR](https://github.com/fhir-crucible/fhir_client) - FHIR client implementation in Ruby.\n  * [Ruby HL7](https://github.com/segfault/ruby-hl7) - Ruby HL7 library.\n  * [Rust FHIR](https://github.com/itsbalamurali/rust-fhir) - Rust SDK for HL7 FHIR\n  * [TorchXRayVision](https://github.com/mlmed/torchxrayvision) - A library for chest X-ray datasets and models. Including pre-trained models.\n  * [Z-Anatomy](https://www.z-anatomy.com) - The libre atlas of anatomy\n\n### Applications\n  * [Intervention Engine](https://github.com/intervention-engine/ie) - Provides a web-application for data-driven team huddles.\n  * [SMART Pediatric Growth Chart](https://github.com/smart-on-fhir/growth-chart-app) - Pediatric growth charts.\n\n### PHR\n  * [Tidepool](https://github.com/tidepool-org) - Data platform to reduce the burden of Type 1 Diabetes.\n  * [HealthLocker](https://github.com/healthlocker/healthlocker) - Elixir-based personal health record.\n\n### Research\n  * [i2b2](https://www.i2b2.org) - Research data warehouse.\n  * [LabKey Server](https://www.labkey.org) - Platform for Translational Research.\n\n### Integration\n  * [FHIR Converter](https://github.com/microsoft/FHIR-Converter) - an open source project that enables conversion of health data from legacy formats to FHIR.\n  * [Google HCLS Data Harmonization](https://github.com/GoogleCloudPlatform/healthcare-data-harmonization) - an engine that converts data of one structure to another\n  * [NextGen Connect Integration Engine](https://github.com/nextgenhealthcare/connect) - The swiss army knife of healthcare integration.\n  * [Open eHealth Integration Platform](https://github.com/oehf/ipf) - An extension of the Apache Camel routing and mediation engine\n  * [OpenHIM](http://openhim.org/) - Health information mediator.\n  * [Zato](https://zato.io/en/industry/healthcare/index.html) - A Python-based ESB and integration platform for healthcare interoperability, automation and orchestration.\n\n### Hardware\n  * [echOpen](https://www.echopen.org) - Low-cost (affordable) echo-stethoscope.\n  * [Gluco](https://github.com/nebulabio/gluco) - Glucometer.\n  * [Murgen](https://hackaday.io/project/9281-murgen-open-source-ultrasound-imaging) - Ultrasound imaging development kit.\n  * [OpenAPS](https://openaps.org/) - The Open Artificial Pancreas System project is an open and transparent effort to make safe and effective basic Artificial Pancreas System.\n\n### Bioinformatics\n  * [ADAM](https://github.com/bigdatagenomics/adam) - Genomics analysis platform.\n  * [Bcbio](https://github.com/bcbio/bcbio-nextgen) - Validated, scalable, community developed variant calling, RNA-seq and small RNA analysis.\n  * [Galaxy](https://galaxyproject.org/) - Open web-based platform for data intensive biomedical research.\n  * [Wregex](https://ehubio.ehu.eus/wregex/) - Amino acid motif searching software with optional Position-Specific Scoring Matrix.\n\n### Data\n  * [Atlas BI Library](https://github.com/atlas-bi/Library) The unified report library.\n  * [Caisis](http://www.caisis.org/) - Oncology research software with a Patient Data Management System.\n  * [Cedar](https://github.com/mitre/cedar) - Open source tool for testing the strength of Electronic Clinical Quality Measure.\n  * [cTAKES](https://ctakes.apache.org/) - Natural Language Processing System for extraction of information from Electronic Medical Record clinical free-text.\n  * [IHRIS](https://www.ihris.org/toolkit-new/) - Health Information System for management of human resources for health.\n  * [Inferno](https://github.com/onc-healthit/inferno) - Open source tool that tests whether patients can access their health data through a standard interface.\n  * [OpenSAFELY](https://www.opensafely.org) - Secure analytics platform for Electronic Health Records in the NHS.\n  * [Snow Owl](https://github.com/b2ihealthcare/snow-owl) - Highly scalable, open source terminology server with revision-control capabilities and collaborative authoring platform features. \n  * [Synthea Patient Generator](https://github.com/synthetichealth/synthea) - Synthetic patient generator that models the medical history of synthetic patients.\n\n### Datasets\n  * [Medical Data for Machine Learning](https://github.com/beamandrew/medical-data) - Curated list of medical data for machine learning.\n\n### EMPI\n  * [MEDIC Client Registry RI](https://github.com/MohawkMEDIC/client-registry) - The Mohawk College MARC-HI/MEDIC Client Registry EMPI Implementation.\n  \n### Machine learning\n  * [Healthcare.ai](https://healthcare.ai) - Python and R tools for healthcare machine learning.\n  * [MONAI](https://github.com/Project-MONAI/MONAI) - AI Toolkit for Healthcare Imaging\n\n### Asset Management\n  * [Tapirx](https://github.com/virtalabs/tapirx) - Networked medical device discovery and identification.\n\n### Logistics\n  * [ID3C](https://github.com/seattleflu/id3c) - Data logistics system enabling real-time genomic epidemiology.\n  * [OpenLMIS](https://openlmis.org) - Open source, web-based, electronic logistics management information system (LMIS) software, purpose-built to manage health commodity supply chains.\n"
 },
 {
  "repo": "wanghaisheng/healthcaredatastandard",
  "language": null,
  "readme_contents": "healthcaredatastandard\n======================\n\n\nlooking for contributor \n\n\u8bf7\u6dfb\u52a0\u6211\u7684\u5fae\u4fe1\n\n\n## \u6982\u8ff0\n\n\u572809\u5e74\u65b0\u533b\u6539\u4e4b\u540e\uff0c\u56fd\u5bb6\u5c42\u9762\u4e0a\u5bf9\u536b\u751f\u4fe1\u606f\u6807\u51c6\u7684\u91cd\u89c6\u7a0b\u5ea6\u4e5f\u7b97\u662f\u63d0\u9ad8\u4e86\uff0c\u4e5f\u6709\u4e00\u4e9b\u4e0d\u9519\u7684\u8fdb\u5c55\uff0c\u6574\u4f53\u4e0a\u8fd8\u662f\u504f\u6162\uff0c\u65e0\u6cd5\u6ee1\u8db3\u65b0\u5f62\u52bf\u4e0b\u7684\u533b\u7597\u7c7b\u5e94\u7528\u548c\u7cfb\u7edf\u7684\u5f00\u53d1\u3002\n\n\u76ee\u524d\u56fd\u5bb6\u5c42\u9762\u4e0a\u7684\u536b\u751f\u4fe1\u606f\u6807\u51c6\u4f53\u7cfb\u5982\u4e0b\n![](overview.png)\n\n\u76ee\u524d\u5df2\u5b58\u5728\u7684\u6570\u91cf  \n\n\n| \u5e74\u5ea6  | \u8ba1\u5212\u6570 | \u5b9e\u9645\u6570 | \u53d1\u5e03/\u62a5\u6279\u6570 | \u9001\u5ba1\u6570 | \u6b63\u5728\u7814\u5236\u6570 |  \n| ----  | ---- | ----  | ---- | ----  | ---- |   \n2008  |     8  | 10  | \t10  | \t0  | \t0\n2009  | \t7  | \t7  | \t7  | \t0  | \t0\n2010  | \t8  | \t8  | \t8  | \t0  | \t0\n2011  | \t108  | \t129  | \t126  | \t3  | \t0\n2012  | \t7  | \t50  | \t49  | \t1  | \t0\n2013  | \t22  | \t37  | \t17  | \t13  | \t7\n2014  | \t7  | \t7  | \t0  | \t0  | \t7\n2015  | \t20  | \t2  | \t0  | \t18  | \t/\n2016  | \t13  | \t11  | \t0  | \t2  | \t87\n2017  | \t5  | \t0  | \t5  | \t0  | \t18\n2018  | \t  | \t  | \t  | \t  | \t  | \n\u5408\u8ba1| 283  | \t37  | \t5  | \t33  | \t209  | \n\n\n## \u57fa\u7840\u7c7b\n\n| \u7f16\u53f7  | \u540d\u79f0 | \n| ----  | ---- | \n| WS/T 303-2009  | \u536b\u751f\u4fe1\u606f\u6570\u636e\u5143\u6807\u51c6\u5316\u89c4\u5219 | \n|  WS/T 304-2009  | \u536b\u751f\u4fe1\u606f\u6570\u636e\u6a21\u5f0f\u63cf\u8ff0\u6307\u5357 | \n|  WS/T 305-2009  | \u536b\u751f\u4fe1\u606f\u6570\u636e\u96c6\u5143\u6570\u636e\u89c4\u8303 | \n|  WS/T 306-2009  | \u536b\u751f\u4fe1\u606f\u6570\u636e\u96c6\u5206\u7c7b\u4e0e\u7f16\u7801\u89c4\u5219 | \n|  WS/T 370-2012  | \u536b\u751f\u4fe1\u606f\u57fa\u672c\u6570\u636e\u96c6\u7f16\u5236\u89c4\u8303 | \n|  WS/T 482-2016  | \u536b\u751f\u4fe1\u606f\u5171\u4eab\u6587\u6863\u7f16\u5236\u89c4\u8303 | \n\n\n## \u6570\u636e\u7c7b\n             \n### \u6570\u636e\u5143\n\n| \u7f16\u53f7  | \u540d\u79f0 | \n| ----  | ---- | \n| WS 363-2011  | \u536b\u751f\u4fe1\u606f\u6570\u636e\u5143\u76ee\u5f55 \u7b2c1-17\u90e8\u5206 | \n| WS 364-2011  | \u536b\u751f\u4fe1\u606f\u6570\u636e\u5143\u503c\u57df\u4ee3\u7801 \u7b2c1-17\u90e8\u5206 | \n\n| \u6807\u51c6\u7f16\u53f7 |   \u6807\u51c6\u4e2d\u6587\u540d\u79f0 |  \u6807\u8bc6\u7b26\u8303\u56f4 |  \u6570\u636e\u5143\u6570\u76ee | \n| ----  | ---- |  ---- |  ---- | \n| WS363.1-2011| \u536b\u751f\u4fe1\u606f\u6570\u636e\u5143\u76ee\u5f55\u7b2c1\u90e8\u5206:\u603b\u5219 \t| \t\t| \t| \n| WS363.2-2011| \u536b\u751f\u4fe1\u606f\u6570\u636e\u5143\u76ee\u5f55\u7b2c2\u90e8\u5206:\u6807\u8bc6\t| DE01.00.001.00-DE01.00.015.00\t| 13\n| WS363.3-2011| \t\u536b\u751f\u4fe1\u606f\u6570\u636e\u5143\u76ee\u5f55\u7b2c3\u90e8\u5206:\u4eba\u53e3\u5b66\u53ca\u793e\u4f1a\u7ecf\u6d4e\u5b66\u7279\u5f81\t| DE02.01.001.00-DE02.01.058.00\t| 62\n| WS363.4-2011 |  \t\u536b\u751f\u4fe1\u606f\u6570\u636e\u5143\u76ee\u5f55\u7b2c4\u90e8\u5206:\u5065\u5eb7\u53f2\t| DE02.10.001.00-DE02.10.096.00\t| 90\n| WS363.5-2011 | \t\u536b\u751f\u4fe1\u606f\u6570\u636e\u5143\u76ee\u5f55\u7b2c5\u90e8\u5206:\u5065\u5eb7\u5371\u9669\u56e0\u7d20\t| DE03.00.001.00-DE03.00.099.00\t| 98\n| WS363.6-2011 | \t\u536b\u751f\u4fe1\u606f\u6570\u636e\u5143\u76ee\u5f55\u7b2c6\u90e8\u5206:\u4e3b\u8bc9\u4e0e\u75c7\u72b6\t| DE04.01.001.00-DE04.01.120.00\t| 119\n| WS363.7-2011 | \t\u536b\u751f\u4fe1\u606f\u6570\u636e\u5143\u76ee\u5f55\u7b2c7\u90e8\u5206:\u4f53\u683c\u68c0\u67e5\t| DE04.10.001.00-DE04.10.243.00\t| 241\n| WS363.8-2011 | \t\u536b\u751f\u4fe1\u606f\u6570\u636e\u5143\u76ee\u5f55\u7b2c8\u90e8\u5206:\u4e34\u5e8a\u8f85\u52a9\u68c0\u67e5\t| DE04.30.001.00-DE04.30.051.00\t| 51\n| WS363.9-2011 | \t\u536b\u751f\u4fe1\u606f\u6570\u636e\u5143\u76ee\u5f55\u7b2c9\u90e8\u5206:\u5b9e\u9a8c\u5ba4\u68c0\u67e5\t| DE04.50.001.00-DE04.50.129.00\t| 129\n| WS363.10-2011| \t\u536b\u751f\u4fe1\u606f\u6570\u636e\u5143\u76ee\u5f55\u7b2c10\u90e8\u5206:\u533b\u5b66\u8bca\u65ad\t| DE05.01.001.00-DE05.01.073.00\t| 73\n| WS363.11-2011\t| \u536b\u751f\u4fe1\u606f\u6570\u636e\u5143\u76ee\u5f55\u7b2c11\u90e8\u5206:\u533b\u5b66\u8bc4\u4f30\t| DE05.10.001.00-DE05.10.128.00\t| 127\n| WS363.12-2011\t| \u536b\u751f\u4fe1\u606f\u6570\u636e\u5143\u76ee\u5f55\u7b2c12\u90e8\u5206:\u8ba1\u5212\u4e0e\u5e72\u9884\t| DE06.00.001.00-DE06.00.177.00\t| 175\n| WS363.13-2011\t| \u536b\u751f\u4fe1\u606f\u6570\u636e\u5143\u76ee\u5f55\u7b2c13\u90e8\u5206:\u536b\u751f\u8d39\u7528\t| DE07.00.001.00-DE07.00.010.00\t| 10\n| WS363.14-2011\t| \u536b\u751f\u4fe1\u606f\u6570\u636e\u5143\u76ee\u5f55\u7b2c14\u90e8\u5206:\u536b\u751f\u673a\u6784\t| DE08.10.001.00-DE08.10.053.00\t| 53\n| WS363.15-2011\t| \u536b\u751f\u4fe1\u606f\u6570\u636e\u5143\u76ee\u5f55\u7b2c15\u90e8\u5206:\u536b\u751f\u4eba\u5458\t| DE08.30.001.00-DE08.30.031.00\t| 31\n| WS363.16-2011\t| \u536b\u751f\u4fe1\u606f\u6570\u636e\u5143\u76ee\u5f55\u7b2c16\u90e8\u5206:\u836f\u54c1\u3001\u8bbe\u5907\u4e0e\u6750\u6599\t| DE08.50.001.00-DE08.50.025.00\t| 25\n| WS363.17-2011\t| \u536b\u751f\u4fe1\u606f\u6570\u636e\u5143\u76ee\u5f55\u7b2c17\u90e8\u5206:\u536b\u751f\u7ba1\u7406\t| DE09.00.001.00-DE09.00.102.00\t| 102\n\n### \u4ee3\u7801\u4e0e\u7f16\u7801\n\n| \u7f16\u53f7  | \u540d\u79f0 | \n| ----  | ---- | \n| WS 364-2011  | \u536b\u751f\u4fe1\u606f\u6570\u636e\u5143\u503c\u57df\u4ee3\u7801 \u7b2c1-17\u90e8\u5206 | \n| WS xxx-2013  | \u536b\u751f\u7edf\u8ba1\u6307\u6807\u76ee\u5f55 \u7b2c1-10\u90e8\u5206 | \n| GB/T 14396-2016\u75be\u75c5\u5206\u7c7b\u4e0e\u4ee3\u7801  | \u75be\u75c5\u5206\u7c7b\u4e0e\u4ee3\u7801 | \n| WS 446-2014  |  \u5c45\u6c11\u5065\u5eb7\u6863\u6848\u533b\u5b66\u68c0\u9a8c\u9879\u76ee\u5e38\u7528\u4ee3\u7801 | \n| WS xxx-2013  |  \u533b\u7597\u670d\u52a1\u9879\u76ee\u5206\u7c7b\u4e0e\u7f16\u7801 | \n\n\n### \u6570\u636e\u96c6\n\n| \u7f16\u53f7  | \u540d\u79f0 | \u6027\u8d28 |  \n| ----  | ---- |  ---- |      \n| WS 365-2011  | \u57ce\u4e61\u5c45\u6c11\u5065\u5eb7\u6863\u6848\u57fa\u672c\u6570\u636e\u96c6 | \n| WS 371-2012  | \u57fa\u672c\u4fe1\u606f\u57fa\u672c\u6570\u636e\u96c6 \u4e2a\u4eba\u4fe1\u606f | \n| WS 372-2012  | \u75be\u75c5\u7ba1\u7406\u57fa\u672c\u6570\u636e\u96c6  \u7b2c1-6\u90e8\u5206 | \n| WS 373-2012  | \u533b\u7597\u670d\u52a1\u57fa\u672c\u6570\u636e\u96c6 \u7b2c1-3\u90e8\u5206 | \n| WS 374-2012  | \u536b\u751f\u7ba1\u7406\u57fa\u672c\u6570\u636e\u96c6 \u7b2c1-4\u90e8\u5206 | \n| WS 375-2012  | \u75be\u75c5\u63a7\u5236\u57fa\u672c\u6570\u636e\u96c6 \u7b2c1-23\u90e8\u5206 | \n| WS 376-2013  | \u513f\u7ae5\u4fdd\u5065\u57fa\u672c\u6570\u636e\u96c6 \u7b2c1-5\u90e8\u5206 | \n| WS 377-2013  | \u5987\u5973\u4fdd\u5065\u57fa\u672c\u6570\u636e\u96c6 \u7b2c1-7\u90e8\u5206 | \n| WS xxx-2013  | \u536b\u751f\u5e94\u6025\u7ba1\u7406\u57fa\u672c\u6570\u636e\u96c6 \u7b2c1-5\u90e8\u5206 | \n| WS 538-2017  | \u533b\u5b66\u6570\u5b57\u5f71\u50cf\u901a\u4fe1\u57fa\u672c\u6570\u636e\u96c6 | \u5f3a\u5236\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6    \n| WS 539-2017  | \u8fdc\u7a0b\u533b\u7597\u4fe1\u606f\u57fa\u672c\u6570\u636e\u96c6 | \u5f3a\u5236\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6     \n| WS 540-2017  | \u7ee7\u7eed\u533b\u5b66\u6559\u80b2\u7ba1\u7406\u57fa\u672c\u6570\u636e\u96c6 | \u5f3a\u5236\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6     \n| WS 541-2017  | \u65b0\u578b\u519c\u6751\u5408\u4f5c\u533b\u7597\u57fa\u672c\u6570\u636e\u96c6 | \u5f3a\u5236\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6          \n| WS 542-2017  | \u9662\u524d\u533b\u7597\u6025\u6551\u57fa\u672c\u6570\u636e\u96c6 | \u5f3a\u5236\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6          \n| WS 537-2017  | \u5c45\u6c11\u5065\u5eb7\u5361\u6570\u636e\u96c6 | \u5f3a\u5236\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6       \n| WS xxx-2013  | \u5c45\u6c11\u5065\u5eb7\u5361\u6ce8\u518c\u7ba1\u7406\u4fe1\u606f\u7cfb\u7edf\u57fa\u672c\u6570\u636e\u96c6 | \n\n\n\n\n\n| \u6570\u636e\u96c6\u540d\u79f0\t| \u6240\u5c5e\u7c7b\u522b\t| \u6240\u5c5e\u6807\u51c6\u7f16\u53f7\t| \u6240\u5c5e\u6807\u51c6\u540d\u79f0   |   \n| ----  | ---- |  ---- |  ---- |       \n| \u4e2a\u4eba\u57fa\u672c\u4fe1\u606f\t| \u57fa\u672c\u4fe1\u606f\t| WS365\t| \u57ce\u4e61\u5c45\u6c11\u5065\u5eb7\u6863\u6848\u57fa\u672c\u6570\u636e\u96c6      | \n| \u5065\u5eb7\u4f53\u68c0\u4fe1\u606f\t| \u5065\u5eb7\u4f53\u68c0\t| WS365\t| \u57ce\u4e61\u5c45\u6c11\u5065\u5eb7\u6863\u6848\u57fa\u672c\u6570\u636e\u96c6      | \n| \u65b0\u751f\u513f\u5bb6\u5ead\u8bbf\u89c6\u4fe1\u606f\t| \u513f\u7ae5\u4fdd\u5065\t| WS365\t| \u57ce\u4e61\u5c45\u6c11\u5065\u5eb7\u6863\u6848\u57fa\u672c\u6570\u636e\u96c6         | \n| \u513f\u7ae5\u5065\u5eb7\u68c0\u67e5\u4fe1\u606f\t| \u513f\u7ae5\u4fdd\u5065\t| WS365\t| \u57ce\u4e61\u5c45\u6c11\u5065\u5eb7\u6863\u6848\u57fa\u672c\u6570\u636e\u96c6       | \n| \u4ea7\u524d\u968f\u8bbf\u670d\u52a1\u4fe1\u606f\t| \u5987\u5973\u4fdd\u5065\t| WS365\t| \u57ce\u4e61\u5c45\u6c11\u5065\u5eb7\u6863\u6848\u57fa\u672c\u6570\u636e\u96c6     | \n| \u4ea7\u540e\u8bbf\u89c6\u670d\u52a1\u4fe1\u606f\t| \u5987\u5973\u4fdd\u5065\t| WS365\t| \u57ce\u4e61\u5c45\u6c11\u5065\u5eb7\u6863\u6848\u57fa\u672c\u6570\u636e\u96c6      | \n| \u4ea7\u540e42\u5929\u5065\u5eb7\u4f53\u68c0\u4fe1\u606f\t| \u5987\u5973\u4fdd\u5065\t| WS365\t| \u57ce\u4e61\u5c45\u6c11\u5065\u5eb7\u6863\u6848\u57fa\u672c\u6570\u636e\u96c6|       \n| \u9884\u9632\u63a5\u79cd\u5361\u4fe1\u606f\t| \u75be\u75c5\u63a7\u5236\t| WS365\t| \u57ce\u4e61\u5c45\u6c11\u5065\u5eb7\u6863\u6848\u57fa\u672c\u6570\u636e\u96c6  |     \n| \u4f20\u67d3\u75c5\u62a5\u544a\u5361\u4fe1\u606f\t| \u75be\u75c5\u63a7\u5236\t| WS365\t| \u57ce\u4e61\u5c45\u6c11\u5065\u5eb7\u6863\u6848\u57fa\u672c\u6570\u636e\u96c6| \n| \u804c\u4e1a\u75c5\u62a5\u544a\u5361\u4fe1\u606f\t| \u75be\u75c5\u63a7\u5236\t| WS365| \u57ce\u4e61\u5c45\u6c11\u5065\u5eb7\u6863\u6848\u57fa\u672c\u6570\u636e\u96c6       |  \n| \u98df\u6e90\u6027\u75be\u75c5\u62a5\u544a\u5361\u4fe1\u606f\t| \u75be\u75c5\u63a7\u5236\t| WS365\t| \u57ce\u4e61\u5c45\u6c11\u5065\u5eb7\u6863\u6848\u57fa\u672c\u6570\u636e\u96c6 |       \n| \u9ad8\u8840\u538b\u60a3\u8005\u968f\u8bbf\u4fe1\u606f\t| \u75be\u75c5\u7ba1\u7406\t| WS365\t| \u57ce\u4e61\u5c45\u6c11\u5065\u5eb7\u6863\u6848\u57fa\u672c\u6570\u636e\u96c6 |      \n| 2\u578b\u7cd6\u5c3f\u75c5\u60a3\u8005\u968f\u8bbf\u4fe1\u606f\t| \u75be\u75c5\u7ba1\u7406\t| WS365\t| \u57ce\u4e61\u5c45\u6c11\u5065\u5eb7\u6863\u6848\u57fa\u672c\u6570\u636e\u96c6  |      \n| \u91cd\u6027\u7cbe\u795e\u75be\u75c5\u60a3\u8005\u7ba1\u7406\u4fe1\u606f\t| \u75be\u75c5\u7ba1\u7406\t| WS365\t| \u57ce\u4e61\u5c45\u6c11\u5065\u5eb7\u6863\u6848\u57fa\u672c\u6570\u636e\u96c6   |        \n| \u95e8\u8bca\u6458\u8981\u4fe1\u606f\t| \u533b\u7597\u670d\u52a1\t| WS365\t| \u57ce\u4e61\u5c45\u6c11\u5065\u5eb7\u6863\u6848\u57fa\u672c\u6570\u636e\u96c6   |    \n| \u4f4f\u9662\u6458\u8981\u4fe1\u606f\t| \u533b\u7597\u670d\u52a1\t| WS365\t| \u57ce\u4e61\u5c45\u6c11\u5065\u5eb7\u6863\u6848\u57fa\u672c\u6570\u636e\u96c6  |    \n| \u4f1a\u8bca\u4fe1\u606f\t| \u533b\u7597\u670d\u52a1\t| WS365\t| \u57ce\u4e61\u5c45\u6c11\u5065\u5eb7\u6863\u6848\u57fa\u672c\u6570\u636e\u96c6      | \n| \u8f6c\u9662(\u8bca)\u4fe1\u606f\t| \u533b\u7597\u670d\u52a1\t| WS365\t| \u57ce\u4e61\u5c45\u6c11\u5065\u5eb7\u6863\u6848\u57fa\u672c\u6570\u636e\u96c6  | \n\n\u5f3a\u5236\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6         \n         \n\n\n| \u6807\u51c6\u7f16\u53f7 |   \u6807\u51c6\u4e2d\u6587\u540d\u79f0 | \u6570\u636e\u5143\u6570\u76ee | \u6027\u8d28 |  \n| ----  | ---- |  ---- | ---- |  \n| WS 371-2012 \t\t| \u57fa\u672c\u4fe1\u606f\u57fa\u672c\u6570\u636e\u96c6 \u4e2a\u4eba\u4fe1\u606f\t\t| 68\n| WS 376.1-2013\t\t| \u513f\u7ae5\u4fdd\u5065\u57fa\u672c\u6570\u636e\u96c6 \u7b2c1\u90e8\u5206 \u51fa\u751f\u533b\u5b66\u8bc1\u660e\t\t| 39\n| WS 376.2-2013\t\t| \u513f\u7ae5\u4fdd\u5065\u57fa\u672c\u6570\u636e\u96c6 \u7b2c2\u90e8\u5206\uff1a\u513f\u7ae5\u5065\u5eb7\u4f53\u68c0\t\t| 61\n| WS 376.3-2013\t\t| \u513f\u7ae5\u4fdd\u5065\u57fa\u672c\u6570\u636e\u96c6 \u7b2c3\u90e8\u5206\uff1a\u65b0\u751f\u513f\u75be\u75c5\u7b5b\u67e5\t\t| 41\n| WS 376.4-2013\t\t| \u513f\u7ae5\u4fdd\u5065\u57fa\u672c\u6570\u636e\u96c6 \u7b2c4\u90e8\u5206\uff1a\u4f53\u5f31\u513f\u7ae5\u7ba1\u7406\t\t| 33\n| WS 376.5-2013\t\t| \u513f\u7ae5\u4fdd\u5065\u57fa\u672c\u6570\u636e\u96c6 \u7b2c5\u90e8\u5206\uff1a5\u5c81\u4ee5\u4e0b\u513f\u7ae5\u6b7b\u4ea1\u62a5\u544a\t\t| 27\n| WS 377.1-2013\t\t| \u5987\u5973\u4fdd\u5065\u57fa\u672c\u6570\u636e\u96c6 \u7b2c1\u90e8\u5206\uff1a\u5a5a\u524d\u4fdd\u5065\u670d\u52a1\t\t| 122\n| WS 377.2-2013\t\t| \u5987\u5973\u4fdd\u5065\u57fa\u672c\u6570\u636e\u96c6 \u7b2c2\u90e8\u5206 \u5987\u5973\u75c5\u666e\u67e5\t\t| 74\n| WS 377.3-2013\t\t| \u5987\u5973\u4fdd\u5065\u57fa\u672c\u6570\u636e\u96c6 \u7b2c3\u90e8\u5206\u8ba1\u5212\u751f\u80b2\u6280\u672f\u670d\u52a1\t\t| 131\n| WS 377.4-2013\t\t| \u5987\u5973\u4fdd\u5065\u57fa\u672c\u6570\u636e\u96c6 \u7b2c4\u90e8\u5206\u5b55\u4ea7\u671f\u4fdd\u5065\u670d\u52a1\u4e0e\u9ad8\u5371\u7ba1\u7406\t\t| 244\n| WS 377.5-2013\t\t| \u5987\u5973\u4fdd\u5065\u57fa\u672c\u6570\u636e\u96c6 \u7b2c5\u90e8\u5206\u4ea7\u524d\u7b5b\u67e5\u4e0e\u8bca\u65ad\t\t| 31\n| WS 377.6-2013\t\t| \u5987\u5973\u4fdd\u5065\u57fa\u672c\u6570\u636e\u96c6 \u7b2c6\u90e8\u5206\u51fa\u751f\u7f3a\u9677\u76d1\u6d4b\t\t| 48\n| WS 377.7-2013\t\t| \u5987\u5973\u4fdd\u5065\u57fa\u672c\u6570\u636e\u96c6 \u7b2c7\u90e8\u5206\u5b55\u4ea7\u5987\u6b7b\u4ea1\u62a5\u544a\t\t| 39\n| WS 375.1-2012 \t| \u75be\u75c5\u63a7\u5236\u57fa\u672c\u6570\u636e\u96c6 \u7b2c1\u90e8\u5206\uff1a\u827e\u6ecb\u75c5\u7efc\u5408\u9632\u6cbb\t\t| 71\n| WS 375.2-2012 \t| \u75be\u75c5\u63a7\u5236\u57fa\u672c\u6570\u636e\u96c6 \u7b2c2\u90e8\u5206\uff1a\u8840\u5438\u866b\u75c5\u75c5\u4eba\u7ba1\u7406\t\t| 115\n| WS 375.3-2012\t\t|  \u75be\u75c5\u63a7\u5236\u57fa\u672c\u6570\u636e\u96c6 \u7b2c3\u90e8\u5206\uff1a\u6162\u6027\u4e1d\u866b\u75c5\u75c5\u4eba\u7ba1\u7406\t\t| 73\n| WS 375.4-2012\t \t| \u75be\u75c5\u63a7\u5236\u57fa\u672c\u6570\u636e\u96c6 \u7b2c4\u90e8\u5206\uff1a\u804c\u4e1a\u75c5\u62a5\u544a\t\t| 63\n| WS 375.5-2012\t    | \u75be\u75c5\u63a7\u5236\u57fa\u672c\u6570\u636e\u96c6 \u7b2c5\u90e8\u5206\uff1a\u804c\u4e1a\u6027\u5065\u5eb7\u76d1\u62a4\t\t| 261\n| WS 375.6-2012 \t| \u75be\u75c5\u63a7\u5236\u57fa\u672c\u6570\u636e\u96c6 \u7b2c6\u90e8\u5206\uff1a\u4f24\u5bb3\u76d1\u6d4b\u62a5\u544a\t\t| 41\n| WS 375.7-2012 \t| \u75be\u75c5\u63a7\u5236\u57fa\u672c\u6570\u636e\u96c6 \u7b2c7\u90e8\u5206\uff1a\u519c\u836f\u4e2d\u6bd2\u62a5\u544a\t\t| 33\n| WS 375.8-2012 \t| \u75be\u75c5\u63a7\u5236\u57fa\u672c\u6570\u636e\u96c6 \u7b2c8\u90e8\u5206\uff1a\u884c\u4e3a\u5371\u9669\u56e0\u7d20\u76d1\u6d4b\t\t| 56\n| WS 375.9-2012 \t| \u75be\u75c5\u63a7\u5236\u57fa\u672c\u6570\u636e\u96c6 \u7b2c9\u90e8\u5206\uff1a\u6b7b\u4ea1\u533b\u5b66\u8bc1\u660e\t\t| 49\n| WS 375.10-2012 \t| \u75be\u75c5\u63a7\u5236\u57fa\u672c\u6570\u636e\u96c6 \u7b2c10\u90e8\u5206\uff1a\u4f20\u67d3\u75c5\u62a5\u544a\t\t| 33\n| WS 375.11-2012 \t| \u75be\u75c5\u63a7\u5236\u57fa\u672c\u6570\u636e\u96c6 \u7b2c11\u90e8\u5206\uff1a\u7ed3\u6838\u75c5\u62a5\u544a\t\t| 78\n| WS 375.12-2012 \t| \u75be\u75c5\u63a7\u5236\u57fa\u672c\u6570\u636e\u96c6 \u7b2c12\u90e8\u5206\uff1a\u9884\u9632\u63a5\u79cd\t\t| 42    \n| WS 375.13-2017 \t| \u75be\u75c5\u63a7\u5236\u57fa\u672c\u6570\u636e\u96c6 \u7b2c13\u90e8\u5206\uff1a\u804c\u4e1a\u75c5\u5371\u5bb3\u56e0\u7d20\u76d1\u6d4b |          \n| WS 375.14-2016 \t| \u75be\u75c5\u63a7\u5236\u57fa\u672c\u6570\u636e\u96c6 \u7b2c14\u90e8\u5206\uff1a\u5b66\u6821\u7f3a\u52e4\u7f3a\u8bfe\u76d1\u6d4b\u62a5\u544a |          \n| WS 375.15-2016 \t| \u75be\u75c5\u63a7\u5236\u57fa\u672c\u6570\u636e\u96c6 \u7b2c15\u90e8\u5206\uff1a\u6258\u5e7c\u673a\u6784\u7f3a\u52e4\u76d1\u6d4b\u62a5\u544a |          \n| WS 375.18-2016 \t| \u75be\u75c5\u63a7\u5236\u57fa\u672c\u6570\u636e\u96c6 \u7b2c18\u90e8\u5206\uff1a\u7591\u4f3c\u9884\u9632\u63a5\u79cd\u5f02\u5e38\u53cd\u5e94\u62a5\u544a |          \n| WS 375.19-2016 \t| \u75be\u75c5\u63a7\u5236\u57fa\u672c\u6570\u636e\u96c6 \u7b2c19\u90e8\u5206\uff1a\u75ab\u82d7\u7ba1\u7406 |        \n| WS 375.20-2016 \t| \u75be\u75c5\u63a7\u5236\u57fa\u672c\u6570\u636e\u96c6 \u7b2c20\u90e8\u5206\uff1a\u8111\u5352\u4e2d\u767b\u8bb0\u62a5\u544a |    \n| WS 375.21-2016 \t| \u75be\u75c5\u63a7\u5236\u57fa\u672c\u6570\u636e\u96c6 \u7b2c21\u90e8\u5206\uff1a\u8111\u5352\u4e2d\u75c5\u4eba\u7ba1\u7406 |    \n| WS 375.22-2016 \t| \u75be\u75c5\u63a7\u5236\u57fa\u672c\u6570\u636e\u96c6 \u7b2c22\u90e8\u5206\uff1a\u5bab\u9888\u764c\u7b5b\u67e5\u767b\u8bb0 |    \n| WS 375.23-2016 \t| \u75be\u75c5\u63a7\u5236\u57fa\u672c\u6570\u636e\u96c6 \u7b2c23\u90e8\u5206\uff1a\u5927\u80a0\u764c\u7b5b\u67e5\u767b\u8bb0 |    \n| WS 372.1-2012 \t| \u75be\u75c5\u7ba1\u7406\u57fa\u672c\u6570\u636e\u96c6 \u7b2c1\u90e8\u5206\uff1a\u4e59\u809d\u60a3\u8005\u7ba1\u7406\t\t| 106\n| WS 372.2-2012\t\t| \u75be\u75c5\u7ba1\u7406\u57fa\u672c\u6570\u636e\u96c6 \u7b2c2\u90e8\u5206\uff1a\u9ad8\u8840\u538b\u60a3\u8005\u5065\u5eb7\u7ba1\u7406\t| 106\n| WS 372.3-2012 \t| \u75be\u75c5\u7ba1\u7406\u57fa\u672c\u6570\u636e\u96c6 \u7b2c3\u90e8\u5206\uff1a\u91cd\u6027\u7cbe\u795e\u75be\u75c5\u60a3\u8005\u7ba1\u7406\t\t| 118\n| WS 372.4-2012 \t| \u75be\u75c5\u7ba1\u7406\u57fa\u672c\u6570\u636e\u96c6 \u7b2c4\u90e8\u5206\uff1a\u8001\u5e74\u4eba\u5065\u5eb7\u7ba1\u7406\t\t| 102\n| WS 372.5-2012 \t| \u75be\u75c5\u7ba1\u7406\u57fa\u672c\u6570\u636e\u96c6 \u7b2c5\u90e8\u5206\uff1a2\u578b\u7cd6\u5c3f\u75c5\u60a3\u8005\u5065\u5eb7\u7ba1\u7406\t\t| 113\n| WS 372.6-2012 \t| \u75be\u75c5\u7ba1\u7406\u57fa\u672c\u6570\u636e\u96c6 \u7b2c6\u90e8\u5206\uff1a\u80bf\u7624\u75c5\u4f8b\u7ba1\u7406\t\t| 72\n| WS 373.1-2012 \t| \u533b\u7597\u670d\u52a1\u57fa\u672c\u6570\u636e\u96c6 \u7b2c1\u90e8\u5206\uff1a\u95e8\u8bca\u6458\u8981\t\t| 62\n| WS 373.2-2012 \t| \u533b\u7597\u670d\u52a1\u57fa\u672c\u6570\u636e\u96c6 \u7b2c2\u90e8\u5206\uff1a\u4f4f\u9662\u6458\u8981\t\t| 72\n| WS 373.3-2012\t   | \u533b\u7597\u670d\u52a1\u57fa\u672c\u6570\u636e\u96c6 \u7b2c3\u90e8\u5206\uff1a\u6210\u4eba\u5065\u5eb7\u4f53\u68c0\t\t| 182\n| WS 374.1-2012 \t\t| \u536b\u751f\u7ba1\u7406\u57fa\u672c\u6570\u636e\u96c6 \u7b2c1\u90e8\u5206\uff1a\u536b\u751f\u76d1\u7763\u68c0\u67e5\u4e0e\u884c\u653f\u5904\u7f5a\t\t| 62\n| WS 374.2-2012 \t\t| \u536b\u751f\u7ba1\u7406\u57fa\u672c\u6570\u636e\u96c6 \u7b2c2\u90e8\u5206\uff1a\u536b\u751f\u76d1\u7763\u884c\u653f\u8bb8\u53ef\u4e0e\u767b\u8bb0\t\t|92\n| WS 374.3-2012 \t\t| \u536b\u751f\u7ba1\u7406\u57fa\u672c\u6570\u636e\u96c6 \u7b2c3\u90e8\u5206\uff1a\u536b\u751f\u76d1\u7763\u76d1\u6d4b\u4e0e\u8bc4\u4ef7\t\t|22\n| WS 374.4-2012 \t\t| \u536b\u751f\u7ba1\u7406\u57fa\u672c\u6570\u636e\u96c6 \u7b2c4\u90e8\u5206\uff1a\u536b\u751f\u76d1\u7763\u673a\u6784\u4e0e\u4eba\u5458\t\t|105\n\n\n\n\n| \u6807\u51c6\u7f16\u53f7 |   \u6807\u51c6\u4e2d\u6587\u540d\u79f0 | \u6570\u636e\u5143\u6570\u76ee | \u6027\u8d28 | \n| ----  | ---- |  ---- | ---- |     \n| WS 445.1-2014 \t\t| \u7535\u5b50\u75c5\u5386\u57fa\u672c\u6570\u636e\u96c6 \u7b2c1\u90e8\u5206\uff1a\u75c5\u5386\u6982\u8981  \t\t|  xx               \n| WS 445.2-2014 \t\t| \u7535\u5b50\u75c5\u5386\u57fa\u672c\u6570\u636e\u96c6 \u7b2c2\u90e8\u5206\uff1a\u95e8\uff08\u6025\uff09\u8bca\u75c5\u5386  \t\t|  xx               \n| WS 445.3-2014 \t\t| \u7535\u5b50\u75c5\u5386\u57fa\u672c\u6570\u636e\u96c6 \u7b2c3\u90e8\u5206\uff1a\u95e8\uff08\u6025\uff09\u8bca\u5904\u65b9  \t\t|  xx               \n| WS 445.4-2014 \t\t| \u7535\u5b50\u75c5\u5386\u57fa\u672c\u6570\u636e\u96c6 \u7b2c4\u90e8\u5206\uff1a\u68c0\u67e5\u68c0\u9a8c\u8bb0\u5f55  \t\t|  xx               \n| WS 445.5-2014 \t\t| \u7535\u5b50\u75c5\u5386\u57fa\u672c\u6570\u636e\u96c6 \u7b2c5\u90e8\u5206\uff1a\u4e00\u822c\u6cbb\u7597\u5904\u7f6e\u8bb0\u5f55  \t\t|  xx               \n| WS 445.6-2014 \t\t| \u7535\u5b50\u75c5\u5386\u57fa\u672c\u6570\u636e\u96c6 \u7b2c6\u90e8\u5206\uff1a\u52a9\u4ea7\u8bb0\u5f55  \t\t|  xx               \n| WS 445.7-2014 \t\t| \u7535\u5b50\u75c5\u5386\u57fa\u672c\u6570\u636e\u96c6 \u7b2c7\u90e8\u5206\uff1a\u62a4\u7406\u64cd\u4f5c\u8bb0\u5f55  \t\t|  xx               \n| WS 445.8-2014 \t\t| \u7535\u5b50\u75c5\u5386\u57fa\u672c\u6570\u636e\u96c6 \u7b2c8\u90e8\u5206\uff1a\u62a4\u7406\u8bc4\u4f30\u4e0e\u8ba1\u5212  \t\t|  xx               \n| WS 445.9-2014 \t\t| \u7535\u5b50\u75c5\u5386\u57fa\u672c\u6570\u636e\u96c6 \u7b2c9\u90e8\u5206\uff1a\u77e5\u60c5\u544a\u77e5\u4fe1\u606f  \t\t|  xx               \n| WS 445.10-2014 \t\t| \u7535\u5b50\u75c5\u5386\u57fa\u672c\u6570\u636e\u96c6 \u7b2c10\u90e8\u5206\uff1a\u4f4f\u9662\u75c5\u6848\u9996\u9875  \t\t|  xx               \n| WS 445.11-2014 \t\t| \u7535\u5b50\u75c5\u5386\u57fa\u672c\u6570\u636e\u96c6 \u7b2c11\u90e8\u5206\uff1a\u4e2d\u533b\u4f4f\u9662\u75c5\u6848\u9996\u9875  \t\t|  xx               \n| WS 445.12-2014 \t\t| \u7535\u5b50\u75c5\u5386\u57fa\u672c\u6570\u636e\u96c6 \u7b2c12\u90e8\u5206\uff1a\u5165\u9662\u8bb0\u5f55  \t\t|  xx               \n| WS 445.13-2014 \t\t| \u7535\u5b50\u75c5\u5386\u57fa\u672c\u6570\u636e\u96c6 \u7b2c13\u90e8\u5206\uff1a\u4f4f\u9662\u75c5\u7a0b\u8bb0\u5f55  \t\t|  xx               \n| WS 445.14-2014 \t\t| \u7535\u5b50\u75c5\u5386\u57fa\u672c\u6570\u636e\u96c6 \u7b2c14\u90e8\u5206\uff1a\u4f4f\u9662\u533b\u5631  \t\t|  xx               \n| WS 445.15-2014 \t\t| \u7535\u5b50\u75c5\u5386\u57fa\u672c\u6570\u636e\u96c6 \u7b2c15\u90e8\u5206\uff1a\u51fa\u9662\u5c0f\u7ed3  \t\t|  xx               \n| WS 445.16-2014 \t\t| \u7535\u5b50\u75c5\u5386\u57fa\u672c\u6570\u636e\u96c6 \u7b2c16\u90e8\u5206\uff1a\u8f6c\u8bca(\u9662)\u8bb0\u5f55  \t\t|  xx               \n| WS 445.17-2014 \t\t| \u7535\u5b50\u75c5\u5386\u57fa\u672c\u6570\u636e\u96c6 \u7b2c17\u90e8\u5206\uff1a\u533b\u7597\u673a\u6784\u4fe1\u606f  \t\t|  xx               \n\n\n### \u5171\u4eab\u6587\u6863\n\n## \u6280\u672f\u7c7b\n\n### \u529f\u80fd\u89c4\u8303\n\n| \u7f16\u53f7  | \u540d\u79f0 | \n| ----  | ---- | \n| WS/T 452-2014  | \u536b\u751f\u76d1\u7763\u4fe1\u606f\u7cfb\u7edf\u529f\u80fd\u89c4\u8303 | \n| WS/T xxx-2013  | \u5987\u5e7c\u4fdd\u5065\u4fe1\u606f\u7cfb\u7edf\u57fa\u672c\u529f\u80fd\u89c4\u8303 | \n| WS/T xxx-2013  | \u57fa\u5c42\u533b\u7597\u536b\u751f\u4fe1\u606f\u7cfb\u7edf\u529f\u80fd\u89c4\u8303 | \n| WS/T 451-2014  | \u9662\u524d\u533b\u7597\u6025\u6551\u6307\u6325\u4fe1\u606f\u7cfb\u7edf\u57fa\u672c\u529f\u80fd\u89c4\u8303 | \n| WS/T 450-2014  | \u65b0\u578b\u519c\u6751\u5408\u4f5c\u533b\u7597\u4fe1\u606f\u7cfb\u7edf\u57fa\u672c\u529f\u80fd\u89c4\u8303 | \n| WS/T 449-2014  | \u6162\u6027\u75c5\u76d1\u6d4b\u4fe1\u606f\u7cfb\u7edf\u57fa\u672c\u529f\u80fd\u89c4\u8303 | \n| WS/T 529-2016  | \u8fdc\u7a0b\u533b\u7597\u4fe1\u606f\u7cfb\u7edf\u57fa\u672c\u529f\u80fd\u89c4\u8303 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |\n| WS/T xxx-2013  | \u514d\u75ab\u89c4\u5212\u4fe1\u606f\u7cfb\u7edf\u57fa\u672c\u529f\u80fd\u89c4\u8303(\u5f81\u6c42\u610f\u89c1\u7a3f) | \n| WS/T 547-2017  | \u533b\u9662\u611f\u67d3\u7ba1\u7406\u4fe1\u606f\u7cfb\u7edf\u57fa\u672c\u529f\u80fd\u89c4\u8303 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |\n\n\n\n\n\n### \u6280\u672f\u89c4\u8303\n\n| \u7f16\u53f7  | \u540d\u79f0 |  \u6027\u8d28 | \n| ----  | ---- |   ---- |    \n| WS/T 448-2014  | \u57fa\u4e8e\u5065\u5eb7\u6863\u6848\u7684\u533a\u57df\u536b\u751f\u4fe1\u606f\u5e73\u53f0\u6280\u672f\u89c4\u8303 | \n| WS/T 447-2014  | \u57fa\u4e8e\u7535\u5b50\u75c5\u5386\u7684\u533b\u9662\u4fe1\u606f\u5e73\u53f0\u6280\u672f\u89c4\u8303 | \n| WS/T 545-2017  | \u8fdc\u7a0b\u533b\u7597\u4fe1\u606f\u7cfb\u7edf\u6280\u672f\u89c4\u8303 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |\n| WS/T 546-2017  | \u8fdc\u7a0b\u533b\u7597\u4fe1\u606f\u7cfb\u7edf\u4e0e\u7edf\u4e00\u901a\u4fe1\u5e73\u53f0\u4ea4\u4e92\u89c4\u8303 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |\n| WS/T 526-2016  | \u5987\u5e7c\u4fdd\u5065\u670d\u52a1\u4fe1\u606f\u7cfb\u7edf\u6280\u672f\u89c4\u8303 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |\n| WS/T 544-2017  | \u533b\u5b66\u6570\u5b57\u5f71\u50cf\u4e2d\u6587\u5c01\u88c5\u4e0e\u901a\u4fe1\u89c4\u8303 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |    \n| WS/T 548-2017  | \u533b\u5b66\u6570\u5b57\u5f71\u50cf\u901a\u4fe1\uff08DICOM\uff09\u4e2d\u6587\u6807\u51c6\u7b26\u5408\u6027\u6d4b\u8bd5\u89c4\u8303 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |    \n| WS/T xxx-2013  | \u533a\u57df\u75be\u75c5\u63a7\u5236\u4e1a\u52a1\u5e94\u7528\u5b50\u5e73\u53f0\u6280\u672f\u89c4\u8303 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |\n| WS/T 517-2016  | \u57fa\u5c42\u533b\u7597\u536b\u751f\u4fe1\u606f\u7cfb\u7edf\u6280\u672f\u89c4\u8303 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |\n| WS/T xxx-2013  | \u8fdc\u7a0b\u533b\u7597\u8bbe\u5907\u53ca\u7edf\u4e00\u901a\u8baf\u4ea4\u4e92\u89c4\u8303(\u5f81\u6c42\u610f\u89c1\u7a3f) |  |\n| WS/T xxx-2013  | \u533a\u57df\u536b\u751f\u4fe1\u606f\u5e73\u53f0\u4ea4\u4e92\u89c4\u8303(\u5f81\u6c42\u610f\u89c1\u7a3f) |  |\n| WS/T xxx-2013  | \u533b\u9662\u4fe1\u606f\u5e73\u53f0\u4ea4\u4e92\u89c4\u8303(\u5f81\u6c42\u610f\u89c1\u7a3f) |  |          \n| WS/T 543.1-2017  | \u5c45\u6c11\u5065\u5eb7\u5361\u6280\u672f\u89c4\u8303 \u7b2c1\u90e8\u5206\uff1a\u603b\u5219 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 543.2-2017  | \u5c45\u6c11\u5065\u5eb7\u5361\u6280\u672f\u89c4\u8303 \u7b2c2\u90e8\u5206\uff1a\u7528\u6237\u5361\u6280\u672f\u89c4\u8303 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 543.3-2017  | \u5c45\u6c11\u5065\u5eb7\u5361\u6280\u672f\u89c4\u8303 \u7b2c3\u90e8\u5206\uff1a\u7528\u6237\u5361\u5e94\u7528\u89c4\u8303 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 543.4-2017  | \u5c45\u6c11\u5065\u5eb7\u5361\u6280\u672f\u89c4\u8303 \u7b2c4\u90e8\u5206\uff1a\u7528\u6237\u5361\u547d\u4ee4\u96c6 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 543.5-2017  | \u5c45\u6c11\u5065\u5eb7\u5361\u6280\u672f\u89c4\u8303 \u7b2c5\u90e8\u5206\uff1a\u7ec8\u7aef\u6280\u672f\u89c4\u8303 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 543.6-2017  | \u5c45\u6c11\u5065\u5eb7\u5361\u6280\u672f\u89c4\u8303 \u7b2c6\u90e8\u5206\uff1a\u7528\u6237\u5361\u53ca\u7ec8\u7aef\u4ea7\u54c1\u68c0\u6d4b\u89c4\u8303 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n\n\n\n\n\n\n### \u5b89\u5168\u4e0e\u9690\u79c1\n\n### \u4f20\u8f93\u4e0e\u4ea4\u6362\n\n| \u7f16\u53f7  | \u540d\u79f0 |  \u6027\u8d28 | \n| ----  | ---- |  ---- | \n| WS/T 483.1-2016  | \u5065\u5eb7\u6863\u6848\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c1\u90e8\u5206\uff1a\u4e2a\u4eba\u57fa\u672c\u5065\u5eb7\u4fe1\u606f\u767b\u8bb0 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 483.2-2016  | \u5065\u5eb7\u6863\u6848\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c2\u90e8\u5206\uff1a\u51fa\u751f\u533b\u5b66\u8bc1\u660e | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 483.3-2016  | \u5065\u5eb7\u6863\u6848\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c3\u90e8\u5206\uff1a\u65b0\u751f\u513f\u5bb6\u5ead\u8bbf\u89c6 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 483.4-2016  | \u5065\u5eb7\u6863\u6848\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c4\u90e8\u5206\uff1a\u513f\u7ae5\u5065\u5eb7\u4f53\u68c0 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 483.5-2016  | \u5065\u5eb7\u6863\u6848\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c5\u90e8\u5206\uff1a\u9996\u6b21\u4ea7\u524d\u968f\u8bbf\u670d\u52a1 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 483.6-2016  | \u5065\u5eb7\u6863\u6848\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c6\u90e8\u5206\uff1a\u4ea7\u524d\u968f\u8bbf\u670d\u52a1 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 483.7-2016  | \u5065\u5eb7\u6863\u6848\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c7\u90e8\u5206\uff1a\u4ea7\u540e\u8bbf\u89c6 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 483.8-2016  | \u5065\u5eb7\u6863\u6848\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c8\u90e8\u5206\uff1a\u4ea7\u540e42\u5929\u5065\u5eb7\u68c0\u67e5 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 483.9-2016  | \u5065\u5eb7\u6863\u6848\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c9\u90e8\u5206\uff1a\u9884\u9632\u63a5\u79cd\u62a5\u544a | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |  \n| WS/T 483.10-2016  | \u5065\u5eb7\u6863\u6848\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c10\u90e8\u5206\uff1a\u4f20\u67d3\u75c5\u62a5\u544a | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 483.11-2016  | \u5065\u5eb7\u6863\u6848\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c11\u90e8\u5206\uff1a\u6b7b\u4ea1\u533b\u5b66\u8bc1\u660e | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 483.12-2016  | \u5065\u5eb7\u6863\u6848\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c12\u90e8\u5206\uff1a\u9ad8\u8840\u538b\u60a3\u8005\u968f\u8bbf\u670d\u52a1 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 483.13-2016  | \u5065\u5eb7\u6863\u6848\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c13\u90e8\u5206\uff1a2\u578b\u7cd6\u5c3f\u75c5\u60a3\u8005\u968f\u8bbf\u670d\u52a1 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 483.14-2016  | \u5065\u5eb7\u6863\u6848\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c14\u90e8\u5206\uff1a\u91cd\u6027\u7cbe\u795e\u75be\u75c5\u60a3\u8005\u4e2a\u4eba\u4fe1\u606f\u767b\u8bb0 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 483.15-2016  | \u5065\u5eb7\u6863\u6848\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c15\u90e8\u5206\uff1a\u91cd\u6027\u7cbe\u795e\u75be\u75c5\u60a3\u8005\u968f\u8bbf\u670d\u52a1 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 483.16-2016  | \u5065\u5eb7\u6863\u6848\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c16\u90e8\u5206\uff1a\u6210\u4eba\u5065\u5eb7\u4f53\u68c0 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 483.17-2016  | \u5065\u5eb7\u6863\u6848\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c17\u90e8\u5206\uff1a\u95e8\u8bca\u6458\u8981 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 483.18-2016  | \u5065\u5eb7\u6863\u6848\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c18\u90e8\u5206\uff1a\u4f4f\u9662\u6458\u8981 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 483.19-2016  | \u5065\u5eb7\u6863\u6848\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c19\u90e8\u5206\uff1a\u4f1a\u8bca\u8bb0\u5f55 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 483.20-2016  | \u5065\u5eb7\u6863\u6848\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c20\u90e8\u5206\uff1a\u8f6c\u8bca(\u9662)\u8bb0\u5f55 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n\n| \u7f16\u53f7  | \u540d\u79f0 |  \u6027\u8d28 | \n| ----  | ---- |  ---- | \n| WS/T 500.1-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c1\u90e8\u5206\uff1a\u75c5\u5386\u6982\u8981 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.2-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c2\u90e8\u5206\uff1a\u95e8(\u6025)\u8bca\u75c5\u5386 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.3-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c3\u90e8\u5206\uff1a\u6025\u8bca\u7559\u89c2\u75c5\u5386 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.4-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c4\u90e8\u5206\uff1a\u897f\u836f\u5904\u65b9 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.5-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c5\u90e8\u5206\uff1a\u4e2d\u836f\u5904\u65b9 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.6-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c6\u90e8\u5206\uff1a\u68c0\u67e5\u62a5\u544a | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.7-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c7\u90e8\u5206\uff1a\u68c0\u9a8c\u62a5\u544a | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.8-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c8\u90e8\u5206\uff1a\u6cbb\u7597\u8bb0\u5f55 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.9-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c9\u90e8\u5206\uff1a\u4e00\u822c\u624b\u672f\u8bb0\u5f55 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.10-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c10\u90e8\u5206\uff1a\u9ebb\u9189\u672f\u524d\u8bbf\u89c6\u8bb0\u5f55 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.11-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c11\u90e8\u5206\uff1a\u9ebb\u9189\u8bb0\u5f55 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.12-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c12\u90e8\u5206\uff1a\u9ebb\u9189\u672f\u540e\u8bbf\u89c6\u8bb0\u5f55 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.13-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c13\u90e8\u5206\uff1a\u8f93\u8840\u8bb0\u5f55 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.14-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c14\u90e8\u5206\uff1a\u5f85\u4ea7\u8bb0\u5f55 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.15-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c15\u90e8\u5206\uff1a\u9634\u9053\u5206\u5a29\u8bb0\u5f55 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.16-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c16\u90e8\u5206\uff1a\u5256\u5bab\u4ea7\u8bb0\u5f55 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.17-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c17\u90e8\u5206\uff1a\u4e00\u822c\u62a4\u7406\u8bb0\u5f55 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.18-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c18\u90e8\u5206\uff1a\u75c5\u91cd\uff08\u75c5\u5371\uff09\u62a4\u7406\u8bb0\u5f55 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.19-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c19\u90e8\u5206\uff1a\u624b\u672f\u62a4\u7406\u8bb0\u5f55 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.20-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c20\u90e8\u5206\uff1a\u751f\u547d\u4f53\u5f81\u6d4b\u91cf\u8bb0\u5f55 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.21-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c21\u90e8\u5206\uff1a\u51fa\u5165\u91cf\u8bb0\u5f55 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.22-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c22\u90e8\u5206\uff1a\u9ad8\u503c\u8017\u6750\u4f7f\u7528\u8bb0\u5f55 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.23-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c23\u90e8\u5206\uff1a\u5165\u9662\u8bc4\u4f30 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.24-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c24\u90e8\u5206\uff1a\u62a4\u7406\u8ba1\u5212 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.25-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c25\u90e8\u5206\uff1a\u51fa\u9662\u8bc4\u4f30\u4e0e\u6307\u5bfc | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.26-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c26\u90e8\u5206\uff1a\u624b\u672f\u77e5\u60c5\u540c\u610f\u4e66 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.27-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c27\u90e8\u5206\uff1a\u9ebb\u9189\u77e5\u60c5\u540c\u610f\u4e66 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.28-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c28\u90e8\u5206\uff1a\u8f93\u8840\u6cbb\u7597\u540c\u610f\u4e66 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.29-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c29\u90e8\u5206\uff1a\u7279\u6b8a\u68c0\u67e5\u53ca\u7279\u6b8a\u6cbb\u7597\u540c\u610f\u4e66 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.30-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c30\u90e8\u5206\uff1a\u75c5\u5371(\u91cd)\u901a\u77e5\u4e66 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.31-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c31\u90e8\u5206\uff1a\u5176\u4ed6\u77e5\u60c5\u544a\u77e5\u540c\u610f\u4e66 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.32-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c32\u90e8\u5206\uff1a\u4f4f\u9662\u75c5\u6848\u9996\u9875 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.33-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c33\u90e8\u5206\uff1a\u4e2d\u533b\u4f4f\u9662\u75c5\u6848\u9996\u9875 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.34-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c34\u90e8\u5206\uff1a\u5165\u9662\u8bb0\u5f55 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.35-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c35\u90e8\u5206\uff1a24\u5c0f\u65f6\u5185\u5165\u51fa\u9662\u8bb0\u5f55 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.36-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c36\u90e8\u5206\uff1a24\u5c0f\u65f6\u5185\u5165\u9662\u6b7b\u4ea1\u8bb0\u5f55 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.37-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c37\u90e8\u5206\uff1a\u4f4f\u9662\u75c5\u7a0b\u8bb0\u5f55  \u9996\u6b21\u75c5\u7a0b\u8bb0\u5f55 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.38-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c38\u90e8\u5206\uff1a\u4f4f\u9662\u75c5\u7a0b\u8bb0\u5f55  \u65e5\u5e38\u75c5\u7a0b\u8bb0\u5f55 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.39-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c39\u90e8\u5206\uff1a\u4f4f\u9662\u75c5\u7a0b\u8bb0\u5f55  \u4e0a\u7ea7\u533b\u5e08\u67e5\u623f\u8bb0\u5f55 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.40-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c40\u90e8\u5206\uff1a\u4f4f\u9662\u75c5\u7a0b\u8bb0\u5f55  \u7591\u96be\u75c5\u4f8b\u8ba8\u8bba\u8bb0\u5f55 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.41-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c41\u90e8\u5206\uff1a\u4f4f\u9662\u75c5\u7a0b\u8bb0\u5f55  \u4ea4\u63a5\u73ed\u8bb0\u5f55 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.42-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c42\u90e8\u5206\uff1a\u4f4f\u9662\u75c5\u7a0b\u8bb0\u5f55 \u8f6c\u79d1\u8bb0\u5f55 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.43-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c43\u90e8\u5206\uff1a\u4f4f\u9662\u75c5\u7a0b\u8bb0\u5f55 \u9636\u6bb5\u5c0f\u7ed3 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.44-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c44\u90e8\u5206\uff1a\u4f4f\u9662\u75c5\u7a0b\u8bb0\u5f55 \u62a2\u6551\u8bb0\u5f55 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.45-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c45\u90e8\u5206\uff1a\u4f4f\u9662\u75c5\u7a0b\u8bb0\u5f55 \u4f1a\u8bca\u8bb0\u5f55 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.46-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c46\u90e8\u5206\uff1a\u4f4f\u9662\u75c5\u7a0b\u8bb0\u5f55 \u672f\u524d\u5c0f\u7ed3 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |           \n| WS/T 500.47-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c47\u90e8\u5206\uff1a\u4f4f\u9662\u75c5\u7a0b\u8bb0\u5f55 \u672f\u524d\u8ba8\u8bba | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.48-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c48\u90e8\u5206\uff1a\u4f4f\u9662\u75c5\u7a0b\u8bb0\u5f55\u672f\u540e \u9996\u6b21\u75c5\u7a0b\u8bb0\u5f55 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.49-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c49\u90e8\u5206\uff1a\u4f4f\u9662\u75c5\u7a0b\u8bb0\u5f55 \u51fa\u9662\u8bb0\u5f55 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.50-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c50\u90e8\u5206\uff1a\u4f4f\u9662\u75c5\u7a0b\u8bb0\u5f55 \u6b7b\u4ea1\u8bb0\u5f55 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.51-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c51\u90e8\u5206\uff1a\u4f4f\u9662\u75c5\u7a0b\u8bb0\u5f55 \u6b7b\u4ea1\u75c5\u4f8b\u8ba8\u8bba\u8bb0\u5f55 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.52-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c52\u90e8\u5206\uff1a\u4f4f\u9662\u533b\u5631 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n| WS/T 500.53-2016  | \u7535\u5b50\u75c5\u5386\u5171\u4eab\u6587\u6863\u89c4\u8303 \u7b2c53\u90e8\u5206\uff1a\u51fa\u9662\u5c0f\u7ed3 | \u63a8\u8350\u6027\u536b\u751f\u884c\u4e1a\u6807\u51c6 |            \n          \n\n\n## \u7ba1\u7406\u7c7b\n\n### \u5efa\u8bbe\u6307\u5357\n\n| \u7f16\u53f7  | \u540d\u79f0 | \n| ----  | ---- | \n| WS/T xxx-2009  | \u7efc\u5408\u536b\u751f\u7ba1\u7406\u4fe1\u606f\u5e73\u53f0\u5efa\u8bbe\u6307\u5357\uff08\u5f81\u6c42\u610f\u89c1\u7a3f\uff09 | \n\n\n### \u6d4b\u8bd5\u4e0e\u8bc4\u4ef7\n\n| \u7f16\u53f7  | \u540d\u79f0 | \n| ----  | ---- | \n| WS/T 502-2016  | \u7535\u5b50\u5065\u5eb7\u6863\u6848\u4e0e\u533a\u57df\u536b\u751f\u4fe1\u606f\u5e73\u53f0\u6807\u51c6\u7b26\u5408\u6027\u6d4b\u8bd5\u89c4\u8303 | \n| WS/T 501-2016  | \u7535\u5b50\u75c5\u5386\u4e0e\u533b\u9662\u4fe1\u606f\u5e73\u53f0\u6807\u51c6\u7b26\u5408\u6027\u6d4b\u8bd5\u89c4\u8303 | \n\n### \u8fd0\u7ef4\u7ba1\u7406\n\n### \u76d1\u7406\u4e0e\u9a8c\u6536\n\n## \u53c2\u8003          \n\n1\u3001[\u56fd\u5bb6\u536b\u751f\u4fe1\u606f\u6807\u51c6\u4e0e\u5b9e\u65bd\u8bc4\u4ef7 \u6c64\u5b66\u519b CHINC2015]()       \n\n2\u3001[\u4e2d\u56fd\u536b\u751f\u4fe1\u606f\u6807\u51c6\u7f51](http://www.chiss.org.cn/hism/wcmpub/hism1029/index/)    \n\n3\u3001[\u7edf\u8ba1\u4fe1\u606f\u4e2d\u5fc3](http://www.moh.gov.cn/mohwsbwstjxxzx/s2907/new_list.shtml)     \n\n\n## \u66f4\u65b0\u65e5\u5fd7\n\n\n2018-04-28\u65e5\u66f4\u65b0\n\n\u8be6\u60c5\u8bf7\u53c2\u8003\u672c\u6b21\u6240\u7684readme\u6587\u4ef6\n\u4e3b\u8981\u662f\u589e\u52a0\u4e862016 17 \u5e74\u53d1\u5e03\u7684\u4e00\u4e9b\u6807\u51c6\u6587\u4ef6\n\u4fee\u6b63\u4e86\u539f\u6765\u8868\u683c\u5c55\u793a\u7684\u95ee\u9898 \n\n\n2017-03-07\u65e5\u66f4\u65b0\n1.\u5bf9\u4e8e README.md \u4e2d\u7684\u6807\u51c6\u7f16\u53f7\u8fdb\u884c\u4e86\u66f4\u65b0          \n\u53c2\u8003\u56fd\u536b\u901a[2016]12\u53f7    \n\n\n2014-11-13\u65e5\u66f4\u65b0\n1.\u5bf9\u4e8e \"\u6570\u636e\u96c6\u6807\u51c6/Excel/WS365\u57ce\u4e61\u5c45\u6c11\u5065\u5eb7\u6863\u6848\u57fa\u672c\u6570\u636e\u96c6.xlsx\"      \n* 5.2.03\u65b0\u751f\u513f\u5bb6\u5ead\u8bbf\u89c6\u4fe1\u606f\u7b2c56\u884c HDSD00.01,261 \u4fee\u6539\u4e3a 5.2.03\u65b0\u751f\u513f\u5bb6\u5ead\u8bbf\u89c6\u4fe1\u606f\u7b2c56\u884c HDSD00.01.261(\u9017\u53f7\u6539\u4e3a\u70b9)       \n* 5.2.01\u4e2a\u4eba\u57fa\u672c\u4fe1\u606f \u7b2c\u4e8c\u884c\u4e3a\u7a7a\u884c \u79fb\u9664       \n* 5.2.04\u513f\u7ae5\u5065\u5eb7\u68c0\u67e5\u4fe1\u606f \u7b2c\u4e00\u5217\u5220\u9664 \u4e0e\u5176\u4ed6\u8868\u5355\u4fdd\u6301\u683c\u5f0f\u4e00\u81f4        \n* 5.2.09\u4f20\u67d3\u75c5\u62a5\u544a\u5361\u4fe1\u606f\u7b2c23\u884c Hr)SD00.01.379  \u4fee\u6539\u4e3a 5.2.09\u4f20\u67d3\u75c5\u62a5\u544a\u5361\u4fe1\u606f\u7b2c23\u884c HDSD00.01.379                 \n* 5.2.09\u4f20\u67d3\u75c5\u62a5\u544a\u5361\u4fe1\u606f\u7b2c33\u884c HDSD00. 01.407 \u4fee\u6539\u4e3a 5.2.09\u4f20\u67d3\u75c5\u62a5\u544a\u5361\u4fe1\u606f\u7b2c33\u884c HDSD00.01.407(00.01.407 \u539f\u676501\u524d\u9762\u6709\u7a7a\u683c)     \n* 5.2.09\u4f20\u67d3\u75c5\u62a5\u544a\u5361\u4fe1\u606f\u7b2c38\u884c HDSD00. 01.412 \u4fee\u6539\u4e3a 5.2.09\u4f20\u67d3\u75c5\u62a5\u544a\u5361\u4fe1\u606f\u7b2c38\u884c HDSD00.01.412 (00.01.412\u539f\u676501\u524d\u9762\u6709\u7a7a\u683c)      \n* 5.2.18\u8f6c\u8bca(\u9662)\u4fe1\u606f\u7b2c49\u884c HDSD00,01.571 \u4fee\u6539\u4e3a 5.2.18\u8f6c\u8bca(\u9662)\u4fe1\u606f\u7b2c49\u884c HDSD00.01.571(\u9017\u53f7\u6539\u4e3a\u70b9)      \n2.\u5bf9\u4e8e\"WS369-375\u536b\u751f\u4fe1\u606f\u57fa\u672c\u6570\u636e\u96c6.xlsx\"      \n* \u513f\u7ae5\u4fdd\u5065\u57fa\u672c\u6570\u636e\u96c6 \u7b2c2\u90e8\u5206 \u513f\u7ae5\u5065\u5eb7\u4f53\u68c0\u7b2c62\u884c 29  \u5220\u9664\u7b2c62\u884c                \n* \u75be\u75c5\u7ba1\u7406\u57fa\u672c\u6570\u636e\u96c6 \u7b2c1\u90e8\u5206 \u4e59\u809d\u60a3\u8005\u7ba1\u7406\u7b2c37\u884c HDSB04,01.037 \u4fee\u6539\u4e3a \u75be\u75c5\u7ba1\u7406\u57fa\u672c\u6570\u636e\u96c6 \u7b2c1\u90e8\u5206 \u4e59\u809d\u60a3\u8005\u7ba1\u7406\u7b2c37\u884c HDSB04.01.037(\u9017\u53f7\u6539\u4e3a\u70b9)     \n* \u75be\u75c5\u7ba1\u7406\u57fa\u672c\u6570\u636e\u96c6 \u7b2c1\u90e8\u5206 \u4e59\u809d\u60a3\u8005\u7ba1\u7406\u7b2c97\u884c  HDSB04,01.097  \u4fee\u6539\u4e3a   HDSB04.01.097  (\u9017\u53f7\u6539\u4e3a\u70b9)       \n* \u75be\u75c5\u7ba1\u7406\u57fa\u672c\u6570\u636e\u96c6 \u7b2c4\u90e8\u5206 \u8001\u5e74\u4eba\u5065\u5eb7\u7ba1\u7406\u7b2c90\u884c  HDSB04,04.090 \u4fee\u6539\u4e3a  HDSB04.04.090       \n* \u75be\u75c5\u7ba1\u7406\u57fa\u672c\u6570\u636e\u96c6 \u7b2c6\u90e8\u5206 \u80bf\u7624\u75c5\u4f8b\u7ba1\u7406\u7b2c30\u884c  HDSB04,06.030 \u4fee\u6539\u4e3a  HDSB04.06.030     \n* \u75be\u75c5\u7ba1\u7406\u57fa\u672c\u6570\u636e\u96c6 \u7b2c6\u90e8\u5206 \u80bf\u7624\u75c5\u4f8b\u7ba1\u7406\u7b2c61\u884c  HDSB04.06.06] \u4fee\u6539\u4e3a  HDSB04.06.061(\u62ff\u6389] )       \n3.\u5bf9\u4e8e\"\u6570\u636e\u5143\u6807\u51c6/Excel/\u536b\u751f\u4fe1\u606f\u6570\u636e\u5143\u76ee\u5f55.xlsx\"          \n\n\n\n"
 },
 {
  "repo": "HealthCatalyst/healthcareai-py",
  "language": "Python",
  "readme_contents": "# healthcareai\n\n[![Code Health](https://landscape.io/github/HealthCatalyst/healthcareai-py/master/landscape.svg?style=flat)](https://landscape.io/github/HealthCatalyst/healthcareai-py/master)\n[![Appveyor build status](https://ci.appveyor.com/api/projects/status/github/HealthCatalyst/healthcareai-py?branch=master&svg=true)](https://ci.appveyor.com/project/CatalystAdmin/healthcareai-py/branch/master)\n[![Build Status](https://travis-ci.org/HealthCatalyst/healthcareai-py.svg?branch=master)](https://travis-ci.org/HealthCatalyst/healthcareai-py)\n<!--[![Anaconda-Server Badge](https://anaconda.org/catalyst/healthcareai/badges/version.svg)](https://anaconda.org/catalyst/healthcareai)\n[![Anaconda-Server Badge](https://anaconda.org/catalyst/healthcareai/badges/installer/conda.svg)](https://conda.anaconda.org/catalyst)-->\n[![PyPI version](https://badge.fury.io/py/healthcareai.svg)](https://badge.fury.io/py/healthcareai)\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.999010.svg)](https://doi.org/10.5281/zenodo.999010)\n[![GitHub license](https://img.shields.io/badge/license-MIT-blue.svg)](https://raw.githubusercontent.com/HealthCatalyst/healthcareai-py/master/LICENSE)\n\nThe aim of **healthcareai** is to streamline machine learning in healthcare. The package has two main goals:\n\n-  Allow one to easily create models based on tabular data, and deploy a best model that pushes predictions to a database such as MSSQL, MySQL, SQLite or csv flat file.\n-  Provide tools related to data cleaning, manipulation, and imputation.\n\n## Installation\n\n### Windows\n\n- If you haven't, install 64-bit Python 3.5 via [the Anaconda distribution](https://repo.continuum.io/archive/Anaconda3-4.2.0-Windows-x86_64.exe)\n    - **Important** When prompted for the **Installation Type**, select **Just Me (recommended)**. This makes permissions later in the process much simpler.\n- Open the terminal (i.e., CMD or PowerShell, if using Windows)\n- Run `conda install pyodbc`\n- Upgrade to latest scipy (note that upgrade command took forever)\n- Run `conda remove scipy`\n- Run `conda install scipy`\n- Run `conda install scikit-learn`\n- Install healthcareai using **one and only one** of these three methods (ordered from easiest to hardest).\n    <!--1. **Recommended:** Install the latest release with conda by running `conda install -c catalyst healthcareai`-->\n    2. **Recommended:** Install the latest release with pip run `pip install healthcareai`\n    3. If you know what you're doing, and instead want the bleeding-edge version direct from our github repo, run `pip install https://github.com/HealthCatalyst/healthcareai-py/zipball/master`\n\n#### Why Anaconda?\n\nWe recommend using the Anaconda python distribution when working on Windows. There are a number of reasons:\n- When running anaconda and installing packages using the `conda` command, you don't need to worry about [dependency hell](https://en.wikipedia.org/wiki/Dependency_hell), particularly because packages aren't compiled on your machine; `conda` installs pre-compiled binaries.\n- A great example of the pain the using `conda` saves you is with the python package **scipy**, which, by [their own admission](http://www.scipy.org/scipylib/building/windows.html) *\"is difficult\"*.\n\n### Linux\n\nYou may need to install the following dependencies:\n- `sudo apt-get install python-tk`\n- `sudo pip install pyodbc`\n    - Note you'll might run into trouble with the `pyodbc` dependency. You may first need to run `sudo apt-get install\n      unixodbc-dev` then retry `sudo pip install pyodbc`. Credit [stackoverflow](http://stackoverflow.com/questions/2960339/unable-to-install-pyodbc-on-linux)\n\nOnce you have the dependencies satisfied run `pip install healthcareai` or `sudo pip install healthcareai`\n\n### macOS\n\n- `pip install healthcareai` or `sudo pip install healthcareai`\n\n### Linux and macOS (via docker)\n\n- Install [docker](https://docs.docker.com/engine/installation/)\n- Clone this repo (look for the green button on the repo main page)\n- cd into the cloned directory\n- run `docker build -t healthcareai .`\n- run the docker instance with `docker run -p 8888:8888 healthcareai` \n- You should then have a jupyter notebook available on `http://localhost:8888`.\n\n### Verify Installation\n\nTo verify that *healthcareai* installed correctly, open a terminal and run `python`. This opens an interactive python\nconsole (also known as a [REPL](https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop)). Then enter this\ncommand: `from healthcareai import SupervisedModelTrainer` and hit enter. If no error is thrown, you are ready to rock.\n\nIf you did get an error, or run into other installation issues, please [let us know](http://healthcare.ai/contact.html)\nor better yet post on [Stack Overflow](http://stackoverflow.com/questions/tagged/healthcare-ai) (with the healthcare-ai\ntag) so we can help others along this process.\n\n## Getting started\n\n1. Read through the [Getting Started](http://healthcareai-py.readthedocs.io/en/latest/getting_started/) section of the [healthcareai-py](http://healthcareai-py.readthedocs.io/en/latest/) documentation.\n\n2. Read through the example files to learn how to use the healthcareai-py API.\n    * For examples of how to train and evaluate a supervised model, inspect and run either `example_regression_1.py` or `example_classification_1.py` using our sample diabetes dataset.\n    * For examples of how to use a model to make predictions, inspect and run either `example_regression_2.py` or `example_classification_2.py` after running one of the first examples.\n    * For examples of more advanced use cases, inspect and run `example_advanced.py`.\n\n3. To train and evaluate your own model, modify the queries and parameters in either `example_regression_1.py` or `example_classification_1.py` to match your own data.\n\n4. Decide what type of prediction output you want. See [Choosing a Prediction Output Type](http://healthcareai-py.readthedocs.io/en/latest/prediction_types/) for details.\n\n5. Set up your database tables to match the schema of the output type you chose. \n   * If you are working in a Health Catalyst EDW ecosystem (primarily MSSQL), please see the [Health Catalyst EDW Instructions](http://healthcareai-py.readthedocs.io/en/latest/catalyst_edw_instructions/) for setup.\n   * Otherwise, please see [Working With Other Databases](http://healthcareai-py.readthedocs.io/en/latest/databases/)\n    for details about writing to different databases (MSSQL, MySQL, SQLite, CSV)\n\n6. Congratulations! After running one of the example files with your own data, you should have a trained model. To use your model to make predictions, modify either `example_regression_2.py` or `example_classification_2.py` to use your new model. You can then run it to see the results. \n\n## For Issues\n\n- Double check that the code follows the examples [here](http://healthcareai-py.readthedocs.io/en/latest/)\n- If you're still seeing an error, create a post in [Stack Overflow](http://stackoverflow.com/questions/tagged/healthcare-ai) (with the healthcare-ai tag) that contains\n    * Details on your environment (OS, database type, R vs Py)\n    * Goals (ie, what are you trying to accomplish)\n    * Crystal clear steps for reproducing the error\n- You can also log a new issue in the GitHub repo by clicking [here](https://github.com/HealthCatalyst/healthcareai-py/issues/new)\n"
 },
 {
  "repo": "microsoft/HealthBotContainerSample",
  "language": "JavaScript",
  "readme_contents": "# Health Bot Container\n\nA simple web page that allows users to communicate with the [Azure Health Bot](https://azure.microsoft.com/en-us/services/bot-services/health-bot/) through a WebChat.\n\n**Note:** In order to use this Web Chat with the Health Bot service, you will need to obtain your Web Chat secret by going to `Integration/Secrets` on the navigation panel.\n\n![Secrets](/secrets.png)\n\n1.Deploy the website:\n\n[![Deploy to Azure](https://aka.ms/deploytoazurebutton)](https://portal.azure.com/#create/Microsoft.Template/uri/https%3A%2F%2Fraw.githubusercontent.com%2Fmicrosoft%2FHealthBotContainerSample%2Fmaster%2Fazuredeploy.json)\n\n2.Set the following environment variables:\n\n`APP_SECRET`\n\n`WEBCHAT_SECRET`\n\n3.Configure scenario invocation (optional):\n\nThe Health Bot service uses [language models](https://docs.microsoft.com/HealthBot/language_model_howto) to interpret end user utterances and trigger the relevant scenario logic in response.\n\nAlternatively, you can programmaticaly invoke a scenario before the end user provides any input.\n\nTo implement this behavior, uncomment\u00a0the\u00a0following\u00a0code\u00a0from\u00a0the\u00a0`function\u00a0initBotConversation()`\u00a0in\u00a0the\u00a0`/public/index.js`\u00a0file:\n```javascript\ntriggeredScenario:\u00a0{\n\u00a0\u00a0\u00a0\u00a0trigger:\u00a0\"{scenario_id}\",\n\u00a0\u00a0\u00a0\u00a0args:\u00a0{\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0myVar1:\u00a0\"{custom_arg_1}\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0myVar2:\u00a0\"{custom_arg_2}\"\n\u00a0\u00a0\u00a0\u00a0}\n}\n```\nReplace\u00a0{scenario_id} with\u00a0the\u00a0scenario\u00a0ID\u00a0of\u00a0the\u00a0scenario\u00a0you\u00a0would\u00a0like\u00a0to\u00a0invoke.\nYou\u00a0can\u00a0also\u00a0pass\u00a0different\u00a0values\u00a0through\u00a0the\u00a0\"args\"\u00a0object.\u00a0\n\nYou can read more about programmatic client side scenario invocation [here](https://docs.microsoft.com/HealthBot/integrations/programmatic_invocation)\n\n\n4.Set the Bot service direct line channel endpoint (optional)\n\nIn some cases it is required to set the endpoint URI so that it points to a specific geography. The geographies supported by the bot service each have a unique direct line endpoint URI:\n\n- `directline.botframework.com` routes your client to the nearest datacenter. This is the best option if you do not know where your client is located.\n- `asia.directline.botframework.com` routes only to Direct Line servers in Eastern Asia.\n- `europe.directline.botframework.com` routes only to Direct Line servers in Europe.\n- `northamerica.directline.botframework.com` routes only to Direct Line servers in North America.\n\nPass your preferred geographic endpoint URI by setting the environment variable: `DIRECTLINE_ENDPOINT_URI` in your deployment. If no variable is found it will default to `directline.botframework.com`\n\n**Note:** If you are deploying the code sample using the \"Deploy to Azure\" option, you should add the above secrets to the application settings for your App Service.\n\n## Agent webchat\nIf the agent webchat sample is also required, [switch to the live agent handoff branch](https://github.com/Microsoft/HealthBotContainerSample/tree/live_agent_handoff)\n"
 },
 {
  "repo": "isaacmg/healthcare_ml",
  "language": null,
  "readme_contents": "## Table Of Contents\n- [Machine Learning for Healthcare](#machine-learning-for-healthcare)\n    - [Introduction](#introduction)\n    - [Genomics](#genomics)\n    - [Precision Medicine/Drug Discovery](#precision-medicinedrug-discovery)\n        - [Tools](#tools)\n    - [Medical Imaging](#medical-imaging)\n        - [Papers](#papers)\n        - [Blogs, blog posts, and reddit discussions](#blogs-blog-posts-and-reddit-discussions)\n        - [Conferences and Workshops](#conferences-and-workshops)\n        - [Research Groups](#research-groups)\n        - [Competitions](#competitions)\n        - [Videos](#videos)\n        - [Datasets](#datasets)\n        - [Code Repositories](#code-repositories)\n        - [Tools](#tools)\n        - [Other](#other)\n    - [Hospital Operations (i.e. OR Utilization, Scheduling, Discharge planning, HAIs...)](#hospital-operations-ie-or-utilization-scheduling-discharge-planning-hais)\n    - [Signal processing, forecasting, and adverse event prediction](#signal-processing-forecasting-and-adverse-event-prediction)\n        - [Papers](#papers)\n    - [Other and Multiple Categories](#other-and-multiple-categories)\n        - [Datasets](#datasets)\n        - [Conferences](#conferences)\n        - [Papers](#papers)\n- [Companies](#companies)\n\n# Machine Learning for Healthcare\nThis repository is a list of the all the relevant resources on applying machine learning to healthcare. If you see an article, repository, or other useful addition please make a pull request. At the moment structure of the repository is as follows: instead of being broken down by machine learning domains as you would technically expect (i.e. computer vision, NLP, audio...etc), it is broken down by application area (i.e. precision medicine, genomics, medical imaging/radiology, hospital operations...). Papers, conferences, tools, or courses that cover multiple areas of healthcare are moved to the \"other/overlapping\" category. If you think that this is confusing or there is a better way of doing things please post in the [issues discussion](https://github.com/isaacmg/healthcare_ml/issues/6)\n\n## Introduction\n\n## Genomics\n\n[AffinityNet](https://arxiv.org/abs/1805.08905)\n\n[Bayesian multi-domain learning for cancer subtype discovery from next-generation sequencing count data](https://arxiv.org/pdf/1810.09433.pdf)\n\n[Machine Learning Genomic Medicine](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7347331)\n\n[Deep learning for Genomics a Overview](https://arxiv.org/abs/1802.00810)\n\n## Precision Medicine/Drug Discovery\n\n[Assessing Disparate Impacts of Personalized Interventions: Identifiability and Bounds](https://arxiv.org/abs/1906.01552)\n\n[Adapting Neural Networks for the Estimation of Treatment Effects](https://arxiv.org/pdf/1906.02120.pdf)\n\n[Attentive State-Space Modeling of Disease Progression](https://nips.cc/Conferences/2019/Schedule?showEvent=14124)\n\n[Dr. VAE](https://arxiv.org/pdf/1706.08203.pdf)\n\n[Deep generative models of genetic variation capture the effects of mutations](https://arxiv.org/abs/1712.06527)\n\n[Deep learning with multimodal representation for pancancer prognosis prediction](https://academic.oup.com/bioinformatics/article/35/14/i446/5529139)\n\n[Deep RL for Radiation Therapy](https://aapm.onlinelibrary.wiley.com/doi/pdf/10.1002/mp.12625)\n\n[GAMENet: Graph Augmented MEmory Networks for Recommending Medication Combination](https://github.com/sjy1203/GAMENet)\n\n[The cornucopia of meaningful leads: Applying deep adversarial autoencoders for new molecule development in oncology](http://www.oncotarget.com/index.php?journal=oncotarget&page=article&op=view&path%5B0%5D=14073&path%5B1%5D=44886)\n\n[End-to-end training of deep probabilistic CCA for\njoint modeling of paired biomedical observations](http://bayesiandeeplearning.org/2018/papers/113.pdf)\n\n\n[Fr\u00e9chet ChemNet Distance: A metric for generative models for molecules in drug discovery](https://arxiv.org/pdf/1803.09518.pdf) \n\n[Lesson Learned from Natural Language Inference in the Clinical Domain](https://arxiv.org/pdf/1808.06752.pdf)\n\n\n[Molecular De Novo design using Recurrent Neural Networks and Reinforcement Learning Code](https://github.com/MarcusOlivecrona/REINVENT)\n\n\n[NAACL Paper on Cross Speciality Entity Recognition for Medicine](https://aclanthology.coli.uni-saarland.de/papers/N18-1001/n18-1001)\n\n[ Natural Language Processing for Precision Medicine](https://www.microsoft.com/en-us/research/wp-content/uploads/2017/07/1707_tutorial.pdf) ACL 2017 Tutorial.\n\n[Near-Optimal Reinforcement Learning in Dynamic Treatment Regimes](https://causalai.net/r48.pdf)\n\n[Predicting drug response of tumors from integrated genomic profiles by deep neural networks](https://bmcmedgenomics.biomedcentral.com/articles/10.1186/s12920-018-0460-9)\n\n[Regression tree methods for precision medicine](https://www.youtube.com/watch?v=jpUItf0Wt4Y) talk by Wei-Yin Loh\nUniversity of Wisconsin-Madison, USA.\n\n[Survey of Computational Methods for Drug Discovery](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4719067/)\n\n### Tools\n[DeepChem](https://deepchem.io)\n\n\n## Medical Imaging\n\n### Papers\n\n[A Two-Stream Mutual Attention Network for Semi-supervised Biomedical Segmentation with Noisy Labels](https://arxiv.org/abs/1807.11719)\n\n[Clinically Applicable deep learning for retinal disease diagnosis and referal](https://lmb.informatik.uni-freiburg.de/Publications/2018/Ron18/paper-De_Fauw_et_al_2018_Nature_Medicine.pdf)\n\n[CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning](https://arxiv.org/pdf/1711.05225.pdf)\n\n[Domain Generalization via Model-Agnostic Learning of Semantic Features (with application to medical image segmentation](https://arxiv.org/abs/1910.13580)\n\n[Dermatologist Level Skin Classification of skin cancer with deep neural networks](https://www.nature.com/articles/nature21056)\n\n[Discrepancy Ratio: Evaluating Model Performance When Even Experts Disagree on the Truth](https://openreview.net/forum?id=Byg-wJSYDS)\n\n[Explanation by Progressive Exaggeration](https://openreview.net/pdf?id=H1xFWgrFPS)\n\n\n[Overview of Deep Learning in Medical Imaging](https://arxiv.org/pdf/1702.05747.pdf)\n\n[On the Automatic Generation of Medical Imaging Reports](https://arxiv.org/abs/1711.08195)\n\n[OBELISK - One Kernel to Solve Nearly Everything: Unified 3D Binary Convolutions for Image Analysis](https://openreview.net/forum?id=BkZu9wooz)\n\n[PGANs: Personalized Generative Adversarial Networks for ECG Generation to improve Patient-Specific Deep ECG Classification](http://www.kiraradinsky.com/files/pgans-personalized-generative.pdf)\n\n[Hybrid Retrieval-Generation Reinforced Agent for Medical Image Report Generation](https://arxiv.org/abs/1805.08298)\n\n\n[Recurrent Registration Neural Networks for Deformable Image Registration](https://arxiv.org/abs/1906.09988)\n\n[Robust breast cancer detection in mammography and digital breast tomosynthesis using annotation-efficient deep learning approach](https://arxiv.org/abs/1912.11027)\n\n[Transfusion: Understanding Transfer Learning for Medical Imaging](http://arxiv.org/abs/1902.07208)\n\n[Towards Deep Cellular Phenotyping in Placental Histology](https://arxiv.org/pdf/1804.03270.pdf)\n\n\n\n### Blogs, blog posts, and reddit discussions\n\n[Luke Oakden Rayner's blog](https://lukeoakdenrayner.wordpress.com)\n\n[A case study of text annotation for medical imaging - LightTag](https://lighttag.io/blog/embrace-the-noise/)\n\n### Conferences and Workshops\n\n[Deep learning for healthcare video series MIT](https://www.youtube.com/watch?v=k0LacC4hyY8&list=PLdPz9_rcdD97b3iExKYmla8vjlsc_k1ee&index=5)\n\n[Harvard Digital Doctor Symposium](https://youtu.be/CiqYtZWBXqE)\n\n[Medical Imaging with deep learning MIDL](https://sites.google.com/view/midl)\n\n[Medical Imaging meets NIPS](https://sites.google.com/view/med-nips-2017)\n\n[Medical Imaging Summer School 2014](http://iplab.dmi.unict.it/miss14/)\n\n[Medical Image Computing and Computer Assisted Intervention](http://www.miccai2017.org)\n\n[Machine Learning in Medical Imaging](http://mlmi2016.web.unc.edu)\n\n[SIM Conference on Machine Intelligence in Medical Imaging](http://siim.org/page/2017CMIMI)\n\n[CVPR 2018 Medical Imaging Workshop](https://sites.google.com/site/cvprmcv18/)\n\n### Research Groups\n[Imperial University](https://biomedia.doc.ic.ac.uk)\n\n[Images Science Institute at Utrecht](https://www.isi.uu.nl/Research/Publications/index.html)\n\n### Competitions\n\n[Digital Mammography Recall Challenge](https://www.synapse.org/#!Synapse:syn4224222)\n\n[Kaggle 2017 Data Science Bowl-Lung diagnosis](https://www.kaggle.com/c/data-science-bowl-2017)\n\n[NIPS 2018 Prothestics Challenge](https://www.crowdai.org/challenges/nips-2018-ai-for-prosthetics-challenge)\n\nLUNA 16\n\n[Kaggle 2016 Data Science Bowl-Measuring ejection fraction](https://www.kaggle.com/c/second-annual-data-science-bowl#description)\n\n### Videos\n[Learning to read deep learning papers -i.e. dicussion of ChexNet by Stanford](https://www.youtube.com/watch?v=xoUpKjxbeC0&t=2s)\n\n\n\n### Datasets\n[CheX-Ray14](https://nihcc.app.box.com/v/ChestXray-NIHCC)\n\n\n### Code Repositories\n\n### Tools\n[DeepInfer](http://www.deepinfer.org)\n\n### Other\n[Medical Image Analysis Network (UK)](https://www.median.ac.uk/network)\n\n\n## Hospital Operations (i.e. OR Utilization, Scheduling, Discharge planning, HAIs, EMRs...)\n\n[Attend and Diagnose](https://arxiv.org/pdf/1711.03905.pdf)\n\n[Adversarial Learning of Privacy-Preserving Text Representations for De-Identification of Medical Records](https://arxiv.org/abs/1906.05000)\n\n[Detecting Hospital Acquired Infections with SVMs](http://journals.sagepub.com/doi/full/10.1177/1460458216656471)\n\n[Deep EHR: a survey of recent deep learning techniques for EHR analysis](https://arxiv.org/pdf/1706.03446.pdf)\n\n[Emergency Department Online Patient-Caregiver Scheduling](https://ojs.aaai.org//index.php/AAAI/article/view/3745)\n\n[Few-Shot and Zero-Shot Multi-Label Learning for Structured Label Spaces (focuses on ICD Coding)](https://aclanthology.org/D18-1352.pdf)\n\n[Learning to predict post-hospitalization VTE risk from EHR data](http://europepmc.org/articles/pmc3540493)\n\n[Multitask Learning and Benchmarking with Clinical Time Series Data](https://arxiv.org/abs/1703.07771)\n\n[Machine-learning Algorithm to Predict Hypotension Based on High- delity Arterial Pressure Waveform Analysis](https://sci-hub.tw/10.1097/ALN.0000000000002300#)\n\n[Privacy-Preserving Classification of Personal Text Messages with Secure Multi-Party Computation](https://arxiv.org/abs/1906.02325) \n\n[Smart Hospital Hand Hygiene (Stanford)](http://ai.stanford.edu/~syyeung/resources/vision_hand_hh_nipsmlhc.pdf)\n\n[Unsupervised Domain Adaptation for Clinical Negation Detection](http://www.aclweb.org/anthology/W17-2320)\n\n[Vision Based Prediction of ICU Mobility with RNNs](https://www.semanticscholar.org/paper/Vision-Based-Prediction-of-ICU-Mobility-Care-using-Bianconi-Mehra/db6cf1ac611668fb61921cd98b9fb14525b7c2a6)\n\n## Signal processing, forecasting, and adverse event prediction\n\n\n### Papers\n\n[Analysing and Improving the Diagnosis of Ischaemic Heart Disease with Machine Learning](https://www.ncbi.nlm.nih.gov/pubmed/10225345) NIH Article\n\n[Asthma Incidence Prediction with DNN](https://www.medrxiv.org/content/10.1101/19012161v1)\n\n[Doctor AI: Predicting Clinical Events via Recurrent Neural Network](https://arxiv.org/abs/1511.05942)s published in MLR\n\n[Cardiologist level classification of arrhythmia (Stanford)](https://arxiv.org/pdf/1707.01836.pdf) \n\n[Dynamic Bayesian Flu Forecasting](https://arxiv.org/abs/1708.09481)\n\n[Deep Self Organization with application to ICU](https://openreview.net/pdf?id=rygjcsR9Y7)\n\n[Interpretable AI for beat-to-beat cardiac function assessment](https://www.medrxiv.org/content/10.1101/19012419v2)\n\n[GRU-ODE-Bayes: Continuous modeling of sporadically-observed time series](https://arxiv.org/pdf/1905.12374v1.pdf)\n\n[Manifold-regression to predict from MEG/EEG brain signals without source modeling](https://arxiv.org/abs/1906.02687)\n\n[U-Time: A Fully Convolutional Network for Time Series Segmentation Applied to Sleep Staging](https://arxiv.org/abs/1910.11162)\n\n[Forecasting Treatment Responses Over Time Using Recurrent Marginal Structural Networks](https://github.com/sjblim/rmsn_nips_2018)\n\n\n## Other and Multiple Categories\n\n\n### Datasets\n\n[Clinical Case Reports Dataset for machine comprehension](https://github.com/clips/clicr)\n\n[HEAD-QA: A Healthcare Dataset for Complex Reasoning](https://arxiv.org/abs/1906.04701)\n\n[NLP Datasets from i2b2](https://www.i2b2.org/NLP/DataSets/Main.php)\n\n[EBM-NLP 5,000 richly annotated abstracts of medical articles](http://www.ccis.northeastern.edu/home/bennye/EBM-NLP/browse.html)\n\n[EMR-Question and Answering Code](https://github.com/panushri25/emrQA)\n\n[OncoKB](http://oncokb.org/)\n\n[MeDAL: A large medical text dataset curated for abbreviation disambiguation](https://github.com/BruceWen120/medal)\n\n[MIMIC - Medical Information Mart for Intensive Care - A large dataset by MIT and made available through Github] (https://mimic.mit.edu/)\n\n\n\n### Conferences\n\n[BioNLP Workshops](https://aclweb.org/aclwiki/BioNLP_Workshop)\n\n[Clinical NLP](https://clinical-nlp.github.io/2019/index.html)\n\n[Machine Learning for Healthcare Conference](http://mucmd.org)\n\n[HealthTac](http://healtex.org/healtac-2019/)\n\n[Trec Clinical Decision Support](http://www.trec-cds.org)\n\n[Machine Learning for Healthcare 2018](https://www.mlforhc.org)\n\n[2017 ICML Healthcare Related Talks](https://2017.icml.cc/Conferences/2017/Schedule?showParentSession=1379)\n\n[ICML AI and Health Workshop](http://sots.brookes.ac.uk/~p0072382/ai4h2018/)\n\n[Ninth Workshop on Health Text Mining at EMNLP](https://louhi2018.fbk.eu)\n\n[NAACL 2019 On Tutorial Applications of Natural Language Processing in Clinical Research and Practice](https://www.aclweb.org/anthology/attachments/N19-5006.Presentation.pdf)\n\n[Rework Healthcare 2018](https://www.re-work.co/events/deep-learning-health-boston-2018)\n\n\n\n### Papers\n\n[Active Learning for Decision-Making from Imbalanced Observational Data (application to personalized treatment](https://arxiv.org/pdf/1904.05268.pdf)\n\n[Adversarial Attacks Against Medical Deep Learning Systems](https://arxiv.org/pdf/1804.05296.pdf)\n\n[Annotating a Large Representative Corpus of Clinical Notes for Parts of Speech](https://www.researchgate.net/publication/301404639_Annotating_a_Large_Representative_Corpus_of_Clinical_Notes_for_Parts_of_Speech)\n\n[Automated Medical Scribe for recording clinical encounters](http://aclweb.org/anthology/N18-5003)\n\n[Deep Learning for Healthcare Review, Opportunities, Challenges](https://www.ncbi.nlm.nih.gov/pubmed/28481991) published Oxford Academic.\n\n[Deep Neural Models for Medical Concept Normalization in User-Generated Texts](link coming)\n\n[Direct Uncertainty Prediction for Medical Second Opinions](https://arxiv.org/abs/1807.01771)\n\n[EMER-QA A large corpus for question answering on electronic medical records](https://arxiv.org/pdf/1809.00732.pdf)\n\n[GAMENet: Graph Augmented MEmory Networks for Recommending Medication Combination](https://arxiv.org/abs/1809.01852)\n\n[Leveraging uncertainty information from deep neural networks for disease detection](https://www.nature.com/articles/s41598-017-17876-z)\n\n[Label-aware Double Transfer Learning for Cross-Specialty Medical Named Entity Recognition](http://aclweb.org/anthology/N18-1001)\n\n[Machine Learning for Medical Diagnosis](https://dl.acm.org/citation.cfm?id=2306356) PSU article 2006\n\n[MiME: Multilevel Medical Embedding of Electronic Health Records for Predictive Healthcare](https://nips.cc/Conferences/2018/Schedule?showEvent=11448)\n\n[Novel Exploration Techniques (NETs) for Malaria Policy Interventions](https://arxiv.org/pdf/1712.00428.pdf)\n\n[Opportunistic Learning: Budgeted Cost-Sensitive Learning from Data Streams with application to diabetes](https://openreview.net/pdf?id=S1eOHo09KX)\n\n[Patient2Vec: A Personalized Interpretable Deep Representation of the Longitudinal Electronic Health Record](https://arxiv.org/abs/1810.04793)\n\n[Towards Automating Healthcare Question Answering in a Noisy Multilingual Low-Resource Setting](https://www.aclweb.org/anthology/P19-1090)\n\n[Learning Phenotypes and Dynamic Patient Representations via RNN Regularized Collective Non-negative Tensor Factorization](https://dmas.lab.mcgill.ca/fung/pub/YQCFP19aaai_postprint.pdf)\n\n[Uncertainty-Aware Attention for Reliable Interpretation and Prediction](https://nips.cc/Conferences/2018/Schedule?showEvent=11112)\n\n### Additional Natural Language Processing for Healthcare Tools\n\n[BioBERT](https://github.com/dmis-lab/biobert)\n\n[Clinical Named Entity Recognition system (CliNER)](https://github.com/text-machine-lab/CliNER)\n\n[Clinical Text Analysis Knowledge Extraction System (cTAKES)](http://ctakes.apache.org/)\n\n\n### Courses\n\n[Machine Learning for Medicine MIT Course](https://mlhc17mit.github.io)\n\n\n# Companies\nCompanies are arranged alphabetical order.\n![Image of stratups](https://cbi-blog.s3.amazonaws.com/blog/wp-content/uploads/2017/01/healthcare_AI_map_2016_1.png)\n\n[Benevolent AI](https://benevolent.ai)\n\n[Camereyes](http://camereyes.com)\n\n[Center Clinical Data Science Mass General](https://www.ccds.io)\n\n[Deep Genomics](https://www.deepgenomics.com)\n\n[Etiometry](http://www.etiometry.com)\n\n[Heartflow](https://www.google.com/search?client=opera&q=heartflow&sourceid=opera&ie=UTF-8&oe=UTF-8)\n\n[Hemonitor](https://www.hemonitor.co)\n\n[Healthcare at Google](https://research.google.com/teams/brain/healthcare/)\n\n[Insitrio](http://www.insitro.com)\n\n[Path.AI](http://path.ai)\n\n[RadAI](https://www.crunchbase.com/organization/radai)\n\n[Recursion Pharmaceuticals](https://www.recursionpharma.com)\n\n[Siemens AI Document](http://www.usa.siemens.com/pool/news_events/innovation-day/10_usinnoday2017_artificial_intelligence.pdf)\n"
 },
 {
  "repo": "TheAlphamerc/flutter_healthcare_app",
  "language": "Dart",
  "readme_contents": "## flutter_healthcare_app ![Twitter URL](https://img.shields.io/twitter/url?style=social&url=https%3A%2F%2Ftwitter.com%2Fthealphamerc) [![GitHub stars](https://img.shields.io/github/stars/Thealphamerc/flutter_healthcare_app?style=social)](https://github.com/login?return_to=%2FTheAlphamerc%flutter_healthcare_app) ![GitHub forks](https://img.shields.io/github/forks/TheAlphamerc/flutter_healthcare_app?style=social) \n\n![Dart CI](https://github.com/TheAlphamerc/flutter_healthcare_app/workflows/Dart%20CI/badge.svg) ![GitHub pull requests](https://img.shields.io/github/issues-pr/TheAlphamerc/flutter_healthcare_app) ![GitHub closed pull requests](https://img.shields.io/github/issues-pr-closed/Thealphamerc/flutter_healthcare_app) ![GitHub last commit](https://img.shields.io/github/last-commit/Thealphamerc/flutter_healthcare_app)  ![GitHub issues](https://img.shields.io/github/issues-raw/Thealphamerc/flutter_healthcare_app) [![Open Source Love](https://badges.frapsoft.com/os/v2/open-source.svg?v=103)](https://github.com/Thealphamerc/flutter_healthcare_app) \n\n\nHealthcare app is a design implementaion of [Healthcare Mobile App](https://www.uplabs.com/posts/healthcare-mobile-app-d9081ded-e7b3-4705-8990-82ead42c22da) designed by [Chirag Chauhan](https://www.uplabs.com/chirag_designer2610)\n\n## Download App ![GitHub All Releases](https://img.shields.io/github/downloads/Thealphamerc/flutter_healthcare_app/total?color=green)\n<a href=\"https://github.com/TheAlphamerc/flutter_healthcare_app/releases/download/v1.0.0/app-release.apk\"><img src=\"https://playerzon.com/asset/download.png\" width=\"200\"></img></a>\n<img src=\"https://github.com/TheAlphamerc/flutter_healthcare_app/blob/master/screenshots/HealthcareMobileApp.png?raw=true\"  /> \n\n## Android Screenshots\n\n  HomePage                 |    Detail Page        \n:-------------------------:|:-------------------------:\n![](https://github.com/TheAlphamerc/flutter_healthcare_app/blob/master/screenshots/screenshot_1.jpg?raw=true)|![](https://github.com/TheAlphamerc/flutter_healthcare_app/blob/master/screenshots/screenshot_2.jpg?raw=true)\n\n## iOS Screenshots\n  HomePage                 |    Detail Page      \n:-------------------------:|:-------------------------:\n![](https://github.com/TheAlphamerc/flutter_healthcare_app/blob/master/screenshots/screenshot_ios_1.png?raw=true)|![](https://github.com/TheAlphamerc/flutter_healthcare_app/blob/master/screenshots/screenshot_ios_2.png?raw=true)\n\n## Directory Structure\n```\n|-- lib\n|   |-- main.dart\n|   '-- src\n|       |-- config\n|       |   '-- route.dart\n|       |-- model\n|       |   |-- dactor_model.dart\n|       |   '-- data.dart\n|       |-- pages\n|       |   |-- detail_page.dart\n|       |   |-- home_page.dart\n|       |   '-- splash_page.dart\n|       |-- theme\n|       |   |-- extention.dart\n|       |   |-- light_color.dart\n|       |   |-- text_styles.dart\n|       |   '-- theme.dart\n|       '-- widgets\n|           |-- coustom_route.dart\n|           |-- progress_widget.dart\n|           '-- rating_start.dart\n|-- pubspec.yaml\n|-- screenshots\n|   |-- HealthcareMobileApp.png\n|   |-- screenshot_1.jpg\n|   |-- screenshot_2.jpg\n|   |-- screenshot_ios_1.png\n|   '-- screenshot_ios_2.png\n'-- test\n    '-- widget_test.dart\n```\n## Pull Requests\n\nI welcome and encourage all pull requests. It usually will take me within 24-48 hours to respond to any issue or request.\n\n## Flutter projects\n Project Name        |Stars        \n:-------------------------|-------------------------\n[Twitter clone](https://github.com/TheAlphamerc/flutter_twitter_clone)| [![GitHub stars](https://img.shields.io/github/stars/Thealphamerc/flutter_twitter_clone?style=social)](https://github.com/login?return_to=%2FTheAlphamerc%flutter_twitter_clone)\n|[Ecommerce App](https://github.com/TheAlphamerc/flutter_ecommerce_app) |[![GitHub stars](https://img.shields.io/github/stars/Thealphamerc/flutter_ecommerce_app?style=social)](https://github.com/login?return_to=%2FTheAlphamerc%flutter_ecommerce_app)\n|[Smart course](https://github.com/TheAlphamerc/flutter_smart_course) |[![GitHub stars](https://img.shields.io/github/stars/Thealphamerc/flutter_smart_course?style=social)](https://github.com/login?return_to=%2FTheAlphamerc%flutter_smart_course)\n|[Pokedex](https://github.com/TheAlphamerc/flutter_pokedex)|[![GitHub stars](https://img.shields.io/github/stars/Thealphamerc/flutter_pokedex?style=social)](https://github.com/login?return_to=%2FTheAlphamerc%flutter_pokedex)\n|[Authentication](https://github.com/TheAlphamerc/flutter_login_signup)|[![GitHub stars](https://img.shields.io/github/stars/Thealphamerc/flutter_login_signup?style=social)](https://github.com/login?return_to=%2FTheAlphamerc%flutter_login_signup)\n|[Wallet App](https://github.com/TheAlphamerc/flutter_wallet_app)|[![GitHub stars](https://img.shields.io/github/stars/Thealphamerc/flutter_wallet_app?style=social)](https://github.com/login?return_to=%2FTheAlphamerc%flutter_wallet_app)\n|[News App](https://github.com/TheAlphamerc/flutter_news_app)|[![GitHub stars](https://img.shields.io/github/stars/Thealphamerc/flutter_news_app?style=social)](https://github.com/login?return_to=%2FTheAlphamerc%flutter_news_app)\n|[Watch App](https://github.com/TheAlphamerc/flutter_SoftUI_watchApp)|[![GitHub stars](https://img.shields.io/github/stars/Thealphamerc/flutter_SoftUI_watchApp?style=social)](https://github.com/login?return_to=%2FTheAlphamerc%flutter_SoftUI_watchApp)\n|[Smart Home App](https://github.com/TheAlphamerc/flutter_smart_home_app)|[![GitHub stars](https://img.shields.io/github/stars/Thealphamerc/flutter_smart_home_app?style=social)](https://github.com/login?return_to=%2FTheAlphamerc%flutter_smart_home_app)\n|[Yatch Booking App](https://github.com/TheAlphamerc/flutter_yatch_booking)|[![GitHub stars](https://img.shields.io/github/stars/Thealphamerc/flutter_yatch_booking?style=social)](https://github.com/login?return_to=%2FTheAlphamerc%flutter_yatch_booking)\n\n## Flutter plugins\nPlugin Name        | Stars        \n:-------------------------|-------------------------\n|[Empty widget](https://github.com/TheAlphamerc/empty_widget) |[![GitHub stars](https://img.shields.io/github/stars/Thealphamerc/empty_widget?style=social)](https://github.com/login?return_to=%2FTheAlphamerc%empty_widget)\n|[Add Thumbnail](https://github.com/TheAlphamerc/flutter_plugin_add_thumbnail) |[![GitHub stars](https://img.shields.io/github/stars/Thealphamerc/flutter_plugin_add_thumbnail?style=social)](https://github.com/login?return_to=%2FTheAlphamerc%flutter_plugin_add_thumbnail)\n|[Filter List](https://github.com/TheAlphamerc/flutter_plugin_filter_list)| [![GitHub stars](https://img.shields.io/github/stars/Thealphamerc/flutter_plugin_filter_list?style=social)](https://github.com/login?return_to=%2FTheAlphamerc%flutter_plugin_filter_list)\n\n## Created & Maintained By\n\n[Sonu Sharma](https://github.com/TheAlphamerc) ([Twitter](https://www.twitter.com/TheAlphamerc)) ([Youtube](https://www.youtube.com/user/sonusharma045sonu/)) ([Insta](https://www.instagram.com/_sonu_sharma__)) ([Dev.to](https://dev.to/thealphamerc))\n  ![Twitter Follow](https://img.shields.io/twitter/follow/thealphamerc?style=social) \n\n\n> If you found this project helpful or you learned something from the source code and want to thank me, consider buying me a cup of :coffee:\n>\n> * [PayPal](https://paypal.me/TheAlphamerc/)\n\n> You can also nominate me for Github Star developer program  https://stars.github.com/nominate\n\n\n## Visitors Count\n\n<img align=\"left\" src = \"https://profile-counter.glitch.me/flutter_healthcare_app/count.svg\" alt =\"Loading\">\n"
 },
 {
  "repo": "nextgenhealthcare/connect",
  "language": "Java",
  "readme_contents": "# Mirth\u00ae Connect by NextGen Healthcare\n\n1. [Useful Links](#useful-links)\n2. [General Information](#general-information)\n3. [Installation and Upgrade](#installation-and-upgrade)\n4. [Starting Mirth Connect](#starting-mirth-connect)\n5. [Running Mirth Connect in Java 9 or greater](#java9)\n6. [Java Licensing](#java-licensing)\n7. [License](#license)\n\n------------\n\n<a name=\"useful-links\"></a>\n## 1. Useful Links\n- [Downloads](https://github.com/nextgenhealthcare/connect/releases) \n- [User Guide](https://docs.nextgen.com/)\n- [Wiki](https://github.com/nextgenhealthcare/connect/wiki)\n  - [FAQ](https://github.com/nextgenhealthcare/connect/wiki/Frequently-Asked-Questions)\n  - [What's New in Mirth Connect](https://github.com/nextgenhealthcare/connect/wiki/Release-Notes)\n- [Forums](https://forums.mirthproject.io/)\n- [Slack Channel](https://mirthconnect.slack.com/) \n  - [Slack Registration](https://join.slack.com/t/mirthconnect/shared_invite/zt-1prqon9tg-UQ_~6AsV8IwdITTo3z1aoA)\n\n------------\n\n<a name=\"general-information\"></a>\n## 2. General Information\n##### The NextGen Solutions Mission\nNextGen Solutions help many of the nation&apos;s largest, most respected healthcare entities streamline their care-management processes to satisfy the demands of a regulatory, competitive healthcare industry. With Mirth Solutions, NextGen Healthcare&apos;s goal is to provide the healthcare community with a secure, efficient, cost-effective means of sharing health information. The natural product of this aim is a family of applications &mdash; which includes Mirth Connect &mdash; flexible enough to manage patient information, from small practices to large HIEs, so our clients and users can work confidently and effectively within the healthcare-delivery system.\n##### About Mirth Connect\nLike an interpreter who translates foreign languages into the one you understand, Mirth Connect translates message standards into the one your system understands. Whenever a &quot;foreign&quot; system sends you a message, Mirth Connect&apos;s integration capabilities expedite the following:\n- Filtering &mdash; Mirth Connect reads message parameters and passes the message to or stops it on its way to the transformation stage.\n- Transformation &mdash; Mirth Connect converts the incoming message standard to another standard (e.g., HL7 to XML).\n- Extraction &mdash; Mirth Connect can &quot;pull&quot; data from and &quot;push&quot; data to a database.\n- Routing &mdash; Mirth Connect makes sure messages arrive at their assigned destinations.\n\nUsers manage and develop channels (message pathways) using the interface known as the Administrator:\n![Administrator screenshot](https://i.imgur.com/tnoAENw.png)\n\n------------\n\n<a name=\"installation-and-upgrade\"></a>\n## 3. Installation and Upgrade\nMirth Connect installers are available for individual operating systems (.exe for Windows, .rpm and .sh for Linux, and .dmg for Mac OS X). Pre-packaged distributions are also available for individual operating systems (ZIP for Windows, tar.gz for Linux, and tar.gz for Mac OS X). The installer allows you to automatically upgrade previous Mirth Connect installations (starting with version 1.5).\n\nMirth Connect installers also come with the option to install and start a service that will run in the background. You also have the option of installing and running the Mirth Connect Server Manager, which allows you to start and stop the service on some operating systems, change Mirth Connect properties and backend database settings, and view the server logs.\n\nAn optional Mirth Connect Command Line Interface can be installed, allowing you to connect to a running Mirth Connect Server using a command line. This tool is useful for performing or scripting server tasks without opening the Mirth Connect Administrator.\n\nThe Mirth Connect Administrator Launcher can also be installed, allowing you to manage connections to multiple Mirth Connect servers and configure options such as Java runtime, max heap size, and security protocols.\n\nAfter the installation, the Mirth Connect directory layout will look as follows:\n\n- /appdata/mirthdb: The embedded database (Do NOT delete if you specify Derby as your database). This will be created when the Mirth Connect Server is started. The path for appdata is defined by the dir.appdata property in mirth.properties.\n- /cli-lib: Libraries for the Mirth Connect Command Line Interface (if installed)\n- /client-lib: Libraries for the Mirth Connect Administrator\n- /conf: Configuration files\n- /custom-lib: Place your custom user libraries here to be used by the default library resource.\n- /docs: This document and a copy of the Mirth Connect license\n- /docs/javadocs: Generated javadocs for the installed version of Mirth Connect. These documents are also available when the server is running at `http://[server address]:8080/javadocs/` (i.e. `http://localhost:8080/javadocs/`).\n- /extensions: Libraries and meta data for Plug-ins and Connectors\n- /logs: Default location for logs generated by Mirth Connect and its sub-components\n- /manager-lib: Libraries for the Mirth Connect Server Manager (if installed)\n- /public_html: Directory exposed by the embedded web server\n- /server-launcher-lib: Libraries in this directory will be loaded into the main Mirth Connect Server thread context classloader upon startup. This is required if you are using any custom log4j appender libraries.\n- /server-lib: Mirth Connect server libraries\n- /webapps: Directory exposed by the embedded web server to host webapps\n\n------------\n\n<a name=\"starting-mirth-connect\"></a>\n## 4. Starting Mirth Connect\nOnce Mirth Connect has been installed, there are several ways to connect to launch the Mirth Connect Administrator. On a Windows installation, there is a Mirth Connect Administrator item in the Start Menu which launches the application directly.\n\nIf the option is not available, you can connect to the Mirth Connect Administrator launch page which by default should be available at `http://[server address]:8080` (i.e. `http://localhost:8080`). It is recommended to use the Administrator Launcher to start the Administrator, which can be downloaded by clicking on the Download Administrator Launcher button. Clicking the Launch Mirth Connect Administrator button will download the Java Web Start file for your server. Opening the file with the Administrator Launcher connects you to the server, which will be listening on `https://[server address]:8443` (i.e. `https://localhost:8443`). \n\nIf running a new installation, the default username and password for the login screen is admin and admin. This should be changed immediately for security purposes.\n\nIf you are launching the administrator for the first time, you will notice that the libraries for the Mirth Connect Administrator will be loaded. This feature allows you run the Administrator from any remote Mirth Connect server without having to download and install a separate client.\n\nYou may also notice a security warning when starting the administrator (dialog box depends on browser being used). This is because by default Mirth Connect creates a self-signed certificate for its web server. For now click Run to continue launching the administrator, but check out the User Guide for instructions on how to replace the certificate.\n\n------------\n\n<a name=\"java9\"></a>\n## 5. Running Mirth Connect in Java 9 or greater\nIn order to run Mirth Connect in Java 9 or greater, copy the options from `docs/mcservice-java9+.vmoptions` and append them to either mcserver.vmoptions or mcservice.vmoptions, depending on your deployment. Then restart Mirth Connect.\n\nTo run the Mirth Connect Command Line Interface, create a new file named mccommand.vmoptions in the Mirth Connect root directory. Copy all of the options from `docs/mcservice-java9+.vmoptions` into mccommand.vmoptions and save before launching the Command Line Interface.\n\n------------\n\n<a name=\"java-licensing\"></a>\n## 6. Java Licensing\nIn 2019, Oracle significantly changed licensing for official Oracle Java releases. You must now purchase a license in order to receive updates to the commercial version of Oracle Java. In response to this change, we officially added support for OpenJDK in Mirth Connect. OpenJDK receives free updates from Oracle for a period of 6 months following each release. While the Oracle OpenJDK distribution is recommended for use with Mirth Connect, we strive to support third-party OpenJDK distributions as well such as AdoptOpenJDK, Azul Zulu and Amazon Corretto. Third party distributions may receive extended release updates from their respective communities, but these are not guaranteed.\n\n------------\n\n<a name=\"license\"></a>\n## 7. License\nMirth Connect is released under the [Mozilla Public License version 2.0](https://www.mozilla.org/en-US/MPL/2.0/ \"Mozilla Public License version 2.0\"). You can find a copy of the license in `server/docs/LICENSE.txt`.\n\nAll licensing information regarding third-party libraries is located in the `server/docs/thirdparty` folder.\n"
 },
 {
  "repo": "OCA/vertical-medical",
  "language": null,
  "readme_contents": "\n[![Runboat](https://img.shields.io/badge/runboat-Try%20me-875A7B.png)](https://runboat.odoo-community.org/builds?repo=OCA/vertical-medical&target_branch=14.0)\n[![Pre-commit Status](https://github.com/OCA/vertical-medical/actions/workflows/pre-commit.yml/badge.svg?branch=14.0)](https://github.com/OCA/vertical-medical/actions/workflows/pre-commit.yml?query=branch%3A14.0)\n[![Build Status](https://github.com/OCA/vertical-medical/actions/workflows/test.yml/badge.svg?branch=14.0)](https://github.com/OCA/vertical-medical/actions/workflows/test.yml?query=branch%3A14.0)\n[![codecov](https://codecov.io/gh/OCA/vertical-medical/branch/14.0/graph/badge.svg)](https://codecov.io/gh/OCA/vertical-medical)\n[![Translation Status](https://translation.odoo-community.org/widgets/vertical-medical-14-0/-/svg-badge.svg)](https://translation.odoo-community.org/engage/vertical-medical-14-0/?utm_source=widget)\n\n<!-- /!\\ do not modify above this line -->\n\n# Open Source Healthcare System for Odoo\n\nTODO: add repo description.\n\n<!-- /!\\ do not modify below this line -->\n\n<!-- prettier-ignore-start -->\n\n[//]: # (addons)\n\nThis part will be replaced when running the oca-gen-addons-table script from OCA/maintainer-tools.\n\n[//]: # (end addons)\n\n<!-- prettier-ignore-end -->\n\n## Licenses\n\nThis repository is licensed under [AGPL-3.0](LICENSE).\n\nHowever, each module can have a totally different license, as long as they adhere to Odoo Community Association (OCA)\npolicy. Consult each module's `__manifest__.py` file, which contains a `license` key\nthat explains its license.\n\n----\nOCA, or the [Odoo Community Association](http://odoo-community.org/), is a nonprofit\norganization whose mission is to support the collaborative development of Odoo features\nand promote its widespread use.\n"
 },
 {
  "repo": "HealthCatalyst/healthcareai-r",
  "language": "R",
  "readme_contents": "---\noutput: github_document\n---\n\n<!-- README.md is generated from README.Rmd. Please edit the .Rmd and knit it to generate the .md. -->\n\n```{r, include = FALSE}\nknitr::opts_chunk$set(collapse = TRUE, comment = \"# >\",\n                      fig.height = 3, fig.width = 6, dpi = 96,\n                      fig.path = \"man/figures/README-\")\noptions(tibble.print_max = 5)\nlibrary(healthcareai)\nset.seed(6751)\n```\n\n# healthcareai <img src=\"man/figures/logo.png\" align=\"right\" />\n\n[![Appveyor Build Status](https://ci.appveyor.com/api/projects/status/0xrpe233o9a16l4l/branch/master?svg=true)](https://ci.appveyor.com/project/CatalystAdmin/healthcareai-r/) \n[![Travis-CI Build Status](https://travis-ci.org/HealthCatalyst/healthcareai-r.svg?branch=master)](https://travis-ci.org/HealthCatalyst/healthcareai-r) \n[![codecov badge](https://codecov.io/gh/HealthCatalyst/healthcareai-r/branch/master/graph/badge.svg)](https://codecov.io/gh/HealthCatalyst/healthcareai-r) \n[![CRAN_Status_Badge](https://www.r-pkg.org/badges/version-last-release/healthcareai)](https://cran.r-project.org/package=healthcareai)\n[![CRAN downloads badge](https://cranlogs.r-pkg.org/badges/grand-total/healthcareai)](https://cranlogs.r-pkg.org/badges/last-week/healthcareai)\n[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://github.com/HealthCatalystSLC/healthcareai-r/blob/master/LICENSE)\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.999334.svg)](https://doi.org/10.5281/zenodo.999334)\n\n## Overview\n\nThe aim of `healthcareai` is to make machine learning in healthcare as easy as possible. It does that by providing functions to:\n\n- Develop customized, reliable, high-performance machine learning models with minimal code\n- Easily make and evaluate predictions and push them to a database\n- Understand how a model makes its predictions\n- Make data cleaning, manipulation, imputation, and visualization as simple as possible\n\n## Usage\n\n`healthcareai` can take you from messy data to an optimized model in one line of code:\n\n```{r, message = FALSE}\nmodels <- machine_learn(pima_diabetes, patient_id, outcome = diabetes)\nmodels\n```\n\nMake predictions and examine predictive performance:\n\n```{r plot_predictions}\npredictions <- predict(models, outcome_groups = TRUE)\nplot(predictions)\n```\n\n## Learn More\n\nFor details on what's happening under the hood and for options to customize data preparation and model training, see [Getting Started with healthcareai](https://docs.healthcare.ai/articles/site_only/healthcareai.html) as well as the helpfiles for individual functions such as `?machine_learn`, `?predict.model_list`, and `?explore`. \n\nDocumentation of all functions as well as vignettes on various uses of the package are available at the package website: https://docs.healthcare.ai/.\n\nAlso, be sure to read our [blog](http://healthcare.ai/blog/) and watch our [broadcasts](https://www.youtube.com/channel/UCGZUobs_x712KbcL6RSzfnQ) to learn more about what's new in healthcare machine learning and how we are using this toolkit to put machine learning to work in real healthcare systems.\n\n## Get Involved\n\nWe have a [Slack community](https://healthcare-ai.slack.com/) that is a great place to introduce yourself, share what you're doing with the package, ask questions, and troubleshoot your code.\n\n### Contributing\n\nIf you are interested in contributing the package (great!), please read the [contributing](https://github.com/HealthCatalyst/healthcareai-r/blob/master/CONTRIBUTING.md) guide, and look for [issues with the \"help wanted\" tag](https://github.com/HealthCatalyst/healthcareai-r/labels/help%20wanted). Feel free to tackle any issue that interests you; those are a few issues that we feel would make a good place to start.\n\n### Feedback\n\nYour feedback is hugely appreciated. It is makes the package work well and helps us make it more useful to the community. Both feature requests and bug reports should be submitted as [Github issues](https://github.com/HealthCatalyst/healthcareai-r/issues/new). \n\n**Bug reports** should be filed with a [minimal reproducable example](https://gist.github.com/hadley/270442). The [reprex package](https://github.com/tidyverse/reprex) is extraordinarily helpful for this. Please also include the output of `sessionInfo()` or better yet, `devtools::session_info()`.\n\n## Legacy\n\nVersion 1 of `healthcareai` has been retired. You can continue to use it, but its compatibility with changes in the R ecosystem are not guaranteed. You should always be able to install it from github with: `install.packages(\"remotes\"); remotes::install_github(\"HealthCatalyst/healthcareai-r@v1.2.4\")`.\n\nFor an example of how to adapt v1 models to the v2 API, check out the [Transitioning vignettes](https://docs.healthcare.ai/articles/site_only/transitioning.html).\n"
 },
 {
  "repo": "acoravos/healthcare-blockchains",
  "language": null,
  "readme_contents": "_UPDATE: As of July 25, 2018, we have combined efforts with the Mt Sinai [Center for Biomedical Blockchain Research](http://biomedicalblockchain.org/) to launch an interactive landscape map and open-source registry of biomedical blockchains. [Check out the map](https://db.biomedicalblockchain.org/), and submit a new project [here](https://db.biomedicalblockchain.org/submit)._\n\n_Learn more about why we took on this project in our [STAT News July 2018 Op-Ed](https://www.statnews.com/2018/07/25/blockchains-biomedicine-health-care-buyer-be-informed/)._\n\n# Where are the healthcare-related blockchains?\n![healthcare blockchain](healthcare-blockchain.png)\nWe've drafted an open-source landscape map for healthcare-related blockchains. This repository was inspired by conversations with [Paul](https://github.com/pfletcherhill) from [PatientBank](https://www.patientbank.us) and Chris from [Hashed Health](https://hashedhealth.com). We wanted to answer the question: *Who is working on blockchain-related technologies for our industry?*\n\n## Overview & Methodology\nThere's a lot of opportunity to use blockchain technologies in healthcare -- [and there are a lot of myths, too](https://blog.andreacoravos.com/myth-busting-can-a-blockchain-save-healthcare-d398cdebf0c1).\n\nWe put together a first cut of this map and wanted to open it up to the community to share updates. Many of the companies on this list are early stage (e.g., vaporware). Over time, we hope to see more projects in production, but few are ready yet.\n\n![landscape-map](hc-landscape-map-v14.png)\n\nHave a better way of organizing the landscape? Did we miss a company? Submit a pull request. You can fork the [landscape map slide (Google Slides)](https://docs.google.com/presentation/d/1yJ9d4w0HpSJ8Wccc3hQQGNmZmqCSwExiFOFWXPVaPvY/edit?usp=sharing). *To add your company to the map, please add your logo to the [Logos folder](https://github.com/acoravos/healthcare-blockchains/tree/master/logos) when making a pull request or else we will be unable to accept your request.*\n\n## Healthcare Projects using Blockchain Technologies\n*Projects listed in alphabetical order*\n\nTo update this list, submit a pull request.\n\n|  Project  | Background (400 characters or less) | Contact |\n|:---|:---|:---|\n|[Accenture](https://www.accenture.com/us-en/insight-perspectives-health-healthcare-innovation) | Accenture is a global professional services company that includes strategy, consulting, digital technology and operations services. Accenture partnered with Microsoft and Avanade to develop an identity prototype based on blockchain technology that could provide a digital identity for 1.1 billion people who don't have a formal ID. ||\n|[Amchart](https://amchart.io/) | AMCHART is a patient driven EHR on a hybrid public/private blockchain with AI for analytics and an incentive drive model for better outcomes. The incentive drive model is based on maintenance of health records, wellness program participation, population health, and data sharing with certified partners for analytics and proactive healthcare management. |@AMCHART4ALL|\n|[Astri](https://www.astri.org/) | The Chinese government formed Astri, formally known as the Hong Kong Applied Science and Technology Research Institute. Astri developed a health technology platform that aims to drive disruption in the traditional healthcare field with preventative health monitoring, medical computing and diagnostics.|corporate@astri.org|\n|[BitMark](https://bitmark.com/) | UC Berkeley and Bitmark partner to bring data donation to public health studies. Bitmark technology allows users to take ownership of their digital lives and help advance the frontiers of public health. Read this [Medium post](https://blog.bitmark.com/uc-berkeley-and-bitmark-partner-to-bring-data-donation-to-public-health-studies-3e9a17891432) on the BitMark UC Berkeley partnership. |support@bitmark.com|\n|[BLOCK M.D.](https://www.block-md.com/) | \u201cBLOCK M.D.\u201d is the platform for Health Information Exchange (HIE) and Electronic Health Records (EHR) on enterprise-grade, permissioned-based blockchain technology. This platform enables secure, high-data-integrity interoperability across hospitals, healthtech startups, labs, insurances, regulators and, definitely, patients through well-defined API and data standard. The company is partnering with Thai government for trial in 2018. |hello@smartcontractthailand.com|\n|[Blockchain Health](https://blockchainhealth.co/) | Blockchain Health is a software company that provides healthcare organizations with HIPAA-compliant blockchain solutions. Users can share health data with researchers using the integrated platform, which creates a tamperproof chain of information custody.|info@blockchainhealth.co|\n|[BlockCypher](https://blockcypher.com)|BlockCypher provides blockchain agnostic web services and infrastructure. Instead of forcing everyone to use one blockchain, BlockCypher enables healthcare organizations and patients to leverage multiple blockchains-- and use the blockchain best suited for a particular use case. For example, BlockCypher enables users to use the Patientory network to manage medical information and pay for services or medication using the Dash network. BlockCypher also provides a proof of patient identity across blockchains, e.g. Ethereum and Dash blockchains.|karen@blockcypher.com|\n|[Blockpharma](https://www.blockpharma.com/) | Blockpharma is a French start-up focused on solutions to trace drug sales online. Blockpharma developed an application programming interface that can plug into pharmaceutical companies' information systems, so when the companies release product information and QR codes, the blockchain records subsequent transactions.|contact@blockpharma.com|\n|[Bloq](http://bloq.com/) | Bloq produces enterprise grade blockchain technologies to organizations across industries. The company's bloqEnterprise software solution allows users to create, test, update and customize permissioned blockchains; bloqThink provides the strategic architecting, design, development and education for bloqEnterprise; and bloqLabs provides space for blockchain research and testing.|hello@bloq.com|\n|[Bowhead Health](https://bowheadhealth.com/) | The Bowhead platform comprises of the Bowhead device which monitors a customer\u2019s biometric data to dispense personalized supplements and medicine. The patent pending \u201cAnonymized Health Token\u201d allows customers and Bowhead token holders to be compensated for the leasing of medical data, and patients have full control of this by means of smart contracts. We believe patient data is some of the most valuable data in the world. The first health survey game is due during the third quarter of 2017 and Bowhead hardware device trial for 200 people due in the second quarter of 2018.||\n|[Bron.tech](https://bron.tech/) | Bron.tech uses blockchain powered by Ethereum, a decentralized platform for applications, to create a decentralized infrastructure for data wallets. The company distributes data storage and ensures integrity while also rewarding users with a native digital currency managed on the blockchain. Users contribute data in exchange for the company's digital currency, cash or offers from business partners.|info@bron.tech|\n|[burstIQ](http://www.burstiq.com/) | Founded in 2015, burstIQ's platform leverages blockchain and machine intelligence to bring together disparate data sources into a unified, HIPAA-compliant data repository. The platform is fully operational with multiple business customers; in 2016, the platform processed 25 billion data points. BurstIQ's HealthWallet allows users to buy, sell, donate, license or loan data; the LifeGraph platform brings together an individual's health data in one place and allows users to manage data through smart contracts. BurstChain is the company's big data blockchain platform for securely managing large, complex health data sets.||\n|[CareChain](https://www.carechain.io) | CareChain is a European consortium to establish public permissioned infrastructure to manage health data owned and controlled by no one except the rightful owners - the individuals. |info@carechain.io|\n|[Chronicled](https://www.chronicled.com/) | Chronicled launches pharma initiative.  Blockchain startup Chronicled and LinkLab have launched The MediLedger Project, a joint venture aimed at exploring blockchain solutions for the pharma industry. Genentech, a member of the Roche group, Pfizer, AmerisourceBergen, and McKesson have already signed on.|support@chronicled.com|\n|[Chemonics](http://www.chemonics.com/Pages/Home.aspx) | Chemonics is an international development consulting firm spanning 70 countries and industries. In October 2016, Chemonics and BanQu partnered to establish the Blockchain for Development Solutions Lab to build, test and scale blockchain solutions that aim to reduce poverty and increase the effectiveness of social programs.||\n|[CoverUS](https://www.coverus.io)| CoverUS is a social venture that leverages blockchain and other technologies to put people in control of their personal health data, helping to close the financial gap in healthcare and promote greater efficiency in the health systems that are of vital importance to society. ||\n|[Chronicled](https://www.chronicled.com/) | Chronicled launches pharma initiative.  Blockchain startup Chronicled and LinkLab have launched The MediLedger Project, a joint venture aimed at exploring blockchain solutions for the pharma industry. Genentech, a member of the Roche group, Pfizer, AmerisourceBergen, and McKesson have already signed on.|support@chronicled.com|\n|[Curisium](https://www.curisium.com/)|The Curisium platform deploys blockchain and secure computation technologies to allow payers, providers and life science companies to engage in patient-centric value-based contracts.|info@curisium.com|\n|[DeepMind Health](https://deepmind.com/blog/trust-confidence-verifiable-data-audit/)| Google's DeepMind Health is working on a blockchain-like [\"Verifiable Data Audit\"](https://deepmind.com/blog/trust-confidence-verifiable-data-audit/) to ensure auditability, the ability to show and justify if logs are challenged. DeepMind sees Verifiable Data Audit as a powerful complement to this scrutiny, giving partner hospitals an additional real-time and fully proven mechanism to check how DeepMind is processing data.||\n|[Doc.AI](https://doc.ai/) | Doc.AI's Robo-Genomics platform is a deep conversational agent designed to improve genetic data comprehension and provide decision support. The agent can converse on disease, traits, pharmacogenomics and family planning. Doc.Ai's founder Walter De Brouwer was one of three parties that executed the first life insurance contract on the public blockchain with bitcoin in January 2017.|info@doc.ai|\n|[EncrypGen](https://www.encrypgen.com/)|Encrypgen provides next generation software for genomic data empowering patients and donors, facilitating health, business, and science in a safe environment.|drkoepsell@encrypgen.com|\n|[Factom](https://www.factom.com/) | Factom is a blockchain-as-a-service technology company that received $8 million in Series A funding in April 2017. In November 2016, the Bill and Melinda Gates Foundation awarded Factom a grant to develop an infrastructure for medical records on the company's blockchain.||\n|[Gem](https://gem.co/health/) | Gem is an enterprise blockchain company. The GemOS enterprise platform for healthcare allows all stakeholders secure access to shareable data with the right permissions. The platform is in compliance with HIPAA, streamlining communication along the continuum of care. Gem entered into a partnership with Philips in 2016 to explore how blockchain can support the patient-centered approach to care. At Gem, we're building towards a blockchain network for the global community of companies that take part in the continuum of healthcare. Blockchain technology addresses the trade-off between personalized care and operational costs by connecting the ecosystem to universal infrastructure. Shared infrastructure allows us to create global standards without compromising privacy and security.|hello@gem.co|\n|[Guardtime](https://guardtime.com/) | Guardtime's platform is designed for data and systems security at the industrial level. The company partnered with the Estonian eHealth Foundation in February 2016 to accelerate the adoption of blockchain-based transparency and auditable lifecycle management for patient records. The partnership integrated KSI blockchain with existing Oracle databases for increased security, transparency, auditability and governance for electronic systems and patient records.||\n|[Hashed Health](https://hashedhealth.com/) | Hashed Health is a blockchain development studio focused on building healthcare applications within a product-focused collaborative ecosystem. To empower its enterprise partners, Hashed Health provides value-added services such as product management, product development, business advisory, education, and technology support services for blockchain solutions and distributed networks.Based in Nashville, Tennessee, Hashed Health\u2019s healthcare experts focus on ensuring that business problems drive the appropriate technical solutions. By convening existing networks with engaged developer communities actively exploring, piloting, and developing applications, we are able to launch new more effective and novel solutions.|info@hashedhealth.com|\n|[healthbase](https://www.healtbase.digital) | healthbase started as an EMR software for dentists called smiledoc. With the prinicpals of creating a strong user experience to outclass the current legacy softwares on the market the co-founders realized that using blockchain would help bring this concept to a larger population. They have currently branched out to the larger EMR market to capture with the goal of allowing a patient to hold their own medical date as they move to different healthprofessionals. With a strong belief in userexperience and a backend that encorporates IPFS and the ethereum network healthbase is a project to watch carefully. Join our [Telegram](https://t.me/joinchat/Fsvr7g48R1utm-ajn0jaTw) to join in on our conversation.|info@healthbase.digital| \n|[Health Wizz](https://www.healthwizz.net/) | Health Wizz is a wellness application platform that acquired healthcare blockchain company kreateloT in January 2017. The combined company is working on Mercatus, a platform allowing individuals to build their own digital health portfolio and grant access to medical researchers, health data scientists, pharmaceutical companies and others in one marketplace to advance precision medicine. Mercatus would allow users to write smart contracts on Ethereum blockchain to trade health data for crypto-currency.||\n|[Healthcoin](https://www.healthcoin.com/) (A ConsenSys Project) | Healthcoin is the world's first blockchain-enabled platform for diabetes prevention. Our mission is to allow employers, insurers and governments across the globe to incentivize and manage their population's lifestyle change. Unlike the vast majority of rewards programs, Healthcoin is biomarker-based. We measure the actual blood lab indicators of disease, rather than just correlates like steps or stress. Our blockchain uses these biomarkers to generate tokenized \"prevention certificates\" that any (permissioned) stakeholder can verify and reward. By accumulating biomarkers on the blockchain, we also create innovative data analytics: patient-owned health records with data viz, population health management tools, and a potentially vast longitudinal research trial.|info@healthcoin.com|\n|[HealthCombix](http://www.healthcombix.com/) | HealthCombix's platform is a token-based healthcare payment and risk management network enabling payments, data asset monetization and risk adjustment. The platform preserves digital privacy while allowing for interoperable data exchange, giving patients and providers control over the data. The company believes blockchain technology will allow consumers to control the brokerage of their data for research, precision health, clinical trials, payment and disease intervention.|disrupt@healthcombix.com|\n|[Health Linkages](http://healthlinkages.com/)|Health Linkages is the Data Provenance Company. We use blockchain-inspired technology to enable healthcare institutions to trust, protect and comfortably share their data.|info@HealthLinkages.com|\n|[Hearthy](https://hearthy.co/) | Hearthy wants to create a decentralized, open and sustainable ecosystem to improve health care access to everyone, regardless of income. Hearthy\u2019s ecosystem will make healthcare more efficient, agnostic to jurisdiction and patient-centered.|\n|[HIE of One](https://http://hieofone.org/)|HIE of One is a free software project developing tools for patients to manage their own health records.[1] HIE stands for Health Information Exchange, an electronic network for sharing health information across different organizations, hospitals, providers, and patients. This is one of a growing number of tools for encrypted data exchange within the health care sphere. A proposal for using HIE of One in conjunction with blockchain technology was reviewed by the US Office of the National Coordinator (ONC), winning an award from the ONC. Code integrating Consensys uPort is on their GitHub.|agropper@healthurl.com|\n|[HIT Foundation](https://hit.foundation/) | HIT Foundation offers an online marketplace for personal health data that allows users and patients to trace data usage and participate in its monetization. It is the first ecosystem that allows everybody to get paid for health information instead of paying others to process or store it. The distributed system supports the global execution of new or existing business cases for information seekers on top of the HIT platform without the need for intermediaries. |info@hit.foundation|\n|[Hyperledger](https://www.hyperledger.org/) | The Hyperledger Healthcare Work Group identifies opportunities for open source software development projects to host on Hyperledger, an operating system for marketplaces, data sharing networks, micro-currencies and decentralized digital communities. In May 2017, Hyperledger hosted a Hyderabad Meetup to discuss the most beneficial blockchain applications in healthcare.||\n|[IBM Blockchain](https://www.ibm.com/blockchain/) | IBM Blockchain is the first managed service for Hyperledger Fabric, enabling the creation of blockchain business networks that owners can control and distribute across different organizations. In August 2016, IBM won the HHS Office of the National Coordinator of Health Information Technology's blockchain health IT ideation challenge with a paper describing the potential impact blockchain could have on resolving interoperability, scalability and privacy challenges in healthcare.||\n|[Iryo](https://iryo.io/)|Iryo network is the world's first participatory healthcare ecosystem build on standardised zero-knowledge electronic health record storage. Disrupting the landscape of traditional health IT by promoting standardised health-data archetypes, redefining medical data ownership and securing from unauthorised access.|info@iryo.io|\n|[Luna](https://www.lunadna.com/)|A genomic and medical research database powered by the blockchain. Luna is a community owned database that rewards individuals Luna Coins for contributing their DNA and other medical information.|info@lunaDNA.com|\n|[Lympo](https://lympo.io/)|Lympo.io is a fitness wallet that will utilise the data users track on their smartphones and wearables to reward LYM tokens for achieved fitness and mindfulness goals and build a healthy lifestyle ecosystem based on user-controlled fitness data. Its players will range from health insurances and employers incentivizing healthy lifestyle to developers submitting new data applications.|ada@lympo.io|\n|[MediBloc](https://medibloc.org/) | MediBloc is creating a decentralized healthcare information ecosystem on blockchain where medical records can be kept safely and securely transferred by their rightful owners, the patients and not the hospitals.  MediBloc is the first healthcare blockchain company that targets Asia where PHR disruption makes much more sense than the US or European PHR market.||\n|[Medicalchain](https://medicalchain.com/en/) | Medicalchain uses blockchain technology to store health records securely so physicians, hospitals, laboratories, pharmacists and health insurers can request a patient's permission to access the record as well as record transactions on the distributed ledger. Medicalchain is set to launch in September 2017.| contact@medicalchain.com |\n|[Medichain](https://medichain.online/) | MediChain gives patients ownership of their own medical data. MediChain is a distributed ledger for patient\u2019s medical data. It allows patients to store their own data in a secure way and gives access to specialists anywhere regardless of the payer network or EMR (Electronic Medical Record) used.| info@medichain.online |\n|[MedRec](https://www.media.mit.edu/research/groups/1454/medrec) | Graduate student researchers at Massachusetts Institute of Technology in Boston developed MedRec, a system for managing medical records using the Ethereum, a decentralized platform for applications. MedRec is designed for patients to control their medical data, including clinical EHR records and data from personal health wearables like Fitbit. Patients can securely allow healthcare providers, researchers and family members to access their data. Medical researchers can also mine the data to sustain the blockchain authentication log and receive anonymous medical metadata in return.||\n|[Microsoft](https://azure.microsoft.com/en-us/solutions/blockchain/) | In June, Microsoft partnered with Accenture to build a blockchain prototype for healthcare as well as other industries. The blockchain will create a digital identity for 1.1 billion people around the world who don't have a formal identity, including refugees. The current model builds on Accenture's blockchain and operates on Microsoft Azure's cloud platform.||\n|[MintHealth](https://www.minthealth.io/) | MintHealth announced the launch of its self-sovereign health record platform at the Connected Health Conference in Boston in October 2017. Powered by blockchain technology, the service allows patients to access their health records in real-time through a mobile or web app, and features a specialized digital currency as an incentive for preferred patient behaviors.|info@minthealth.io|\n|[Netki](https://netki.com/) | Netki aims to support blockchain use with the Open Source, Open Standards tools for digital identity. The company removes risk and compliance barriers to blockchain projects. In May 2017, Netki launched a digital identity service to make blockchain safe for business, finance and healthcare applications. The Digital ID works across public and private blockchains to reduce risk associated with blockchain transactions.||\n|[NeuroMesh](http://www.neuromesh.co/) | A vaccine for your IoT. Neuromesh uses the Bitcoin blockchain to protect expensive equipment like X-Rays and MRI machines from attacks.||\n|[OPAL/Enigma](https://www.trust.mit.edu/projects) | Published a paper on Blockchain and Health IT: Algorithms, Privacy and Data. Check out [the whitepaper](https://www.healthit.gov/sites/default/files/1-78-blockchainandhealthitalgorithmsprivacydata_whitepaper.pdf). | |\n|[OpenMined](https://openmined.org/) | The OpenMined project is volunteer-only, open-source project aiming to create the world\u2019s largest decentralized network of encrypted personal information. In this world, the user gets to own their information and store it themselves, while data scientists and developers pay for anonymized access to this information. The community has started to explore healthcare applications. Join the [Slack](https://openmined.slack.com/) for more details. | |\n|[Patientory](https://patientory.com/) | Patientory was founded in 2016 through the Boomtown Health-Tech Accelerator in Boulder, Colo. Patientory collaborates with Denver-based Colorado Permanente Medical Group, a member of Oakland, Calif.-based Kaiser Permanente. Patientory allows users to create profiles on a mobile app to securely store, manage and share medical information. The solution is compatible with Epic, Cerner, Allscripts and Meditech, among other EHR systems.|info@patientory.com|\n|[Peer Ledger](https://peerledger.com/) | Peer Ledger provides an identity Bridge product as an administrator portal to enable existing known IDs to be tightly coupled with blockchain user IDs, and ID management such as revocation, delegation, multiple factor authentication, registering/blacklisting of blockchain applications, and the secure management of private keys. The Bridge also provides a user portal to sign with blockchain keys (e.g. Hyperledger, Bitcoin, and Ethereum keys), and to create auxiliary workflows e.g. sign to consent or approve. This product enables organizations to on-board existing known users securely and conveniently on their corporate blockchain applications when those come into play later in 2018 - 2020. We have proven the product out in a collaboration with SAFE-BioPharma and Zentry/Synchronoss via strongly linking Verizon Universal IDs with blockchain IDs.|sales@peerledger.com|\n|[PointNurse](https://www.pointnurse.com/) | Founded in 2014, PointNurse is a virtual and on-demand care platform that allows nurses to lead consumer-focused care outside of the hospital and clinic setting. The platform is a blockchain-based digital community enabling licensed professionals to engage in secure and private conversations with patients in remote locations.|team@pointnurse.com|\n|[PokitDok](https://pokitdok.com/) | PokitDok provides a secure software development platform for the business of health. The company powers DokChain, a distributed network of transaction processors operating on financial and clinical data across the healthcare industry, integrated to PokitDok's clearinghouse and API platform with Identity, Personal Health Records and Crypto Asset framework components, as well as client frameworks for mobile and web. As of March 2017, the company had raised $48 million to develop DokChain.||\n|[ProofWork](https://www.proof.work/)| Leveraging blockchain immutable trust to form the world's first patient-first healthcare ecosystem. We create one single version of truth in healthcare, always in sync. Practice management. Electronic Health Records. Medical research data exchange. ||\n|[ScalaMed](http://www.scalamed.com/) | ScalaMed believes in centering and empowering the consumer on their healthcare journey. ScalaMed is building a scalable, integrated and secure platform for managing healthcare transactions and data. ScalaMed is beginning its healthcare revolution through providing a decentralized application for patients, doctors and pharmacists to manage, prescribe and dispense prescription medicines.||\n|[Spiritus](http://www.spirituspartners.com/)|Spiritus offers cloud-based assurance software for safe, secure and compliant use of critical assets at the point of use and accountability. Overcome costly, inefficient siloes and gain necessary transparency, verifiability and auditability across an asset's service life through a blockchain-enabled, permissioned network. Rely on Spiritus to be sure an asset's in good order - from service providers and operators, upstream to manufacturers and distributors, and downstream to field service engineers, MROs and specialists in testing, inspection, certification and audit.  With support from the Scottish government, the company has undertaken a pilot with NHS Scotland and a leading cybersecurity researcher at Edinburgh Napier University.|sramonat@spirituspartners.com|\n|[SimplyVital Health](https://www.simplyvitalhealth.com/) |Intentionally simple care coordination platform backed by Blockchain technology to create a tamper-proof audit trail. Providers use our tool to support care coordination in Bundle payments and to attain MACRA requirements.| LetsDoThis@simplyvitalhealth.com |\n|[Tierion](https://tierion.com/) | Tierion's HashAPI allows developers to anchor up to 100 records per second on the blockchain for free, with time stamping and data security. Tierion was the first company to join Philips' Blockchain Lab to explore using blockchain in healthcare. The company has also partnered with Microsoft to build a service linking data to blockchain to prove the data's integrity and existence.||\n|[YouBase](https://www.youbase.io/) | YouBase combines blockchain compatible technologies to deliver a secure and flexible container for independent data. The company's solution allows individuals to maintain their data and identity across networks and share data as they chose. Youbase.io is designed to decentralize sensitive consumer and personal information while compiling a single source of anonymous data.|info@youbase.io|\n|[Shivom](http://www.shivom.io/) | Shivom combines genome sequencing, artificial intelligence, cryptogrpahy, and next-gen distributed ledger technology, aiming to build the world's largest genomics & precision medicine ecosystem. Other healthcare companies can 'dock' their solution (Apps, Service) to the Shivom ecosystem. In addition building a genetic counseling network and not-for-profit R&D organization.|info@shivom.io|\n|[Zenome Platform](https://zenome.io/)| Zenome is a blockchain-based genomic ecosystem built on the interaction between three different types of information: genomic, personal, and financial data.| |\n\n## Where are the Healthcare ICOs?\nThankfully [vincek39](https://github.com/vincek39) has come to our rescue and he's created a [Google Doc](https://docs.google.com/spreadsheets/d/1TANOZmuYtVhyn1C9PV6YLsOBlQNOEOBExB7u2_Kkork/edit#gid=0) of the ICOs and token sales in the healthcare industry, all 38 of them (as of 12/1/18).\n"
 },
 {
  "repo": "itachi9604/healthcare-chatbot",
  "language": "Python",
  "readme_contents": "# healthcare-chatbot\na chatbot based on sklearn where you can give a symptom and it will ask you questions and will tell you the details and give some advice.\n"
 },
 {
  "repo": "prasadseemakurthi/Deep-Neural-Networks-HealthCare",
  "language": "Python",
  "readme_contents": "# Deep Learning in Healthcare and Computational Biology\n\n## NOTE/ANNOUNCEMENT to what we intend to do here!\n\n---------------------------\nAll this stuff is collected from the github which was not well maintained. I will soon reorganize this to reflect recency (as a lot of work is happening in comp biology that CNNs are using lately -- hopefully CapsNETs too) and some easy to undrstand structure.\n\nKey collaborators and researchers (besides me) will be some budding computational biologists such as [Huadong Liao](https://github.com/naturomics) who did an awesome job with recent Capsule Networks and will work with me to not only do awesome projects across the globe but also work and travel with me to deliver workshops for both for and non-profit organizations.\n\nIf you are a researcher, enthusiast or even someone just interested and  want to join computational biology researches with deep learning, then contact me at : tarry.singh@gmail.com\n\nSo stay tuned!!!\n\nThanks,\n\nTarry Singh\n\n---------------------------\n\n<img src='images/compbio.jpg'>\n\nThis is a list of implementations of deep learning methods to biology, originally published on [Follow the Data](https://followthedata.wordpress.com/). There is a slant towards genomics because that's the subfield that I follow most closely.\n\nPlease, contribute to this growing list, especially in categories that I haven't covered well! Also, do add your contributions to [GitXiv](http://gitxiv.com/) as well if you can.\n\nYou might also want to refer to the [curaterd list of deepbio work](#awesome-deep-biology) below.\n* Data driven decision making\n* Questions -> Data -> Models/Tools\n\n# Table of Contents\n1. [Overview](#overview)\n2. [EHR data](#ehr-data)\n3. [Insurance claims data](#claims)\n4. [Clinical notes](#clinical-notes)\n5. [Image data](#image-data)\n6. [Time series data](#time-series-data)\n7. [Genomics data](#genomics-data)\n8. [Deep Learning Computational biology](#deep-computational-biology)\n9. [Curated List](#awesome-deep-biology)\n\n\n\n\n## Overview\n|Data type|Models/Tools|Applications|\n|---|---|---|\n|-EHR data <br/>-Insurance claims data |ML(logistic regression,XGBoost)|Predict outcomes (disease, death, readmission etc.)|\n|-Clinical notes <br/>-Conversation text data|-Rule based approach(regular expression)<br/>-Deep learning apporach|-Extract concepts from clinical notes <br/>-Knowledge graphs<br/>-Chat-bot<br/>-QA system|\n|Medical image data (X-ray, CT, OCR image etc.)|CNN|-Detection: diagnosis of skin cancer lung nodule or diabetic reinopathy<br/>-Segmentation of tumor, histopathology|\n|Time series data (EEG, ECG, vital sign data etc.)|HMM,RNN,CNN|-Heart disease<br/>-Sleep disorder(apnea)<br/>-ICU monitoring|\n|Genomics data|GATK,QIIME|-Cancer mutation identification<br/>-Biomarker identification<br/>-Durg discovery |\n|Other data (hospital operational data)|-ML(regression)<br/>-Queueing model|-Reduce operational cost<br/>-Improve patient experience<br/>-ER wait time and queueing|\n\n## EHR data\n\n\n|Prediction outcomes|Models/Tools|Data type|Sample size|Reference|Year|\n|---|---|---|---|---|---|\n|Review||||[Mining electronic health records: towards better research applications and clinical care](https://www.nature.com/nrg/journal/v13/n6/full/nrg3208.html)|2012|\n|Review||||[Opportunities and challenges in developing risk prediction models with electronic health records data: a systematic review](https://academic.oup.com/jamia/article/24/1/198/2631444/Opportunities-and-challenges-in-developing-risk)|2016|\n|heart failure|-logistic regression<br/>-random forest|longitudinal EHR data|1684 heart failure cases and 13525 matched controls|[Early Detection of Heart Failure Using Electronic Health Records](http://circoutcomes.ahajournals.org/content/9/6/649.long)|2016|\n|heart failure (review)||||[Population Risk Prediction Models for Incident Heart Failure](http://circheartfailure.ahajournals.org/content/8/3/438.long)|2015|\n|Kidney transplant graft failure|Cox regression|10-years EHR data|69,440 kidney transpants|[A comprehensive risk quantification score for deceased donor kidneys: the kidney donor risk index](https://insights.ovid.com/pubmed?pmid=19623019)|2009|\n\n\n## Clinical notes\n|Prediction outcomes|Models/Tools|Data type|Sample size|Reference|Year|\n|---|---|---|---|---|---|\n|Review||||[Realizing the full potential of electronic health records: the role of natural language processing](https://academic.oup.com/jamia/article-lookup/doi/10.1136/amiajnl-2011-000501)|2011|\n|Review||||[Natural language processing: an introduction](https://academic.oup.com/jamia/article-lookup/doi/10.1136/amiajnl-2011-000464)|2011|\n|Negation|Regular expression and rule-based approach|Clinical reports|2060 discharge summaries|[A simple algorithm for identifying negated findings and diseases in discharge summaries](http://www.sciencedirect.com/science/article/pii/S1532046401910299?via%3Dihub)|2001|\n|||||[Using electronic health records to drive discovery in disease genomics](https://www.nature.com/nrg/journal/v12/n6/pdf/nrg2999.pdf)||\n|NER||discharge summaries|826 notes|[A study of machine-learning-based approaches to extract clinical entities and their assertions from discharge summaries](https://academic.oup.com/jamia/article-lookup/doi/10.1136/amiajnl-2011-000163)|2011|\n\n\n\n\n## Image data\n|Prediction outcomes|Models/Tools|Data type|Sample size|Reference|Year|\n|---|---|---|---|---|---|\n|Diabetic retinopathy|CNN|retinal fundus images|128175 retinal images|[Development and Validation of a Deep Learning Algorithm for Detection of Diabetic Retinopathy in Retinal Fundus Photographs](http://jamanetwork.com/journals/jama/fullarticle/2588763)|2016|\n|Skin cancer |CNN|skin images|129,450 skin images|[Dermatologist-level classification of skin cancer with deep neural networks](https://www.nature.com/nature/journal/v542/n7639/full/nature21056.html)|2017|\n|Tumor|CNN|Pathology images|400+110 slides|[Detecting Cancer Metastases on Gigapixel Pathology Images](https://arxiv.org/abs/1703.02442)|2017|\n|||||[Deep Learning Automates the Quantitative Analysis of Individual Cells in Live-Cell Imaging Experiments](http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005177)||\n\n\n\n## Time series data\n|Prediction outcomes|Models/Tools|Data type|Sample size|Reference|Year|\n|---|---|---|---|---|---|\n|sinus rhythm and atrial fibrillation|34-layer convolutional neural network (CNN)|single-lead ECG|-(Train) 64,121 ECG records from 29,163 patients<br/>-(Test) 336 records from 328 unique patients|[Cardiologist-Level Arrhythmia Detection with Convolutional Neural Networks](https://arxiv.org/abs/1707.01836)|2017|\n|Hand movements|CNN|sEMG|67 intact subjects and 11 transradial amputees|[Deep Learning with Convolutional Neural Networks Applied to Electromyography Data: A Resource for the Classification of Movements for Prosthetic Hands](http://journal.frontiersin.org/article/10.3389/fnbot.2016.00009/full)|2016|\n|Review||ICU data||[Machine Learning and Decision Support in Critical Care](http://ieeexplore.ieee.org/document/7390351/?part=1)|2017|\n\n\n\n## Genomics data\n|Prediction outcomes|Models/Tools|Data type|Sample size|Reference|Year|\n|---|---|---|---|---|---|\n|Genetic variants|Exome NGS|NGS&EHR data|50,726 individuals|[Distribution and clinical impact of functional variants in 50,726 whole-exome sequences from the DiscovEHR study](http://science.sciencemag.org/content/354/6319/aaf6814)|2016|\n|Familial hypercholesterolemia|Exome NGS|NGS&EHR data|50,726 individuals|[Genetic identification of familial hypercholesterolemia within a single U.S. health care system](http://science.sciencemag.org/content/354/6319/aaf7000)|2016|\n\n\n## Other\n|Prediction outcomes|Models/Tools|Data type|Sample size|Reference|Year|\n|---|---|---|---|---|---|\n|Drug discovery|LSTM|Assay|12-27 assays|[Low data drug discovery with one-shot learning](http://pubs.acs.org/doi/full/10.1021/acscentsci.6b00367)|2017|\n|Tutorial||Image||[Deep learning models for health care: challenges and solutions](http://www-bcf.usc.edu/~liu32/icml_tutorial.pdf)|2017|\n|Tutorial||Image||[Deep learning in radiology: recent advances, challenges and future trends](https://ulasbagci.wordpress.com/2016/12/10/deep-learning-in-radiology-rsna-2016/)|2016|\n|Tutorial||||[Big data analytics for healthcare](https://www.siam.org/meetings/sdm13/sun.pdf)|2013|\n|Tutorial||Image||[Survey of deep learning in radiology](https://healthcare.ai/survey-of-deep-learning-in-radiology/)|2017|\n|ER wait time||ER visit time||[Accurate ED Wait Time Prediction](https://web.stanford.edu/~bayati/papers/edwait.pdf)|2017|\n\n\n## Deep Computational Biology\n\n# deeplearning-biology\n\nThis is a list of implementations of deep learning methods to biology, originally published on [Follow the Data](https://followthedata.wordpress.com/). There is a slant towards genomics because that's the subfield that I follow most closely.\n\nPlease, contribute to this growing list, especially in categories that I haven't covered well! Also, do add your contributions to [GitXiv](http://gitxiv.com/) as well if you can.\n\nYou might also want to refer to the [curaterd list of deepbio work](#awesome-deep-biology) below.\n\n## Table of contents\n* [Reviews](#reviews)\n* [Chemoinformatics and drug discovery](#chemo)\n* [Proteomics](#proteomics)\n* [Generic 'omics tools](#omics)\n* [Genomics](#genomics)\n  - [Gene expression](#genomics_expression)\n  - [Predicting enhancers and regulatory elements](#genomics_enhancers)\n  - [Methylation](#genomics_methylation)\n  - [Single-cell applications](#genomics_single-cell)\n  - [Non-coding RNA](#genomics_non-coding)\n  - [Population genetics](#genomics_pop)\n* [Neuroscience](#neuro)\n\n## Reviews <a name=\"reviews\"></a>\n\nThese are not implementations as such, but contain useful pointers.\n\n**Opportunities And Obstacles For Deep Learning In Biology And Medicine** [[bioRxiv preprint](http://biorxiv.org/content/early/2017/05/28/142760)]\n\nThis impressive collaborative review was written completely in the open on [Github](https://github.com/greenelab/deep-review). It is focused on discussing how deep learning may be able to transform patient classification and treatment as well as fundamental biological research in the future, and what the main obstacles are that could prevent it from happening. A lot of interesting points are brought up here. Together with the review listed below, which has a more technical slant, you will get a good overview of how deep learning is used and can be used in biology and medicine.\n\n**Deep learning for computational biology** [[open access paper](http://msb.embopress.org/content/12/7/878)]\n\nThis is a very nice review of deep learning applications in biology. It primarily deals with convolutional networks and explains well why and how they are used for sequence (and image) classification.\n\n**Deep learning for health informatics** [[open access paper](http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7801947)]\n\nAn overview of several types of deep nets and their applications in translational bioinformatics, medical imaging, \"pervasive sensing\", medical data and public health.\n\n## Chemoinformatics and drug discovery <a name=\"chemo\"></a>\n\n**Neural graph fingerprints** [[github](https://github.com/HIPS/neural-fingerprint)][[gitxiv](http://gitxiv.com/posts/DFtFytneou3SXLuSM/convolutional-networks-on-graphs-for-learning-molecular)]\n\nA convolutional net that can learn features which are useful for predicting properties of novel molecules; \u201cmolecular fingerprints\u201d. The net works on a graph where atoms are nodes and bonds are edges. Developed by the group of Ryan Adams, who co-hosts the very good [Talking Machines](http://www.thetalkingmachines.com/) podcast.\n\n**Deep-learning models for Drug Discovery and Quantum Chemistry** [[github](https://github.com/deepchem/deepchem)][[Python library](http://deepchem.io/)][[preprint](https://arxiv.org/abs/1611.03199)]\n\nThis is a \"... [P]ython library that aims to make the use of machine-learning in drug discovery straightforward and convenient\" which checks a lot of boxes when it comes to advanced is deep learning: one-shot learning, graph convolutional networks, learning from less data, and LSTM embeddings. According to the GitHub site, \"DeepChem aims to provide a high quality open-source toolchain that democratizes the use of deep-learning in drug discovery, materials science, and quantum chemistry.\"\n\n## Generic 'omics tools <a name=\"omics\"></a>\n\n**Continuous Distributed Representation of Biological Sequences for Deep Genomics and Deep Proteomics**[[github](https://github.com/ehsanasgari/Deep-Proteomics)][[paper](http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0141287)]\n\nThe GitHub summary reads: \"We introduce a new representation for biological sequences. Named bio-vectors (BioVec) to refer to biological sequences in general with protein-vectors (ProtVec) for proteins (amino-acid sequences) and gene-vectors (GeneVec) for gene sequences, this representation can be widely used in applications of deep learning in proteomics and genomics. Biovectors are basically n-gram character skip-gram wordvectors for biological sequences (DNA, RNA, and Protein). In this work, we have explored biophysical and biochemical meaning of this space. In addition, in variety of bioinformatics tasks we have shown the strength of such a sequence representation.\"\n\n## Proteomics <a name=\"proteomics\"></a>\n\n**Pcons2 \u2013 Improved Contact Predictions Using the Recognition of Protein Like Contact Patterns** [[web interface](http://c2.pcons.net/)]\n\nHere, a \u201cdeep random forest\u201d with five layers is used to improve predictions of which residues (amino acids) in a protein are physically interacting which each other. This is useful for predicting the overall structure of the protein (a very hard problem.)\n\n## Genomics <a name=\"genomics\"></a>\n\nThis category is divided into several subfields.\n\n### Gene expression <a name='genomics_expression'></a>\n\nIn modeling gene expression, the inputs are typically numerical values (integers or floats) estimating how much RNA is produced from a DNA template in a particular cell type or condition.\n\n**ADAGE \u2013 Analysis using Denoising Autoencoders of Gene Expression** [[github](https://github.com/greenelab/adage)][[gitxiv](http://gitxiv.com/posts/M9Dnc8HbKvNgsSp5D/adage-analysis-using-denoising-autoencoders-of-gene)]\n\nThis is a Theano implementation of stacked denoising autoencoders for extracting relevant patterns from large sets of gene expression data, a kind of feature construction approach if you will. I have played around with this package quite a bit myself. The authors initially published a [conference paper](http://www.worldscientific.com/doi/abs/10.1142/9789814644730_0014) applying the model to a compendium of breast cancer (microarray) gene expression data, and more recently posted a paper on [bioRxiv](http://biorxiv.org/content/early/2015/11/05/030650) where they apply it to all available expression data (microarray and RNA-seq) on the pathogen Pseudomonas aeruginosa. (I understand that this manuscript will soon be published in a journal.)\n\n**Learning structure in gene expression data using deep architectures** [[paper](http://biorxiv.org/content/early/2015/11/16/031906)]\n\nThis is also about using stacked denoising autoencoders for gene expression data, but there is no available implementation (as far as I could tell). Included here for the sake of completeness (or something.)\n\n**Gene expression inference with deep learning** [[github](https://github.com/uci-cbcl/D-GEX)][[paper](http://biorxiv.org/content/early/2015/12/15/034421)]\n\nThis deals with a specific prediction task, namely to predict the expression of specified target genes from a panel of about 1,000 pre-selected \u201clandmark genes\u201d. As the authors explain, gene expression levels are often highly correlated and it may be a cost-effective strategy in some cases to use such panels and then computationally infer the expression of other genes. Based on Pylearn2/Theano.\n\n**Learning a hierarchical representation of the yeast transcriptomic machinery using an autoencoder model** [[paper](http://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-015-0852-1)]\n\nThe authors use stacked autoencoders to learn biological features in yeast from thousands of microarrays. They analyze the hidden layer representations and show that these encode biological information in a hierarchical way, so that for instance transcription factors are represented in the first hidden layer.\n\n### Predicting enhancers and regulatory regions <a name='genomics_enhancers'></a>\n\nHere the inputs are typically \u201craw\u201d DNA sequence, and convolutional networks (or layers) are often used to learn regularities within the sequence. Hat tip to [Melissa Gymrek](http://melissagymrek.com/science/2015/12/01/unlocking-noncoding-variation.html) for pointing out some of these.\n\n**DanQ: a hybrid convolutional and recurrent deep neural network for quantifying the function of DNA sequences** [[github](https://github.com/uci-cbcl/DanQ)][[gitxiv](http://gitxiv.com/posts/aqrWwLoyg75jqNAYX/danq-a-hybrid-convolutional-and-recurrent-deep-neural)]\n\nMade for predicting the function of non-protein coding DNA sequence. Uses a convolution layer to capture regulatory motifs (i e single DNA snippets that control the expression of genes, for instance), and a recurrent layer (of the LSTM type) to try to discover a \u201cgrammar\u201d for how these single motifs work together. Based on Keras/Theano.\n\n**Basset \u2013 learning the regulatory code of the accessible genome with deep convolutional neural networks** [[github](https://github.com/davek44/Basset)][[gitxiv](http://gitxiv.com/posts/fhET6G7gnBrGS8S9u/basset-learning-the-regulatory-code-of-the-accessible-genome)]\n\nBased on Torch, this package focuses on predicting the accessibility (or \u201copenness\u201d) of the chromatin \u2013 the physical packaging of the genetic information (DNA+associated proteins). This can exist in more condensed or relaxed states in different cell types, which is partly influenced by the DNA sequence (not completely, because then it would not differ from cell to cell.)\n\n**DeepSEA \u2013 Predicting effects of noncoding variants with deep learning\u2013based sequence model** [[web server](http://deepsea.princeton.edu/job/analysis/create/)][[paper](http://www.nature.com/nmeth/journal/v12/n10/full/nmeth.3547.html)]\n\nLike the packages above, this one also models chromatin accessibility as well as the binding of certain proteins (transcription factors) to DNA and the presence of so-called histone marks that are associated with changes in accessibility. This piece of software seems to focus a bit more explicitly than the others on predicting how single-nucleotide mutations affect the chromatin structure. Published in a high-profile journal (Nature Methods).\n\n**DeepBind \u2013 Predicting the sequence specificities of DNA- and RNA-binding proteins by deep learning** [[code](http://tools.genes.toronto.edu/deepbind/)][[paper](http://www.nature.com/nbt/journal/v33/n8/full/nbt.3300.html)]\n\nThis is from the group of Brendan Frey in Toronto, and the authors are also involved in the company Deep Genomics. DeepBind focuses on predicting the binding specificities of DNA-binding or RNA-binding proteins, based on experiments such as ChIP-seq, ChIP-chip, RIP-seq,  protein-binding microarrays, and HT-SELEX. Published in a high-profile journal (Nature Biotechnology.)\n\n**DeeperBind - Enhancing Prediction of Sequence Specificities of DNA Binding Proteins** [[preprint](https://arxiv.org/pdf/1611.05777.pdf)]\n\nThis is an attempt to improve on DeepBind by adding a recurrent sequence learning module (LSTM) after the convolutional layer(s). In this way, the authors propose to capture a positional dimension that is lost in the pooling step in the original DeepBind design. They claim that benchmarking shows that this architecture leads to superior performance compared to previous work.\n\n**DeepMotif - Visualizing Genomic Sequence Classifications** [[paper](https://arxiv.org/abs/1605.01133)]\n\nThis is also about learning and predicting binding specificities of proteins to certain DNA patterns or \"motifs\". However, this paper makes use of a combination of convolutional layers and [highway networks](https://arxiv.org/pdf/1505.00387v2.pdf), with more layers than the DeepBind network. The authors also show how a learned classifier can generate typical DNA motifs by input optimization; applying back-propagation with all the weights held constant in order to find an input pattern that maximally activates the appropriate output node in the network.\n\n**Convolutional Neural Network Architectures for Predicting DNA-Protein Binding** [[code](http://cnn.csail.mit.edu/)][[paper](http://bioinformatics.oxfordjournals.org/content/32/12/i121.full)]\n\nThis work describes a systematic exploration of convolutional neural network (CNN) architectures for DNA-protein binding. It concludes that the convolutional kernels are very important for the success of the networks on motif-based tasks. Interestingly, the authors have provided a Dockerized implementation of DeepBind from the Frey lab (see above) and also provide EC2-laucher scripts and code for comparing different GPU enabled models programmed in Caffe.\n\n**PEDLA: predicting enhancers with a deep learning-based algorithmic framework** [[code](https://github.com/wenjiegroup/PEDLA)][[paper](http://biorxiv.org/content/early/2016/01/07/036129)]\n\nThis package is for predicting enhancers (stretches of DNA that can enhance the expression of a gene under certain conditions or in a certain kind of cell, often working at a distance from the gene itself) based on heterogeneous data from (e.g.) the ENCODE project, using 1,114 features altogether.\n\n**DEEP: a general computational framework for predicting enhancers** [[paper](http://nar.oxfordjournals.org/content/early/2014/11/05/nar.gku1058.full)][[code](http://cbrc.kaust.edu.sa/deep/)]\n\nAn ensemble prediction method for enhancers.\n\n**Genome-Wide Prediction of cis-Regulatory Regions Using Supervised Deep Learning Methods** (and several other papers applying various kinds of deep networks to regulatory region prediction) [[code](https://github.com/yifeng-li/DECRES)] (one [[paper](http://biorxiv.org/content/early/2016/02/28/041616)] out of several)\n\nWyeth Wasserman\u2019s group have made a kind of [toolkit](https://github.com/yifeng-li/DECRES) (based on the Theano tutorials) for applying different kinds of deep learning architectures to cis-regulatory element (DNA stretches that can modulate the expression of a nearby gene) prediction. They use a specific \u201cfeature selection layer\u201d in their nets to restrict the number of features in the models. This is implemented as an additional sparse one-to-one linear layer between the input layer and the first hidden layer of a multi-layer perceptron.\n\n**FIDDLE: An integrative deep learning framework for functional genomic data inference** [[paper](http://biorxiv.org/content/early/2016/10/17/081380)][[code](https://github.com/ueser/FIDDLE)[[Youtube talk](https://www.youtube.com/watch?v=pcLTUsOm5pc&feature=youtu.be&list=PLlMMtlgw6qNjROoMNTBQjAcdx53kV50cS&t=2411)]\n\nThe group predicted transcription start site and regulatory regions but claims this solution could be easily generalized and predict other features too. FIDDLE stands for Flexible Integration of Data with Deep LEarning. The idea (nicely explained by the author in the YouTube video above) is to model several genomic signals jointly using convolutional networks. This could be for example DNase-seq, ATAC-seq, ChIP-seq, TSS-seq, maybe RNA-seq signals (as in .wig files with one value per base in the genome).\n\n\n### Non-coding RNA <a name='genomics_non-coding'></a>\n\n**DeepLNC, a long non-coding RNA prediction tool using deep neural network** [[paper](http://link.springer.com/article/10.1007%2Fs13721-016-0129-2)] [[web server](http://bioserver.iiita.ac.in/deeplnc/)]\n\nIdentification of potential long non-coding RNA molecules from DNA sequence, based on k-mer profiles.\n\n### Methylation <a name='genomics_methylation'></a>\n\n**DeepCpG - Predicting DNA methylation in single cells**\n[[paper](http://dx.doi.org/10.1186/s13059-017-1189-z)]\n[[code](https://github.com/cangermueller/deepcpg)]\n[[docs](http://deepcpg.readthedocs.io/en/latest/)]\n\nDeepCpG is a deep neural network for predicting DNA methylation in multiple cells. DeepCpG has a modular architecture, consisting of a recurrent CpG module to account for correlations between CpG sites within and across cells, a convolutional DNA module to extract patterns from a wide DNA sequence window, and a Joint module that integrates the evidence from the CpG and DNA module to predict the methylation state of multiple cells for a target CpG site. DeepCpG yields accurate predictions, enables discovering DNA sequence motifs that are associated with DNA methylation states and cell-to-cell variability, and can be used for analyzing the effect of single-nucleotide mutations on DNA methylation. DeepCpG is implemented in Python and publicly available.\n\n**Predicting DNA Methylation State of CpG Dinucleotide Using Genome Topological Features and Deep Networks** [[paper](http://www.nature.com/articles/srep19598)][[web server](http://dna.cs.usm.edu/deepmethyl/)]\n\nThis implementation uses a stacked autoencoder with a supervised layer on top of it to predict whether a certain type of genomic region called \u201cCpG islands\u201d (stretches with an overrepresentation of a sequence pattern where a C nucleotide is followed by a G) is methylated (a chemical modification to DNA that can modify its function, for instance methylation in the vicinity of a gene is often but not always related to the down-regulation or silencing of that gene.) This paper uses a network structure where the hidden layers in the autoencoder part have a much larger number of nodes than the input layer, so it would have been nice to read the authors\u2019 thoughts on what the hidden layers represent.\n\n### Single-cell applications <a name='genomics_single-cell'></a>\n\n**DeepCpG - Predicting DNA methylation in single cells**\n[[paper](http://dx.doi.org/10.1186/s13059-017-1189-z)]\n[[code](https://github.com/cangermueller/deepcpg)]\n[[docs](http://deepcpg.readthedocs.io/en/latest/)]\n\nSee above.\n\n**CellCnn \u2013 Representation Learning for detection of disease-associated cell subsets**\n[[code](https://github.com/eiriniar/CellCnn)][[paper](http://biorxiv.org/content/early/2016/03/31/046508)]\n\nThis is a convolutional network (Lasagne/Theano) based approach for \u201cRepresentation Learning for detection of phenotype-associated cell subsets.\u201d It is interesting because most neural network approaches for high-dimensional molecular measurements (such as those in the gene expression category above) have used autoencoders rather than convolutional nets.\n\n**DeepCyTOF: Automated Cell Classification of Mass Cytometry Data by Deep Learning and Domain Adaptation**[[paper](http://biorxiv.org/content/biorxiv/early/2016/05/31/054411.full.pdf)]\n\nDescribes autoencoder approaches (stacked AE and multi-AE) to gating (assigning cells into discrete groups) with mass cytometry (CyTOF).\n\n**Using Neural Networks To Improve Single-Cell RNA-Seq Data Analysis**[[preprint](http://biorxiv.org/content/early/2017/04/23/129759)]\n\nTests a variety of neural network architectures for obtaining a reduced representation of single-cell gene expression data. Introduces a database of tens of thousands of single-cell profiles which can be queried to infer a cell type or state based on this reduced representation.\n\n**Removal of batch effects using distribution-matching residual networks**[[code](https://github.com/ushaham/BatchEffectRemoval)][[paper](https://academic.oup.com/bioinformatics/article-abstract/doi/10.1093/bioinformatics/btx196/3611270/Removal-of-Batch-Effects-using-Distribution)]\n\nMost high-throughput assays in genomics, proteomics etc. are affected to some extent by systematic technical errors, so-called \"batch effects\". This paper uses a residual neural network to attenuate batch effects by trying to match the distributions of replicate experiments on e.g. single-cell RNA sequencing or mass cytometry. \n\n### Population genetics <a name='genomics_pop'></a>\n\n**Deep learning for population genetic inference** [[code](https://sourceforge.net/projects/evonet/)][[paper](http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004845)]\n\n**Diet networks: thin parameters for fat genomics** [[manuscript](http://openreview.net/pdf?id=Sk-oDY9ge)]\n\nThis weirdly-named paper addresses the frequently encountered problem in genomics where the number of features is much larger than the number of training examples. Here, it is addressed in the context of SNPs (single-nucleotide polymorphisms, genetic variations between individuals). The authors propose a new network parametrization that reduces the number of free parameters using a multi-task architecture which tries to learn a useful embedding of the input features.\n\n## Neuroscience <a name='neuro'></a>\n\nThere are potentially lots of implementations that could go here.\n\n**Deep learning for neuroimaging: a validation study** [[paper](http://journal.frontiersin.org/article/10.3389/fnins.2014.00229/abstract)]\n\n**SPINDLE: SPINtronic deep learning engine for large-scale neuromorphic computing** [[paper](http://dl.acm.org/citation.cfm?id=2627625)]\n\n## Awesome Deep Biology\n\nA curated list of deep learning applications in the field of computational biology\n\n\n- **2012-07** | Deep architectures for protein contact map prediction | *Pietro Di Lena, Ken Nagata and Pierre Baldi* [Bioinformatics](https://doi.org/10.1093/bioinformatics/bts475)\n\n- **2012-10** | Predicting protein residue\u2013residue contacts using deep networks and boosting | *Jesse Eickholt and Jianlin Cheng* | [Bioinformatics](https://doi.org/10.1093/bioinformatics/bts598)\n\n- **2013-03** | DNdisorder: predicting protein disorder using boosting and deep networks | *Jesse Eickholt and Jianlin Cheng* | [BMC Bioinformatics](https://doi.org/10.1186/1471-2105-14-88)\n\n- **2014-06** | Deep learning of the tissue-regulated splicing code | *Michael K. K. Leung, Hui Yuan Xiong, Leo J. Lee and Brendan J. Frey* | [Bioinformatics](https://doi.org/10.1093/bioinformatics/btu277)\n\n- **2014-10** | DANN: a deep learning approach for annotating the pathogenicity of genetic variants  | *Daniel Quang, Yifei Chen and Xiaohui Xie* | [Bioinformatics](https://doi.org/10.1093/bioinformatics/btu703)\n\n- **2014-11** | Pairwise input neural network for target-ligand interaction prediction | *Caihua Wang, Juan Liu, Fei Luo, Yafang Tan, Zixin Deng, Qian-Nan Hu* | [2014 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)](https://doi.org/10.1109/BIBM.2014.6999129)\n\n- **2015-01** | Unsupervised feature construction and knowledge extraction from genome-wide assays of breast cancer with denoising autoencoders. | *Jie Tan, Matt Ung, Chao Cheng, Casey Greene* | [Pacific Symposium on Biocomputing (PSB)](https://doi.org/10.1142/9789814644730_0014) | [Models & Data](http://discovery.dartmouth.edu/~cgreene/da-psb2015/)\n\n- **2015-01** | The human splicing code reveals new insights into the genetic determinants of disease  | *Hui Y. Xiong, Babak Alipanahi, Leo J. Lee, Hannes Bretschneider, Daniele Merico, Ryan K. C. Yuen, Yimin Hua, Serge Gueroussov, Hamed S. Najafabadi, Timothy R. Hughes, Quaid Morris, Yoseph Barash, Adrian R. Krainer, Nebojsa Jojic, Stephen W. Scherer, Benjamin J. Blencowe, Brendan J. Frey* | [Science](https://doi.org/10.1126/science.1254806)\n\n- **2015-03** | Deep Feature Selection: Theory and Application to Identify Enhancers and Promoters | *Yifeng Li, Chih-Yu Chen, and Wyeth W. Wasserman* | [19th Annual International Conference, RECOMB 2015, Warsaw, Proceedings](https://doi.org/10.1007/978-3-319-16706-0_20)\n\n- **2015-05** | Trans-species learning of cellular signaling systems with bimodal deep belief networks | *Lujia Chen, Chunhui Cai, Vicky Chen and Xinghua Lu* | [Bioinformatics](https://doi.org/10.1093/bioinformatics/btv315)\n\n- **2015-05** | Deep convolutional neural networks for annotating gene expression patterns in the mouse brain | *Tao Zeng, Rongjian Li, Ravi Mukkamala, Jieping Ye and Shuiwang Ji* | [BMC Bioinformatics](https://doi.org/10.1186/s12859-015-0553-9)\n\n- **2015-07** | DeepBind: Predicting the sequence specificities of DNA- and RNA-binding proteins by deep learning | *Babak Alipanahi,\t Andrew Delong,\tMatthew T. Weirauch & Brendan J. Frey* | [Nature Biotechnology](https://doi.org/10.1038/nbt.3300)\n\n- **2015-08** | Deep learning for regulatory genomics | *Yongjin Park & Manolis Kellis* | [Nature Biotechnology](https://doi.org/10.1038/nbt.3313)\n\n- **2015-08** | DeepSEA: Predicting effects of noncoding variants with deep learning\u2013based sequence model | *Jian Zhou & Olga G. Troyanskaya* | [Nature Methods: Short intro](https://doi.org/10.1038/nmeth.3604) & [Nature Methods](https://doi.org/10.1038/nmeth.3547)\n\n- **2015-08** | Integrative Data Analysis of Multi-Platform Cancer Data with a Multimodal Deep Learning Approach | *Muxuan Liang, Zhizhong Li, Ting Chen, Jianyang Zeng* | [IEEE/ACM Transactions on Computational Biology and Bioinformatics (TCBB)](https://doi.org/10.1109/TCBB.2014.2377729)\n\n- **2015-10** | A deep learning framework for modeling structural features of RNA-binding protein targets | *Sai Zhang, Jingtian Zhou, Hailin Hu, Haipeng Gong, Ligong Chen, Chao Cheng, and Jianyang Zeng* | [NAR](https://doi.org/10.1093/nar/gkv1025)\n\n- **2015-10** | Basset: Learning the regulatory code of the accessible genome with deep convolutional neural networks | *David R. Kelley, Jasper Snoek, John Rinn* | [Biorxiv](https://doi.org/10.1101/028399) | [code](https://github.com/davek44/Basset)\n\n- **2015-10** | Deep Learning for Drug-Induced Liver Injury | *Youjun Xu, Ziwei Dai, Fangjin Chen, Shuaishi Gao, Jianfeng Pei, and Luhua Lai* | [ASC Journal of Chemical Information and Modeling](https://doi.org/10.1021/acs.jcim.5b00238)\n\n- **2016-01** | ADAGE-Based Integration of Publicly Available Pseudomonas aeruginosa Gene Expression Data with Denoising Autoencoders Illuminates Microbe-Host Interactions | [mSystems](https://dx.doi.org/10.1128/mSystems.00025-15) | [code](https://github.com/greenelab/adage)\n\n- **2015-11** | De novo identification of replication-timing domains in the human genome by deep learning | *Feng Liu, Chao Ren, Hao Li, Pingkun Zhou, Xiaochen Bo and Wenjie Shu* | [Bioinformatics](https://doi.org/10.1093/bioinformatics/btv643)\n\n- **2015-11** | Recurrent Neural Network Based Hybrid Model of Gene Regulatory Network | *Khalid Raza, Mansaf Alam* | [Arxiv](https://arxiv.org/abs/1408.5405v2)\n\n- **2015-11** | Continuous Distributed Representation of Biological Sequences for Deep Proteomics and Genomics | *Ehsaneddin Asgari, Mohammad R. K. Mofrad* | [PloS one](http://dx.doi.org/10.1371/journal.pone.0141287)\n\n- **2016-01** | Learning a hierarchical representation of the yeast transcriptomic machinery using an autoencoder model | *Lujia Chen, Chunhui Cai, Vicky Chen and Xinghua Lu* | [BMC Bioinformatics](https://doi.org/10.1186/s12859-015-0852-1)\n\n- **2016-01** | PEDLA: predicting enhancers with a deep learning-based algorithmic framework | *Feng Liu, Hao Li, Chao Ren, Xiaochen Bo, Wenjie Shu* | [Biorxiv](https://doi.org/10.1101/036129)\n\n- **2016-01** | TensorFlow: Biology\u2019s Gateway to Deep Learning? | *Ladislav Rampasek, Anna Goldenberg* | [Cell Systems](https://doi.org/10.1016/j.cels.2016.01.009)\n\n- **2016-01** | ADAGE-Based Integration of Publicly Available Pseudomonas aeruginosa Gene Expression Data with Denoising Autoencoders Illuminates Microbe-Host Interactions | [mSystems](https://doi.org/10.1128/mSystems.00025-15) | [code](https://github.com/greenelab/adage)\n\n- **2016-01** | Deep Learning in Drug Discovery | *Erik Gawehn, Jan A. Hiss and Gisbert Schneider* | [Molecular Informatics](https://doi.org/10.1002/minf.201501008)\n\n- **2016-02** | Gene expression inference with deep learning | *Yifei Chen, Yi Li, Rajiv Narayan, Aravind Subramanian, Xiaohui Xie* | [Bioinformatics](https://doi.org/10.1093/bioinformatics/btw074)\n\n- **2016-02** | Semi-Supervised Learning of the Electronic Health Record for Phenotype Stratification | *Brett Beaulieu-Jones, Casey Greene* | [bioRxiv](https://doi.org/10.1101/039800)\n\n- **2016-03** | Genome-Wide Prediction of cis-Regulatory Regions Using Supervised Deep Learning Methods | *Yifeng Li, Wenqiang Shi, Wyeth W Wasserman* | [Biorxiv](https://doi.org/10.1101/041616)\n\n- **2016-03** | Applications of deep learning in biomedicine | *Polina Mamoshina, Armando Vieira, Evgeny Putin, and Alex Zhavoronkov* | [ACS Molecular Pharmaceutics](https://dx.doi.org/10.1021/acs.molpharmaceut.5b00982)\n\n- **2016-03** | Deep Learning in Bioinformatics | *Seonwoo Min, Byunghan Lee, Sungroh Yoon* | [Arxiv](http://arxiv.org/abs/1603.06430)\n\n- **2016-03** | DeepNano: Deep Recurrent Neural Networks for Base Calling in MinION Nanopore Reads | *Vladim\u00edr Bo\u017ea, Bro\u0148a Brejov\u00e1, Tom\u00e1\u0161 Vina\u0159* | [Arxiv](http://arxiv.org/abs/1603.09195) | [code](https://bitbucket.org/vboza/deepnano)\n\n- **2016-03** | deepTarget: End-to-end Learning Framework for microRNA Target Prediction using Deep Recurrent Neural Networks | *Byunghan Lee, Junghwan Baek, Seunghyun Park, Sungroh Yoon* | [Arxiv](http://arxiv.org/abs/1603.09123)\n\n- **2016-03** | Deep Learning in Label-free Cell Classification | *Claire Lifan Chen, Ata Mahjoubfar, Li-Chia Tai, Ian K. Blaby, Allen Huang, Kayvan Reza Niazi & Bahram Jalali* | [Nature Scientific Reports](https://doi.org/10.1038/srep21471)\n\n- **2016-04** | Accurate classification of protein subcellular localization from high throughput microscopy images using deep learning | *Tanel P\u00e4rnamaa, Leopold Parts* | [bioRxiv](http://dx.doi.org/10.1101/050757)\n\n- **2016-04** | DanQ: a hybrid convolutional and recurrent deep neural network for quantifying the function of DNA sequences | *Daniel Quang & Xiaohui Xie* | [Nucleic Acids Research](https://doi.org/10.1093/nar/gkw226) | [code](https://github.com/uci-cbcl/DanQ)\n\n- **2016-04** | deepMiRGene: Deep Neural Network based Precursor microRNA Prediction | *Seunghyun Park, Seonwoo Min, Hyun-soo Choi, and Sungroh Yoon* | [Arxiv](http://arxiv.org/abs/1605.00017)\n\n- **2016-04** | Microscopy cell counting and detection with fully convolutional regression networks | *Weidi Xie, J. Alison Noble and Andrew Zisserman* | [Computer Methods in Biomechanics and Biomedical Engineering: Imaging & Visualization](https://doi.org/10.1080/21681163.2016.1149104)\n\n- **2016-04** | Protein Secondary Structure Prediction Using Cascaded Convolutional and Recurrent Neural Networks | *Zhen Li and Yizhou Yu* | [Arxiv](https://arxiv.org/abs/1604.07176)\n\n- **2016-05** | Denoising genome-wide histone ChIP-seq with convolutional neural networks | *Pang Wei Koh, Emma Pierson, Anshul Kundaje* | [Biorxiv](https://doi.org/10.1101/052118)\n\n- **2016-05** | Deep Motif: Visualizing Genomic Sequence Classifications | *Jack Lanchantin, Ritambhara Singh, Zeming Lin, Yanjun Qi* | [Arxiv](http://arxiv.org/abs/1605.01133)\n\n- **2016-05** | Not Just a Black Box: Learning Important Features Through Propagating Activation Differences | *Avanti Shrikumar, Peyton Greenside, Anna Shcherbina, Anshul Kundaje* | [Arxiv](https://arxiv.org/abs/1605.01713)\n\n- **2016-05** | Deep biomarkers of human aging: Application of deep neural networks to biomarker development | *Evgeny Putin, Polina Mamoshina, Alexander Aliper, Mikhail Korzinkin, Alexey Moskalev, Alexey Kolosov, Alexander Ostrovskiy, Charles Cantor, Jan Vijg, and Alex Zhavoronkov* | [Aging](https://doi.org/10.18632/aging.100968)\n\n- **2016-05** | Deep learning applications for predicting pharmacological properties of drugs and drug repurposing using transcriptomic data | *Alexander Aliper, Sergey Plis, Artem Artemov, Alvaro Ulloa, Polina Mamoshina, and Alex Zhavoronkov* | [ACS Molecular Pharmaceutics](https://doi.org/10.1021/acs.molpharmaceut.6b00248)\n\n- **2016-05** | Accurate prediction of single-cell DNA methylation states using deep learning | *Christof Angermueller, Heather Lee, Wolf Reik, Oliver Stegle* | [Biorxiv](https://doi.org/10.1101/055715)\n\n- **2016-05** | Deep Machine Learning provides state-of-the-art performance in image-based plant phenotyping | *Michael P. Pound, Alexandra J. Burgess, Michael H. Wilson, Jonathan A. Atkinson, Marcus Griffiths, Aaron S. Jackson, Adrian Bulat, Yorgos Tzimiropoulos, Darren M. Wells, Erik H. Murchie, Tony P. Pridmore, Andrew P. French* | [Biorxiv](https://doi.org/10.1101/053033)\n\n- **2016-05** | Genetic Architect: Discovering Genomic Structure with Learned Neural Architectures | *Laura Deming, Sasha Targ, Nate Sauder, Diogo Almeida, Chun Jimmie Ye* | [Arxiv](https://arxiv.org/abs/1605.07156v1)\n\n- **2016-05** | DeepCyTOF: Automated Cell Classification of Mass Cytometry Data by Deep Learning and Domain Adaptation | *Huamin Li, Uri Shaham, Yi Yao, Ruth Montgomery, Yuval Kluger* | [Biorxiv](https://doi.org/10.1101/054411)\n\n- **2016-06** | Classifying and segmenting microscopy images with deep multiple instance learning | *Oren Z. Kraus, Jimmy Lei Ba and Brendan J. Frey* | [Bioinformatics](https://doi.org/10.1093/bioinformatics/btw252)\n\n- **2016-06** | Convolutional neural network architectures for predicting DNA\u2013protein binding | *Haoyang Zeng, Matthew D. Edwards, Ge Liu and David K. Gifford*  | [Bioinformatics](https://doi.org/10.1093/bioinformatics/btw255) | [code](http://cnn.csail.mit.edu)\n\n- **2016-06** | DeepLNC, a long non-coding RNA prediction tool using deep neural network | *Rashmi Tripathi, Sunil Patel, Vandana Kumari, Pavan Chakraborty, Pritish Kumar Varadwaj* | [Network Modeling Analysis in Health Informatics and Bioinformatics](https://doi.org/10.1007/s13721-016-0129-2)\n\n- **2016-06** | Virtual Screening: A Challenge for Deep Learning | *Javier P\u00e9rez-Sianes, Horacio P\u00e9rez-S\u00e1nchez, Fernando D\u00edaz* | [10th International Conference on Practical Applications of Computational Biology & Bioinformatics](https://doi.org/10.1007/978-3-319-40126-3_2)\n\n- **2016-07** | Deep learning for computational biology | *Christof Angermueller, Tanel P\u00e4rnamaa, Leopold Parts, Oliver Stegle* | [Molecular Systems Biology](https://doi.org/10.15252/msb.20156651)\n\n- **2016-07** | Deep Learning in Bioinformatics | *Seonwoo Min, Byunghan Lee, Sungroh Yoon* | [Briefings in Bioinformatics](https://doi.org/10.1093/bib/bbw068)\n\n- **2016-08** | DeepChrome: deep-learning for predicting gene expression from histone modifications | *Ritambhara Singh, Jack Lanchantin,  Gabriel Robins,  Yanjun Qi* | [Bioinformatics](https://doi.org/10.1093/bioinformatics/btw427)\n\n- **2016-08** | Deep Artificial Neural Networks and Neuromorphic Chips for Big Data Analysis: Pharmaceutical and Bioinformatics Applications | *Lucas Ant\u00f3n Pastur-Romay, Francisco Cedr\u00f3n, Alejandro Pazos and Ana Bel\u00e9n Porto-Pazos* | [International Journal of Molecular Sciences](https://doi.org/10.3390/ijms17081313)\n\n- **2016-08** | Deep GDashboard: Visualizing and Understanding Genomic Sequences Using Deep Neural Networks | *Jack Lanchantin, Ritambhara Singh, Beilun Wang, Yanjun Qi* | [Arxiv](https://arxiv.org/abs/1608.03644v2)\n\n- **2016-08** | Modeling translation elongation dynamics by deep learning reveals new insights into the landscape of ribosome stalling | *Sai Zhang, Hailin Hu, Jingtian Zhou, Xuan He and Jianyang Zeng* | [bioRxiv](http://dx.doi.org/10.1101/067108)\n\n- **2016-08** | DeepWAS: Directly integrating regulatory information into GWAS using deep learning supports master regulator MEF2C as risk factor for major depressive disorder | *G\u00f6kcen Eraslan, Janine Arloth, Jade Martins, Stella Iurato, Darina Czamara, Elisabeth B. Binder, Fabian J. Theis, Nikola S. Mueller* | [bioRxiv](https://dx.doi.org/10.1101/069096)\n\n- **2016-09** | The Next Era: Deep Learning in Pharmaceutical Research | *Sean Ekins* | [Pharmaceutical Research](https://dx.doi.org/10.1007/s11095-016-2029-7)\n\n- **2016-09** | Accurate De Novo Prediction of Protein Contact Map by Ultra-Deep Learning Model | *Sheng Wang, Siqi Sun, Zhen Li, Renyu Zhang, Jinbo Xu* | [Arxiv](https://arxiv.org/abs/1609.00680)\n\n- **2016-10** | Automatic chemical design using a data-driven continuous representation of molecules | *Rafael G\u00f3mez-Bombarelli, David Duvenaud, Jos\u00e9 Miguel Hern\u00e1ndez-Lobato, Jorge Aguilera-Iparraguirre, Timothy D. Hirzel, Ryan P. Adams, Al\u00e1n Aspuru-Guzik* | [Arxiv](https://arxiv.org/abs/1610.02415)\n\n- **2016-10** | FIDDLE: An integrative deep learning framework for functional genomic data inference | *Umut Eser, L. Stirling Churchman* | [bioRxiv](http://dx.doi.org/10.1101/081380)\n\n- **2016-10** | Deep Learning for Imaging Flow Cytometry: Cell Cycle Analysis of Jurkat Cells | *Philipp Eulenberg, Niklas Koehler, Thomas Blasi, Andrew Filby, Anne E. Carpenter, Paul Rees, Fabian J. Theis, F. Alexander Wolf* | [bioRxiv](http://dx.doi.org/10.1101/081364)\n\n- **2016-10** | Leveraging uncertainty information from deep neural networks for disease detection | *Christian Leibig, Vaneeda Allken, Philipp Berens, Siegfried Wahl* | [bioRxiv](http://dx.doi.org/10.1101/084210)\n\n- **2016-11** | Predicting Enhancer-Promoter Interaction from Genomic Sequence with Deep Neural Networks | *Shashank Singh, Yang Yang, Barnabas Poczos, Jian Ma* | [bioRxiv](https://doi.org/10.1101/085241)\n\n- **2016-11** | RNA-protein binding motifs mining with a new hybrid deep learning based cross-domain knowledge integration approach | *Xiaoyong Pan, Hong-Bin Shen* | [bioRxiv](http://dx.doi.org/10.1101/085191)\n\n- **2016-11** | Low Data Drug Discovery with One-shot Learning | *Han Altae-Tran, Bharath Ramsundar, Aneesh S. Pappu, Vijay Pande* | [Arxiv](https://arxiv.org/abs/1611.03199)\n\n- **2016-11** | Diet Networks: Thin Parameters for Fat Genomic | *Adriana Romero, Pierre Luc Carrier, Akram Erraqabi, Tristan Sylvain, Alex Auvolat, Etienne Dejoie, Marc-Andr\u00e9 Legault, Marie-Pierre Dub\u00e9, Julie G. Hussin, Yoshua Bengio* | [Arxiv](https://arxiv.org/abs/1611.09340)\n\n- **2016-11** | DeeperBind: Enhancing Prediction of Sequence Specificities of DNA Binding Proteins | *Hamid Reza Hassanzadeh, May D. Wang* | [Arxiv](https://arxiv.org/abs/1611.05777)\n\n- **2016-11** | Accurate De Novo Prediction of Protein Contact Map by Ultra-Deep Learning Model | *Sheng Wang, Siqi Sun, Zhen Li, Renyu Zhang, Jinbo Xu* | [bioRxiv](https://doi.org/10.1101/073239)\n\n- **2016-11** | Deep learning with feature embedding for compound-protein interaction prediction | *Fangping Wan, Jianyang Zeng* | [bioRxiv](https://doi.org/10.1101/086033)\n\n- **2016-12** | Creating a universal SNP and small indel variant caller with deep neural networks | *Ryan Poplin, Dan Newburger, Jojo Dijamco, Nam Nguyen, Dion Loy, Sam S. Gross, Cory Y. McLean, Mark A. DePristo* | [bioRxiv](https://doi.org/10.1101/092890)\n\n- **2016-12** | DeepCancer: Detecting Cancer through Gene Expressions via Deep Generative Learning | *Rajendra Rana Bhat, Vivek Viswanath, Xiaolin Li* | [Arxiv](http://arxiv.org/abs/1612.03211)\n\n- **2016-12** | Cox-nnet: an artificial neural network Cox regression for prognosis prediction | *Travers Ching, Xun Zhu, Lana Garmire* | [bioRxiv](https://doi.org/10.1101/093021)\n\n- **2016-12** | Deep learning is effective for the classification of OCT images of normal versus Age-related Macular Degeneration | *Cecilia S Lee, Doug M Baughman, Aaron Y Lee* | [bioRxiv](https://doi.org/10.1101/094276)\n\n- **2016-12** | Partitioned learning of deep Boltzmann machines for SNP data | *Moritz Hess, Stefan Lenz, Tamara Blaette, Lars Bullinger, Harald Binder* | [bioRxiv](https://doi.org/10.1101/095638)\n\n- **2016-12** | DeepAD: Alzheimer\u2032s Disease Classification via Deep Convolutional Neural Networks using MRI and fMRI | *Saman Sarraf, John Anderson, Ghassem Tofighi, for the Alzheimer's Disease Neuroimaging Initiativ* | [bioRxiv](https://doi.org/10.1101/070441)\n\n- **2016-12** | Training Genotype Callers with Neural Networks | *R\u00e9mi Torracinta, Fabien Campagne* | [bioRxiv](https://doi.org/10.1101/097469)\n\n- **2016-12** | EP-DNN: A Deep Neural Network-Based Global Enhancer Prediction Algorithm | *Seong Gon Kim, Mrudul Harwani, Ananth Grama, Somali Chaterji* | [Nature Scientific Reports](https://doi.org/10.1038/srep38433)\n\n- **2016-12** | EnhancerPred: a predictor for discovering enhancers based on the combination and selection of multiple features | *Cangzhi Jia, Wenying He* | [Nature Scientific Reports](https://doi.org/10.1038/srep38741)\n\n- **2016-12** | DeepEnhancer: Predicting enhancers by convolutional neural networks | *Min, Xu, Ning Chen, Ting Chen, and Rui Jiang* | [2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)](https://doi.org/10.1109/BIBM.2016.7822593)\n\n- **2016-12** | DeepSplice: Deep classification of novel splice junctions revealed by RNA-seq | *Zhang, Yi, Xinan Liu, James N. MacLeod, and Jinze Liu* | [2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)](https://doi.org/10.1109/BIBM.2016.7822541)\n\n- **2016-12** | Deep convolutional neural networks for detecting secondary structures in protein density maps from cryo-electron microscopy | *Li, Rongjian, Dong Si, Tao Zeng, Shuiwang Ji, and Jing He* | [2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)](https://doi.org/10.1109/BIBM.2016.7822490)\n\n- **2016-12** | Towards recognition of protein function based on its structure using deep convolutional networks | *Tavanaei, Amirhossein, Anthony S. Maida, Arun Kaniymattam, and Rasiah Loganantharaj* | [2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)](https://doi.org/10.1109/BIBM.2016.7822509)\n\n- **2016-12** | Emotion recognition from multi-channel EEG data through Convolutional Recurrent Neural Network | *Li, Xiang, Dawei Song, Peng Zhang, Guangliang Yu, Yuexian Hou, and Bin Hu* | [2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)](https://doi.org/10.1109/BIBM.2016.7822545)\n\n- **2016-12** | Coarse-to-Fine Stacked Fully Convolutional Nets for lymph node segmentation in ultrasound images | *Zhang, Yizhe, Michael TC Ying, Lin Yang, Anil T. Ahuja, and Danny Z. Chen* | [2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)](https://doi.org/10.1109/BIBM.2016.7822557)\n\n- **2016-12** | CNNsite: Prediction of DNA-binding residues in proteins using Convolutional Neural Network with sequence features | *Zhou, Jiyun, Qin Lu, Ruifeng Xu, Lin Gui, and Hongpeng Wang* | [2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)](https://doi.org/10.1109/BIBM.2016.7822496)\n\n- **2016-12** | A predictive model of gene expression using a deep learning framework | *Xie, Rui, Andrew Quitadamo, Jianlin Cheng, and Xinghua Shi* | [2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)](https://doi.org/10.1109/BIBM.2016.7822599)\n\n- **2016-12** | Deep convolutional neural network for survival analysis with pathological images | *Zhu, Xinliang, Jiawen Yao, and Junzhou Huang* | [2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)](https://doi.org/10.1109/BIBM.2016.7822579)\n\n- **2016-12** | Dependency-based convolutional neural network for drug-drug interaction extraction | *Liu, Shengyu, Kai Chen, Qingcai Chen, and Buzhou Tang* | [2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)](https://doi.org/10.1109/BIBM.2016.7822671)\n\n- **2016-12** | Pervasive EEG diagnosis of depression using Deep Belief Network with three-electrodes EEG collector | *Cai, Hanshu, Xiaocong Sha, Xue Han, Shixin Wei, and Bin Hu* | [2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)](https://doi.org/10.1109/BIBM.2016.7822696)\n\n- **2016-12** | Cardiac left ventricular volumes prediction method based on atlas location and deep learning | *Luo, Gongning, Suyu Dong, Kuanquan Wang, and Henggui Zhang* | [2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)](https://doi.org/10.1109/BIBM.2016.7822759)\n\n- **2016-12** | A high-precision shallow Convolutional Neural Network based strategy for the detection of Genomic Deletions | *Wang, Jing, Cheng Ling, and Jingyang Gao* | [2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)](https://doi.org/10.1109/BIBM.2016.7822793)\n\n- **2016-12** | The cornucopia of meaningful leads: Applying deep adversarial autoencoders for new molecule development in oncology | *Kadurin, Artur, Alexander Aliper, Andrey Kazennov, Polina Mamoshina, Quentin Vanhaelen, Kuzma Khrabrov, and Alex Zhavoronkov* | [Oncotarget](https://doi.org/10.18632/oncotarget.14073)\n\n- **2016-12** | Medical Image Synthesis with Context-Aware Generative Adversarial Networks | *Dong Nie, Roger Trullo, Caroline Petitjean, Su Ruan, Dinggang Shen* | [Arxiv](https://arxiv.org/abs/1612.05362)\n\n- **2016-12** | Unsupervised Learning from Noisy Networks with Applications to Hi-C Data | *Wang, Bo, Junjie Zhu, Armin Pourshafeie, Oana Ursu, Serafim Batzoglou, and Anshul Kundaje* | [Advances in Neural Information Processing Systems (NIPS 2016)](http://papers.nips.cc/paper/6291-unsupervised-learning-from-noisy-networks-with-applications-to-hi-c-data)\n\n- **2016-12** | Deep Learning for Health Informatics | *Daniele Rav\u00ec, Charence Wong, Fani Deligianni, Melissa Berthelot, Javier Andreu-Perez, Benny Lo, and Guang-Zhong Yang* | [IEEE Journal of Biomedical and Health Informatics](https://doi.org/10.1109/JBHI.2016.2636665)\n\n- **2017-01** | A Deep Learning Approach for Cancer Detection and Relevant Gene Identification | *Wang, Jing, Cheng Ling, and Jingyang Gao* | [Pacific Symposium on Biocomputing 2017](http://dx.doi.org/10.1142/9789813207813_0022)\n\n- **2017-01** | Deep Motif Dashboard: Visualizing and Understanding Genomic Sequences Using Deep Neural Networks | *Lanchantin, Jack, Ritambhara Singh, Beilun Wang, and Yanjun Qi* | [Pacific Symposium on Biocomputing 2017](http://dx.doi.org/10.1142/9789813207813_0025)\n\n- **2017-01** | HLA class I binding prediction via convolutional neural networks | *Yeeleng Scott Vang, Xiaohui Xie* | [bioRxiv](https://doi.org/10.1101/099358)\n\n- **2017-01** | DeadNet: Identifying Phototoxicity from Label-free Microscopy Images of Cells using Deep ConvNets | *David Richmond, Anna Payne-Tobin Jost, Talley Lambert, Jennifer Waters, Hunter Elliott* | [arXiv](https://arxiv.org/abs/1701.06109)\n\n- **2017-01** | Dermatologist-level classification of skin cancer with deep neural networks | *Andre Esteva, Brett Kuprel, Roberto A. Novoa, Justin Ko, Susan M. Swetter, Helen M. Blau & Sebastian Thrun* | [Nature](https://doi.org/10.1038/nature21056)\n\n- **2017-01** | Understanding sequence conservation with deep learning | *Yi Li, Daniel Quang, Xiaohui Xie* | [Biorxiv](https://doi.org/10.1101/103929)\n\n- **2017-01** | Learning the Structural Vocabulary of a Network | *Saket Navlakha* | [Neural Computation](https://doi.org/10.1162/NECO_a_00924)\n\n- **2017-01** | Mining the Unknown: Assigning Function to Noncoding Single Nucleotide Polymorphisms | *Sierra S. Nishizaki, Alan P. Boyle* | [Trends in Genetics](http://dx.doi.org/10.1016/j.tig.2016.10.008)\n\n- **2017-01** | Reverse-complement parameter sharing improves deep learning models for genomics | *Avanti Shrikumar, Peyton Greenside, Anshul Kundaje* | [bioRxiv](https://doi.org/10.1101/103663)\n\n- **2017-01** | TIDE: predicting translation initiation sites by deep learning | *Sai Zhang, Hailin Hu, Tao Jiang, Lei Zhang, Jianyang Zeng* | [bioRxiv](https://doi.org/10.1101/103374)\n\n- **2017-01** | Integrative Deep Models for Alternative Splicing | *Anupama Jha, Matthew R Gazzara, Yoseph Barash* | [bioRxiv](https://doi.org/10.1101/104869)\n\n- **2017-01** | Deep Recurrent Neural Network for Protein Function Prediction from Sequence | *Xueliang\u00a0Leon\u00a0Liu* | [bioRxiv](https://doi.org/10.1101/103994)\n\n- **2017-01** | Nucleotide sequence and DNaseI sensitivity are predictive of 3D chromatin architecture | *Jacob Schreiber, Maxwell Libbrecht, Jeffrey Bilmes, William Noble* | [bioRxiv](https://doi.org/10.1101/103614)\n\n- **2017-02** | Imputation for transcription factor binding predictions based on deep learning | *Qian Qin, Jianxing Feng* | [PloS Computational Biology](http://dx.doi.org/10.1371/journal.pcbi.1005403)\n\n- **2017-02** | Deep Learning based multi-omics integration robustly predicts survival in liver cancer | *Kumardeep Chaudhary, Olivier B. Poirion, Liangqun Lu, Lana Garmire* | [bioRxiv](https://doi.org/10.1101/114892)\n\n- **2017-03** | Predicting the impact of non-coding variants on DNA methylation | *Zeng, Haoyang, and David K. Gifford* | [Nucleic Acids Research](https://doi.org/10.1093/nar/gkx177)\n\n- **2017-03** | H&E-stained Whole Slide Image Deep Learning Predicts SPOP Mutation State in Prostate Cancer | *Andrew J Schaumberg, Mark A Rubin, Thomas J Fuchs* | [bioRxiv](https://doi.org/10.1101/064279)\n\n### Contribution\n\nFeel free to send a pull request.\n\n\n"
 },
 {
  "repo": "pratik008/HealthCare_Twitter_Analysis",
  "language": "Python",
  "readme_contents": "# Twitter-Healthcare-Analysis\n\nI have written the source code as the core of the Twitter Healthcare Analysis Open Source project. If you have any questions, feel free to contact me at pratik008@gmail.com (Pratik Mehta) Please read the [Wiki](https://github.com/wywfalcon/Twitter-Healthcare-Analysis/wiki) for more information.\n\nGood luck with your projects!\n"
 },
 {
  "repo": "MoH-Malaysia/covid19-public",
  "language": "Jupyter Notebook",
  "readme_contents": "# Open data on COVID-19 in Malaysia\n\n**The scope and granularity of data in this repo will evolve over time.**\n+ Documentation and data descriptions contained within subfolders. \n+ Submit pull requests to [share your work for the community](/CONTRIB.md#share-your-work) or [request more data](/CONTRIB.md#data-requests).\n\n**All data is correct as of 2359 of date, unless stated otherwise.**\n\n---\n\n### Cases and Testing\n\n1) [`cases_malaysia.csv`](/epidemic/cases_malaysia.csv): Daily recorded COVID-19 cases at country level.\n2) [`cases_state.csv`](/epidemic/cases_state.csv): Daily recorded COVID-19 cases at state level.\n3) [`clusters.csv`](/epidemic/clusters.csv): Exhaustive list of announced clusters with relevant epidemiological datapoints.\n4) [`tests_malaysia.csv`](/epidemic/tests_malaysia.csv): Daily tests (note: not necessarily unique individuals) by type at country level.\n4) [`tests_state.csv`](/epidemic/tests_malaysia.csv): Daily tests (note: not necessarily unique individuals) by type at state level.\n\n### Healthcare\n\n1) [`pkrc.csv`](/epidemic/pkrc.csv): Flow of patients to/out of Covid-19 Quarantine and Treatment Centres (PKRC), with capacity and utilisation.\n2) [`hospital.csv`](/epidemic/hospital.csv): Flow of patients to/out of hospitals, with capacity and utilisation.\n3) [`icu.csv`](/epidemic/icu.csv): Capacity and utilisation of intensive care unit (ICU) beds.\n\n### Deaths\n\n1) [`deaths_malaysia.csv`](/epidemic/deaths_malaysia.csv): Daily deaths due to COVID-19 at country level.\n2) [`deaths_state.csv`](/epidemic/deaths_state.csv): Daily deaths due to COVID-19 at state level.\n\n### Vaccinations\n\n1) [`vax_malaysia.csv`](/vaccination/vax_malaysia.csv): Vaccinations (daily and cumulative, by dose type and brand) at country level.\n2) [`vax_state.csv`](/vaccination/vax_state.csv): Vaccinations (daily and cumulative, by dose type and brand) at state level.\n3) [`vax_district.csv`](/vaccination/vax_district.csv): Vaccinations (daily and cumulative, by dose type and brand) at district level.\n4) [`vax_school.csv`](/vaccination/vax_school.csv): Vaccination coverage for public schools.\n5) [`vax_demog_age.csv`'](/vaccination/vax_demog_age.csv): Vaccinations by age group, at district level.\n6) [`vax_demog_age_children.csv`'](/vaccination/vax_demog_age_children.csv): Vaccinations by age group with single-year granularity for individuals < 18yo, at district level.\n7) [`vax_demog_sex.csv`'](/vaccination/vax_demog_sex.csv): Vaccinations by sex, at district level.\n8) [`vax_demog_ethnicity.csv`'](/vaccination/vax_demog_ethnicity.csv): Vaccinations by ethnicity, at district level.\n9) [`vax_demog_nationality.csv`'](/vaccination/vax_demog_nationality.csv): Vaccinations by nationality, at district level.\n10) [`vax_demog_highrisk.csv`'](/vaccination/vax_demog_highrisk.csv): Vaccinations for special categories (healthcare workers, OKU, individuals with comorbidities) at district level.\n\n### Mobility and Contact Tracing\n\n1) [`checkin_malaysia.csv`](/mysejahtera/checkin_malaysia.csv): Daily checkins on MySejahtera at country level.\n2) [`checkin_state.csv`](/mysejahtera/checkin_state.csv): Daily checkins on MySejahtera at state level.\n3) [`checkin_malaysia_time.csv`](/mysejahtera/checkin_malaysia_time.csv): Time distribution of daily checkins on MySejahtera at country level.\n4) [`trace_malaysia.csv`](/mysejahtera/trace_malaysia.csv): Daily casual contacts traced and hotspots identified by HIDE, at country level.\n\n### Static data\n\n1) [`population.csv`](/static/population.csv) (last updated from DOSM 2020 census, as published in 2022): \n - `idxs`: integer coding for states (employed in cases linelist, cluster file, and school vax file)\n - `pop`: total population (all other columns are subset of `pop`)\n - `pop_18`: population aged 18+\n - `pop_60`: population aged 60+, also a subset of `pop_18`\n - `pop_12`: population aged 12-17\n - `pop_5`: population aged 5-11\n\n_Static data will remain unchanged unless there is an update from the source, e.g. if DOSM makes an update to population estimates. We provide this data here not to supersede the source, but rather to be transparent about the data we use to compute key statistics e.g. the % of the population that is vaccinated. We also hope this ensures synchronisation (across various independent analysts) of key statistics._\n"
 },
 {
  "repo": "DataKind-SG/healthcare_ASEAN",
  "language": "Jupyter Notebook",
  "readme_contents": "healthcare_ASEAN\n==============================\n\nOpen data project on exploration of healthcare data for the ASEAN region, currently focusing on Malaria and Dengue. \n\nSocial Coding board: https://github.com/DataKind-SG/healthcare_ASEAN/projects/1   \n\nSlack Channel on DataKindSG (datakindsg.slack.com) team: #healthcare_asean  \n\nThe data folder has been uploaded to the github repo data\\ folder.\n\nFurther information: \ndocs\\README.md\n\nGranularity\n------------\n * weekly data\n * location: state/province level \n\nProject Organization\n------------\n\n    \u251c\u2500\u2500 LICENSE\n    \u251c\u2500\u2500 Makefile           <- Makefile with commands like `make data` or `make train`\n    \u251c\u2500\u2500 README.md          <- The top-level README for developers using this project.\n    \u251c\u2500\u2500 data\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 external       <- Data from third party sources.\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 interim        <- Intermediate data that has been transformed.\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 processed      <- The final, canonical data sets for modeling.\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 raw            <- The original, immutable data dump.\n    \u2502\n    \u251c\u2500\u2500 docs               <- A default Sphinx project; see sphinx-doc.org for details\n    \u2502\n    \u251c\u2500\u2500 models             <- Trained and serialized models, model predictions, or model summaries\n    \u2502\n    \u251c\u2500\u2500 notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),\n    \u2502                         the creator's initials, and a short `-` delimited description, e.g.\n    \u2502                         `1.0-jqp-initial-data-exploration`.\n    \u251c\u2500\u2500 references         <- Data dictionaries, manuals, and all other explanatory materials.\n    \u2502\n    \u251c\u2500\u2500 reports            <- Generated analysis as HTML, PDF, LaTeX, etc.\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 figures        <- Generated graphics and figures to be used in reporting\n    \u2502\n    \u251c\u2500\u2500 requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.\n    \u2502                         generated with `pip freeze > requirements.txt`\n    \u2502\n    \u251c\u2500\u2500 src                <- Source code for use in this project.\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py    <- Makes src a Python module\n    \u2502   \u2502\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 data\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 download   <- Scripts for downloading from each raw data source\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 logconf.ini <- setup for logging configuration for scripts in download/\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 download.py <- Script to download raw data using modules in `download/`\n    \u2502   \u2502   \u2502\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 clean      <- Scripts to clean raw data\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 clean.py   <- Script to clean raw data using modules in 'clean/'\n    \u2502   \u2502   \u2502\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 logconf.ini <- setup for logging configuration for scripts in data/\n    \u2502   \u2502\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 features       <- Scripts to turn raw data into features for modeling\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 build_features.py\n    \u2502   \u2502\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 models         <- Scripts to train models and then use trained models to make\n    \u2502   \u2502   \u2502                 predictions\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 predict_model.py\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 train_model.py\n    \u2502   \u2502\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 visualization  <- Scripts to create exploratory and results oriented visualizations\n    \u2502\u00a0\u00a0     \u2514\u2500\u2500 visualize.py\n    \u251c\u2500\u2500 test               <- Directory for souce codes testing\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 func           <- Directory for souce codes functional testing\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 data\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 features\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 models\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 unit           <- Directory for souce codes unit testing\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 data\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 features\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 models\n    \u2514\u2500\u2500 tox.ini            <- tox file with settings for running tox; see tox.testrun.org\n"
 },
 {
  "repo": "llSourcell/AI_for_healthcare",
  "language": "Jupyter Notebook",
  "readme_contents": "# ChemGAN challenge\n\n\n## Overview\n\nThis is the code for [this](https://www.youtube.com/watch?v=hY9Bc3mtphs) video on Youtube by Siraj Raval as part of the AI for business series. Find the original code and authors [here](https://github.com/mostafachatillon/ChemGAN-challenge). \n\n* Code for the paper: Benhenda, M. 2017. [ChemGAN challenge for drug discovery: can AI reproduce natural chemical diversity? arXiv preprint arXiv:1708.08227.](https://arxiv.org/abs/1708.08227)\n\n* Related blog post: [https://medium.com/the-ai-lab/chemgan-challenge-for-drug-discovery-can-ai-reproduce-natural-chemical-diversity-8f1f2528ee22](https://medium.com/the-ai-lab/chemgan-challenge-for-drug-discovery-can-ai-reproduce-natural-chemical-diversity-8f1f2528ee22)\n\n* Chat room: [https://gitter.im/Startcrowd/drugdiscovery](https://gitter.im/Startcrowd/drugdiscovery) \n\n* Requirements: Rdkit version 2017.03.3 from Anaconda, Tensorflow 1.0.1\n\n* The code has not been cleaned, don't hesitate to post an issue if you don't find what you are looking for.\n"
 },
 {
  "repo": "sunlabuiuc/PyHealth",
  "language": "Python",
  "readme_contents": "Welcome to PyHealth!\n====================================\n\n.. image:: https://img.shields.io/pypi/v/pyhealth.svg?color=brightgreen\n   :target: https://pypi.org/project/pyhealth/\n   :alt: PyPI version\n\n\n.. image:: https://readthedocs.org/projects/pyhealth/badge/?version=latest\n   :target: https://pyhealth.readthedocs.io/en/latest/\n   :alt: Documentation status\n   \n\n.. image:: https://img.shields.io/github/stars/sunlabuiuc/pyhealth.svg\n   :target: https://github.com/sunlabuiuc/pyhealth/stargazers\n   :alt: GitHub stars\n\n\n.. image:: https://img.shields.io/github/forks/sunlabuiuc/pyhealth.svg?color=blue\n   :target: https://github.com/sunlabuiuc/pyhealth/network\n   :alt: GitHub forks\n\n\n.. image:: https://pepy.tech/badge/pyhealth\n   :target: https://pepy.tech/project/pyhealth\n   :alt: Downloads\n\n\n.. image:: https://img.shields.io/badge/Tutorials-Google%20Colab-red\n   :target: https://pyhealth.readthedocs.io/en/latest/tutorials.html\n   :alt: Tutorials\n\n\n.. image:: https://img.shields.io/badge/YouTube-16%20Videos-red\n   :target: https://www.youtube.com/playlist?list=PLR3CNIF8DDHJUl8RLhyOVpX_kT4bxulEV\n   :alt: YouTube\n\n\n\n.. -----\n\n\n.. **Build Status & Coverage & Maintainability & License**\n\n.. .. image:: https://travis-ci.org/yzhao062/pyhealth.svg?branch=master\n..    :target: https://travis-ci.org/yzhao062/pyhealth\n..    :alt: Build Status\n\n\n.. .. image:: https://ci.appveyor.com/api/projects/status/1kupdy87etks5n3r/branch/master?svg=true\n..    :target: https://ci.appveyor.com/project/yzhao062/pyhealth/branch/master\n..    :alt: Build status\n\n\n.. .. image:: https://api.codeclimate.com/v1/badges/bdc3d8d0454274c753c4/maintainability\n..    :target: https://codeclimate.com/github/yzhao062/pyhealth/maintainability\n..    :alt: Maintainability\n\n\n.. .. image:: https://img.shields.io/github/license/yzhao062/pyhealth\n..    :target: https://github.com/yzhao062/pyhealth/blob/master/LICENSE\n..    :alt: License\n\nPyHealth is designed for both **ML researchers and medical practitioners**. We can make your **healthcare AI applications** easier to deploy and more flexible and customizable. `[Tutorials] <https://pyhealth.readthedocs.io/>`_\n\n **[News!]** Our PyHealth is accepted by KDD 2023 Tutorial Track! We will present a 3-hour tutorial on PyHealth at `[KDD 2023] <https://kdd.org/kdd2023/>`_, August 6-10, Long Beach, CA.\n\n.. image:: figure/poster.png\n   :width: 810\n\n..\n\n1. Installation :rocket:\n----------------------------\n\n- You could install from PyPi:\n\n.. code-block:: sh\n\n    pip install pyhealth\n\n- or from github source:\n\n.. code-block:: sh\n\n    pip install .\n\n\n2. Introduction :book:\n--------------------------\n``pyhealth`` provides these functionalities (we are still enriching some modules):\n\n.. image:: figure/overview.png\n   :width: 770\n\nYou can use the following functions independently:\n\n- **Dataset**: ``MIMIC-III``, ``MIMIC-IV``, ``eICU``, ``OMOP-CDM``, ``customized EHR datasets``, etc.\n- **Tasks**: ``diagnosis-based drug recommendation``, ``patient hospitalization and mortality prediction``, ``length stay forecasting``, etc. \n- **ML models**: ``CNN``, ``LSTM``, ``GRU``, ``LSTM``, ``RETAIN``, ``SafeDrug``, ``Deepr``, etc.\n\n*Building a healthcare AI pipeline can be as short as 10 lines of code in PyHealth*.\n\n\n3. Build ML Pipelines :trophy:\n---------------------------------\n\nAll healthcare tasks in our package follow a **five-stage pipeline**: \n\n.. image:: figure/five-stage-pipeline.png\n   :width: 640\n\n..\n\n We try hard to make sure each stage is as separate as possible, so that people can customize their own pipeline by only using our data processing steps or the ML models.\n\nModule 1: <pyhealth.datasets>\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\n``pyhealth.datasets`` provides a clean structure for the dataset, independent from the tasks. We support `MIMIC-III`, `MIMIC-IV` and `eICU`, etc. The output (mimic3base) is a multi-level dictionary structure (see illustration below).\n\n.. code-block:: python\n\n    from pyhealth.datasets import MIMIC3Dataset\n\n    mimic3base = MIMIC3Dataset(\n        # root directory of the dataset\n        root=\"https://storage.googleapis.com/pyhealth/Synthetic_MIMIC-III/\", \n        # raw CSV table name\n        tables=[\"DIAGNOSES_ICD\", \"PROCEDURES_ICD\", \"PRESCRIPTIONS\"],\n        # map all NDC codes to CCS codes in these tables\n        code_mapping={\"NDC\": \"CCSCM\"},\n    )\n\n.. image:: figure/structured-dataset.png\n   :width: 400\n\n..\n\nModule 2: <pyhealth.tasks>\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\n``pyhealth.tasks`` defines how to process each patient's data into a set of samples for the tasks. In the package, we provide several task examples, such as ``drug recommendation`` and ``length of stay prediction``. **It is easy to customize your own tasks following our** `template <https://colab.research.google.com/drive/1r7MYQR_5yCJGpK_9I9-A10HmpupZuIN-?usp=sharing>`_.\n\n.. code-block:: python\n\n    from pyhealth.tasks import readmission_prediction_mimic3_fn\n\n    mimic3sample = mimic3base.set_task(task_fn=readmission_prediction_mimic3_fn) # use default task\n    mimic3sample.samples[0] # show the information of the first sample\n    \"\"\"\n    {\n        'visit_id': '100183',\n        'patient_id': '175',\n        'conditions': ['5990', '4280', '2851', '4240', '2749', '9982', 'E8499', '42831', '34600'],\n        'procedures': ['0040', '3931', '7769'],\n        'drugs': ['N06DA02', 'V06DC01', 'B01AB01', 'A06AA02', 'R03AC02', 'H03AA01', 'J01FA09'],\n        'label': 0\n    }\n    \"\"\"\n\n    from pyhealth.datasets import split_by_patient, get_dataloader\n\n    train_ds, val_ds, test_ds = split_by_patient(mimic3sample, [0.8, 0.1, 0.1])\n    train_loader = get_dataloader(train_ds, batch_size=32, shuffle=True)\n    val_loader = get_dataloader(val_ds, batch_size=32, shuffle=False)\n    test_loader = get_dataloader(test_ds, batch_size=32, shuffle=False)\n\nModule 3: <pyhealth.models>\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\n``pyhealth.models`` provides different ML models with very similar argument configs.\n\n.. code-block:: python\n\n    from pyhealth.models import Transformer\n\n    model = Transformer(\n        dataset=mimic3sample,\n        feature_keys=[\"conditions\", \"procedures\", \"drug\"],\n        label_key=\"label\",\n        mode=\"binary\",\n    )\n\nModule 4: <pyhealth.trainer>\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\n``pyhealth.trainer`` can specify training arguments, such as epochs, optimizer, learning rate, etc. The trainer will automatically save the best model and output the path in the end.\n\n.. code-block:: python\n    \n    from pyhealth.trainer import Trainer\n\n    trainer = Trainer(model=model)\n    trainer.train(\n        train_dataloader=train_loader,\n        val_dataloader=val_loader,\n        epochs=50,\n        monitor=\"pr_auc_samples\",\n    )\n\nModule 5: <pyhealth.metrics>\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\n``pyhealth.metrics`` provides several **common evaluation metrics** (refer to `Doc <https://pyhealth.readthedocs.io/en/latest/api/metrics.html>`_ and see what are available).\n\n.. code-block:: python\n\n    # method 1\n    trainer.evaluate(test_loader)\n    \n    # method 2\n    from pyhealth.metrics.binary import binary_metrics_fn\n\n    y_true, y_prob, loss = trainer.inference(test_loader)\n    binary_metrics_fn(y_true, y_prob, metrics=[\"pr_auc\", \"roc_auc\"])\n\n4. Medical Code Map :hospital: \n---------------------------------\n\n``pyhealth.codemap`` provides two core functionalities. **This module can be used independently.**\n\n* For code ontology lookup within one medical coding system (e.g., name, category, sub-concept); \n\n.. code-block:: python\n\n    from pyhealth.medcode import InnerMap\n\n    icd9cm = InnerMap.load(\"ICD9CM\")\n    icd9cm.lookup(\"428.0\")\n    # `Congestive heart failure, unspecified`\n    icd9cm.get_ancestors(\"428.0\")\n    # ['428', '420-429.99', '390-459.99', '001-999.99']\n    \n    atc = InnerMap.load(\"ATC\")\n    atc.lookup(\"M01AE51\")\n    # `ibuprofen, combinations`\n    atc.lookup(\"M01AE51\", \"drugbank_id\")\n    # `DB01050`\n    atc.lookup(\"M01AE51\", \"description\")\n    # Ibuprofen is a non-steroidal anti-inflammatory drug (NSAID) derived ...\n    atc.lookup(\"M01AE51\", \"indication\")\n    # Ibuprofen is the most commonly used and prescribed NSAID. It is very common over the ...\n\n* For code mapping between two coding systems (e.g., ICD9CM to CCSCM). \n\n.. code-block:: python\n\n    from pyhealth.medcode import CrossMap\n\n    codemap = CrossMap.load(\"ICD9CM\", \"CCSCM\")\n    codemap.map(\"428.0\")\n    # ['108']\n\n    codemap = CrossMap.load(\"NDC\", \"RxNorm\")\n    codemap.map(\"50580049698\")\n    # ['209387']\n\n    codemap = CrossMap.load(\"NDC\", \"ATC\")\n    codemap.map(\"50090539100\")\n    # ['A10AC04', 'A10AD04', 'A10AB04']\n\n5. Medical Code Tokenizer :speech_balloon:\n---------------------------------------------\n\n``pyhealth.tokenizer`` is used for transformations between string-based tokens and integer-based indices, based on the overall token space. We provide flexible functions to tokenize 1D, 2D and 3D lists. **This module can be used independently.**\n\n.. code-block:: python\n\n    from pyhealth.tokenizer import Tokenizer\n\n    # Example: we use a list of ATC3 code as the token\n    token_space = ['A01A', 'A02A', 'A02B', 'A02X', 'A03A', 'A03B', 'A03C', 'A03D', \\\n            'A03F', 'A04A', 'A05A', 'A05B', 'A05C', 'A06A', 'A07A', 'A07B', 'A07C', \\\n            'A12B', 'A12C', 'A13A', 'A14A', 'A14B', 'A16A']\n    tokenizer = Tokenizer(tokens=token_space, special_tokens=[\"<pad>\", \"<unk>\"])\n\n    # 2d encode \n    tokens = [['A03C', 'A03D', 'A03E', 'A03F'], ['A04A', 'B035', 'C129']]\n    indices = tokenizer.batch_encode_2d(tokens) \n    # [[8, 9, 10, 11], [12, 1, 1, 0]]\n\n    # 2d decode \n    indices = [[8, 9, 10, 11], [12, 1, 1, 0]]\n    tokens = tokenizer.batch_decode_2d(indices)\n    # [['A03C', 'A03D', 'A03E', 'A03F'], ['A04A', '<unk>', '<unk>']]\n\n    # 3d encode\n    tokens = [[['A03C', 'A03D', 'A03E', 'A03F'], ['A08A', 'A09A']], \\\n        [['A04A', 'B035', 'C129']]]\n    indices = tokenizer.batch_encode_3d(tokens)\n    # [[[8, 9, 10, 11], [24, 25, 0, 0]], [[12, 1, 1, 0], [0, 0, 0, 0]]]\n\n    # 3d decode\n    indices = [[[8, 9, 10, 11], [24, 25, 0, 0]], \\\n        [[12, 1, 1, 0], [0, 0, 0, 0]]]\n    tokens = tokenizer.batch_decode_3d(indices)\n    # [[['A03C', 'A03D', 'A03E', 'A03F'], ['A08A', 'A09A']], [['A04A', '<unk>', '<unk>']]]\n..\n\n6. Tutorials :teacher:\n----------------------------\n\n.. image:: https://colab.research.google.com/assets/colab-badge.svg\n    :target: https://pyhealth.readthedocs.io/en/latest/tutorials.html\n\n..\n\n We provide the following tutorials to help users get started with our pyhealth. \n\n`Tutorial 0: Introduction to pyhealth.data <https://colab.research.google.com/drive/1y9PawgSbyMbSSMw1dpfwtooH7qzOEYdN?usp=sharing>`_  `[Video] <https://www.youtube.com/watch?v=Nk1itBoLOX8&list=PLR3CNIF8DDHJUl8RLhyOVpX_kT4bxulEV&index=2>`__  \n\n`Tutorial 1: Introduction to pyhealth.datasets <https://colab.research.google.com/drive/18kbzEQAj1FMs_J9rTGX8eCoxnWdx4Ltn?usp=sharing>`_  `[Video] <https://www.youtube.com/watch?v=c1InKqFJbsI&list=PLR3CNIF8DDHJUl8RLhyOVpX_kT4bxulEV&index=3>`__  \n\n`Tutorial 2: Introduction to pyhealth.tasks <https://colab.research.google.com/drive/1r7MYQR_5yCJGpK_9I9-A10HmpupZuIN-?usp=sharing>`_  `[Video] <https://www.youtube.com/watch?v=CxESe1gYWU4&list=PLR3CNIF8DDHJUl8RLhyOVpX_kT4bxulEV&index=4>`__  \n\n`Tutorial 3: Introduction to pyhealth.models <https://colab.research.google.com/drive/1LcXZlu7ZUuqepf269X3FhXuhHeRvaJX5?usp=sharing>`_  `[Video] <https://www.youtube.com/watch?v=fRc0ncbTgZA&list=PLR3CNIF8DDHJUl8RLhyOVpX_kT4bxulEV&index=6>`__  \n\n`Tutorial 4: Introduction to pyhealth.trainer <https://colab.research.google.com/drive/1L1Nz76cRNB7wTp5Pz_4Vp4N2eRZ9R6xl?usp=sharing>`_  `[Video] <https://www.youtube.com/watch?v=5Hyw3of5pO4&list=PLR3CNIF8DDHJUl8RLhyOVpX_kT4bxulEV&index=7>`__  \n\n`Tutorial 5: Introduction to pyhealth.metrics <https://colab.research.google.com/drive/1Mrs77EJ92HwMgDaElJ_CBXbi4iABZBeo?usp=sharing>`_  `[Video] <https://www.youtube.com/watch?v=d-Kx_xCwre4&list=PLR3CNIF8DDHJUl8RLhyOVpX_kT4bxulEV&index=8>`__ \n\n\n`Tutorial 6: Introduction to pyhealth.tokenizer <https://colab.research.google.com/drive/1bDOb0A5g0umBjtz8NIp4wqye7taJ03D0?usp=sharing>`_ `[Video] <https://www.youtube.com/watch?v=CeXJtf0lfs0&list=PLR3CNIF8DDHJUl8RLhyOVpX_kT4bxulEV&index=10>`__ \n\n\n`Tutorial 7: Introduction to pyhealth.medcode <https://colab.research.google.com/drive/1xrp_ACM2_Hg5Wxzj0SKKKgZfMY0WwEj3?usp=sharing>`_ `[Video] <https://www.youtube.com/watch?v=MmmfU6_xkYg&list=PLR3CNIF8DDHJUl8RLhyOVpX_kT4bxulEV&index=9>`__  \n\n\n The following tutorials will help users build their own task pipelines.\n\n`Pipeline 1: Drug Recommendation <https://colab.research.google.com/drive/10CSb4F4llYJvv42yTUiRmvSZdoEsbmFF?usp=sharing>`_ `[Video] <https://\nwww.youtube.com/watch?v=GGP3Dhfyisc&list=PLR3CNIF8DDHJUl8RLhyOVpX_kT4bxulEV&index=12>`__  \n\n`Pipeline 2: Length of Stay Prediction <https://colab.research.google.com/drive/1JoPpXqqB1_lGF1XscBOsDHMLtgvlOYI1?usp=sharing>`_ `[Video] <https://\nwww.youtube.com/watch?v=GGP3Dhfyisc&list=PLR3CNIF8DDHJUl8RLhyOVpX_kT4bxulEV&index=12>`__  \n\n`Pipeline 3: Readmission Prediction <https://colab.research.google.com/drive/1bhCwbXce1YFtVaQLsOt4FcyZJ1_my7Cs?usp=sharing>`_ `[Video] <https://\nwww.youtube.com/watch?v=GGP3Dhfyisc&list=PLR3CNIF8DDHJUl8RLhyOVpX_kT4bxulEV&index=12>`__  \n\n`Pipeline 4: Mortality Prediction <https://colab.research.google.com/drive/1Qblpcv4NWjrnADT66TjBcNwOe8x6wU4c?usp=sharing>`_ `[Video] <https://\nwww.youtube.com/watch?v=GGP3Dhfyisc&list=PLR3CNIF8DDHJUl8RLhyOVpX_kT4bxulEV&index=12>`__ \n\n`Pipeline 5: Sleep Staging <https://colab.research.google.com/drive/1mpSeNCAthXG3cqROkdUcUdozIPIMTCuo?usp=sharing>`_ `[Video] <https://www.youtube.com/watch?v=ySAIU-rO6so&list=PLR3CNIF8DDHJUl8RLhyOVpX_kT4bxulEV&index=16>`__  \n\n\n We provided the advanced tutorials for supporting various needs. \n\n`Advanced Tutorial 1: Fit your dataset into our pipeline <https://colab.research.google.com/drive/1UurxwAAov1bL_5OO3gQJ4gAa_paeJwJp?usp=sharing>`_  `[Video] <https://www.youtube.com/watch?v=xw2hGLEQ4Y0&list=PLR3CNIF8DDHJUl8RLhyOVpX_kT4bxulEV&index=13>`__ \n\n`Advanced Tutorial 2: Define your own healthcare task <https://colab.research.google.com/drive/1gK6zPXvfFGBM1uNaLP32BOKrnnJdqRq2?usp=sharing>`_ \n\n`Advanced Tutorial 3: Adopt customized model into pyhealth <https://colab.research.google.com/drive/1F_NJ90GC8_Eq-vKTf7Tyziew4gWjjKoH?usp=sharing>`_  `[Video] <https://www.youtube.com/watch?v=lADFlcmLtdE&list=PLR3CNIF8DDHJUl8RLhyOVpX_kT4bxulEV&index=14>`__ \n\n`Advanced Tutorial 4: Load your own processed data into pyhealth and try out our ML models <https://colab.research.google.com/drive/1ZRnKch2EyJLrI3G5AvDXVpeE2wwgBWfw?usp=sharing>`_ `[Video] <https://www.youtube.com/watch?v=xw2hGLEQ4Y0&list=PLR3CNIF8DDHJUl8RLhyOVpX_kT4bxulEV&index=13>`__ \n\n\n7. Datasets :mountain_snow:\n-----------------------------\nWe provide the processing files for the following open EHR datasets:\n\n===================  =======================================  ========================================  ======================================================================================================== \nDataset              Module                                   Year                                      Information                                                             \n===================  =======================================  ========================================  ========================================================================================================\nMIMIC-III            ``pyhealth.datasets.MIMIC3Dataset``      2016                                      `MIMIC-III Clinical Database <https://physionet.org/content/mimiciii/1.4//>`_    \nMIMIC-IV             ``pyhealth.datasets.MIMIC4Dataset``      2020                                      `MIMIC-IV Clinical Database <https://physionet.org/content/mimiciv/0.4/>`_  \neICU                 ``pyhealth.datasets.eICUDataset``        2018                                      `eICU Collaborative Research Database <https://eicu-crd.mit.edu//>`_                 \nOMOP                 ``pyhealth.datasets.OMOPDataset``                                                  `OMOP-CDM schema based dataset <https://www.ohdsi.org/data-standardization/the-common-data-model/>`_    \nSleepEDF             ``pyhealth.datasets.SleepEDFDataset``    2018                                      `Sleep-EDF dataset <https://physionet.org/content/sleep-edfx/1.0.0/>`_\nSHHS                 ``pyhealth.datasets.SHHSDataset``        2016                                      `Sleep Heart Health Study dataset <https://sleepdata.org/datasets/shhs>`_   \nISRUC                ``pyhealth.datasets.ISRUCDataset``       2016                                      `ISRUC-SLEEP dataset <https://sleeptight.isr.uc.pt/?page_id=48>`_                               \n===================  =======================================  ========================================  ========================================================================================================\n\n\n8. Machine/Deep Learning Models and Benchmarks :airplane:\n------------------------------------------------------------\n\n==================================    ================  =================================  ======  ============================================================================================================================================================================  =======================================================================================================================================================================================\nModel Name                            Type              Module                             Year    Summary                                                                                                                                                                       Reference\n==================================    ================  =================================  ======  ============================================================================================================================================================================  =======================================================================================================================================================================================\nMulti-layer Perceptron                deep learning     ``pyhealth.models.MLP``            1986    MLP treats each feature as static                                                                                                                                             `Backpropagation: theory, architectures, and applications <https://www.taylorfrancis.com/books/mono/10.4324/9780203763247/backpropagation-yves-chauvin-david-rumelhart>`_\nConvolutional Neural Network (CNN)    deep learning     ``pyhealth.models.CNN``            1989    CNN runs on the conceptual patient-by-visit grids                                                                                                                             `Handwritten Digit Recognition with a Back-Propagation Network <https://proceedings.neurips.cc/paper/1989/file/53c3bce66e43be4f209556518c2fcb54-Paper.pdf>`_\nRecurrent Neural Nets (RNN)           deep Learning     ``pyhealth.models.RNN``            2011    RNN (includes LSTM and GRU) can run on any sequential level (e.g., visit by visit sequences)                                                                                  `Recurrent neural network based language model <http://www.fit.vutbr.cz/research/groups/speech/servite/2010/rnnlm_mikolov.pdf>`_\nTransformer                           deep Learning     ``pyhealth.models.Transformer``    2017    Transformer can run on any sequential level (e.g., visit by visit sequences)                                                                                                  `Atention is All you Need <https://arxiv.org/abs/1706.03762>`_\nRETAIN                                deep Learning     ``pyhealth.models.RETAIN``         2016    RETAIN uses two RNN to learn patient embeddings while providing feature-level and visit-level importance.                                                                     `RETAIN: An Interpretable Predictive Model for Healthcare using Reverse Time Attention Mechanism <https://arxiv.org/abs/1608.05745>`_\nGAMENet                               deep Learning     ``pyhealth.models.GAMENet``        2019    GAMENet uses memory networks, used only for drug recommendation task                                                                                                          `GAMENet: Graph Attention Mechanism for Explainable Electronic Health Record Prediction <https://arxiv.org/abs/1809.01852>`_\nMICRON                                deep Learning     ``pyhealth.models.MICRON``         2021    MICRON predicts the future drug combination by instead predicting the changes w.r.t. the current combination, used only for drug recommendation task                          `Change Matters: Medication Change Prediction with Recurrent Residual Networks <https://www.ijcai.org/proceedings/2021/0513>`_\nSafeDrug                              deep Learning     ``pyhealth.models.SafeDrug``       2021    SafeDrug encodes drug molecule structures by graph neural networks, used only for drug recommendation task                                                                    `SafeDrug: Dual Molecular Graph Encoders for Recommending Effective and Safe Drug Combinations <https://arxiv.org/abs/2105.02711>`_\nMoleRec                               deep Learning     ``pyhealth.models.MoleRec``        2023    MoleRec encodes drug molecule in a substructure level as well as the patient's information into a drug combination representation, used only for drug recommendation task     `MoleRec: Combinatorial Drug Recommendation with Substructure-Aware Molecular Representation Learning <https://dl.acm.org/doi/10.1145/3543507.3583872>`_\nDeepr                                 deep Learning     ``pyhealth.models.Deepr``          2017    Deepr is based on 1D CNN. General purpose.                                                                                                                                    `Deepr : A Convolutional Net for Medical Records <https://arxiv.org/abs/1607.07519>`_\nContraWR Encoder (STFT+CNN)           deep Learning     ``pyhealth.models.ContraWR``       2021    ContraWR encoder uses short time Fourier transform (STFT) + 2D CNN, used for biosignal learning                                                                               `Self-supervised EEG Representation Learning for Automatic Sleep Staging <https://arxiv.org/abs/2110.15278>`_\nSparcNet (1D CNN)                     deep Learning     ``pyhealth.models.SparcNet``       2023    SparcNet is based on 1D CNN, used for biosignal learning                                                                                                                      `Development of Expert-level Classification of Seizures and Rhythmic and Periodic Patterns During EEG Interpretation <#>`_\nTCN                                   deep learning     ``pyhealth.models.TCN``            2018    TCN is based on dilated 1D CNN. General purpose                                                                                                                               `Temporal Convolutional Networks <https://arxiv.org/abs/1803.01271>`_\nAdaCare                               deep learning     ``pyhealth.models.AdaCare``        2020    AdaCare uses CNNs with dilated filters to learn enriched patient embedding. It uses feature calibration module to provide the feature-level and visit-level interpretability  `AdaCare: Explainable Clinical Health Status Representation Learning via Scale-Adaptive Feature Extraction and Recalibration <https://arxiv.org/abs/1911.12205>`_\nConCare                               deep learning     ``pyhealth.models.ConCare``        2020    ConCare uses transformers to learn patient embedding and calculate inter-feature correlations.                                                                                `ConCare: Personalized Clinical Feature Embedding via Capturing the Healthcare Context <https://arxiv.org/abs/1911.12216>`_\nStageNet                              deep learning     ``pyhealth.models.StageNet``       2020    StageNet uses stage-aware LSTM to conduct clinical predictive tasks while learning patient disease progression stage change unsupervisedly                                    `StageNet: Stage-Aware Neural Networks for Health Risk Prediction <https://arxiv.org/abs/2001.10054>`_\nDr. Agent                             deep learning     ``pyhealth.models.Agent``          2020    Dr. Agent uses two reinforcement learning agents to learn patient embeddings by mimicking clinical second opinions                                                            `Dr. Agent: Clinical predictive model via mimicked second opinions <https://academic.oup.com/jamia/article/27/7/1084/5858308>`_\nGRASP                                 deep learning     ``pyhealth.models.GRASP``          2021    GRASP uses graph neural network to identify latent patient clusters and uses the clustering information to learn patient                                                      `GRASP: Generic Framework for Health Status Representation Learning Based on Incorporating Knowledge from Similar Patients <https://ojs.aaai.org/index.php/AAAI/article/view/16152>`_\n==================================    ================  =================================  ======  ============================================================================================================================================================================  =======================================================================================================================================================================================\n\n* Check the `interactive map on benchmark EHR predictive tasks <https://pyhealth.readthedocs.io/en/latest/index.html#benchmark-on-healthcare-tasks>`_.\n\n9. Citing PyHealth :handshake:\n----------------------------------\n\n.. code-block:: bibtex\n\n    @inproceedings{pyhealth2023yang,\n        author = {Yang, Chaoqi and Wu, Zhenbang and Jiang, Patrick and Lin, Zhen and Gao, Junyi and Danek, Benjamin and Sun, Jimeng},\n        title = {{PyHealth}: A Deep Learning Toolkit for Healthcare Predictive Modeling},\n        url = {https://github.com/sunlabuiuc/PyHealth},\n        booktitle = {Proceedings of the 27th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD) 2023},\n        year = {2023}\n    }\n\n"
 },
 {
  "repo": "llSourcell/How_to_Build_a_healthcare_startup",
  "language": "Dart",
  "readme_contents": "\n\n\n## Overview\n\nThis is the code for [this](https://youtu.be/b8xlCNzkX5w) video on Youtube by Siraj Raval on \"How to Build a Healthcare Startup\". The app uses PoseNet to detect human poses and a text to speech engine to speak to you. This emulates the role of a Yoga instructor! This code is unfinished, but meant to give you a starting point and guide so that you can build a profitable business using it or a similar idea. \n\n## Dependencies\n\nAll of these can be downloaded in a single command, see below. \n\n- PoseNet Model \n- Tensorflow Lite\n- Stripe\n- RazorPay\n- Flutter Text to Speech\n\n## Instructions\n\nFirst install [Flutter](https://flutter.dev/docs/get-started/install). \n\nAfter download, from command line run this to install the dependencies\n```\nflutter packages get\n```\nThen run this command to run the app\n\n```\nflutter run\n```\nAlternatively you can open the app as a new flutter project in Android Studio after installing the Flutter plugin. See the video for instructions on how to do that. \n\n## TODO - please make a PR if you fix any of these\n\n- Firebase is integrated, but it still needs to be properly wired up to the login and signup pages.\n- Stripe and RazorPay are integrated, but each still need to be wired up to the Credit/Debit Card view i created.\n- Generate some text everytime a pose is detected, not just on startup.\n- Make the personal 0/10 score some meaningful metric, store it in Firebase.\n- PoseNet is integrated, but still needs to be replaced by YogaNet. \n\n## Wait what's YogaNet?\n\n[this](https://github.com/smellslikeml/YogAI) is YogaNet. This person retrained a neural network to detect yoga poses and outputted the result as a TFLite file in their /models folder. Notice how in this flutter app, there is space to import TF Lite models. Integrate the Yoga Model into the app by replacing the existing posenet model. \n\n## Credits\n\nThanks to [shaqian](https://github.com/shaqian/flutter_realtime_detection) for her starter code. \n"
 },
 {
  "repo": "GoogleCloudPlatform/healthcare-data-harmonization",
  "language": "Go",
  "readme_contents": "# Google HCLS Data Harmonization\n\n## Summary\n\nThis is an engine that converts data of one structure to another, based on a\nconfiguration file which describes how.\n\nThe configuration file can be written in either the native\n[protobuf](https://developers.google.com/protocol-buffers/docs/overview) format\nor a condensed\n[Whistle Data Transformation Language](http://github.com/GoogleCloudPlatform/healthcare-data-harmonization/blob/master/mapping_language)\nwhich is transpiled to protobuf configs for you.\n\nThe engine accepts data in JSON format and outputs it in JSON format. For\ninformation on the mapping configuration, look at the protobuf files in the\nproto directory.\n\n## Overview\n\nThis repository is organized into several packages that together enable you to\nauthor Whistle configs, extend existing mapping configurations, and test configs\nwithin a Jupyter notebook environment.\n\n*   [Mapping Engine](http://github.com/GoogleCloudPlatform/healthcare-data-harmonization/blob/master/mapping_engine/README.md)\n*   [Mapping Language](http://github.com/GoogleCloudPlatform/healthcare-data-harmonization/blob/master/mapping_language/README.md)\n*   [Mapping Configs](http://github.com/GoogleCloudPlatform/healthcare-data-harmonization/blob/master/mapping_configs/README.md)\n*   [Jupyter Notebook](http://github.com/GoogleCloudPlatform/healthcare-data-harmonization/blob/master/tools/notebook/README.md)\n\n## Getting Started\n\nWe highly recommend that you start by setting up your\n[Jupyter Notebook](http://github.com/GoogleCloudPlatform/healthcare-data-harmonization/blob/master/tools/notebook/README.md)\nenvironment using the published docker images and executing the\n[example notebook](http://github.com/GoogleCloudPlatform/healthcare-data-harmonization/blob/master/tools/notebook/examples/demo-sample.ipynb).\nOnce setup, work through the\n[Whistle Data Transformation Language Codelab](http://github.com/GoogleCloudPlatform/healthcare-data-harmonization/blob/master/mapping_language/doc/codelab.md)\nto get yourself familiar with Whistle. As you author more Whistle configs, use\nthe\n[Whistle Data Transformation Language Reference](http://github.com/GoogleCloudPlatform/healthcare-data-harmonization/blob/master/mapping_language/doc/reference.md)\nto deepen your understanding of the language.\n\n### Details\n\nThis project consists of three components, the mapping engine, the mapping\nlanguage, and Jupyter notebook UI extensions and magic commands. **If you want\nto build the mapping engine and mapping language packages:**\n\nMake sure you have installed and added to PATH\n\n1.  [Golang](https://golang.org/dl/) (>= 1.13)\n1.  [Java JDK](https://openjdk.java.net/install/) (>= 8)\n1.  [Protobuf Compiler `protoc`](https://github.com/protocolbuffers/protobuf/releases/tag/v3.11.4)\n    (>= 3.11.4)\n1.  [Clang](https://clang.llvm.org/get_started.html) (>= 11.0.1-2)\n\nThen run `build_all.sh`.\n\nThis command will build and run the tests of the above packages. In addition,\nthere are a set of JupyterLab UI extensions and magic commands that simplify the\nauthoring workflow. The extensions are packaged into a set of pre-built and\npublished docker images that contain and Jupyter notebook extensions/magic\ncommands and does not require you to build the mapping engine and mapping\nlibrary packages. For more details about each package, please refer to their\nindividual READMEs for more information.\n\n### Language Reference\n\nA language reference is available:\n[Whistle Data Transformation Language Reference](http://github.com/GoogleCloudPlatform/healthcare-data-harmonization/blob/master/mapping_language/doc/reference.md)\n\n### Codelab\n\nPlease refer to the\n[Whistle Data Transformation Language Codelab](http://github.com/GoogleCloudPlatform/healthcare-data-harmonization/blob/master/mapping_language/doc/codelab.md)\nfor instructions on how to run the mapping engine and for getting familiar with\nthe mapping language.\n\n### Sample pipelines\n\nWhistle configs can be executed in [Apache Beam](https://beam.apache.org/).\nPlease refer to the\n[Whistle Dataflow Pipelines Repo](https://github.com/GoogleCloudPlatform/healthcare-data-harmonization-dataflow)\nfor sample pipelines.\n\n### Feedback\n\nWant to help the Google Cloud Healthcare and Life Sciences team improve Whistle?\nPlease email: whistle-feedback@google.com to connect with the Whistle team for a\nfurther discussion on your experience with Whistle.\n\n## License\n\nApache License, Version 2.0\n"
 },
 {
  "repo": "vsharathchandra/AI-Healthcare-chatbot",
  "language": "Python",
  "readme_contents": "# AI-Healthcare-chatbot\nThrough a series of questions about symptoms it diagnosis the health condition of patient. <br />\nLanguage     : python. <br />\nmodules used : scikit-learn,pandas,numpy <br />\nModel        : Decision Tree\n\n"
 },
 {
  "repo": "Rishabh42/HealthCare-Insurance-Ethereum",
  "language": "JavaScript",
  "readme_contents": "# Medical Insurance claiming DApp (for ConsenSys)\nProblem statement:\n1) Patient logs in, uploads medical/lab test bills and submits it for insurance. Notifications are sent to hospital and lab admin.\n2) Hospital admin logs in, verifies and approves the bills. This approval is stored on the smart contract\n3) Lab admin approves the lab test bills. This approval is also stored on the smart contract\n4) Once both of them approve, notification are sent to insurance admin.\n5) Insurance admin can check for approvals of hospital and lab after which he will calculate the claim amount and do the claim.\n\n `HealthCare.sol` contract maintains the logic for this DApp.  \n  The web pages found in the `Web-client` folder are used to communicate with the deployed smart contract and also allow logging in for each specific user\n\n## Steps to deploy and interact with the contract:\n1. Copy and paste the contract code on https://remix.ethereum.org/\n2. Run an instance of ganache-cli on your local machine and connect your metamask wallet to it. Also, add the first 3 accounts from ganache to your metamask by importing their private keys and assign the following names to it:  \n    account 1: Hospital admin  \n    account 2: Lab admin  \n    account 3: Patient  \n3. Pass the Lab Admin's address as an argument in the constructor while deploying the contract\n4. Select `Injected Web3` in the `Environment` field and make sure your Metamask wallet is unlocked. This will connect Remix to the first account(Hospital admin) in your Metamask wallet.\n5. Deploy the contract\n6. Select Account 3(Patient) and created a new medical record by calling the `newRecord` function with the respective fields.\n7. You can check if the record was created and it's details by calling the `_records` mapping with index 1.\n8. To sign the record, switch back to account 1(Hospital admin) in Metamask, enter the record's `_ID` in the `signRecord` function and click on transact.\n9. Repeat the same steps using account 2(Lab Admin) from metamask.\n10. Now the record is approved and you can verify the same by calling the `_records` mapping again where you can see that the `signatureCount` has incremented. \n\nNote that you can not sign the record using the patient's account from metamask and neither can the same account sign a record twice.\n\nUpdate:  \nWith Remix's new interface, you need to change the account address from the `ACCOUNT` drop down on the `Deploy and Run` tab (required in step 8):  \n\n<img width=\"369\" alt=\"Screenshot 2021-05-02 at 2 10 52 PM\" src=\"https://user-images.githubusercontent.com/20457952/117578650-f00c6480-b10c-11eb-906e-c5ff79252585.png\">\n\n## Known issues:  \n- The table on the React front end doesn't display the records created by the user (Issue #1).  \n\nThe main focus of this project at the time of making was the smart contract logic, I just made the front end in a jiffy as I had some extra time left after implementing the contracts.  \n\nContributions to fix the open issues are welcome, you'll receive some DOGE as well \ud83d\ude0f\n\n## Steps to contribute  \n1. Fork this repo.\n2. Commit your changes.\n3. Send a PR to this project's `master` branch and add me as a reviewer\n\n\n"
 },
 {
  "repo": "PacktPublishing/Machine-Learning-for-Healthcare-Analytics-Projects",
  "language": "HTML",
  "readme_contents": "\n\n\n# Machine Learning for Healthcare Analytics Projects\n\n<a href=\"https://www.packtpub.com/big-data-and-business-intelligence/machine-learning-healthcare-analytics-projects?utm_source=github&utm_medium=repository&utm_campaign=9781789536591 \"><img src=\"https://d255esdrn735hr.cloudfront.net/sites/default/files/imagecache/ppv4_main_book_cover/cover_8.png\" alt=\"Machine Learning for Healthcare Analytics Projects\" height=\"256px\" align=\"right\"></a>\n\nThis is the code repository for [Machine Learning for Healthcare Analytics Projects](https://www.packtpub.com/big-data-and-business-intelligence/machine-learning-healthcare-analytics-projects?utm_source=github&utm_medium=repository&utm_campaign=9781789536591), published by Packt.\n\n**Build smart AI applications using neural network methodologies across the healthcare vertical market**\n\n## What is this book about?\n\nThis book covers the following exciting features:\n* Explore super imaging and natural language processing (NLP) to classify DNA sequencing \n* Detect cancer based on the cell information provided to the SVM \n* Apply supervised learning techniques to diagnose autism spectrum disorder (ASD) \n* Implement a deep learning grid and deep neural networks for detecting diabetes \n* Analyze data from blood pressure, heart rate, and cholesterol level tests using neural networks \n* Use ML algorithms to detect autistic disorders \n\nIf you feel this book is for you, get your [copy](https://www.amazon.com/dp/1789536596) today!\n\n<a href=\"https://www.packtpub.com/?utm_source=github&utm_medium=banner&utm_campaign=GitHubBanner\"><img src=\"https://raw.githubusercontent.com/PacktPublishing/GitHub/master/GitHub.png\" \nalt=\"https://www.packtpub.com/\" border=\"5\" /></a>\n\n## Instructions and Navigations\nAll of the code is organized into folders. For example, Chapter02.\n\nThe code will look like the following:\n\nimport sys\nimport pandas as pd\nimport sklearn\nimport keras\nprint 'Python: {}'.format(sys.version)\nprint 'Pandas: {}'.format(pd.__version__)\nprint 'Sklearn: {}'.format(sklearn.__version__)\nprint 'Keras: {}'.format(keras.__version__)\n\n\n*Following is what you need for this book:*\nMachine Learning for Healthcare Analytics Projects is for data scientists, machine learning engineers, and healthcare professionals who want to implement machine learning algorithms to build smart AI applications. Basic knowledge of Python or any programming language is expected to get the most from this book.\n\nWith the following software and hardware list you can run all code files present in the book (Chapter 1-5).\n### Software and Hardware List\n| Chapter | Software required | OS required |\n| -------- | ------------------------------------ | ----------------------------------- |\n| All | Python 3.6 or later | Windows, Mac OS X, and Linux (Any) |\n|  | Anaconda 5.2 | Windows, Mac OS X, and Linux (Any) |\n|  | Jupyter Notebook | Windows, Mac OS X, and Linux (Any) |\n\n\nWe also provide a PDF file that has color images of the screenshots/diagrams used in this book. [Click here to download it](https://www.packtpub.com/sites/default/files/downloads/9781789536591_ColorImages.pdf).\n\n### Related products\n* Healthcare Analytics Made Simple  [[Packt]](https://www.packtpub.com/big-data-and-business-intelligence/healthcare-analytics-made-simple?utm_source=github&utm_medium=repository&utm_campaign=) [[Amazon]](https://www.amazon.com/dp/1787286703)\n\n\n## Get to Know the Author\n*Eduonix Learning Solutions*\ncreates and distributes high-quality technology training content. Our team of industry professionals has been developing workforces for more than a decade. We aim to teach technology the way it is used in industry and the professional world. We have a professional team of trainers for technologies ranging from mobility, web enterprises, and database and server administration.\n\n\n## Other books by the authors\n[Learn to Create WordPress Themes by Building 5 Projects](https://www.packtpub.com/web-development/learn-create-wordpress-themes-building-5-projects?utm_source=github&utm_medium=repository&utm_campaign=9781787286641 )\n\n[Learn Node.js by Building 6 Projects](https://www.packtpub.com/web-development/learn-nodejs-building-6-projects?utm_source=github&utm_medium=repository&utm_campaign=9781788293631 )\n\n\n\n### Suggestions and Feedback\n[Click here](https://docs.google.com/forms/d/e/1FAIpQLSdy7dATC6QmEL81FIUuymZ0Wy9vH1jHkvpY57OiMeKGqib_Ow/viewform) if you have any feedback or suggestions.\n### Download a free PDF\n\n <i>If you have already purchased a print or Kindle version of this book, you can get a DRM-free PDF version at no cost.<br>Simply click on the link to claim your free PDF.</i>\n<p align=\"center\"> <a href=\"https://packt.link/free-ebook/9781789536591\">https://packt.link/free-ebook/9781789536591 </a> </p>"
 },
 {
  "repo": "GoogleCloudPlatform/healthcare-dicom-dicomweb-adapter",
  "language": "Java",
  "readme_contents": "# DICOM Adapter\n\nThe DICOM adapter is a set of components that translate between traditional DICOM DIMSE protocols (e.g., C-STORE) and the RESTful DICOMweb protocols (e.g., STOW-RS). There are\ntwo components, namely import and export adapter.\n\nTable of Contents\n=================\n\n   * [DICOM Adapter](#dicom-adapter)\n      * [Import Adapter](#import-adapter)\n      * [Export Adapter](#export-adapter)\n      * [Stackdriver Monitoring](#stackdriver-monitoring)\n      * [DICOM Redactor](#dicom-redactor)\n      * [Deployment using Kubernetes](#deployment-using-kubernetes)\n         * [Requirements](#requirements)\n         * [Deploying Docker Images to GKE](#deploying-docker-images-to-gke)\n      * [Local Deployment](#local-deployment)\n      * [Deployment using Data Protection Toolkit](#deployment-using-data-protection-toolkit)\n      * [Building from source](#building-from-source)\n         * [Building and publishing Docker Images](#building-and-publishing-docker-images)\n      * [Wiki](#wiki)\n      * [Troubleshooting](#troubleshooting)\n\n## Import Adapter\n\nThe Import Adapter converts incoming DIMSE requests to corresponding DICOMWeb requests and passes the converted results back to the DIMSE client. The following requests are supported:\n- C-STORE to STOW-RS\n- C-FIND to QIDO-RS\n- C-MOVE uses QIDO-RS to determine which instances to transfer, then for each instance executes a \nWADO-RS request to fetch the instance and a C-STORE request to transfer it to the C-MOVE destination\n- Storage commitment service to QIDO-RS\n\nNote that any C-FIND query on the ModalitiesInStudy tag will result in 1 QIDO-RS query per modality.\n\nAvailable AET destinations for the C-MOVE and storage commitment services are configured via an AET dictionary json file, \nwhich can be specified either by using the \"--aet_dictionary\" command line parameter or \nspecifying the \"ENV_AETS_JSON\" environment variable.\n\nThe following configuration needs to be added to the dicom-adapter.yaml file to use CMOVE. \nPlease see the [Deployment using Kubernetes](#deployment-using-kubernetes) section for more information.\n```yaml\nenv:\n- name: ENV_AETS_JSON\n  valueFrom:\n    configMapKeyRef:\n      name: aet-dictionary\n      key: AETs.json\n```\n\nHere is an example JSON dictionary:\n```shell\n[\n\t{\n\t\t\"name\": \"DEVICE_A\", \n\t\t\"host\": \"localhost\", \n\t\t\"port\": 11113\n\t},\n\t{\n\t\t\"name\": \"DEVICE_B\", \n\t\t\"host\": \"192.168.0.1\", \n\t\t\"port\": 11114\n\t},\n\t...\n]\n```\n\nAnd command to create configmap from it:\n\n```shell\nkubectl create configmap aet-dictionary --from-file=AETs.json\n```\n\nThe AET dictionary JSON can also be specified directly via the \"--aet_dictionary_inline\" parameter.\n\nFor the list of command line flags, see [here](import/src/main/java/com/google/cloud/healthcare/imaging/dicomadapter/Flags.java)\n\n## Export Adapter\n\nThe Export Adapter listens to [Google Cloud Pub/Sub](https://cloud.google.com/pubsub/)\nfor new instances, fetches them using WADO-RS, then sends them to the client.\nThis binary can be configured to output either C-STORE or STOW-RS via command\nline flags.\n\nTo use [Google Cloud Pub/Sub](https://cloud.google.com/pubsub/), you require a [Google Cloud project](https://cloud.google.com). Furthermore, [Cloud Pubsub API](https://console.cloud.google.com/apis/api/pubsub.googleapis.com/overview) must be enabled in your Google project. The binary expects that each Cloud Pub/Sub notification consists of the WADO-RS path for the DICOM instance that is to be exported (e.g. `/studies/<STUDY_UID>/series/<SERIES_UID>/instances/<INSTANCE_UID>`).\n\nFor the list of command line flags, see [here](export/src/main/java/com/google/cloud/healthcare/imaging/dicomadapter/Flags.java)\n\n## Stackdriver Monitoring\n\nBoth the Import and Export adapter include support for Stackdriver Monitoring.\nIt is enabled by specifying the --monitoring_project_id parameter, which must be the same project in which the adapter is running.\nFor the list of events logged to Stackdriver for the Export Adapter, see [here](export/src/main/java/com/google/cloud/healthcare/imaging/dicomadapter/monitoring/Event.java). \nFor the list of events logged to Stackdriver for the Import Adapter, see [here](import/src/main/java/com/google/cloud/healthcare/imaging/dicomadapter/monitoring/Event.java).\n\nThe monitored resource is configured as k8s_container, with values set from a combination of environment variables configured via Downward API (pod name, pod namespace and container name) and GCP Metadata (project id, cluster name and location). Defaults to the global resource, if k8s_container can't be configured.\n\nThe following configuration needs to be added to the dicom-adapter.yaml file to configure the \nstackdriver monitoring resource. Please see the [Deployment using Kubernetes](#deployment-using-kubernetes) section \nfor more information.\n```yaml\nenv:\n- name: ENV_POD_NAME\n  valueFrom:\n    fieldRef:\n      fieldPath: metadata.name\n- name: ENV_POD_NAMESPACE\n  valueFrom:\n    fieldRef:\n      fieldPath: metadata.namespace\n- name: ENV_CONTAINER_NAME\n  value: *containerName # referencing earlier anchor in same yaml\n```\n\n## DICOM Redactor\n\nThe Import Adapter can be configured to use the [DICOM Redactor Library](https://github.com/GoogleCloudPlatform/healthcare-deid/tree/master/offline_tools/redactor) to redact sensitive data contained in DICOM tags during a C-STORE upload.\nThe user can configure which tags to redact/remove in one of 3 ways:\n- redact_keep_list - a list of DICOM tags to keep untouched. Other tags are removed.\n- redact_remove_list - a list of DICOM tags to remove. Other tags are kept untouched.\n- redact_filter_profile - a predefined profile that will keep and remove particular tags.\n\nIf enabled via one of the above options, the redactor also always regenerates the following UIDs:\n- StudyInstanceUID\n- SeriesInstanceUID\n- SOPInstanceUID\n- MediaStorageSOPInstanceUID \n\n## Deployment using Kubernetes\n\nThe adapters can be deployed to Google Cloud Platform using [GKE] (https://cloud.google.com/kubernetes-engine/). We have published prebuilt Docker images for the both adapters to [Google Container Registry](https://cloud.google.com/container-registry/).\n\n- Import Adapter: `gcr.io/cloud-healthcare-containers/healthcare-api-dicom-dicomweb-adapter-import`\n- Export Adapter: `gcr.io/cloud-healthcare-containers/healthcare-api-dicom-dicomweb-adapter-export`\n\n### Requirements\n\n- A [Google Cloud project](https://cloud.google.com).\n- Installed [gcloud](https://cloud.google.com/sdk/gcloud/) and [kubectl](https://kubernetes.io/docs/tasks/tools/install-kubectl/) command line tools.\n\n### Deploying Docker Images to GKE\n\nCreate a local file called `dicom_adapter.yaml`. This file will contain the\nconfiguration specifying the number of adapters to deploy, along with their\ncommand line flags.\n\nTo deploy an Import Adapter, add the following to `dicom_adapter.yaml`. Modify\nthe flags for your use case.\n\n```yaml\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  name: dicom-adapter\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: dicom-adapter\n    spec:\n      containers:\n        - name: dicom-import-adapter\n          image: gcr.io/cloud-healthcare-containers/healthcare-api-dicom-dicomweb-adapter-import:0.2.29\n          ports:\n            - containerPort: 2575\n              protocol: TCP\n              name: \"port\"\n          args:\n            - \"--dimse_aet=IMPORTADAPTER\"\n            - \"--dimse_port=2575\"\n            - \"--dicomweb_address=https://healthcare.googleapis.com/v1/projects/myproject/locations/us-central1/datasets/mydataset/dicomStores/mydicomstore/dicomWeb\"\n```\n\n**The yaml configuration has changed slightly from version 0.1 to 0.2. Please see the [upgrade guide](https://github.com/GoogleCloudPlatform/healthcare-dicom-dicomweb-adapter/wiki/DICOM-Adapter-Upgrade-Guide#to-version-020) for instructions on how to upgrade your configuration.**\n\nThe dicomweb_addr and dicomweb_stow_path parameters have been deprecated, please use the dicomweb_address parameter instead as shown above.\nThe old address parameters will not work with C-FIND, C-MOVE, and storage commitment.\n\nIf needed, to additionally include an Export Adapter, you can add the to the\ncontainers in `dicom_adapter.yaml`. Modify the flags for your use case.\n\n```yaml\n        - name: dicom-export-adapter\n          image: gcr.io/cloud-healthcare-containers/healthcare-api-dicom-dicomweb-adapter-export:0.2.29\n          args:\n            - \"--peer_dimse_aet=PEERAET\"\n            - \"--peer_dimse_ip=localhost\"\n            - \"--peer_dimse_port=104\"\n            - \"--project_id=myproject\"\n            - \"--subscription_id=mysub\"\n            - \"--dicomweb_addr=https://healthcare.googleapis.com/v1\"\n            - \"--oauth_scopes=https://www.googleapis.com/auth/pubsub\"\n```\n\nThe peer_dicomweb_addr and peer_dicomweb_stow_path parameters have been deprecated, please use the peer_dicomweb_address parameter instead.\n\nTo deploy the configuration to GKE cluster, execute the following:\n\n```shell\ngcloud container clusters create dicom-adapter --zone=us-central1-a --scopes https://www.googleapis.com/auth/cloud-healthcare,https://www.googleapis.com/auth/pubsub\nkubectl create -f dicom_adapter.yaml\n```\n\nIf you are deploying an Import Adapter, you can expose the DIMSE port internally\n(e.g. 2575 here). This can be done through a load\nbalancer. Create a `dicom_adapter_load_balancer.yaml`, and add the following:\n\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: dicom-adapter-load-balancer\n  # The \"Internal\" annotation will result in an load balancer that can only\n  # be accessed from within the VPC the Kubernetes cluster is in.\n  # You can remove this annotation to get an externally accessible load balancer.\n  annotations:\n    cloud.google.com/load-balancer-type: \"Internal\"\nspec:\n  ports:\n  - port: 2575\n    targetPort: 2575\n    protocol: TCP\n    name: port\n  selector:\n    app: dicom-adapter\n  type: LoadBalancer\n```\n\nTo deploy the load balancer, execute the following:\n\n```shell\nkubectl create -f dicom_adapter_load_balancer.yaml\n```\n\nThe status and IP address of load balancer can be seen by executing:\n\n```shell\nkubectl get service dicom-adapter-load-balancer\n```\n## Local Deployment\n\nInstructions on how to run the Import Adapter Docker image locally are available on the [wiki](https://github.com/GoogleCloudPlatform/healthcare-dicom-dicomweb-adapter/wiki/Running-Docker-image-locally).\n\n## Deployment using Data Protection Toolkit\n\nThe adapters can be deployed as a gke_workload using the [data protection toolkit](https://github.com/GoogleCloudPlatform/healthcare/tree/master/deploy). Sample configuration may be found in this [folder.](https://github.com/GoogleCloudPlatform/healthcare-dicom-dicomweb-adapter/tree/master/samples) \n\n## Building from source\n\nAs an alternative to using the prebuilt Docker images, you can build the adapters from source code. Both adapters exist as separate binaries and are built using [Gradle](https://gradle.org/). Please refer to these [instructions](https://gradle.org/install/) to build Gradle for your system.\n\nFor example, to build Import Adapter:\n\n```shell\ncd import\ngradle build\n```\n\nFor example, to additionally execute Import Adapter locally:\n\n```shell\ngradle run -Dexec.args=\"--dimse_aet=IMPORTADAPTER --dimse_port=4008 --dicomweb_address=http://localhost:80\"\n```\n\n### Building and publishing Docker Images\n\nTo build and upload Import Adapter Docker images:\n\n```shell\ncd import\nPROJECT=<Your Google Cloud Project>\nTAG=gcr.io/${PROJECT}/dicom-import-adapter\ngradle dockerBuildImage -Pdocker_tag=${TAG}\ndocker push ${TAG}\n```\n\nTo build and upload Export Adapter Docker images:\n\n```shell\ncd export\nPROJECT=<Your Google Cloud Project>\nTAG=gcr.io/${PROJECT}/dicom-export-adapter\ngradle dockerBuildImage -Pdocker_tag=${TAG}\ndocker push ${TAG}\n```\n\n## Wiki\n\nFor addition documentation please see the [Wiki](https://github.com/GoogleCloudPlatform/healthcare-dicom-dicomweb-adapter/wiki).\nThe wiki includes information on advanced features such as:\n* [C-Store Retries and File Backup](https://github.com/GoogleCloudPlatform/healthcare-dicom-dicomweb-adapter/wiki/C-STORE-Backup-and-Retries)\n* [Routing to Multiple DICOM Stores](https://github.com/GoogleCloudPlatform/healthcare-dicom-dicomweb-adapter/wiki/Routing-to-multiple-DICOM-stores)\n* [C-Store In-Transit Transcoding](https://github.com/GoogleCloudPlatform/healthcare-dicom-dicomweb-adapter/wiki/In-transit-transcoding)\n\n## Troubleshooting\n\nBoth the Import and Export adapter output server logs that can be used to diagnose issues. When running on GKE, these server logs show up in Cloud Logging. You can view these logs by navigating to https://console.cloud.google.com/kubernetes/workload, clicking on dicom-adapter deployment and following the link titled \"Container logs\". Alternatively you can view the logs via `kubectl logs <pod-name>` where `<pod-name>` can be found by running `kubectl get pods`.\n"
 },
 {
  "repo": "newmediamedicine/CollaboRhythm",
  "language": "ActionScript",
  "readme_contents": "CollaboRhythm\r\n=============\r\n\r\nCollaboRhythm is an open-source platform for patient-centered care research.\r\n\r\n<http://newmed.media.mit.edu/collaborhythm>\r\n\r\n<http://groups.google.com/group/collaborhythm-developers?hl=en>\r\n\r\n\r\nDevelopers\r\n----------\r\n\r\nInstructions for developers are maintained on our [wiki](https://github.com/newmediamedicine/CollaboRhythm/wiki).\r\nPlease see the following pages to get started:\r\n\r\n1. [Preparing Your Machine for CollaboRhythm Development](https://github.com/newmediamedicine/CollaboRhythm/wiki/Preparing-Your-Machine-for-CollaboRhythm-Development)\r\n\r\n2. [Forking CollaboRhythm](https://github.com/newmediamedicine/CollaboRhythm/wiki/Forking-CollaboRhythm)\r\n\r\n3. [Cloning and Using a Fork of CollaboRhythm](https://github.com/newmediamedicine/CollaboRhythm/wiki/Cloning-and-Using-a-Fork-of-CollaboRhythm)\r\n\r\n4. [Pulling Upstream Changes from the Main CollaboRhythm Repository](https://github.com/newmediamedicine/CollaboRhythm/wiki/Pulling-Upstream-Changes-from-the-Main-CollaboRhythm-Repository)\r\n\r\nCopyright and License\r\n---------------------\r\n\r\nCopyright 2012 John Moore, Scott Gilroy\r\n\r\nThis file is part of CollaboRhythm.\r\n\r\nCollaboRhythm is free software: you can redistribute it and/or modify it under the terms of the GNU General Public\r\nLicense as published by the Free Software Foundation, either version 2 of the License, or (at your option) any later\r\nversion.\r\n\r\nCollaboRhythm is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied\r\nwarranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more\r\ndetails.\r\n\r\nYou should have received a copy of the GNU General Public License along with CollaboRhythm.  If not, see\r\n<http://www.gnu.org/licenses/>."
 },
 {
  "repo": "neee/healthcare-service",
  "language": "Java",
  "readme_contents": "# \u0421\u0435\u0440\u0432\u0438\u0441 \u043c\u0435\u0434\u0438\u0446\u0438\u043d\u0441\u043a\u0438\u0445 \u043f\u043e\u043a\u0430\u0437\u0430\u043d\u0438\u0439\n\n\u0412 \u043a\u043b\u0430\u0441\u0441\u0435 Main, \u0441\u043e\u0437\u0434\u0430\u044e\u0442\u0441\u044f \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u043e \u043f\u0430\u0446\u0438\u0435\u043d\u0442\u0430\u0445 \u0438 \u0437\u0430\u043f\u0438\u0441\u044b\u0432\u0430\u044e\u0442\u0441\u044f \u0432 \u0444\u0430\u0439\u043b (\u0440\u0435\u043f\u043e\u0437\u0438\u0442\u043e\u0440\u0438\u0439)\n"
 },
 {
  "repo": "openhealthcare/opal",
  "language": "JavaScript",
  "readme_contents": "Opal\n====\n\n![Build](https://github.com/openhealthcare/opal/workflows/.github/workflows/build.yml/badge.svg)\n\n[![Coverage Status](https://coveralls.io/repos/github/openhealthcare/opal/badge.svg?branch=v0.11.0)](https://coveralls.io/github/openhealthcare/opal?branch=v0.11.0)\n\n[![PyPI version](https://badge.fury.io/py/opal.svg)](https://badge.fury.io/py/opal)\n\nOpal is a full stack web framework that makes building digital tools for health care easy.\n\nIt builds on established open source technologies with a track record of helping developers\nbuild easy to maintain, robust applications.\n\nMost notably, it makes use of [Django](https://djangoproject.com/), [AngularJS](https://angularjs.org/)\nand [Bootstrap](http://getbootstrap.com/).\n\nFrom there, Opal provides you with a common batteries-included architecture for writing healthcare\napplications, and a composable modular framework that takes advantage of generic, re-usable components.\n\nOpal is entirely open ([source](https://github.com/openhealthcare/opal) &\n[governance](https://github.com/openhealthcare/opal/issues)) as are the wide library of plugins.\n\nOpal was created by [Open Health Care UK](http://openhealthcare.org.uk), because it makes Healthcare IT Less Bad.\n\nWe'd love you to get involved by using what we make, reporting bugs/suggesting improvements, and fixing bugs/updating documentation/making improvements.\n\n## Documentation\n\nDocumentation is available at: [http://opal.openhealthcare.org.uk/docs/](http://opal.openhealthcare.org.uk/docs/).\n(The source is in this repository at `./doc`)\n\nIf you're just getting started we suggest:\n\n* [Installation instructions](http://opal.openhealthcare.org.uk/docs/installation/)\n* [The introductory tutorial](http://opal.openhealthcare.org.uk/docs/tutorial/)\n* Reading through some [High level topic guides](http://opal.openhealthcare.org.uk/docs/guides/topic-guides/)\n\nThe documentation is updated frequently, and we welcome any feedback or contributions to it. If you find any problems,\nor feel that anything needs clarifying in any way, please take 30 seconds to fill out a new issue [here](https://github.com/openhealthcare/opal/issues/new).\n\nDocumentation for old and development branches are available at e.g. [http://opal.openhealthcare.org.uk/docs/v0.7.1/](http://opal.openhealthcare.org.uk/docs/v0.7.1/)\n\n## Getting more help\n\nIf you're looking for help and support, feel free to post to our [Mailing list](https://groups.google.com/forum/?ohc-dev#!forum/ohc-opal)\n\nYou could also tweet us at [@opalframework](http://twitter.com/opalframework) - although it can be hard to give long form support there !\n\n## Contributing\n\nCheck out [CONTRIBUTING.md](./CONTRIBUTING.md) for information about getting involved.\n\n## Open source\n\nOpal is Licensed under the GNU Affero GPLv3\n\n## Communications\n\n* Email: hello@openhealthcare.org.uk\n* Twitter: [@opalframework](https://twitter.com/opalframework)\n* Mailing List: https://groups.google.com/forum/?ohc-dev#!forum/ohc-opal\n"
 },
 {
  "repo": "SoumyaRSethi/Data-Science-Capstone-Healthcare",
  "language": "Jupyter Notebook",
  "readme_contents": "# Data-Science-Capstone-Healthcare\n Data Science Capstone Project Using Python and Tableau 10\n\nDESCRIPTION\n\nProblem Statement\nNIDDK (National Institute of Diabetes and Digestive and Kidney Diseases) research creates knowledge about and treatments for the most chronic, costly, and consequential diseases.\nThe dataset used in this project is originally from NIDDK. The objective is to predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset.\nBuild a model to accurately predict whether the patients in the dataset have diabetes or not.\nDataset Description\nThe datasets consists of several medical predictor variables and one target variable (Outcome). Predictor variables includes the number of pregnancies the patient has had, their BMI, insulin level, age, and more.\n\n \n\nVariables\tDescription\nPregnancies\tNumber of times pregnant\nGlucose\tPlasma glucose concentration in an oral glucose tolerance test\nBloodPressure\tDiastolic blood pressure (mm Hg)\nSkinThickness\tTriceps skinfold thickness (mm)\nInsulin\tTwo hour serum insulin\nBMI\tBody Mass Index\nDiabetesPedigreeFunction\tDiabetes pedigree function\nAge\tAge in years\nOutcome\tClass variable (either 0 or 1). 268 of 768 values are 1, and the others are 0\nProject Task: Week 1\nData Exploration:\n\n1. Perform descriptive analysis. Understand the variables and their corresponding values. On the columns below, a value of zero does not make sense and thus indicates missing value:\n\n\u2022 Glucose\n\n\u2022 BloodPressure\n\n\u2022 SkinThickness\n\n\u2022 Insulin\n\n\u2022 BMI\n\n2. Visually explore these variables using histograms. Treat the missing values accordingly.\n\n3. There are integer and float data type variables in this dataset. Create a count (frequency) plot describing the data types and the count of variables. \n\nProject Task: Week 2\nData Exploration:\n\n1. Check the balance of the data by plotting the count of outcomes by their value. Describe your findings and plan future course of action.\n\n2. Create scatter charts between the pair of variables to understand the relationships. Describe your findings.\n\n3. Perform correlation analysis. Visually explore it using a heat map.\n\n \n\nProject Task: Week 3\nData Modeling:\n\n1. Devise strategies for model building. It is important to decide the right validation framework. Express your thought process.\n\n2. Apply an appropriate classification algorithm to build a model. Compare various models with the results from KNN algorithm.\n\n \n\nProject Task: Week 4\n\nData Modeling:\n\n1. Create a classification report by analyzing sensitivity, specificity, AUC (ROC curve), etc. Please be descriptive to explain what values of these parameter you have used.\n\nData Reporting:\n\n2. Create a dashboard in tableau by choosing appropriate chart types and metrics useful for the business. The dashboard must entail the following:\n\na. Pie chart to describe the diabetic or non-diabetic population\n\nb. Scatter charts between relevant variables to analyze the relationships\n\nc. Histogram or frequency charts to analyze the distribution of the data\n\nd. Heatmap of correlation analysis among the relevant variables\n\ne. Create bins of these age values: 20-25, 25-30, 30-35, etc. Analyze different variables for these age brackets using a bubble chart.\n\n\n\nTableau Screen Shot-\n\n![Tableau](https://github.com/SoumyaRSethi/Data-Science-Capstone-Healthcare/blob/d7b148f5b8ee701c43adde87660856b8e6095215/Tableau%20dashbord.PNG)\n"
 },
 {
  "repo": "pramodramdas/digital_healthcare",
  "language": "JavaScript",
  "readme_contents": "# digital_healthcare\nelectronic health records on blockchain\n\n#### demo: http://digital-healthcare.herokuapp.com/\n##### Note: Demo url to work you need to have metamask extension installed in your browser and to buy fake tickets you need to have fake ethers from rinkeby faceut.\n##### Optimized contract can be found in contracts/optimized_healthCare.sol\n\n### Summary\nProject stores patient records on blockchain(hybrid). Hybrid because files are not stored on blockchain, but access information is stored on blockchain. There will be two participants doctor and patient.  \n- Doctor register by providing name.  \n- Patient register by providing name and age.\n- Patient uploads files and provides random nounce to encrypt the file, file will be uploaded to IPFS and secret is stored in ethereum.\n- Patient provides access to particular doctor.\n- Once doctor is given access by patient, he will be able to see patient's address in his home page.\n- Doctor can get all files ipfs hash of patient and send request to node app for file view.\n- Node app will fetch file from ipfs and get secret from blockchain, decrypt file and send it to doctor.\n\n### Note\nCode has been tested only with ganache, not with any testnet.\n\n### Project setup\nHTTP_PROVIDER = provider url ex: http://127.0.0.1:7545  \nIPFS_HOST = currently infura (can be changed to local node as well)\n\n**1. Start Ganache**  \n&nbsp;&nbsp;&nbsp;Contract can be deployed to any network, In my case ganache.\nUpdate CONTRACT_DEPLOYED_PORT in env, which can be found in build -> contracts -> HealthCare.json -> \"networks\".  \n\n**2. Start react server**  \n&nbsp;&nbsp;&nbsp;`npm run start`  \n&nbsp;&nbsp;&nbsp; visit http://localhost:3000  \n\n**3. Start node app**   \n&nbsp;&nbsp;&nbsp;`npm run server`  \n\n**4. Connect metamask to ganache and Import ganache accounts to metamask**  \n&nbsp;&nbsp;&nbsp;ex: http://localhost:7545  \n\n___High Level Use Case___  \n\n![Alt text](readme_images/high_level.png?raw=true \"high_level\")  \n\n___Sign In___  \n\n&nbsp;&nbsp;&nbsp; User should sign challenge to login, after which jwt token will be issued  \n\n![Alt text](readme_images/2nd.png?raw=true \"sign_in\")  \n\n___Upload Files___  \n\n&nbsp;&nbsp;&nbsp; Here we have two layer of security \n1. hash provided by ipfs(ie. files can be accessed only if file hash is known)\n2. file uploaded to ipfs is encrypted by secret (however secret is not encrypted in ethereum, should be done in future)\n\n![Alt text](readme_images/3rd.png?raw=true \"upload_files\")  \n\n___Access Files___  \n\n![Alt text](readme_images/4th.png?raw=true \"access_files\")  \n\n### TODO  \n- Test cases, Currently deployment and registation tests has been written.\n- Encrypt file secret while saving on ethereum (can be encrypted or NuCypher etc)\n"
 },
 {
  "repo": "loutfialiluch/HealthCare",
  "language": "Java",
  "readme_contents": "# HealthCare\n<b>Healthcare</b> is an application that makes the communication between doctors and patients much easier.\n<pre>\n<img src=\"Images/1.png\" height = \"500px\" width= \"250px\">    <img src=\"Images/2.png\" height = \"500px\" width= \"250px\">    <img src=\"Images/3.png\" height = \"500px\" width= \"250px\"> <br/></br>\n<img src=\"Images/4.png\" height = \"500px\" width= \"250px\">    <img src=\"Images/5.png\" height = \"500px\" width= \"250px\">    <img src=\"Images/6.png\" height = \"500px\" width= \"250px\"> <br/></br>\n<img src=\"Images/7.png\" height = \"500px\" width= \"250px\">    <img src=\"Images/8.png\" height = \"500px\" width= \"250px\">    <img src=\"Images/9.png\" height = \"500px\" width= \"250px\"> <br/></br>\n<img src=\"Images/10.png\" height = \"500px\" width= \"250px\">\n</pre>\n"
 },
 {
  "repo": "grfiv/healthcare_twitter_analysis",
  "language": "Jupyter Notebook",
  "readme_contents": "Healthcare Twitter Analysis  \n===========================  \n\n#### The use of social media data and data science to gain insights into health care and medicine. \n\nThe current **status report** is in the main folder and you would do well to start by at least skimming it. \n\n[![DOI](https://zenodo.org/badge/5738/grfiv/healthcare_twitter_analysis.png)](http://dx.doi.org/10.5281/zenodo.11426)\n\n-------------------------------\n####RESTful interface to the MongoDB database\n\nUnder the `RESTful Interface` folder you will find the entire file structure required to run a Chrome web browser app that makes queries to a MongoDB database with all of the project's ~4 million json documents.\n\nThe instructions for running the project after you have installed the files  are under the `Instructions` tab of the main web page `HTAinterface.html` which you can simply load into your Chrome browser (Ctrl+o). The most-current instructions are contained here and will be updated as the project evolves.\n\nThe Status Report has a section with some of the technical details of Bottle, jQuery and Ajax\n\n-------------------------------\n####The Status Report `Status Report.pdf` in the main folder\n \n- a comprehensive explanation of the dataset  \n- examples of analyses done with this dataset  \n- a list of references to other healthcare-related Twitter analyses  \n- instructions for using Amazon Web Services\n- sample programs using this file with Python, R and MongoDB.\n- technical details of the RESTful interface. \n\n\n-------------------------------\n####Complete dataset of the tweets for this project\n\nNumerous files were created in the course of this project. They can be viewed at and downloaded from the Amazon S3 bucket where they have been archived at this web address: http://healthcare-twitter-analysis.com.s3-website-us-west-1.amazonaws.com/ \n\nAll of the tweets for this project have been processed and consolidated into a single file **HTA_noduplicates.gz** that can be found by entering the file name in the search box at http://healthcare-twitter-analysis.com.s3-website-us-west-1.amazonaws.com/\n\n\nEach of the 4 million rows in this file is a tweet in json format.\n\n* Every record contains the following information:\n    - All the Twitter data in exactly the json format of the original  \n    - Unix time stamp  \n    - data from the original files:  \n        - originating file name  \n        - score  \n        - author screen name  \n        - URLs  \n\n\n* In addition, 60% of the records have geographic information\n    - Latitude & Longitude  \n    - Country name & ISO2 country code  \n    - City  \n    - For country code \"US\"  \n      - Zipcode  \n      - Telephone area code  \n      - Square miles inside the zipcode  \n      - 2010 Census population of the zipcode  \n      - County & FIPS code  \n      - State name & USPS abbreviation   \n\nThe basic technique for using this file in Python is the following:\n\n\n    import json\n    \n    with open(\"HTA_noduplicates.json\", \"r\") as f:\n        # convert each row in turn into json format and process\n        for row in f:\n            tweet = json.loads(row)\n            text  = tweet[\"text\"]      # text of original tweet\n            ...                        # etc.\n            \n\nThe Status Report includes instructions for loading the json text file into a MongoDB database collection; I keep mine on an external hard drive and I start the MongoDB server as follows:\n\n    mongod --dbpath \"E:\\HTA\"\n\nThe database is HTA and the collection is grf. In that case the Python code would look like this:\n\n    import json\n    from pymongo import MongoClient\n\n    # start up MongoDB\n    # ================\n    client = MongoClient()  # assuming you have the MongoDB server running ...\n\n    db     = client['HTA']   # reference the database\n    tweets = db.grf          # reference the collection\n\n    for tweet in tweets.find():\n        text  = tweet[\"text\"]\n        if tweet['geo']:\n            (...)\n\n"
 },
 {
  "repo": "instamed/healthcare-payments-blockchain",
  "language": "TypeScript",
  "readme_contents": "PROJECT IS DEPRECIATED. CODE PROVIDED FOR REFERENCE ONLY.\n\n------------\n\n\n# Healthcare Payments on Blockchain\n\n__This is a prototype useful for exploring blockchain or as a basis for a project. It is not intended for production use without further modification and testing.__\n\nIn the InstaMed Innovation Lab, we built a blockchain prototype focused on healthcare payments among providers, payers and patients. One of the prototype\u2019s purposes is to evaluate the value of blockchain in driving a better healthcare payments experience for all stakeholders. [Learn more about the project](https://developers.instamed.com/healthcare-payments-blockchain/)\n\nThis is a [Hyperledger Fabric](https://www.hyperledger.org/projects/fabric) blockchain project that implements the FHIR Financial module. It is built with [Convector](https://github.com/worldsibu/convector) and follows the [FHIR spec](https://www.hl7.org/fhir/). A Vuejs demo frontend app is included in the project in /packages/frontend. \n\n~~The live demo can be found at: https://blockchain-demo.instamed.com/~~\n\n~~The live network block browser can be found at: https://blockchain-demo.instamed.com:8443/~~\n\nA video describing this flow can be found at: https://vimeo.com/325931177/e21834462d\n\n## Prerequisites\n\n* [Node](https://nodejs.org/en/download/) 8.11.0\n* [Docker Community Edition](https://www.docker.com/community-edition)\n* [npx](https://www.npmjs.com/package/npx) \n* If you are running in Ubuntu, make sure you meet all the prerequisites for Fabric and Convector - [Prerequisites Ubuntu](https://docs.worldsibu.com/article/120-install-on-ubuntu)\n\n## How to run the project\n\n~~Detailed instructions for installing on Ubuntu can be found here: https://developers.instamed.com/healthcare-payments-blockchain/install-blockchain-on-linux/~~\n\n### Start from scratch\n\n```bash\n# Install dependencies\nnpm install\n\n# Start the blockchain and the server\nnpm start\n\n# Create some mock data automatically to setup the network\nnpm run mockData\n\n# Start the server\nnpm run server:start\n\n# You can now run transactions (there's a Postman file included to help you talk to the endpoints \"./Fhir Financial.postman_collection.json\")\n# Read first the section \"Identities on the project\" of this README\n# You should send transactions all transactions from postman_collection.json in the order defined before install the remaining views\n# Views are associated to databases and Fabric doesn't generate them until at least 1 value was saved there\nnpm run views:install\n```\n\nThis will:\n\n* Install a development *Hyperledger Fabric Network* (and remove any previous one) with [Hurley](https://github.com/worldsibu/hurley).\n* Install the chaincode with the name `financial` in the network.\n* Start the NodeJS server.\n* Install CouchDB views.\n* Instantiate the chaincode servers.\n* Create some mock data for you.\n\nTo get the **front end** to work properly, you need to run the postman added in the repository by configuring the fingerprints correctly.\n\nGo to the Postman collection settings and set the value to the variable `patientFingerprint` to use the same for every transaction after you run `npm run user:fingerprint -- $HOME/hyperledger-fabric-network/.hfc-org1/user1` then go and set the value of `consortiumAdminFingerprint` to `npm run user:fingerprint -- $HOME/hyperledger-fabric-network/.hfc-org2/user1` and then value of `providerFingerprint` to `npm run user:fingerprint -- $HOME/hyperledger-fabric-network/.hfc-org3/user1`.\n\n### Individual tasks\n\n* Just start the server in dev mode `npm run server:start`. Run this in case after the `npm start` you close the terminal. This won't install the network again, just the NodeJS server.\n\n### Enable the block browser capabilities\n\nThe front end project makes it possible to visualize blocks in the network as well as its contents.\n\n![Blocks](/images/blocks.png)\n\nThe current project uses the [Byzantine Browser](https://github.com/in-the-keyhole/byzantine-browser)'s API to get the blocks from the transactions to the ledger in realtime. For now it uses a fork from [WorldSibu that enables TLS in the server](https://github.com/worldsibu/byzantine-browser).\n\nMake sure you already started the blockchain (healthcare-payments-blockchain) with `npm start` so a blockchain network is running on your computer with [Hurley](https://github.com/worldsibu/hurley).\n\nYou have to run npm install twice for the backend and the frontend.\n\n```bash\n# Go outside this folder and clone the repo\ngit clone https://github.com/worldsibu/byzantine-browser.git\ncd byzantine-browser\nnpm install\ncd ui\nnpm install\nnpm run build\ncd ..\n```\nCopy the keys from the hyperledger-fabric-network directory. We're assuming here you have installed the byzantine-browser in that same parent directory as the blockchain.\n\n\n```\ncp $HOME/hyperledger-fabric-network/.hfc-org1/* ./hfc-key-store\n```\n\nReplace the `.env` in the root of the Byzantine Browser folder (or create it if it doesn't exist) with the information below. \n\n```bash\nUSERID=user1\nNETWORK_URL=grpc://localhost:7051\nEVENT_URL=grpc://localhost:7052\n```\n\nUse your favorite text editor or use Nano\n\n```\nnano .env\n(copy text from above and right click to paste into terminal)\ncontrol-O\ncontrol-X\n\n```\n\nRun the Byzantine server\n\n```\n./runApiServer.sh\n\n```\n\n\n## Explore the project\n\n### Code structure\n\n* `packages/financial-cc`: contains the whole smart contract with all its models and controllers.\n* `packages/server`: contains the server calling the blockchain.\n* `chaincode.config.json`: links the controllers and packages the config for the smart contract.\n* `dev-env` a folder containing development environment needed files like the CouchDB views and the installation script.\n* `Fhir Financial.postman_collection.json`: import this file into Postman to see the queries to the database, follow the numbers in the tasks to create a full flow.\n\n### Identities on the project\n\n`Payer Organizations`, `Provider Organizations`, and `Consumer Participants` are identified in the blockchain through a **fingerprint** of a certificate generated from the Certificate authority.\n\nThe logic goes as follows:\n\n* A identity (user) is created in the Certificate Authority.\n* That user is enrolled in the blockchain network (in the case of the development environment the identity is registered and then enrolled by default).\n* Extract the fingerprint from the cert by calling:\n\n```bash\n# I.e.: npm run user:fingerprint -- $HOME/hyperledger-fabric-network/.hfc-org1/user1\nnpm run user:fingerprint -- $HOME/hyperledger-fabric-network/.hfc-<org>/<user>\n```\n\n* The result fingerprint looks like `A5:EB:E4:1E:8E:86:03:72:00:3F:EA:CA:D2:9D:98:08:CA:70:24:F6`.\n* That same fingerprint will be validated when a transaction is signed by a identity from the blockchain.\n* Be sure to pass it throught Postman when registering a new `Payer Organization` or `Consumer Participant` as a param called `fingerprint`. Transactions will validate that the right identity is trying to perform requests.\n* For example, to create a Consumer Participant, the following JSON is valid:\n\n```json\n{\n    \"participant\": {\n        \"id\": \"Consumer::Bob\"\n    },\n    \"fingerprint\": \"A5:EB:E4:1E:8E:86:03:72:00:3F:EA:CA:D2:9D:98:08:CA:70:24:F6\"\n}\n```\n\nYou will need two different identities. One can be shared between the Payer and InstaMed (working on behalf of the patients) and the other one for a provider. The reason for this is that some data is stored only accessible to some identities (look for Private Collections later in this document), therefore a switch in the identity is made.\n\nGo to the Postman collection settings and set the value to the variable `patientFingerprint` to use the same for every transaction after you run `npm run user:fingerprint -- $HOME/hyperledger-fabric-network/.hfc-org1/user1` then go and set the value of `consortiumAdminFingerprint` to `npm run user:fingerprint -- $HOME/hyperledger-fabric-network/.hfc-org2/user1` and then value of `providerFingerprint` to `npm run user:fingerprint -- $HOME/hyperledger-fabric-network/.hfc-org3/user1`.\n\n#### Private Collections\n\nFor this project running locally, organizations are related to **Hurley organizations** in the followin order:\n\n|Organization|Hurley Org|\n|---|---|\n|ABC_HEALTHCARE|org1MSP|\n|INSTAMED (Patient)|org2MSP|\n|XYZ_PROVIDER|org3MSP|\n\n### Routing the server to query the different collections\n\nTo *query* the private collections from the nodejs server you can pass the id of the user's nodes you'd like to access (any value of './packages/server/src/config/identities.json' and the server will route the read query to those nodes). \n\n* I.e.: `GET https://----/----/----?user=payer` will send a transaction and look for data inside of the payer's nodes\n* I.e.: `GET https://----/----/----?user=provider` will send a transaction and look for data inside of the provider's nodes\n* I.e.: `GET https://----/----/----?user=patient` will send a transaction and look for data inside of the patient's nodes\n\n#### A practical example\n\nGet the fingerprint of the user1 in the org1\n\n```bash\n$ npm run user:fingerprint -- $HOME/hyperledger-fabric-network/.hfc-org1/user1\nA5:EB:E4:1E:8E:86:03:72:00:3F:EA:CA:D2:9D:98:08:CA:70:24:F6\n```\n\nBe sure that your server is using the identity of user1 in org1, defined in `./packages/server/src/config/identities.json`\n\nEvery transaction sent from the server will be signed with the user1 in org1 identity, so the chaincode can safely check for the fingerprint through the `this.sender`\n\nExcept for the transaction made by the provider (mark the payment as made) through another certificate in `org2`.\n\n### Running local environment\n\n* Call the server located in `http://localhost:8080`\n* Check the CouchDB server provisioned at http://localhost:5084/_utils/#/database/ch1_financial/_all_docs\n\n## Architecture\n\n![Development Environment](images/devenv.png?raw=true \"Development Environment\")\n\n![Production Environment](images/prodenv.png?raw=true \"Production Environment\")\n\n## Tests\n\n### Run unit tests\n\n#### Optional - debugging\n\nBy default the project will run unit tests in debug mode. To explore the code go to a new Chrome window and put the address to `chrome://inspect`. Add the server as a connection in the tab (top of the screen) \"Connection\", then click the button \"Add Connection\" and add `localhost:9229`.\n\nWrite `debugger;` in the code line you'd like the debugger to stop and run the tests.\n\n#### Start unit tests\n\n```bash\n# Include npx if you use NPX for package management\n[npx] lerna run test --scope financial-cc --stream\n```\n\n### Install in the blockchain\n\n```bash\n# Be sure you started the blockchain before with `npm run env:restart`\nnpm run cc:start\n```\n\n### Upgrade your chaincode to the blockchain\n\n```bash\n# I.e.: npm run cc:upgrade -- 1.2\nnpm run cc:upgrade -- <version>\n```\n\n--\n\nEdits are done by InstaMed Development user\n"
 },
 {
  "repo": "sarveshraj/blockchain-for-healthcare",
  "language": "JavaScript",
  "readme_contents": "# Blockchain for Healthcare: A Proof of Concept\n\n> **Note**: A lot has changed in the Ethereum world since this project was completed and the setup instructions might not work now. If you, being a good samaritan, run into an error during setup and are able to fix it, please raise a pull request to help others. Big big thanks from me!\n\n## Installation\n\nThe projects requires NodeJS and npm to work. Instructions to install all other dependencies are given below.\n> Note: The instructions given below are for Linux (specifically Ubuntu 18.04). You should be able to find similar instructions for MacOS and Windows. Although support is available for Windows, I recommend using Linux or MacOS. Windows has some difficulty playing with npm.\n\n### Node modules\n\n1. Move to the project directory and open it in your terminal.\n2. Run `npm install`.\n\n### Ganache\n\n1. Go to [Ganache homepage](https://truffleframework.com/ganache) and download. \n2. If you are on Linux, you must have received an _.appimage_ file. Follow installation instructions available [here.](https://itsfoss.com/use-appimage-linux/)\n\n### IPFS\n\n1. Go to the [download page](https://docs.ipfs.io/introduction/install/) of IPFS and follow the instructions given.\n\n### Local server\n\n1. You can use any local server to deploy the web application.\n2. I used PHP but feel free to choose anything of your liking.\n3. To install PHP on your Linux machine, run `sudo apt-get install php`. Detailed instructions available [here.](https://thishosting.rocks/install-php-on-ubuntu/)\n4. One more great option is lite-server which is available as a node module.\n5. Install lite-server by running the following command on your terminal `npm install -g lite-server`\n\n### Metamask\n\n1. Metamask is a browser extension available for Google Chrome, Mozilla Firefox and Brave Browser.\n2. Go to the this [link](http://metamask.io/) and add Metamask to your browser.\n\n## Getting the dApp running\n\n### Configuration\n\n#### 1. Ganache\n  - Open Ganache and click on settings in the top right corner.\n  - Under **Server** tab:\n    - Set Hostname to 127.0.0.1 -lo\n    - Set Port Number to 8545\n    - Enable Automine\n  - Under **Accounts & Keys** tab:\n    - Enable Autogenerate HD Mnemonic\n\n#### 2. IPFS\n  - Fire up your terminal and run `ipfs init`\n  - Then run \n    ```\n    ipfs config --json API.HTTPHeaders.Access-Control-Allow-Origin \"['*']\"\n    ipfs config --json API.HTTPHeaders.Access-Control-Allow-Credentials \"['true']\"\n    ipfs config --json API.HTTPHeaders.Access-Control-Allow-Methods \"['PUT', 'POST', 'GET']\"\n    ```\n#### 3. Metamask\n  - After installing Metamask, click on the metamask icon on your browser.\n  - Click on __TRY IT NOW__, if there is an announcement saying a new version of Metamask is available.\n  - Click on continue and accept all the terms and conditions after reading them.\n  - Stop when Metamask asks you to create a new password. We will come back to this after deploying the contract in the next section.\n  \n### Deploying the contract\n\nI purposely haven't used any development framework so as to keep the code as raw as possible. This will also be easier to understand for any newcomer who is already having a tough time understanding the many technologies the application is built on.\n\n#### 1. Starting your local development blockchain\n  - Open Ganache.\n  - Make sure to configure it the way mentioned above.\n  \nMoving on, to deploy the contract on the blockchain you have two options:\n  - Use any available development framework for dApps. I recommend the [Truffle](https://truffleframework.com/truffle) framework. [Embark](https://embark.status.im/) is another great alternative.\n  - Go full on geek mode and deploy it yourself with a few lines of code.\n\nI'll be explaining the second method here.\n\n#### 2. Deploying the contract and linking it to the frontend\n  - Fire up your terminal and move to the project directory\n  - Now open up `/YOUR_PROJECT_DIRECTORY/src/js/run.js` in your favourite text editor\n  - You have to make two changes:\n    1. Make sure the address in line number 3 is the same as your RPC server address on Ganache.\n    If you have configured Ganache as instructed above, the code should look like this:\n    \n    ```\n    var web3 = new Web3(new Web3.providers.HttpProvider(\"http://localhost:8545\"));\n    ```\n    2. The path in this line should point to where your solidity contract is located:\n    \n    ```\n    var code = fs.readFileSync('/YOUR_PROJECT_DIRECTORY/contracts/Agent.sol').toString();\n    ```\n  - Go back to your terminal, type `node` and hit enter\n  - Copy and paste all the contents of `run.js` to the terminal\n  - If all goes well, you should see some few lines as output of the command\n    ```\n    console.log(compiledCode.contracts[':Agent'].interface);\n    ```\n  - This is the ABI of the contract, copy and paste these lines in line number 10 of `app.js`. The code should look like:\n    ``` \n    abi = JSON.parse('PASTE_YOUR_ABI_HERE')\n    ```\n  - Go back to the terminal and type `deployedContract.address;`, which is also the last command of your `run.js` file. The     output is the address where the contract is deployed on the blockchain.\n  - Copy the output and paste it on line number 13 of `app.js`. The code should look like:\n    ```\n    contractInstance = AgentContract.at('PASTE_YOUR_ADDRESS_HERE');\n    ```\n  - That's it for this part. Now lets set up Metamask.\n  \n### Running the dApp\n\n#### 1. Connecting Metamask to our local blockchain\n  - Let's go back to the configuration section of Metamask.\n  - If done correctly, you would have stopped at the part where Metamask asks you to create a new password.\n  - Just below the __CREATE__ button, click on the __Import with seed phrase__.\n  - A form should open up, asking you to enter __Wallet Seed__.\n  - Open Ganache, copy the twelve words that make up the __MNEMONIC__ on the __ACCOUNTS__ tab. \n  - Paste the twelve words in __Wallet Seed__. Create a new password and click __IMPORT__.\n\n#### 2. Starting IPFS \n  - Open a new terminal window.\n  - Make sure you have configured IPFS as mentioned above.\n  - Run `ipfs daemon`.\n  \n#### 3. Start a local server\n  - Open a new terminal window and navigate to `/YOUR_PROJECT_DIRECTORY/src/`.\n  - Run `php -S locahost:3000`.\n  - Open `localhost:3000/register.html` on your browser.\n  - That's it! The dApp is up and running locally.\n"
 },
 {
  "repo": "STRML/Healthcare.gov-Marketplace",
  "language": "JavaScript",
  "readme_contents": "**Note**: There has been some confusion between this and the late CMSGov/healthcare.gov repository.\n\nThere were two contractors working on healthcare.gov, each with separate responsibilities. The CMSGov\nrepository had one section. This repository contains the other.\n\n***CMSGov Repository***\n- Frontend Blog Files\n- No Marketplace application code\n- Relatively bug-free\n- Completed by [Development Seed](http://developmentseed.org/)\n\n***This repository***\n- Marketplace application code\n- Numerous bugs and poor coding practices\n- Completed by [CGI Federal](http://www.cgi.com/en/us-federal/services-solutions)\n- This is the code that has been on the news.\n\nAs of this writing, this is **the only repository on GitHub with this data.**\n\nWhat This Is\n------------\n\nThis repository is an unofficial bug tracker and pull request target for fixes\nto [healthcare.gov/marketplace](https://healthcare.gov/marketplace/global/en_US/registration),\nthe much-maligned backend piece created by CGI Federal. Please post issues you've been having\nwith the marketplace here. As there is no other publicly available bugtracker, this is the place\nto post issues and bugs.\n\nThis repository attempts to be a working fork of the marketplace. You should be able to run this\non a local web server and access healthcare.gov in the same way.\n\nAs of this time, the login page and much of the basic application will function correctly from\nyour local machine, making this repository great for testing and bugfixes.\n\n\nWhat This Isn't\n---------------\n\nThis is not an *official* repository. For all we know, nobody is listening.\n\nThis is not a clone of the CMSGov/healthcare.gov repository.\n\nI have created this in hopes that there are some concerned programmers at CGI Federal who want to see\nthe project succeed. Sourcing fixes from the users of healthcare.gov is one way to achieve that goal.\n\nSee [the pull request](http://webcache.googleusercontent.com/search?q=cache:Tqg9LB2D2aYJ:https://github.com/CMSgov/healthcare.gov/pull/31+&cd=3&hl=en&ct=clnk) that started this idea. \n(Google Cache)\n\nSee the [open issues](https://github.com/STRML/Healthcare.gov-Marketplace/issues) and \n[closed issues](https://github.com/STRML/Healthcare.gov-Marketplace/issues?page=1&state=closed).\n\n\nHow To Run\n----------\n\nPrerequisites: `node`.\n\n```bash\ngit clone git@github.com:STRML/Healthcare.gov-Marketplace.git # or download ZIP\ncd Healthcare.gov-Marketplace\nnpm install\nnpm start # Starts local proxy server & launches browser\n```\n\nTests\n-----\n\nThere are no tests at this time. Please submit some in your favorite test framework. I lean towards QUnit but \nI won't refuse adding any worthwhile test code.\n\n\nTODO\n----\n\n[Open Issues](https://github.com/STRML/Healthcare.gov-Marketplace/issues)\n* ~~Redirect API calls to their actual destination so this fork works~~\n* ~~Rewrite incoming redirects so we don't get moved back to healthcare.gov on login.~~\n* Add any missing JS/CSS from other sections of the site\n* Add unit tests and TravisCI integration\n* Pass JSHint (good luck)\n\n\nContributing\n------------\n\nIf healthcare.gov frustrates you, please contribute! My hope is that this repository becomes large enough\nto attract some real attention, not just from CGI Federal but from Health & Human Services. They have been thoroughly\nembarassed by this boondoggle and with luck will be looking for a way to reform the system and save face.\n\nSee the TODO list above.\n\nWhile the existing source does not pass jshint, please make sure that any contributions do (we have to start somewhere).\nUnit tests would be greatly appreciated. Please place them inside the `test/` folder, prefixed by unit test framework\n(qunit, jasmine). Please just make sure they pass, and feel free to use your favorite test framework. I will take care\nof wiring them into Grunt and TravisCI.\n\nSee the [baseline](https://github.com/STRML/Healthcare.gov-Marketplace/tree/baseline) branch for unmodified\nupstream files. If you notice a change in the Healthcare.gov Marketplace, please commit it to that branch. Changes\nwill be merged from baseline to master when possible.\n\nDevelopment\n-----------\n\nIf you want to run without minification for development, use `grunt develop`. Be sure to install grunt globally\nif you haven't already, using `npm install -g grunt`.\n"
 },
 {
  "repo": "medtorch/awesome-healthcare-ai",
  "language": null,
  "readme_contents": "# awesome-healthcare-ai [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)\nA curated list of awesome open source healthcare tools, machine learning algorithms, datasets and research papers.\n\nDisclaimer :exclamation: I am not a medical specialist, and there might be mistakes. :exclamation:\n\n\n## Contents\n\n- :zap: [Medical specialties](#medical-specialties)\n- :cyclone: [Medical tasks](#medical-tasks)\n- :key: [Medical privacy](#medical-privacy)\n- :book: [References](#references)\n\n### Medical specialties\n  * [Generic resources](resources/medical-specialties/generic.md)\n  * [Allergy, Immunology, & Rheumatology](resources/medical-specialties/allergy-immunology-rheumatology.md)\n  * [Anesthesiology](resources/medical-specialties/anesthesiology.md)\n  * [Cardiovascular Health](resources/medical-specialties/cardiovascular-health.md)\n  * [Complimentary Medicine](resources/medical-specialties/complimentary-medicine.md)\n  * [Critical Care](resources/medical-specialties/critical-care.md)\n  * [Dermatology](resources/medical-specialties/dermatology.md)\n  * [Emergency Medicine & Trauma](resources/medical-specialties/emergency-medicine.md)\n  * [Endocrinology & Metabolism](resources/medical-specialties/endocrinology.md)\n  * [Family Medicine & Community Health](resources/medical-specialties/family-medicine.md)\n  * [Gastroenterology & Hepatology](resources/medical-specialties/gastroenterology.md)\n  * [Genetics & Genomics](resources/medical-specialties/genetics-genomics.md)\n  * [Gerontology](resources/medical-specialties/gerontology.md)\n  * [Hematology](resources/medical-specialties/hematology.md)\n  * [Infectious Disease & Global Health](resources/medical-specialties/infectious-disease.md)\n  * [Internal Medicine](resources/medical-specialties/internal-medicine.md)\n  * [Nephrology](resources/medical-specialties/nephrology.md)\n  * [Neurologic Surgery](resources/medical-specialties/neurologic-surgery.md)\n  * [Neurology](resources/medical-specialties/neurology.md)\n  * [Obstetrics & Gynecology](resources/medical-specialties/obstetrics-gynecology.md)\n  * [Occupational Therapy](resources/medical-specialties/occupational-therapy.md)\n  * [Oncology](resources/medical-specialties/oncology.md)\n  * [Ophthalmology](resources/medical-specialties/ophthalmology.md)\n  * [Orthopedics & Sports Medicine](resources/medical-specialties/orthopedics.md)\n  * [Otolaryngology (ENT)](resources/medical-specialties/otolaryngology.md)\n  * [Pain Medicine](resources/medical-specialties/anesthesiology.md)\n  * [Pathology & Laboratory Medicine](resources/medical-specialties/pathology-laboratory.md)\n  * [Pediatrics](resources/medical-specialties/pediatrics.md)\n  * [Physical Therapy](resources/medical-specialties/physical-therapy.md)\n  * [Plastic Surgery](resources/medical-specialties/plastic-surgery.md)\n  * [Preventative Medicine & Nutrition](resources/medical-specialties/preventative-medicine.md)\n  * [Psychiatry & Behavioral Sciences](resources/medical-specialties/psychiatry.md)\n  * [Pulmonology](resources/medical-specialties/pulmonology.md)\n  * [Radiology](resources/medical-specialties/radiology.md)\n  * [Sleep Medicine](resources/medical-specialties/sleep-medicine.md)\n  * [Social Welfare](resources/medical-specialties/social-welfare.md)\n  * [Speech Pathology](resources/medical-specialties/speech-pathology.md)\n  * [Surgery](resources/medical-specialties/surgery.md)\n  * [Urology](resources/medical-specialties/urology.md)\n  \n### Medical tasks\n  * [Semantic Segmentation](https://paperswithcode.com/area/medical/semantic-segmentation)\n  * [Medical Image Segmentation](https://paperswithcode.com/area/medical/medical-image-segmentation)\n  * [3D](https://paperswithcode.com/area/medical/3d)\n  * [EEG](https://paperswithcode.com/area/medical/eeg)\n  * [3D Absolute Human Pose Estimation](https://paperswithcode.com/area/medical/3d-absolute-human-pose-estimation)\n  * [Drug discovery](https://paperswithcode.com/area/medical/drug-discovery)\n  * [Electrocardiography (ECG)](https://paperswithcode.com/area/medical/electrocardiography-ecg)\n  * [Medical Diagnosis](https://paperswithcode.com/area/medical/medical-diagnosis)\n  * [Medical Image Registration](https://paperswithcode.com/area/medical/medical-image-registration)\n  * [Cancer Detection](https://paperswithcode.com/area/medical/cancer)\n  * [Disease Prediction](https://paperswithcode.com/area/medical/disease-prediction)\n  * [Sleep Quality prediction](https://paperswithcode.com/area/medical/sleep-quality-prediction)\n  * [Mortality Prediction](https://paperswithcode.com/area/medical/mortality-prediction)\n  * [Synthetic Data Generation](https://paperswithcode.com/area/medical/synthetic-data-generation)\n  * [Epidemiology](https://paperswithcode.com/area/medical/epidemiology)\n  * [Skin diseases](https://paperswithcode.com/area/medical/skin)\n  * [Medical Image Generation](https://paperswithcode.com/area/medical/medical-image-generation)\n  * [Length-of-Stay prediction](https://paperswithcode.com/area/medical/length-of-stay-prediction)\n  * [Pneumonia Detection](https://paperswithcode.com/area/medical/pneumonia-detection)\n  * [Seizure Detection](https://paperswithcode.com/area/medical/seizure-detection)\n  * [Breast Tumour Classification](https://paperswithcode.com/area/medical/breast-tumour-classification)\n  * [Diabetic Retinopathy Detection](https://paperswithcode.com/area/medical/diabetic-retinopathy-detection)\n  * [Protein Secondary Structure Prediction](https://paperswithcode.com/area/medical/protein-secondary-structure-prediction)\n  * [Medical Relation Extraction](https://paperswithcode.com/area/medical/medical-relation-extraction)\n  * [Electromyography (EMG)](https://paperswithcode.com/task/electromyography-emg)\n  * [Tomography](https://paperswithcode.com/task/tomography)\n  * [Patient Outcomes](https://paperswithcode.com/task/patient-outcomes)\n  * [Computational Phenotyping](https://paperswithcode.com/task/computational-phenotyping)\n  * [Lung Nodule Classification](https://paperswithcode.com/task/lung-nodule-classification)\n  * [Mitosis Detection](https://paperswithcode.com/task/mitosis-detection)\n  * [Mammogram](https://paperswithcode.com/task/mammogram)\n  * [Histopathological Image Classification](https://paperswithcode.com/task/histopathological-image-classification)\n  * [Seizure prediction](https://paperswithcode.com/task/seizure-prediction)\n  * [Lung Disease Classification](https://paperswithcode.com/task/lung-disease-classification)\n  * [Lung Nodule Detection](https://paperswithcode.com/task/lung-nodule-detection)\n  * [Magnetic Resonance Fingerprinting](https://paperswithcode.com/task/magnetic-resonance-fingerprinting)\n  * [Multi-Label Classification Of Biomedical Texts](https://paperswithcode.com/task/multi-label-classification-of-biomedical)\n  * [Readmission Prediction](https://paperswithcode.com/task/readmission-prediction)\n  * [X-Ray subtasks](https://paperswithcode.com/area/medical/x-ray)\n  * [Automatic Sleep Stage Classification](https://paperswithcode.com/task/automatic-sleep-stage-classification)\n  * [Diabetic Foot Ulcer Detection](https://paperswithcode.com/task/diabetic-foot-ulcer-detection)\n  * [ECG Classification](https://paperswithcode.com/task/photoplethysmography-ppg)\n  * [Immune Repertoire Classification](https://paperswithcode.com/task/immune-repertoire-classification)\n  * [Participant Intervention Comparison Outcome Extraction](https://paperswithcode.com/task/participant-intervention-comparison-outcome)\n  * [Protein Function Prediction](https://paperswithcode.com/task/protein-function-prediction)\n  * [Surgical Gesture Recognition](https://paperswithcode.com/task/surgical-gesture-recognition)\n  * [Surgical Skills Evaluation](https://paperswithcode.com/task/surgical-skills-evaluation)\n  * [Ultrasound](https://paperswithcode.com/task/ultrasound)\n  * [Cancer Metastasis Detection](https://paperswithcode.com/task/cancer-metastasis-detection)\n  * [Chemical Reaction Prediction](https://paperswithcode.com/task/chemical-reaction-prediction)\n  * [Diabetes prediction](https://paperswithcode.com/task/diabetes-prediction)\n  * [Epilepsy Prediction](https://paperswithcode.com/task/epilepsy-prediction)\n  * [Knee Osteoarthritis Prediction](https://paperswithcode.com/task/knee-osteoarthritis-prediction)\n  * [Medical Report Generation](https://paperswithcode.com/task/medical-report-generation)\n  * [Medical Super-Resolution](https://paperswithcode.com/task/medical-super-resolution)\n  * [Molecule Interpretation](https://paperswithcode.com/task/molecule-interpretation)\n  * [Pain Intensity Regression](https://paperswithcode.com/task/pain-intensity-regression)\n  * [Pulmonary Embolism Detection](https://paperswithcode.com/task/pulmonary-embolism-detection)\n  * [Single-cell modeling](https://paperswithcode.com/task/single-cell-modeling)\n  * [White Matter Fiber Tractography](https://paperswithcode.com/task/white-matter-fiber-tractography)\n  * [Breast density classification](https://paperswithcode.com/task/breast-density-classification)\n  * [Atrial Fibrillation](https://paperswithcode.com/task/atrial-fibrillation)\n  * [Age-Related Macular Degeneration Classification](https://paperswithcode.com/task/classification-of-age-related-macular)\n  * [ECG Risk Stratification](https://paperswithcode.com/task/ecg-risk-stratification)\n  * [Malaria Risk Exposure Prediction](https://paperswithcode.com/task/malaria-risk-exposure-prediction)\n  * [Medical Code Prediction](https://paperswithcode.com/task/medical-code-prediction)\n  * [Multi Diseases Detection](https://paperswithcode.com/task/multi-diseases-detection)\n  * [Muscular Movement Recognition](https://paperswithcode.com/task/muscular-movement-recognition)\n  * [Sequential Diagnosis](https://paperswithcode.com/task/sequential-diagnosis)\n  * [Medical VQA](https://github.com/aioz-ai/MICCAI19-MedVQA)\n\n### Medical Privacy \n  * Safe harbour\n  * Anonymization\n  * De-identification\n     - [Customize Deep Learning-based De-Identification Systems Using Local Clinical Notes - A Study of Sample Size](https://www.medrxiv.org/content/10.1101/2020.08.09.20171231v1)\n     - [deidentify](https://github.com/nedap/deidentify)\n  * Cryptography\n\n### References \n  * [Stanford Medicine](https://stanford.cloud-cme.com/default.aspx)\n  * [Awesome Machine Learning in Biomedical Healthcare Imaging](https://github.com/XindiWu/Awesome-Machine-Learning-in-Biomedical-Healthcare-Imaging)\n  * [Papers With Code](https://paperswithcode.com/area/medical)\n  * [Awesome Healthcare](https://github.com/kakoni/awesome-healthcare)\n  * [Awesome Healthmetrics](https://github.com/leandromineti/awesome-healthmetrics)\n  * [Medical Data for Machine Learning](https://github.com/beamandrew/medical-data)\n  * [Awesome mental health](https://github.com/dreamingechoes/awesome-mental-health)\n"
 },
 {
  "repo": "microsoft/InnerEye-DeepLearning",
  "language": "Python",
  "readme_contents": "# InnerEye-DeepLearning\n\n[![Build Status](https://innereye.visualstudio.com/InnerEye/_apis/build/status/InnerEye-DeepLearning/InnerEye-DeepLearning-PR?branchName=main)](https://innereye.visualstudio.com/InnerEye/_build?definitionId=112&branchName=main)\n\nInnerEye-DeepLearning (IE-DL) is a toolbox for easily training deep learning models on 3D medical images. Simple to run both locally and in the cloud with [AzureML](https://docs.microsoft.com/en-gb/azure/machine-learning/), it allows users to train and run inference on the following:\n\n- Segmentation models.\n- Classification and regression models.\n- Any PyTorch Lightning model, via a [bring-your-own-model setup](docs/source/md/bring_your_own_model.md).\n\nIn addition, this toolbox supports:\n\n- Cross-validation using AzureML, where the models for individual folds are trained in parallel. This is particularly important for the long-running training jobs often seen with medical images.\n- Hyperparameter tuning using [Hyperdrive](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters).\n- Building ensemble models.\n- Easy creation of new models via a configuration-based approach, and inheritance from an existing architecture.\n\n## Documentation\n\nFor all documentation, including setup guides and APIs, please refer to the [IE-DL Read the Docs site](https://innereye-deeplearning.readthedocs.io/#).\n\n## Quick Setup\n\nThis quick setup assumes you are using a machine running Ubuntu with Git, Git LFS, Conda and Python 3.7+ installed. Please refer to the [setup guide](docs/source/md/environment.md) for more detailed instructions on getting InnerEye set up with other operating systems and installing the above prerequisites.\n\n1. Clone the InnerEye-DeepLearning repo by running the following command:\n\n   ```shell\n   git clone --recursive https://github.com/microsoft/InnerEye-DeepLearning && cd InnerEye-DeepLearning\n   ```\n\n2. Create and activate your conda environment:\n\n   ```shell\n   conda env create --file environment.yml && conda activate InnerEye\n   ```\n\n3. Verify that your installation was successful by running the HelloWorld model (no GPU required):\n\n   ```shell\n   python InnerEye/ML/runner.py --model=HelloWorld\n   ```\n\nIf the above runs with no errors: Congratulations! You have successfully built your first model using the InnerEye toolbox.\n\nIf it fails, please check the\n[troubleshooting page on the Wiki](https://github.com/microsoft/InnerEye-DeepLearning/wiki/Issues-with-code-setup-and-the-HelloWorld-model).\n\n## Full InnerEye Deployment\n\nWe offer a companion set of open-sourced tools that help to integrate trained CT segmentation models with clinical\nsoftware systems:\n\n- The [InnerEye-Gateway](https://github.com/microsoft/InnerEye-Gateway) is a Windows service running in a DICOM network,\nthat can route anonymized DICOM images to an inference service.\n- The [InnerEye-Inference](https://github.com/microsoft/InnerEye-Inference) component offers a REST API that integrates\nwith the InnerEye-Gateway, to run inference on InnerEye-DeepLearning models.\n\nDetails can be found [here](docs/source/md/deploy_on_aml.md).\n\n![docs/deployment.png](docs/source/images/deployment.png)\n\n## Benefits of InnerEye-DeepLearning\n\nIn combiniation with the power of AzureML, InnerEye provides the following benefits:\n\n- **Traceability**: AzureML keeps a full record of all experiments that were executed, including a snapshot of the code. Tags are added to the experiments automatically, that can later help filter and find old experiments.\n- **Transparency**: All team members have access to each other's experiments and results.\n- **Reproducibility**: Two model training runs using the same code and data will result in exactly the same metrics. All sources of randomness are controlled for.\n- **Cost reduction**: Using AzureML, all compute resources (virtual machines, VMs) are requested at the time of starting the training job and freed up at the end. Idle VMs will not incur costs. Azure low priority nodes can be used to further reduce costs (up to 80% cheaper).\n- **Scalability**: Large numbers of VMs can be requested easily to cope with a burst in jobs.\n\nDespite the cloud focus, InnerEye is designed to be able to run locally too, which is important for model prototyping, debugging, and in cases where the cloud can't be used. Therefore, if you already have GPU machines available, you will be able to utilize them with the InnerEye toolbox.\n\n## Licensing\n\n[MIT License](/LICENSE)\n\n**You are responsible for the performance, the necessary testing, and if needed any regulatory clearance for\n any of the models produced by this toolbox.**\n\n## Acknowledging usage of Project InnerEye OSS tools\n\nWhen using Project InnerEye open-source software (OSS) tools, please acknowledge with the following wording:\n\n> This project used Microsoft Research's Project InnerEye open-source software tools ([https://aka.ms/InnerEyeOSS](https://aka.ms/InnerEyeOSS)).\n\n## Contact\n\nIf you have any feature requests, or find issues in the code, please create an\n[issue on GitHub](https://github.com/microsoft/InnerEye-DeepLearning/issues).\n\nPlease send an email to InnerEyeInfo@microsoft.com if you would like further information about this project.\n\n## Publications\n\nOktay O., Nanavati J., Schwaighofer A., Carter D., Bristow M., Tanno R., Jena R., Barnett G., Noble D., Rimmer Y., Glocker B., O\u2019Hara K., Bishop C., Alvarez-Valle J., Nori A.: Evaluation of Deep Learning to Augment Image-Guided Radiotherapy for Head and Neck and Prostate Cancers. JAMA Netw Open. 2020;3(11):e2027426. [doi:10.1001/jamanetworkopen.2020.27426](https://pubmed.ncbi.nlm.nih.gov/33252691/)\n\nBannur S., Oktay O., Bernhardt M, Schwaighofer A., Jena R., Nushi B., Wadhwani S., Nori A., Natarajan K., Ashraf S., Alvarez-Valle J., Castro D. C.: Hierarchical Analysis of Visual COVID-19 Features from Chest Radiographs. ICML 2021 Workshop on Interpretable Machine Learning in Healthcare. [https://arxiv.org/abs/2107.06618](https://arxiv.org/abs/2107.06618)\n\nBernhardt M., Castro D. C., Tanno R., Schwaighofer A., Tezcan K. C., Monteiro M., Bannur S., Lungren M., Nori S., Glocker B., Alvarez-Valle J., Oktay. O: Active label cleaning for improved dataset quality under resource constraints. [https://www.nature.com/articles/s41467-022-28818-3](https://www.nature.com/articles/s41467-022-28818-3). Accompanying code [InnerEye-DataQuality](https://github.com/microsoft/InnerEye-DeepLearning/blob/1606729c7a16e1bfeb269694314212b6e2737939/InnerEye-DataQuality/README.md)\n\n## Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit [https://cla.opensource.microsoft.com](https://cla.opensource.microsoft.com).\n\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## Maintenance\n\nThis toolbox is maintained by the [Microsoft Medical Image Analysis team](https://www.microsoft.com/en-us/research/project/medical-image-analysis/).\n"
 },
 {
  "repo": "Project-Based-Learning-IT/healthcare-appointment-scheduling-app",
  "language": "JavaScript",
  "readme_contents": "## healthcare-appointment-scheduling-app\n\n**Frontend**- https://healthcareapp.netlify.app/\n\n**Backend** - https://hospitalappointmentbooking.herokuapp.com/\n\n## Patient Guide: \n\n### Patient Login\n![Patient Login](https://github.com/Project-Based-Learning-IT/healthcare-appointment-scheduling-app/blob/calendar/Software-Engineering/Screenshots/original_login%20patient.jpg)\n\n### Patient Personal Details\n![Patient Personal Details](https://github.com/Project-Based-Learning-IT/healthcare-appointment-scheduling-app/blob/calendar/Software-Engineering/Screenshots/original_patient_personal%20details.png)\n\n### Search\n![Search](https://github.com/Project-Based-Learning-IT/healthcare-appointment-scheduling-app/blob/calendar/Software-Engineering/Screenshots/original_search%20doctor.jpg)\n\n### Select Date\n![Select date](https://github.com/Project-Based-Learning-IT/healthcare-appointment-scheduling-app/blob/calendar/Software-Engineering/Screenshots/original_select%20date.jpg)\n\n### Select Slot\n![Select Slot](https://github.com/Project-Based-Learning-IT/healthcare-appointment-scheduling-app/blob/calendar/Software-Engineering/Screenshots/original_booking%20status.jpg)\n\n### Payment\n![Payment](https://github.com/Project-Based-Learning-IT/healthcare-appointment-scheduling-app/blob/calendar/Software-Engineering/Screenshots/original_payment.jpg)\n\n![Address](https://github.com/Project-Based-Learning-IT/healthcare-appointment-scheduling-app/blob/calendar/Software-Engineering/Screenshots/original_address%20details.jpg)\n\n![Card details](https://github.com/Project-Based-Learning-IT/healthcare-appointment-scheduling-app/blob/calendar/Software-Engineering/Screenshots/original_card%20details.jpg)\n\n### Appointment Status\n![Appointment Status](https://github.com/Project-Based-Learning-IT/healthcare-appointment-scheduling-app/blob/calendar/Software-Engineering/Screenshots/original_appointment%20status.jpg)\n\n### Previous Appointments\n![Previous Appointments](https://github.com/Project-Based-Learning-IT/healthcare-appointment-scheduling-app/blob/calendar/Software-Engineering/Screenshots/original_previous%20appointments.jpg)\n\n### Patient Feedback\n![Patient Feedback](https://github.com/Project-Based-Learning-IT/healthcare-appointment-scheduling-app/blob/calendar/Software-Engineering/Screenshots/original_patient%20feedback.jpg)\n\n## Doctor Guide: \n![Hompage doctor login](https://github.com/Project-Based-Learning-IT/healthcare-appointment-scheduling-app/blob/calendar/Software-Engineering/Screenshots/original_login%20both.jpg)\n\n### Doctor Login\n![Doctor login](https://github.com/Project-Based-Learning-IT/healthcare-appointment-scheduling-app/blob/calendar/Software-Engineering/Screenshots/original_doctor%20login.jpg)\n\n### Doctor's Today's Schedule\n![Doctors today's schedule](https://github.com/Project-Based-Learning-IT/healthcare-appointment-scheduling-app/blob/calendar/Software-Engineering/Screenshots/original_todays%20schedule.png)\n\n### Doctor's Personal Details\n![doctor's personal details](https://github.com/Project-Based-Learning-IT/healthcare-appointment-scheduling-app/blob/calendar/Software-Engineering/Screenshots/original_doctor%20personal%20details.jpg)\n\n### Doctor's Previous Appointments\n![Doctor's previous appointments](https://github.com/Project-Based-Learning-IT/healthcare-appointment-scheduling-app/blob/calendar/Software-Engineering/Screenshots/original_doctor%20previous%20appointments.png)\n\n### Doctor View Feedback\n![Doctor's View feedback](https://github.com/Project-Based-Learning-IT/healthcare-appointment-scheduling-app/blob/calendar/Software-Engineering/Screenshots/original_doctor%20feedback.jpg)\n"
 },
 {
  "repo": "edaaydinea/AI-Projects-for-Healthcare",
  "language": "Jupyter Notebook",
  "readme_contents": "# AI-Projects-for-Healthcare\n\nThis repository is included artificial intelligence, machine learning, data science, computer vision projects related to healthcare.\n\nInformation about completion: \u2705(Complete), \ud83d\udea7 (Work in Progress), \u274c (Incomplete)\n\n## Table of Contents\n\n- [AI-Projects-for-Healthcare](#ai-projects-for-healthcare)\n  - [Table of Contents](#table-of-contents)\n  - [Projects in Bootcamp Education](#projects-in-bootcamp-education)\n  - [Projects in Healthcare + Artificial Intelligence Education](#projects-in-healthcare--artificial-intelligence-education)\n  - [Research Projects](#research-projects)\n\n## Projects in Bootcamp Education\n\n- **[Breast Cancer Classification \u2705](https://github.com/edaaydinea/AI-Projects-for-Healthcare/blob/master/Breast%20Cancer%20Classification/%20Breast_Cancer_Classification.ipynb):** The aim of this project is classification the tumors into malignant or benign with machine learning techniques.\n- **[Detecting COVID-19 with Chest X-ray using PyTorch \u2705](https://github.com/edaaydinea/AI-Projects-for-Healthcare/blo/731619a7f8e041059d15832d56c1ca1df540a221/Detecting%20COVID-19%20with%20Chest%20X-Ray%20using%20PyTorch/Detecting%20COVID-19%20with%20Chest%20X-Ray%20using%20PyTorch.ipynb):** The aim of this project is detection\n  COVID-19 on the chest x-ray images by using PyTorch. The [dataset](https://www.kaggle.com/datasets/tawsifurrahman/covid19-radiography-database) is taken from Kaggle.\n- **[Diabetes Prediction with PySpark MLLIB \u2705](https://github.com/edaaydinea/AI-Projects-for-Healthcare/blob/731619a7f8e041059d15832d56c1ca1df540a221/Diabetes%20Prediction%20With%20Pyspark%20MLLIB/Diabetes_Prediction.ipynb):** The aim of this project is to build logistic regression model using PySpark MLLIB\n  to classify patients as either diabetic or non-diabetic. This project is a Guided project([Link](https://www.coursera.org/projects/diabetes-prediction-with-pyspark-mllib)) available on Coursera.\n- **[Heart Failure Data Analysis \u2705](https://jovian.ai/edaaydinea/health-failure-prediction):** The aim of this project is to make a detailed exploratory data analysis on the Heart Failure Prediction [dataset](https://www.kaggle.com/datasets/andrewmvd/heart-failure-clinical-data) which is taken from Kaggle by using the plotly library.\n- **[Relationship between COVID-17 & Happiness in that Country \u2705](https://github.com/edaaydinea/AI-Projects-for-Healthcare/blob/master/Relationship%20between%20COVID-19%20%20%26%20Happiness%20in%20that%20Country/covid19%20data%20analysis%20notebook.ipynb):** The aim of this project is to work on whether\n  where is any relationship between the spread of the coronavirus in a country and how happy people are living in\n  that country or not. The dataset is taken from COVID-19 dataset published by Johns Hopkins University and World\n  Happiness Report.\n\n## Projects in Healthcare + Artificial Intelligence Education\n\n- **[DNA Classification Project \u2705](https://github.com/edaaydinea/AI-Projects-for-Healthcare/blob/master/DNA%20Classification%20Project/DNA%20Classification.ipynb):** The aim of this project is to find out whether the DNA sequence is the promoter.\n- **[Heart Disease Classification Project \u2705](https://github.com/edaaydinea/AI-Projects-for-Healthcare/blob/master/Heart%20Disease%20Classification%20Project/Heart%20Disease%20Classification.ipynb):** The aim of this project is to predict  the condition of her/his disease throughout a classification algorithm based on a neural network. The dataset is taken from [UCI Machine learning Respiratory](https://archive.ics.uci.edu/ml/datasets/Heart+Disease).\n- **[Diagnosing Coronary Artery Disease Project \u2705](https://github.com/edaaydinea/AI-Projects-for-Healthcare/blob/master/Diagnosing%20Coronary%20Artery%20Disease%20Project/Diagnosing%20Coronary%20Artery%20Disease.ipynb):** The aim of this project is to predict the condition of her/his disease throughout a classification algorithm based on a neural network.\n- **[Breast Cancer Detection \u2705](https://github.com/edaaydinea/AI-Projects-for-Healthcare/blob/master/Breast%20Cancer%20Detection/Breast_Cancer_Detection.ipynb):** The aim of this project is to predict the breast cancer from a digitized image of a fine needle aspirate (FNA) of a breast muscles\n\n## Research Projects\n\n- The projects here are included in different repository.\n- **[Chest X-Ray Image Classification by using PyTorch, CNN (Pneumonia)\u2705](https://github.com/edaaydinea/Chest-Xray-Image-Classification-by-using-PyTorch-CNN)**\n- **[Pneumonia Detection on Chest X-ray Images with Deep Learning (Keras) \u2705](<https://github.com/edaaydinea/Pneumonia-Detection-on-Chest-Xray-Images-with-Deep-Leaning>)**\n- **[Estimating the Probability of Confirmed COVID-19 Cases Taking into the Intensive Care Unit (ICU) \u2705](<https://github.com/edaaydinea/Estimating-the-Probability-of-Confirmed-COVID-19-Cases-Taking-into-the-Intensive-Care-Unit-ICU>)**\n- **[OP1 - Prediction of the Different Progressive Levels of Alzheimer's Disease \u2705](<https://github.com/edaaydinea/OP1-Prediction-of-the-Different-Progressive-Levels-of-Alzheimer-s-Disease>)**\n- **[OP2 - Prediction of the Different Progressive Levels of Alzheimer's Disease with MRI data \u2705](<https://github.com/edaaydinea/OP2-Prediction-of-the-Different-Progressive-Levels-of-Alzheimer-s-Disease-with-MRI-data>)**\n- **[Low Grade Glioma Segmentation \u2705](<https://github.com/edaaydinea/Low-Grade-Glioma-Segmentation>)**\n- **[Multiple Sclerosis Lesion Segmentation from Brain Magnetic Resonance Images via Fully Convolutional Neural Network \ud83d\udea7](<https://github.com/edaaydinea/Multiple-Sclerosis-Lesion-Segmentation-from-Brain-Magnetic-Resonance-Images-via-Fully-Convolutional>)**\n- **[Magnetic Resonance Imaging Comparisons of Demented and Non-demented Adults \ud83d\udea7](<https://github.com/edaaydinea/Magnetic-Resonance-Imaging-Comparisons-of-Demented-and-Non-demented-Adults>)**\n"
 },
 {
  "repo": "IBMStreams/streamsx.health",
  "language": "Java",
  "readme_contents": "# Streams Healthcare Analytics Platform\n\nWelcome to the Streams Healthcare Analytics Platform!\n\nOur goal is to make it easy to create real-time healthcare analytics application using IBM Streams.  We want our users to be able to rapidly develop, test and validate healthcare analytics. Researchers and clinicians should focus on the analytics part of an application, while the platform should take care of the necessary plumbing and infrastructure work.\n\n## Getting Started\n\n**NEW Release v0.1 is now available [here](https://github.com/IBMStreams/streamsx.health/releases/tag/v0.1)!**  See this [post](https://github.com/IBMStreams/streamsx.health/wiki/First-Release-Overview) to learn more about this release!\n\nFollow the [**Getting Started Guide**]https://github.com/IBMStreams/streamsx.health/wiki/Getting-Started) to learn about how to leverage the services from the Streams Healthcare Analytics Platform\n\n## Streams Healthcare Demos\n\n### Python Jupyter Notebook Demo\n\nAs part of our initial work for this platform, we have developed a real-time ECG monitoring sample, using the Physionet Ingest Service, Python and Jupyter notebook.  \n\n[<img src=\"https://github.com/IBMStreams/streamsx.health/blob/master/samples/HealthcareJupyterDemo/images/Healthcare_Demo.png\" alt=\"Healthcare Jupyter Notebook Demo\" width=\"600\">](https://github.com/IBMStreams/streamsx.health/blob/master/samples/HealthcareJupyterDemo/)\n\nTo see this sample in action, you can run this sample using [**IBM Data Science Experience**](https://datascience.ibm.com/) and [**Streaming Analytics Service**](https://console.ng.bluemix.net/docs/services/StreamingAnalytics/index.html) on Bluemix.  See this [notebook](https://datascience.ibm.com/exchange/public/entry/view/9fc33ce7301f10e21a9f92039cad29a6\n) for details.\n\nTo run this sample in Streams Quick Start Edition:\n\n1.  Get the Streams Quick Start Edition VM from [here](https://www-01.ibm.com/marketing/iwm/iwm/web/preLogin.do?source=swg-ibmistvi&S_TACT=000000VP&S_OFF_CD=10000737).\n1.  Clone this repository.\n1.  Follow the instructions from here to run the demo:  [Healthcare Python Streaming Application Demo](https://github.com/IBMStreams/streamsx.health/tree/master/samples/HealthcareJupyterDemo)\n\n### Population Health and Patient Monitoring\n\nThis sample demonstrates how we can use IBM Streams and the Streams Healthcare Anallytics Platform to monitor patient status in real-time. The sample generates vitals and ECG data for 100 patients. Patient data is fed into an analytics application that checks if a patient's vitals are in the normal range. If the vitals exceed the normal ranges, an alert is raised and is displayed on the dashboard.\n\n[<img src=\"https://github.com/IBMStreams/streamsx.health/blob/develop/samples/PatientsMonitoringDemo/images/patientsMonitoring.jpeg\" alt=\"Population Health and Patient Monitoring\" width=\"600\">](https://github.com/IBMStreams/streamsx.health/tree/develop/samples/PatientsMonitoringDemo)\n\nTo run this sample in Streams Quick Start Edition:\n\n1.  Get the Streams Quick Start Edition VM from [here](https://www-01.ibm.com/marketing/iwm/iwm/web/preLogin.do?source=swg-ibmistvi&S_TACT=000000VP&S_OFF_CD=10000737).\n1.  Clone this repository.\n1.  Follow the instructions from here to run the demo:  [Population Health and Patient Monitoring Demo](https://github.com/IBMStreams/streamsx.health/tree/develop/samples/PatientsMonitoringDemo)\n\n\n## Platform Design and Roadmap\n\n[<img src=\"https://github.com/IBMStreams/streamsx.health/blob/wiki/img/healthroadmap.jpg\" alt=\"Streams Healthcare Analytics Platform Roadmap\" width=\"600\">](https://github.com/IBMStreams/streamsx.health/blob/master/samples/HealthcareJupyterDemo/)\n\nThis diagram shows what we think a typical Streams healthcare application will look like and its major components.  The blue boxes represent components that should be provided by the platform.  The purple box represents an area where our end-user should focus on.  (i.e. developing advanced analytics).  \n\nFor details on the design and roadmap of this platform, please refer to here:\n\nhttps://github.com/IBMStreams/streamsx.health/wiki\n\nOur design and roadmap are always up for discussions and we welcome your feedback and contribution.  Please submit an [issue](https://github.com/IBMStreams/streamsx.health/issues) if you have any feedback for us.\n\n## Repository Organization\n\nThe platform is designed to employ the microservice architecture.  A microservice is a small application written in SPL, Java, or Python that fulfills a specific task in a bigger healthcare application.  An application is made up of one or more of microservices, loosely connected to each other using the dynamic connection feature (Import/Export operators) in Streams.  To learn more about the microservice architecture in Streams, refer to this [post](https://developer.ibm.com/streamsdev/2016/09/02/analytics-microservice-architecture-with-ibm-streams/).\n\nThe repository is set up to accomodate this architecture.  The top level folders represent major functional components of the platform.  Under each folder, you will find one or more microservices for that component.  Each of the services can be built independently using gradle.  You can build them by following the build instructions below.  \n\nTo run the services, follow instructions as documented in their respective README.md files.\n\n## Build Instructions\n\nThis repository is set up to build using [Gradle](https://gradle.org/).\n\nAll of the services can be built from the root folder by running **`gradle build`**.\n\nIf gradle is not installed on your system, the project is shipped with a gradle wrapper.  You can build the projects by using this wrapper and running **`gradlew build`**.\n\nSimilarly, individual components and  services can be built by navigating to either the component or service directory and running **`gradle build`**. \n\nAll projects can be cleaned from either the root folder, a component folder or a service folder by running **`gradle clean`**\n\n# The Contributors\n\nThank you to all our contributors.  This platform is made available from their contributions and valuable feedback/advises.\n\n| Name | Company |\n|------|------|\n| Brandon Swink | [IBM](https://www.ibm.com/analytics/us/en/technology/stream-computing/) |\n| Gergens Polynice | [CleMetric](http://www.clemetric.com/)\n| James Cancilla | [IBM](https://www.ibm.com/analytics/us/en/technology/stream-computing/) |\n| Jonathan Lachman  | [True Process](http://www.trueprocess.com/)|\n| Peter Nicholls | [IBM](https://www.ibm.com/analytics/us/en/technology/stream-computing/) |\n| Samantha Chan | [IBM](https://www.ibm.com/analytics/us/en/technology/stream-computing/) |\n| Sharath Cholleti | [CleMetric](http://www.clemetric.com/)\n\n\n[<img src=\"images/logo.png\" alt=\"CleMetric\" width=\"200\">](http://www.clemetric.com/)      [<img src=\"images/TP-Logo-Default.png\" alt=\"True Process\" width=\"200\">](http://www.trueprocess.com/)      [<img src=\"images/ibmpos_blue.jpg\" alt=\"IBM\" width=\"200\">](https://www.ibm.com/analytics/us/en/technology/stream-computing/)         \n\n## Learn more about Streams\n\nTo learn more about Streams:\n\n* [IBM Streams on Github](http://ibmstreams.github.io)\n* [Introduction to Streams Quick Start Edition](http://ibmstreams.github.io/streamsx.documentation/docs/4.1/qse-intro/)\n* [Streams Getting Started Guide](http://ibmstreams.github.io/streamsx.documentation/docs/4.1/qse-getting-started/)\n* [StreamsDev](https://developer.ibm.com/streamsdev/)\n"
 },
 {
  "repo": "vanderschaarlab/mlforhealthlabpub",
  "language": "Python",
  "readme_contents": "# van der Schaar Lab\n__Note__ : For the most recent papers and code, checkout https://github.com/vanderschaarlab.\n\n__Legacy code__ : This repository contains the implementations of algorithms developed\nby the [van der Schaar Lab](https://www.vanderschaar-lab.com/) for papers before 2023.\n\n\n\n## Content\nAn overview of the content of this repository is as below:\n```python\n.\n\u251c\u2500\u2500 alg/        # Directory contains algorithms.\n\u251c\u2500\u2500 app/        # Directory contains apps.\n\u251c\u2500\u2500 cfg/        # Directory contains common config.\n\u251c\u2500\u2500 doc/        # Directory contains common docs.\n\u251c\u2500\u2500 init/       # Directory contains algorithms.\n\u251c\u2500\u2500 template/   # Directory contains templates.\n\u2514\u2500\u2500 util/       # Directory contains common utilities.\n```\n\n## Publications\nThe publications and the corresponding locations in the repo are listed below:\n\nPaper [[Link]](#) | Journal/Conference | Code\n--- | --- | ---\nBayesian Inference of Individualized Treatment Effects using Multi-task Gaussian Processes [[Link]](https://proceedings.neurips.cc/paper/2017/hash/6a508a60aa3bf9510ea6acb021c94b48-Abstract.html) | NIPS 2017 | [alg/causal_multitask_gaussian_processes_ite](alg/causal_multitask_gaussian_processes_ite)\nDeep Multi-task Gaussian Processes for Survival Analysis with Competing Risks [[Link]](https://proceedings.neurips.cc/paper/2017/hash/861dc9bd7f4e7dd3cccd534d0ae2a2e9-Abstract.html) | NIPS 2017 | [alg/dgp_survival](alg/dgp_survival)\nAutoPrognosis: Automated Clinical Prognostic Modeling via Bayesian Optimization with Structured Kernel Learning [[Link]](https://icml.cc/Conferences/2018/Schedule?showEvent=2050) | ICML 2018 | [alg/autoprognosis](alg/autoprognosis)\nLimits of Estimating Heterogeneous Treatment Effects: Guidelines for Practical Algorithm Design [[Link]](http://proceedings.mlr.press/v80/alaa18a.html) | ICML 2018 | [alg/causal_multitask_gaussian_processes_ite](alg/causal_multitask_gaussian_processes_ite)\nGAIN: Missing Data Imputation using Generative Adversarial Nets [[Link]](http://proceedings.mlr.press/v80/yoon18a.html) | ICML 2018 | [alg/gain](alg/gain)\nRadialGAN: Leveraging multiple datasets to improve target-specific predictive models using Generative Adversarial Networks [[Link]](http://proceedings.mlr.press/v80/yoon18b.html) | ICML 2018 | [alg/RadialGAN](alg/RadialGAN)\nGANITE: Estimation of Individualized Treatment Effects using Generative Adversarial Nets [[Link]](https://openreview.net/forum?id=ByKWUeWA-) | ICLR 2018 | [alg/ganite](alg/ganite)\nDeep Sensing: Active Sensing using Multi-directional Recurrent Neural Networks [[Link]](https://openreview.net/forum?id=r1SnX5xCb) | ICLR 2018 | [alg/DeepSensing (MRNN)](alg/DeepSensing%20(MRNN))\nDeepHit: A Deep Learning Approach to Survival Analysis with Competing Risks [[Link]](https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16160/15945) | AAAI 2018 | [alg/deephit](alg/deephit)\nINVASE: Instance-wise Variable Selection using Neural Networks [[Link]](https://openreview.net/forum?id=BJg_roAcK7) | ICLR 2019 | [alg/invase](alg/invase)\nPATE-GAN: Generating Synthetic Data with Differential Privacy Guarantees [[Link]](https://openreview.net/forum?id=S1zk9iRqF7) | ICLR 2019 | [alg/pategan](alg/pategan)\nKnockoffGAN: Generating Knockoffs for Feature Selection using Generative Adversarial Networks [[Link]](https://openreview.net/forum?id=ByeZ5jC5YQ) | ICLR 2019 | [alg/knockoffgan](alg/knockoffgan)\nASAC: Active Sensing using Actor-Critic Models [[Link]](https://arxiv.org/abs/1906.06796) | MLHC 2019 | [alg/asac](alg/asac)\nDemystifying Black-box Models with Symbolic Metamodels [[Link]](https://papers.nips.cc/paper/2019/hash/567b8f5f423af15818a068235807edc0-Abstract.html) | NeurIPS 2019 | [alg/symbolic_metamodeling](alg/symbolic_metamodeling)\nDifferentially Private Bagging: Improved Utility and Cheaper Privacy than Subsample-and-Aggregate [[Link]](https://papers.nips.cc/paper/2019/hash/5dec707028b05bcbd3a1db5640f842c5-Abstract.html) | NeurIPS 2019 | [alg/dpbag](alg/dpbag)\nTime-series Generative Adversarial Networks [[Link]](https://papers.nips.cc/paper/2019/hash/c9efe5f26cd17ba6216bbe2a7d26d490-Abstract.html) | NeurIPS 2019 | [alg/timegan](alg/timegan)\nAttentive State-Space Modeling of Disease Progression [[Link]](https://papers.nips.cc/paper/2019/hash/1d0932d7f57ce74d9d9931a2c6db8a06-Abstract.html) | NeurIPS 2019 | [alg/attentivess](alg/attentivess)\nConditional Independence Testing using Generative Adversarial Networks [[Link]](https://arxiv.org/abs/1907.04068) | NeurIPS 2019 | [alg/gcit](alg/gcit)\nDynamic-DeepHit: A Deep Learning Approach for Dynamic Survival Analysis with Competing Risks based on Longitudinal Data [[Link]](https://ieeexplore.ieee.org/document/8681104) | IEEE | [alg/dynamic_deephit](alg/dynamic_deephit)\nTemporal Quilting for Survival Analysis [[Link]](http://proceedings.mlr.press/v89/lee19a.html) | AISTATS 2019 | [alg/survivalquilts](alg/survivalquilts)\nEstimating Counterfactual Treatment Outcomes over Time through Adversarially Balanced Representations [[Link]](https://openreview.net/forum?id=BJg866NFvB) | ICLR 2020 | [alg/counterfactual_recurrent_network](alg/counterfactual_recurrent_network)\nContextual Constrained Learning for Dose-Finding Clinical Trials [[Link]](https://arxiv.org/abs/2001.02463) | AISTATS 2020 | [alg/c3t_budgets](alg/c3t_budgets)\nLearning Overlapping Representations for the Estimation of Individualized Treatment Effects [[Link]](https://arxiv.org/abs/2001.04754) | AISTATS 2020 | [alg/dklite](alg/dklite)\nLearning Dynamic and Personalized Comorbidity Networks from Event Data using Deep Diffusion Processes [[Link]](https://arxiv.org/abs/2001.02585) | AISTATS 2020 | [alg/dynamic_disease_network_ddp](alg/dynamic_disease_network_ddp)\nStepwise Model Selection for Sequence Prediction via Deep Kernel Learning [[Link]](https://arxiv.org/abs/2001.03898) | AISTATS 2020 | [alg/smsdkl](alg/smsdkl)\nTemporal Phenotyping using Deep Predicting Clustering of Disease Progression [[Link]](http://proceedings.mlr.press/v119/lee20h.html) | ICML 2020 | [alg/ac_tpc](alg/ac_tpc)\nTime Series Deconfounder: Estimating Treatment Effects over Time in the Presence of Hidden Confounders [[Link]](http://proceedings.mlr.press/v119/bica20a.html) | ICML 2020 | [alg/time_series_deconfounder](alg/time_series_deconfounder)\nDiscriminative Jackknife: Quantifying Uncertainty in Deep Learning via Higher-Order Influence Functions [[Link]](http://proceedings.mlr.press/v119/alaa20a.html) | ICML 2020 | [alg/discriminative-jackknife](alg/discriminative-jackknife)\nFrequentist Uncertainty in Recurrent Neural Networks via Blockwise Influence Functions [[Link]](http://proceedings.mlr.press/v119/alaa20b.html) | ICML 2020 | [alg/rnn-blockwise-jackknife](alg/rnn-blockwise-jackknife)\nUnlabelled Data Improves Bayesian Uncertainty Calibration under Covariate Shift [[Link]](http://proceedings.mlr.press/v119/chan20a.html) | ICML 2020 | [alg/transductive_dropout](alg/transductive_dropout)\nAnonymization Through Data Synthesis Using Generative Adversarial Networks (ADS-GAN) [[Link]](https://ieeexplore.ieee.org/document/9034117) | IEEE | [alg/adsgan](alg/adsgan)\nWhen and How to Lift the Lockdown? Global COVID-19 Scenario Analysis and Policy Assessment using Compartmental Gaussian Processes [[Link]](https://vanderschaar-lab.com/papers/NeurIPS2020_CGP.pdf) | NeurIPS 2020 | [alg/compartmental_gp](alg/compartmental_gp)\nStrictly Batch Imitation Learning by Energy-based Distribution Matching [[Link]](https://arxiv.org/abs/2006.14154) | NeurIPS 2020 | [alg/edm](alg/edm)\nGradient Regularized V-Learning for Dynamic Treatment Regimes [[Link]](https://vanderschaar-lab.com/papers/NeurIPS2020_GRV.pdf) | NeurIPS 2020 | [alg/grv](alg/grv)\nCASTLE: Regularization via Auxiliary Causal Graph Discovery [[Link]](https://arxiv.org/abs/2009.13180) | NeurIPS 2020 | [alg/castle](alg/castle)\nOrganITE: Optimal transplant donor organ offering using an individual treatment effect [[Link]](https://vanderschaar-lab.com/papers/NeurIPS2020_OrganITE.pdf) | NeurIPS 2020 | [alg/organite](alg/organite)\nRobust Recursive Partitioning for Heterogeneous Treatment Effects with Uncertainty Quantification [[Link]](https://arxiv.org/abs/2006.07917) | NeurIPS 2020 | [alg/r2p-hte](alg/r2p-hte)\nEstimating the Effects of Continuous-valued Interventions using Generative Adversarial Networks [[Link]](https://arxiv.org/abs/2002.12326) | NeurIPS 2020 | [alg/scigan](alg/scigan)\nLearning outside the Black-Box: The pursuit of interpretable models [[Link]](https://arxiv.org/abs/2011.08596) | NeurIPS 2020 | [alg/Symbolic-Pursuit](alg/Symbolic-Pursuit)\nVIME: Extending the Success of Self- and Semi-supervised Learning to Tabular Domain [[Link]](https://papers.nips.cc/paper/2020/hash/7d97667a3e056acab9aaf653807b4a03-Abstract.html) | NeurIPS 2020 | [alg/vime](alg/vime)\nScalable Bayesian Inverse Reinforcement Learning [[Link]](https://openreview.net/pdf?id=4qR3coiNaIv) | ICLR 2021 | [alg/scalable-birl](alg/scalable-birl)\nNonparametric Estimation of Heterogeneous Treatment Effects: From Theory to Learning Algorithms [[Link]](https://arxiv.org/abs/2101.10943) | AISTATS 2021 | [alg/CATENets](https://github.com/vanderschaarlab/CATENets)\nLearning Matching Representations for Individualized Organ Transplantation Allocation [[Link]](https://arxiv.org/abs/2101.11769) | AISTATS 2021| [alg/MatchingRep](alg/MatchingRep)\nExplaining by Imitating: Understanding Decisions by Interpretable Policy Learning [[Link]](https://openreview.net/forum?id=unI5ucw_Jk) | ICLR 2021 | [alg/interpole](alg/interpole)\nInverse Decision Modeling: Learning Interpretable Representations of Behavior [[Link]](http://proceedings.mlr.press/v139/jarrett21a.html) | ICML 2021 | [alg/ibrc](alg/ibrc)\nPolicy Analysis using Synthetic Controls in Continuous-Time [[Link]](http://proceedings.mlr.press/v139/bellot21a/bellot21a.pdf) | ICML 2021 | [alg/Synthetic-Controls-in-Continuous-Time](https://github.com/vanderschaarlab/Synthetic-Controls-in-Continuous-Time/)\nLearning Queueing Policies for Organ Transplantation Allocation using Interpretable Counterfactual Survival Analysis [[Link]](http://proceedings.mlr.press/v139/berrevoets21a/berrevoets21a.pdf) | ICML 2021 | [alg/organsync](https://github.com/vanderschaarlab/organsync/)\nExplaining Time Series Predictions with Dynamic Masks [[Link]](http://proceedings.mlr.press/v139/crabbe21a.html) | ICML 2021 | [alg/Dynamask](https://github.com/vanderschaarlab/Dynamask/)\nGenerative Time-series Modeling with Fourier Flows [[Link]](https://openreview.net/forum?id=PpshD0AXfA) | ICLR 2021 | [alg/Fourier-flows](https://github.com/vanderschaarlab/Fourier-flows/)\nOn Inductive Biases for Heterogeneous Treatment Effect Estimation [[Link]](https://arxiv.org/pdf/2106.03765.pdf) | NeurIPS 2021 | [alg/CATENets](https://github.com/vanderschaarlab/CATENets/)\nReally Doing Great at Estimating CATE? A Critical Look at ML Benchmarking Practices in Treatment Effect Estimation [[Link]](https://openreview.net/pdf?id=FQLzQqGEAH) | NeurIPS 2021 | [alg/CATENets](https://github.com/vanderschaarlab/CATENets/)\nThe Medkit-Learn(ing) Environment: Medical Decision Modelling through Simulation [[Link]](https://arxiv.org/abs/2106.04240) | NeurIPS 2021 | [alg/medkit-learn](https://github.com/vanderschaarlab/medkit-learn)\nMIRACLE: Causally-Aware Imputation via Learning Missing Data Mechanisms [[Link]](https://neurips.cc/Conferences/2021/ScheduleMultitrack?event=27670) | NeurIPS 2021 | [alg/MIRACLE](https://github.com/vanderschaarlab/MIRACLE)\nDECAF: Generating Fair Synthetic Data Using Causally-Aware Generative Networks [[Link]](https://neurips.cc/Conferences/2021/ScheduleMultitrack?event=27552) | NeurIPS 2021 | [alg/DECAF](https://github.com/vanderschaarlab/DECAF)\nExplaining Latent Representations with a Corpus of Examples [[Link]](https://arxiv.org/abs/2110.15355) | NeurIPS 2021 | [alg/Simplex](https://github.com/vanderschaarlab/Simplex)\nClosing the loop in medical decision support by understanding clinical decision-making: A case study on organ transplantation [[Link]](https://neurips.cc/Conferences/2021/ScheduleMultitrack?event=26815) | NeurIPS 2021 | [alg/iTransplant](https://github.com/vanderschaarlab/iTransplant)\nIntegrating Expert ODEs into Neural ODEs: Pharmacology and Disease Progression [[Link]](https://papers.neurips.cc/paper/2021/hash/5ea1649a31336092c05438df996a3e59-Abstract.html) | NeurIPS 2021 | [alg/Hybrid-ODE-NeurIPS-2021](https://github.com/vanderschaarlab/Hybrid-ODE-NeurIPS-2021)\nSyncTwin: Treatment Effect Estimation with Longitudinal Outcomes [[Link]](https://proceedings.neurips.cc/paper/2021/hash/19485224d128528da1602ca47383f078-Abstract.html) | NeurIPS 2021 | [alg/SyncTwin-NeurIPS-2021](https://github.com/vanderschaarlab/SyncTwin-NeurIPS-2021)\nConformal Time-series Forecasting [[Link]](https://proceedings.neurips.cc/paper/2021/hash/312f1ba2a72318edaaa995a67835fad5-Abstract.html) | NeurIPS 2021 | [alg/conformal-rnn](https://github.com/vanderschaarlab/conformal-rnn/tree/master)\nEstimating Multi-cause Treatment Effects via Single-cause Perturbation [[Link]](https://proceedings.neurips.cc/paper/2021/hash/c793b3be8f18731f2a4c627fb3c6c63d-Abstract.html) | NeurIPS 2021 | [alg/Single-Cause-Perturbation-NeurIPS-2021](https://github.com/vanderschaarlab/Single-Cause-Perturbation-NeurIPS-2021/)\nInvariant Causal Imitation Learning for Generalizable Policies [[Link]](https://papers.nips.cc/paper/2021/file/204904e461002b28511d5880e1c36a0f-Paper.pdf) | NeurIPS 2021 | [alg/Invariant-Causal-Imitation-Learning](https://github.com/vanderschaarlab/Invariant-Causal-Imitation-Learning/tree/main)\nInferring Lexicographically-Ordered Rewards from Preferences [[Link]](https://ojs.aaai.org/index.php/AAAI/article/view/20516) | AAAI 2022 | [alg/lori](https://github.com/vanderschaarlab/lori)\nInverse Online Learning: Understanding Non-Stationary and Reactionary Policies [[Link]](https://openreview.net/forum?id=DYypjaRdph2) | ICLR 2022 | [alg/inverse-online](https://github.com/vanderschaarlab/inverse-online)\nD-CODE: Discovering Closed-form ODEs from Observed Trajectories [[Link]](https://openreview.net/forum?id=wENMvIsxNN) | ICLR 2022 | [alg/D-CODE-ICLR-2022](https://github.com/vanderschaarlab/D-CODE-ICLR-2022)\nNeural graphical modelling in continuous-time: consistency guarantees and algorithms [[Link]](https://openreview.net/forum?id=SsHBkfeRF9L) | ICLR 2022 | [alg/Graphical-modelling-continuous-time](https://github.com/vanderschaarlab/Graphical-modelling-continuous-time)\nLabel-Free Explainability for Unsupervised Models [[Link]](https://proceedings.mlr.press/v162/crabbe22a) | ICML 2022 | [alg/Label-Free-XAI](https://github.com/vanderschaarlab/Label-Free-XAI)\nInverse Contextual Bandits: Learning How Behavior Evolves over Time [[Link]](https://proceedings.mlr.press/v162/huyuk22a.html) | ICML 2022 | [alg/invconban](https://github.com/vanderschaarlab/invconban)\nData-SUITE: Data-centric identification of in-distribution incongruous examples [[Link]](https://proceedings.mlr.press/v162/seedat22a.html) | ICML 2022 | [alg/Data-SUITE](https://github.com/vanderschaarlab/Data-SUITE)\nContinuous-Time Modeling of Counterfactual Outcomes Using Neural Controlled Differential Equations [[Link]](https://proceedings.mlr.press/v162/seedat22b) | ICML 2022 | [alg/TE-CDE](https://github.com/vanderschaarlab/TE-CDE)\nConcept Activation Regions: A Generalized Framework For Concept-Based Explanations[[Link]](https://arxiv.org/abs/2209.11222) | NeurIPS 2022 | [alg/CARs](https://github.com/vanderschaarlab/CARs)\nBenchmarking Heterogeneous Treatment Effect Models through the Lens of Interpretability[[Link]](https://arxiv.org/abs/2206.08363) | NeurIPS 2022 | [alg/ITErpretability](https://github.com/vanderschaarlab/ITErpretability)\nTransfer Learning on Heterogeneous Feature Spaces for Treatment Effects Estimation[[Link]](https://arxiv.org/abs/2210.06183) | NeurIPS 2022 | [alg/HTCE-learners](https://github.com/vanderschaarlab/HTCE-learners)\nSynthetic Model Combination: An Instance-wise Approach to Unsupervised Ensemble Learning[[Link]](https://arxiv.org/abs/2210.05320) | NeurIPS 2022 | [alg/HTCE-learners](https://github.com/vanderschaarlab/synthetic-model-combination)\n<br/>\n\nDetails of apps and other software is listed below:\n\nApp/Software [[Link]](#) | Description | Publication | Code\n--- | --- | --- | ---\nAdjutorium COVID-19 [[Link]](https://www.vanderschaar-lab.com/paper-on-covid-19-hospital-capacity-planning-published-in-machine-learning/) | Adjutorium COVID-19: an AI-powered tool that accurately predicts how COVID-19 will impact resource needs (ventilators, ICU beds, etc.) at the individual patient level and the hospital level | - | [app/adjutorium-covid19-public](app/adjutorium-covid19-public)\nClairvoyance [[Link]](https://www.vanderschaar-lab.com/clairvoyance-alpha-the-first-unified-end-to-end-automl-pipeline-for-time-series-data/) | Clairvoyance: A Pipeline Toolkit for Medical Time Series | [ICML 2021](https://openreview.net/forum?id=xnC8YwKUE3k) | [clairvoyance repository](https://github.com/vanderschaarlab/clairvoyance)\nClairvoyance2 [[Link]](https://github.com/vanderschaarlab/clairvoyance2) | `clairvoyance2`: a Unified Toolkit for Medical Time Series | - | [clairvoyance2 repository](https://github.com/vanderschaarlab/clairvoyance2)\nHide-and-Seek Privacy Challenge [[Link]](http://www.vanderschaar-lab.com/privacy-challenge/) | Hide-and-Seek Privacy Challenge: Synthetic Data Generation vs. Patient Re-identification with Clinical Time-series Data | [NeurIPS 2020 competition track](https://arxiv.org/abs/2007.12087) | [app/hide-and-seek](app/hide-and-seek)\n\n## Citations\nPlease cite the *the applicable papers* and [van der Schaar Lab repository](https://github.com/vanderschaarlab/mlforhealthlabpub/) if you use the software.\n\n## Breakdown by category\n\n**See breakdown [here](https://github.com/vanderschaarlab/.github/tree/main/profile).**\n\n## License\nCopyright **2019-2022** van der Schaar Lab.\n\nThis software is released under the [3-Clause BSD license](https://opensource.org/licenses/BSD-3-Clause) unless mentioned otherwise by the respective algorithms and apps.\n\n## Installation instructions\n*See individual algorithm and app directories for installation instructions.*\n\nSee also [doc/install.md](doc/install.md) for common installation instructions.\n\n## Tutorials and or examples\n*See individual algorithm and app directories for tutorials and examples.*\n\n## Data\nData files (as well as other large files such as saved models etc.) can be downloaded as per instructions in the `DATA-*.md` (see e.g. [DATA-PUBLIC.md](./DATA-PUBLIC.md)) files found in the corresponding directories.\n\n## More info\nFor more information on the van der Schaar Lab\u2019s work, visit [our homepage](https://www.vanderschaar-lab.com/).\n\n## References\n*See individual algorithm and app directories for references.*\n"
 },
 {
  "repo": "MichaelAllen1966/1804_python_healthcare",
  "language": "Jupyter Notebook",
  "readme_contents": "# 1804_python_healthcare\npdf, py, and jupyter notebook files for https://pythonhealthcare.org/\n"
 },
 {
  "repo": "IBM-MIL/IBM-Ready-App-for-Healthcare",
  "language": "Objective-C",
  "readme_contents": "![](README_assets/banner.png)\n# IBM Ready App for Healthcare\n\n### Overview\n\nIBM Ready App for Healthcare is the first of the IBM Ready App Series. \n\n\nThis app \n* improves patient recovery timeframes \n* increases patient adherence to at-home physical therapy programs \n* tracks patient progress regardless of wearable utilized\n* gives patients access to a customized, at-home exercise library that can be accessed anywhere\n* enables patients to track and manage pain levels throughout the recovery process\n\nWith this app, patients can also fill out medical questionnaires and progress reports from any place with their mobile device prior to their in-clinic appointments.\n\n### Getting started\nPlease visit the [Getting Started page](http://lexdcy040194.ecloud.edst.ibm.com/physio_1_0_2/getting_started) to set up the project.\n\n### Documentation\nPlease visit [this page](http://lexdcy040194.ecloud.edst.ibm.com/physio_1_0_2/home) for access to the full documentation.\n\n### License\nIBM Ready App for Healthcare is available under the IBM Ready Apps License Agreement. See the [License file](https://github.com/IBM-MIL/IBM-Ready-App-for-Healthcare/blob/master/License.txt) for more details.\n"
 },
 {
  "repo": "qgzang/ComputationalHealthcare",
  "language": "Python",
  "readme_contents": "# Computational Healthcare Library \nThis repository contains Computational Healthcare library (chlib), the underlying library used in [Computational Healthcare](http://www.computationalhealthcare.com/). \nComputational Healthcare library is designed to allow computer scientists to use large healthcare claims databases. Using chlib you can easily load & process large healthcare databases with millions of patients. \n\n## Analyze up to 200 Million visits & 70 Million patients\n\nCurrently we support following three databases:\n\n 1. [Texas Inpatient public use data file 2006-2009](https://www.dshs.texas.gov/thcic/hospitals/Inpatientpudf.shtm): This database contains approximately 11 Million de-identified inpatient visits from Texas during 2006-2009, this data is available as free download. Inpatients visits in this database lack patient identifier.\n   \n 2. [HCUP Nationwide Readmission database for 2013](https://www.hcup-us.ahrq.gov/nrdoverview.jsp): This database contains de-identified inpatients visits during 2013 & 14. Unlike Texas database all inpatient visits are associated with a patient identifier and its possible to track patient through multiple visits.\n \n 3. [HCUP State Inpatient, ED & SASD database](http://www.hcup-us.ahrq.gov/sidoverview.jsp): This is one of the largest logitudinal database of medical claims in the world. Acquiring this database typically takes several weeks and can cost few 100$ to ~10,000$ depending number of states/years/types. We currently support data from California, Florida & New York. If you are interested in using Computational Healthcare with this dataset please contact us.\n          \n**Please note that this repository does not contains any data, nor do we provide any data. You should acquire the datasets on your own \n  from AHRQ and/or other state agencies.**         \n\n## Architecture & Data Model\nA quick overview of data model, architecture is available in this [presentation](https://docs.google.com/presentation/d/1Oh_-FShr3BCGiCSqghI2dQYnyKvVOeiOqkIjaaEOPwc/edit?usp=sharing).\n\n- The library uses Protocol buffers for storing [raw data (visits & patients)](/chlib/entity/protocols/pvisit.proto) and [aggregate statistics](/chlib/entity/protocols/pstat.proto).\n- Categorical fields-values are represented as [enums](/chlib/entity/protocols/penums.proto) using Protocol buffers. \n- Raw data is stored in a levelDB database\n- Protocol Buffers and LevelDB makes it easy to use any programming language\n- We provide code to compute aggregate statistics in privacy preserving manner\n- Integrated with TensorFlow for building machine learning models\n \n## Installation & Setup\n\n- The [docker folder](docker/) contains a Dockerfile with all dependencies specified. \nIt also contains script for building docker image, starting container, preparing databases from user supplied files.\n\n- Once you have obtained data you should modify [docker/prepare_nrd.sh](docker/prepare_nrd.sh) script with correct path to .CSV file and run the script.\n\n- For Texas dataset modify/run the [prepare_tx.sh](docker/prepare_tx.sh).\n\n- The dockerfile uses TensorFlow version 0.11 docker image as a starting point. Thus in addition to Computational Healthcare library it \nalso contains a Jupyter notebook server which runs automatically when the container is started. Once the preparation step is \ncomplete you can use the jupyter notebook server running (inside the container) on port 8888 of your local machine.\n\n\n## Quick overview  \n\n```python\n    import chlib\n    NRD = chlib.data.Data.get_from_config('../config.json','HCUPNRD')\n    # patients\n    for p_key,patient in NRD.iter_patients():\n        break\n    print p_key,patient\n    \n    # visits\n    for p_key,patient in NRD.iter_patients():\n        for v in patient.visits:\n            break\n        break\n    print v\n```\n\n#### output (fake)\n\n````\n123213213 patient_key: \"213213213\"\nvisits {\n  key: \"123213\"\n  patient_key: \"213123213213\"\n  dataset: \"NRD_2011\"\n  state: \"NRD\"\n  facility: \"1232131\"\n  vtype: IP\n  age: 23\n  sex: FEMALE\n  race: R_UNKNOWN\n  source: S_ED\n  disposition: D_ROUTINE\n  los: 0\n  death: ALIVE\n  payer: PRIVATE\n  primary_diagnosis: \"D80\"\n  primary_procedure {\n    pcode: \"P86\"\n    pday: 0\n    ctype: ICD\n  }\n  drg: \"DG05\"\n  prs {\n    pcode: \"P8659\"\n    pday: -1\n    ctype: ICD\n    occur: 1\n  }\n  year: 2013\n  month: 10\n  quarter: 1\n  zip: Z_THIRD\n  dnr: DNR_UNAVAILABLE\n  charge: 229.0\n}\nraw: \"<>\"\nlinked: true\n\n  key: \"123213\"\n  patient_key: \"213213213123\"\n  dataset: \"NRD_2011\"\n  state: \"NRD\"\n  facility: \"1232131\"\n  vtype: IP\n  age: 65\n  sex: FEMALE\n  race: R_UNKNOWN\n  source: S_ED\n  disposition: D_ROUTINE\n  los: 0\n  death: ALIVE\n  payer: PRIVATE\n  primary_diagnosis: \"D80\"\n  primary_procedure {\n    pcode: \"P86\"\n    pday: 0\n    ctype: ICD\n  }\n  drg: \"DG05\"\n  dxs: \"D709\"\n  prs {\n    pcode: \"P8659\"\n    pday: -1\n    ctype: ICD\n    occur: 1\n  }\n  year: 2013\n  day: 5151\n  month: 10\n  quarter: 1\n  zip: Z_THIRD\n  dnr: DNR_UNAVAILABLE\n  charge: 229.0\n````\n      \n### Text description of codes and enums      \n```python\n    coder =  chlib.codes.Coder() \n    print 'D486',coder['D486'] # ICD-9 diagnosis codes are prepended with 'D'\n    print 'P9971',coder['P9971'] # ICD-9 procedure codes are prepended with 'P'\n    print coder[chlib.entity.enums.D_AMA] # You can also print string representation of Enums            \n```\n#### output\n````\nD486 Pneumonia, organism unspecified\nP9971 Therapeutic plasmapheresis\nAgainst medical advice\n````\n\n### Retrieve list of patients with particular diagnosis or procedure\n\n```python \n    patients_undergoing_plasmapheresis = [p for _,p in NRD.iter_patients_by_code('P9971')]\n    # You can speed this up by precomputing list of patients for each codes, using 'fab precompute'\n    print len(patients_undergoing_plasmapheresis)\n    for v in patients_undergoing_plasmapheresis[0].visits:\n        print v.key,v.day,v.prs\n```   \n\n## Tutorials / Articles\n\n1. [Computational Healthcare for reproducible machine learning: building embedding from million inpatient visits](blog/introduction.ipynb)\n \n2. [Analyzing long term outcomes of Ventriculostomy in pediatric patients](blog/ventriculostomy.ipynb)\n\n3. [Exploring OHDSI common data model, comparison with Computational Healthcare (currently writing)](blog/ohdsi.ipynb)\n\n## Issues & Bugs\nTo minimize chances of visit/patient level information leaking via Exceptions messages or Traceback, we have not enabled\nissues on github repo. If you find any bugs, make sure that your bug report/question does not contains any visit or patient\n level information. To file a bug please email us at address provided below.\n\n## Contact\nFor more information, comments or if you plan on citing Computational Healthcare library please contact Akshay Bhat at aub3@cornell.edu.\n \n## Copyright\nCopyright Cornell University 2016; All rights reserved;\nPlease contact us for more information.\n"
 },
 {
  "repo": "microsoft/healthcare-shared-components",
  "language": "C#",
  "readme_contents": "\r\n# Health Care Shared Components\r\n[![Build Status](https://microsofthealthoss.visualstudio.com/SharedComponents/_apis/build/status/CI-Build-OSS?branchName=main)](https://microsofthealthoss.visualstudio.com/SharedComponents/_build/latest?definitionId=83&branchName=main)\r\n\r\nThis repository is a collection of components used by the Microsoft Health Care team which develops services such as\r\nthe [FHIR Server for Azure](https://github.com/microsoft/fhir-server), the [IoMT FHIR Connector for Azure](https://github.com/microsoft/iomt-fhir),\r\nand the [Medical Imaging Server for DICOM](https://github.com/microsoft/dicom-server).\r\n\r\n# Contributing\r\n\r\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\r\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\r\nthe rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\r\n\r\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\r\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\r\nprovided by the bot. You will only need to do this once across all repos using our CLA.\r\n\r\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\r\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\r\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\r\n\r\n# Privacy\r\nMicrosoft values your privacy. See the [Microsoft Privacy Statement](http://go.microsoft.com/fwlink/?LinkId=518021) for more information\r\n"
 },
 {
  "repo": "bluehalo/node-fhir-server-core",
  "language": "JavaScript",
  "readme_contents": "# Asymmetrik FHIR API Server\n\n> A Secure Rest implementation for the [HL7 FHIR Specification](https://www.hl7.org/fhir/). For API documentation, please see [our documents](https://github.com/Asymmetrik/node-fhir-server-core/tree/master/docs).\n\n[![Build Status](https://travis-ci.org/Asymmetrik/node-fhir-server-core.svg?branch=develop)](https://travis-ci.org/Asymmetrik/node-fhir-server-core) [![Known Vulnerabilities](https://snyk.io/test/github/asymmetrik/node-fhir-server-core/badge.svg?targetFile=package.json)](https://snyk.io/test/github/asymmetrik/node-fhir-server-core?targetFile=package.json)\n\nThe Asymmetrik Extensible Server Framework for Healthcare allows organizations to build secure, interoperable solutions that can aggregate and expose healthcare resources via a common HL7\u00ae FHIR\u00ae-compatible REST API. This server framework currently supports **DSTU2** (1.0.2), **STU3** (3.0.1), and **R4** (4.0.0) simultaneously. You can decide to support all three or just one by editing the configuration.\n\nThe framework defines a core server, `node-fhir-server-core`, a simple, secure Node.js module built according to the FHIR specification and compliant with the [US Core](http://www.hl7.org/fhir/us/core/) implementation.\n\nFor an example implementation using MongoDB, please refer to our Github repository that we used for the ONC FHIR Secure API Server Showdown Challenge: [https://github.com/Asymmetrik/node-fhir-server-mongo](https://github.com/Asymmetrik/node-fhir-server-mongo).\n\n<img src=\"https://www.asymmetrik.com/wp-content/uploads/2018/01/FHIR-Server-Architecture_Update.png\" width=\"800\">\n\n## node-fhir-server-core@2.0.0\n\nPlease view the [Migration Guide](https://github.com/Asymmetrik/node-fhir-server-core/blob/master/docs/MIGRATION_2.0.0.md) for version `2.0.0`. We **will absolutely** continue supporting previous versions but **will prioritize** new features going to `2.0.0` unless we receive requests to retrofit them to older versions.\n\n## Prerequisites\n\n[Node.js](https://nodejs.org/en/) version later than `>7.6` is required, **but** you should **NOT** use `8.5` (see [Attention](#attention)). A basic understanding of [promises](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise) and a familiarity of the FHIR specification is not required, but will be very helpful.\n\n## Getting Started\n\nPlease see our [Getting Started](./docs/GettingStarted.md) guide for a walkthrough of how to set up our FHIR server.\n\n## Frequently Asked Questions\n\n- [What configurations does `FHIRServer.initialize()` accept?](./docs/ServerConfiguration.md)\n- [How do I configure a \"profile\"?](./docs/ConfiguringProfiles.md)\n- [Can I add more loggers or customize how the logger works?](./docs/CustomizeLogging.md)\n- [How do I customize the capability statement?](./docs/CustomCapability.md)\n- [How do I add custom operations?](./docs/CustomOperations.md)\n- [How do I enable/disable/customize access control (authentication)?](./docs/AccessControl.md)\n\n## Philosophy\n\nOur project vision is to build an easy to use FHIR server that supports all resource profiles defined in the [US Core implementation guide](http://www.hl7.org/fhir/us/core/) and is built with security in mind from the ground up. We decided to use a plugin style architecture so implementors could focus on writing queries and not worry about all the other technical difficulties of securing the server. As this project matures, we plan to support more resources, custom extensions, versions, write capabilities, etc.\n\nWe believe in establishing a robust security, especially when it comes to health information. Part of the ONC Secure API Server Challenge was to stand up a server and let penetration testers have a go at it (you can see their results [here](https://github.com/Asymmetrik/node-fhir-server-core/issues?utf8=%E2%9C%93&q=label%3A%22ONC+FHIR+Challenge+Vulnerability%22+)). We are committed to continuing this practice and we will continue fixing any vulnerabilities discovered so we can do our best to make this server as secure as possible. For authentication, we are actively working on methods for simplifying integration with [SMART on FHIR](http://docs.smarthealthit.org/).\n\n## Contributing\n\nPlease see [CONTRIBUTING.md](https://github.com/Asymmetrik/node-fhir-server-core/blob/master/CONTRIBUTING.md) for more details regarding contributing issues or code.\n\n## Questions\n\nIf you are experiencing a bug, please feel free to file an [issue](https://github.com/Asymmetrik/node-fhir-server-core/issues). For general questions, please post them to [StackOverflow](https://stackoverflow.com/) with the tag `node-fhir-server-core` or `javascript-fhir`.\n\n## Attention\n\nThis library makes use of node's path module. This is potentially exploitable in node version `8.5`, see [here](https://nodejs.org/en/blog/vulnerability/september-2017-path-validation/). When deploying this, you need to deploy with a node version later than `>7.6` but **NOT** `8.5`.\n\n## License\n\n`@asymmetrik/node-fhir-server-core` is [MIT licensed](https://github.com/Asymmetrik/node-fhir-server-core/blob/master/LICENSE).\n"
 },
 {
  "repo": "CMSgov/HealthCare.gov-Styleguide",
  "language": "CSS",
  "readme_contents": "**WARNING:** This website is no longer being updated or supported. Please refer to the [CMS Design System](https://design.cms.gov).\n\n# [styleguide.healthcare.gov](https://styleguide.healthcare.gov)\n\nTo get started with the HealthCare.gov assets library, you\u2019ll need to use the required HTML, grid system framework, JavaScript, and CSS.\n\nMore detail info can be found at [styleguide.healthcare.gov](https://styleguide.healthcare.gov)\n\n## Table of contents\n\n- [Quick start](#quick-start)\n- [What's included](#whats-included)\n- [Bugs and feature requests](#bugs-and-feature-requests)\n- [Documentation](#documentation)\n- [Running documentation locally](#running-documentation-locally)\n- [Contributing](#contributing)\n- [Copyright and license](#copyright-and-license)\n\n## Quick start\n\nA couple of quick start options are available:\n\n- [Download the latest release](https://github.com/CMSgov/HealthCare.gov-Styleguide/archive/master.zip).\n- Clone the repo: `git clone https://github.com/CMSgov/HealthCare.gov-Styleguide.git`.\n\nRead the [Assets landing page](https://styleguide.healthcare.gov/assets/) for information on the framework contents, templates and examples, and more.\n\n### What's included\n\nWithin the download you'll find the following directories and files, logically grouping common assets. You'll see something like this:\n\n```\nassets-components/\n\u251c\u2500\u2500 css/\n\u2502   \u251c\u2500\u2500 bootstrap/\n\u2502   \u251c\u2500\u2500 cards/\n\u2502   \u251c\u2500\u2500 components/\n\u2502   \u251c\u2500\u2500 forms/\n\u2502   \u251c\u2500\u2500 layouts/\n\u2502   \u251c\u2500\u2500 all.less\n\u2502   \u2514\u2500\u2500 style.css\n\u2514\u2500\u2500 fonts/\n    \u251c\u2500\u2500 Bitter-Bold.eot\n    \u251c\u2500\u2500 Bitter-Italic.eot\n    \u251c\u2500\u2500 Bitter-Regular.eot\n    \u251c\u2500\u2500 glyphicons-halflings-regular.eot\n    \u251c\u2500\u2500 OpenSans-Bold-webfont.eot\n    \u251c\u2500\u2500 OpenSans-Italic-webfont.eot\n    \u251c\u2500\u2500 OpenSans-Regular-webfont.eot\n    \u2514\u2500\u2500 OpenSans-Semibold-webfont.eot\n```\n\nWe provide compiled CSS (`style.css`), as well as the CSS Less source. Glyphicon fonts are also included. Since this styleguide's functionality is built directly on top of Bootstrap, you will need to include references to our jQuery and Bootstrap code bases in your html file:\n\n- `https://assets.healthcare.gov/resources/libs/jquery/1.11/js/jquery.min.js`\n- `https://assets.healthcare.gov/resources/libs/bootstrap/3.1.1/js/bootstrap.min.js`\n\n**Note**: [Assets.healthcare.gov](https://assets.healthcare.gov) gives you Section 508 compliant, cross-browser compatible UI components that you can use in your accessible web site or web application. Assets is an accessible, responsive, and modern framework.\n\n## Bugs and feature requests\n\nHave a bug to report or a feature to request? Please  read our [contribution policy](https://github.com/CMSgov/HealthCare.gov-Styleguide/blob/master/CONTRIBUTING.md) and search for existing and closed issues. If your problem or idea is not addressed yet, you can [open a new issue](https://github.com/CMSgov/HealthCare.gov-Styleguide/issues/new).\n\n\n## Documentation\n\nHealthCare.gov's Styleguide documentation, included in this repo in the gh-pages branch root directory, is built with [Jekyll](http://jekyllrb.com) and publicly hosted on GitHub Pages at <https://styleguide.healthcare.gov/>. The docs may also be run locally.\n\n### Running documentation locally\n\n1. If necessary, [install Jekyll](http://jekyllrb.com/docs/installation) (requires version 2.5.x).\n  - **Windows users:** Read [this unofficial guide](http://jekyll-windows.juthilo.com/) to get Jekyll up and running without problems.\n2. From the gh-pages branch root directory, run `jekyll serve` in the command line.\n3. Open <http://localhost:9001> in your browser, and you should see the entire Styleguide documentation run locally.\n\n## Contributing\n\nPlease read through our [contribution guidelines](https://github.com/CMSgov/HealthCare.gov-Styleguide/blob/master/CONTRIBUTING.md). Included are directions for opening issues, coding standards, and notes on development.\n\n## Copyright and license\n\nAs a work of the United States Government, this project is in the public domain within the United States.\n\n[Full license can be found here](https://github.com/CMSgov/HealthCare.gov-Styleguide/blob/master/LICENSE.md).\n"
 },
 {
  "repo": "medplum/medplum",
  "language": "TypeScript",
  "readme_contents": "# [Medplum](https://www.medplum.com) &middot; [![GitHub license](https://img.shields.io/badge/license-Apache-blue.svg)](https://github.com/medplum/medplum/blob/main/LICENSE.txt) [![npm version](https://img.shields.io/npm/v/@medplum/core.svg?color=blue)](https://www.npmjs.com/package/@medplum/core) [![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=medplum_medplum&metric=alert_status&token=207c95a43e7519809d6d336d8cc7837d3e057acf)](https://sonarcloud.io/dashboard?id=medplum_medplum) [![Coverage Status](https://coveralls.io/repos/github/medplum/medplum/badge.svg?branch=main)](https://coveralls.io/github/medplum/medplum?branch=main)\n\n![Medplum](packages/docs/static/img/cover.webp)\n\nMedplum is a developer platform that enables flexible and rapid development of healthcare apps.\n\n- **Medplum Auth** - End-to-end identity solution for easy user authentication, sign-in, and permissions using OAuth, OpenID, and SMART-on-FHIR.\n- **Medplum Clinical Data Repository (CDR)** - Backend server that hosts your healthcare data in a secure, compliant, and standards based repository.\n- **Medplum API** - FHIR-based API for sending, receiving, and manipulating data.\n- **Medplum SDK** - Client libraries that simplify the process of interacting with the **Medplum API**.\n- **Medplum App** - Web application where you can view your data, perform basic editing tasks. You can also use the Medplum App to manage basic workflows.\n- **Medplum Bots** - Write and run application logic server-side without needing to set up your own server.\n- **UI Component Library** - React components designed to help you quickly develop custom healthcare applications.\n\n## Docs\n\n- [Contributing](#contributing)\n  - [Ground Rules](#ground-rules)\n  - [Codebase](#codebase)\n    - [Technologies](#technologies)\n    - [Folder Structure](#folder-structure)\n  - [First time setup](#first-time-setup)\n\n## Contributing\n\n**We heartily welcome any and all contributions that match our engineering standards!**\n\nThat being said, this codebase isn't your typical open source project because it's not a library or package with a limited scope -- it's our entire product.\n\n### Ground Rules\n\n#### Contributions and discussion guidelines\n\nBy making a contribution to this project, you are deemed to have accepted the [Developer Certificate of Origin](https://developercertificate.org/) (DCO).\n\nAll conversations and communities on Medplum agree to GitHub's [Community Guidelines](https://help.github.com/en/github/site-policy/github-community-guidelines) and [Acceptable Use Policies](https://help.github.com/en/github/site-policy/github-acceptable-use-policies). This code of conduct also applies to all conversations that happen within our contributor community here on GitHub. We expect discussions in issues and pull requests to stay positive, productive, and respectful. Remember: there are real people on the other side of that screen!\n\n#### Reporting a bug or discussing a feature idea\n\nIf you found a technical bug on Medplum or have ideas for features we should implement, the issue tracker is the best place to share your ideas. Make sure to follow the issue template and you should be golden! ([click here to open a new issue](https://github.com/medplum/medplum/issues/new))\n\n#### Fixing a bug or implementing a new feature\n\nIf you find a bug on Medplum and open a PR that fixes it we'll review it as soon as possible to ensure it matches our engineering standards.\n\nIf you want to implement a new feature, open an issue first to discuss what it'd look like and to ensure it fits in our roadmap and plans for the app.\n\nIf you want to contribute but are unsure to start, we have [a \"good first issue\" label](https://github.com/medplum/medplum/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22) which is applied to newcomer-friendly issues. Take a look at [the full list of good first issues](https://github.com/medplum/medplum/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22) and pick something you like!\n\nWant to fix a bug or implement an agreed-upon feature? Great, jump to the [local setup instructions](#first-time-setup)!\n\n### Codebase\n\n#### Technologies\n\nWith the ground rules out of the way, let's talk about the coarse architecture of this mono repo:\n\n- **Full-stack TypeScript**: We use Node.js to power our servers, and React to power our frontend apps. Almost all of the code you'll touch in this codebase will be TypeScript.\n\nHere is a list of all the big technologies we use:\n\n- **PostgreSQL**: Data storage\n- **Redis**: Background jobs and caching\n- **Express**: API server\n- **TypeScript**: Type-safe JavaScript\n- **React**: Frontend React app\n\n#### Folder structure\n\n```sh\nmedplum/\n\u251c\u2500\u2500 packages\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 app          # Frontend web app\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 bot-layer    # AWS Lambda Layer for Bots\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 cdk          # AWS CDK infra as code\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 cli          # Command line interface\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 core         # Core shared library\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 definitions  # Data definitions\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 docs         # Documentation\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 examples     # Example code used in documentation\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 fhir-router  # FHIR URL router\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 fhirtypes    # FHIR TypeScript definitions\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 generator    # Code generator utilities\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 graphiql     # Preconfigured GraphiQL\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 mock         # Mock FHIR data for testing\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 react        # React component library\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 server       # Backend API server\n\u2514\u2500\u2500 scripts          # Helper bash scripts\n```\n\n### First time setup\n\nSee developer setup documentation: https://www.medplum.com/docs/contributing\n\n## License\n\n[Apache 2.0](LICENSE.txt)\n\nCopyright &copy; Medplum 2023\n\nFHIR&reg; is a registered trademark of HL7.\n\nSNOMED&reg; is a registered trademark of the International Health Terminology Standards Development Organisation.\n\nLOINC&reg; is a registered trademark of Regenstrief Institute, Inc.\n\nDICOM&reg; is the registered trademark of the National Electrical Manufacturers Association (NEMA).\n"
 },
 {
  "repo": "nickls/awesome-healthcare-datasets",
  "language": null,
  "readme_contents": "# Awesome Healthcare Datasets\nA curated list of awesome healthcare datasets in the public domain.\n\n\n## Contents\n- [Provider Data](#provider-data)\n- [Electronic Health Record Systems](#eletronic-health-record-systems)\n- [Drugs](#drugs)\n- [Medicare Advantage Plans](#medicare-advantage-plans)\n\n- - -\n\n## Provider Data\n* [National Provider Identifier](http://download.cms.gov/nppes/NPI_Files.html) - gives a unique ID for all health care providers and organizations in the US. - [ZIP (578M)](http://download.cms.gov/nppes/NPPES_Data_Dissemination_June_2016.zip)\n  * Provider Details (name, credentials, gender, etc.)\n  * Organizations Details (name, type, etc.)\n  * Practice Address\n  * Speciality / Healthcare Taxonomy\n  * State License\n* [List of Excluded Individuals and Entities](http://oig.hhs.gov/exclusions/exclusions_list.asp) - the list you do not want to be on, excluded from all Federally funded health care programs - [ZIP (11M)](http://oig.hhs.gov/exclusions/downloadables/UPDATED.csv)\n  * Provider Details (NPI, etc)\n  * Exclusion Details\n* [Physician Compare](https://data.medicare.gov/data/physician-compare) - gives education and affiliation details for providers - [CSV (196M)](https://data.medicare.gov/api/views/s63f-csi6/rows.csv?accessType=DOWNLOAD)\n  * Provider Details (NPI, name, credentials, gender, etc.)\n  * Credentials (Medical School, Year attended, Speciality)\n  * Group Practices (legal name, PAC ID, address, etc.)\n* [Medicare Utilization](https://www.cms.gov/Research-Statistics-Data-and-Systems/Statistics-Trends-and-Reports/Medicare-Provider-Charge-Data/Physician-and-Other-Supplier.html) - Medicare Provider Utilization and Payment Data - lists procedures and payments for individual providers -  [ZIP (1.9G)](http://download.cms.gov/Research-Statistics-Data-and-Systems/Statistics-Trends-and-Reports/Medicare-Provider-Charge-Data/Downloads/Medicare_Provider_Util_Payment_PUF_CY2014.zip)\n  * Provider Details (NPI, name, credentials, gender, etc.)\n  * Procedure Code (HCPCS)\n  * Procedure Description\n  * Number of procedures\n  * Reimbursement Details\n* [Open Payments](https://www.cms.gov/OpenPayments/Explore-the-Data/Dataset-Downloads.html) - Direct and indirect payments to Physicians by device and drug manufacturers\n  * Provider Details (name, id, etc.)\n  * Manufacturer Details (name, id)\n  * Product Details (drug or device name)\n  * Payment details (type, dollar value, etc)\n* [Physician Referral](https://questions.cms.gov/faq.php?faqId=7977) - Referrals of medicare beneficiaries between providers\n  * Initial NPI\n  * Secondary NPI\n  * Share Count & unique beneficiary count\n\n<!-- ## Hospital Data\n* [Hospital Compare](https://data.medicare.gov/data/hospital-compare) -  -->\n\n\n## Electronic Health Record Systems\n* [EHR Attestation Program](http://dashboard.healthit.gov/datadashboard/documentation/ehr-products-mu-attestation-data-documentation.php) - Meaningful Use EHR Attestation Data -- [CSV  (234M)](http://dashboard.healthit.gov/datadashboard/data/MU_REPORT.csv)\n  * Certification IDs\n  * Vendor and Product Name\n  * Usage Details (State, Provider Type, Specialty, NPI, etc.)  \n* [Certified Health IT Product List](http://oncchpl.force.com/ehrcert) - certification details for EHRs - [XSL (7M)](http://oncchpl.force.com/ehrcert/DownloadReport)\n  * Product Details\n  * Certification Criteria\n  * Clinical Quality Measures\n\n## Drugs\n* [FAERS Data Files](http://www.fda.gov/Drugs/GuidanceComplianceRegulatoryInformation/Surveillance/AdverseDrugEffects/ucm082193.htm) - FDA Adverse Event Reporting System (FAERS) Data Files - [XML (73M)](http://www.fda.gov/downloads/Drugs/GuidanceComplianceRegulatoryInformation/Surveillance/UCM477218.zip)\n* [Drug Code Directory](http://www.fda.gov/Drugs/InformationOnDrugs/ucm142438.htm) - Drug name, dosage, code and label details, for all drugs - [ZIP (19M)](http://www.accessdata.fda.gov/cder/ndc.zip)  \n* [Pill Identification](https://pillbox.nlm.nih.gov/developer.html#data) - pill names, images, shapes and imprints - [TAB (40M)](https://pillbox.nlm.nih.gov/downloads/pillbox_engine_20150511.tab)\n\n\n## Medicare Advantage\n* [MA Plan Directory](https://www.cms.gov/Research-Statistics-Data-and-Systems/Statistics-Trends-and-Reports/MCRAdvPartDEnrolData/MA-Plan-Directory.html) - Listing of all Medicare Advantage companies and contracts - [ZIP (190K)](https://www.cms.gov/Research-Statistics-Data-and-Systems/Statistics-Trends-and-Reports/MCRAdvPartDEnrolData/Downloads/MA-Plan-Directory.zip)\n\n\n\n- - -\n\nTodo:\n* Hospital Data\n* ACOs\n* Medicaid Managed Care\n* Clinical Trials dataset\n* Health Exchange Data (https://www.healthcare.gov/health-and-dental-plan-datasets-for-researchers-and-issuers/)\n* National Electronic Injury Surveillance System (NEISS)\nhttp://www.cpsc.gov/en/Research--Statistics/NEISS-Injury-Data/\n\nInspiration From:\n* [Awesome Python](https://github.com/vinta/awesome-python)\n* [Awesome Public Datasets](https://github.com/caesar0301/awesome-public-datasets)\n* [Meta Awesome](https://github.com/sindresorhus/awesome)\n"
 },
 {
  "repo": "Conservatory/healthcare.gov-2013-10-01",
  "language": "CSS",
  "readme_contents": "# Restored HealthCare.gov repository from 1 Oct 2013.\n\nThis repository originally lived at [github.com/CMSgov/healthcare.gov](https://github.com/CMSgov/healthcare.gov), but apparently disappeared from there sometime on 12 Oct 2013.  There is [reason to believe](http://www.wired.com/wiredenterprise/2013/10/obamacare-github/) that the repository's owners pulled it down mainly because they didn't want to handle misdirected bug reports being filed against it -- bug reports that were really about the back-end systems that this code merely interfaced with but had no control over.\n\n(There was also a problem with the original repository's commit history.  The repository as originally posted -- i.e., what this is a clone of -- contained only one commit, a \"top-skim\" style import of the code, and was thus missing the true commit history.  An issue [had been opened](https://www.google.com/search?q=%22benbalter%22+healthcare.gov+%22contributor+information%22+%22commit+history%22) against it, asking for the problem to be fixed, but the repository was taken down before that had a chance to be addressed.)\n\nA possibly better course would have been for them to [rename](https://help.github.com/articles/renaming-a-repository) the repository to \"healthcare.gov-web-front-end\" or something like that, and update the README.md file to prominently state which kinds of bug reports would be appropriate to file there and which wouldn't.  I hope that after the brouhaha dies down, the repository is restored, with properly historicized commit history.\n\nIn the meantime, the repository's disappearance was widely noticed.  Lauren C. Still saw a [tweet](https://twitter.com/kfogel/status/389134395694526464) of mine asking about it, and [replied](https://twitter.com/laurencstill/status/389181641689534464) that there was a git bundle at [archive.org/details/healthcare-gov-gitrepo](https://archive.org/details/healthcare-gov-gitrepo) preserving this repository as of 1 Oct 2013.  That's what's imported here.  The contents of the original README.md follow.\n\n-Karl Fogel (@kfogel), for the [Conservatory](http://conservatory.github.io/)\n\n--------------------------------------------------------------------------\n# HealthCare.gov-Open-Source-Release\n\nThis project includes the source code and content for the healthcare.gov website. For more information, please visit https://www.healthcare.gov/developers\n\n## Local Installation Requirements\n\n- Linux, Unix, Windows or Mac OS X\n- [Ruby](http://www.ruby-lang.org/en/downloads/)\n- [RubyGems](http://rubygems.org/pages/download)\n- [Jekyll](http://jekyllrb.com)\n\n\n## Ruby\n\n### To install ruby on unix:\n\n`yum install ruby` (or `sudo apt-get install ruby1.9.1`)\n\n\n### To install ruby on Mac OS X:\n\n`curl -L https://get.rvm.io | bash -s stable --ruby`\n\nVisit the following links for more detailed information on how to set up Ruby using a method applicable to your environment:\n\nThree Ways of Installing Ruby (Linux/Unix)\nhttp://www.ruby-lang.org/en/downloads/\n \nRubyInstaller for Windows\nhttp://rubyinstaller.org/\n\nHow to Install Ruby on a Mac\nhttp://net.tutsplus.com/tutorials/ruby/how-to-install-ruby-on-a-mac/\n\n\n## Install rubygems: \n\n- `cd ~/`\n- `wget http://production.cf.rubygems.org/rubygems/rubygems-1.8.24.tgz`\n- `tar xzvf rubygems-1.8.24.tgz`\n- `cd rubygems-1.8.24`\n- `ruby setup.rb`\n\n\n## Managing Dependencies Using Bundler\n\nWe recommend using Bundler to manage dependencies. Once you have Ruby installed, install Bundler by running the following command: 'gem install bundler'\n\nOnce Bundler is installed, you install/update depencies by simply running 'bundle install' within your project folder.\n\nMore information on Bundler may be found here: http://gembundler.com/\n\n\n## Install Jekyll\n\n- `cd healthcare.gov` (or the location of your cloned repository)\n- `bundle install`\n\nFor more information and detailed documentation on Jekyll, visit the following sites:\n\nJekyll Project Home\nhttp://jekyllrb.com\n\nJekyll on GitHub\nhttps://github.com/mojombo/jekyll\n\n\n## Clone the repository\n\n- `cd /var/www/html` (or the location you would like the compiled site to live)\n- `git clone https://github.com/CMSgov/HealthCare.gov-Open-Source-Release.git healthcare.gov`\n\n\n## Generate the site and serve\n\n- `jekyll serve`\n- Browse to [localhost:4000](http://localhost:4000) to view the site"
 }
]