,repo,language,readme_contents
0,Project-MONAI/MONAI,Python,"<p align=""center"">
  <img src=""https://raw.githubusercontent.com/Project-MONAI/MONAI/dev/docs/images/MONAI-logo-color.png"" width=""50%"" alt='project-monai'>
</p>

**M**edical **O**pen **N**etwork for **AI**

![Supported Python versions](https://raw.githubusercontent.com/Project-MONAI/MONAI/dev/docs/images/python.svg)
[![License](https://img.shields.io/badge/license-Apache%202.0-green.svg)](https://opensource.org/licenses/Apache-2.0)
[![PyPI version](https://badge.fury.io/py/monai.svg)](https://badge.fury.io/py/monai)
[![docker](https://img.shields.io/badge/docker-pull-green.svg?logo=docker&logoColor=white)](https://hub.docker.com/r/projectmonai/monai)
[![conda](https://img.shields.io/conda/vn/conda-forge/monai?color=green)](https://anaconda.org/conda-forge/monai)

[![premerge](https://github.com/Project-MONAI/MONAI/actions/workflows/pythonapp.yml/badge.svg?branch=dev)](https://github.com/Project-MONAI/MONAI/actions/workflows/pythonapp.yml)
[![postmerge](https://img.shields.io/github/checks-status/project-monai/monai/dev?label=postmerge)](https://github.com/Project-MONAI/MONAI/actions?query=branch%3Adev)
[![docker](https://github.com/Project-MONAI/MONAI/actions/workflows/docker.yml/badge.svg?branch=dev)](https://github.com/Project-MONAI/MONAI/actions/workflows/docker.yml)
[![Documentation Status](https://readthedocs.org/projects/monai/badge/?version=latest)](https://docs.monai.io/en/latest/)
[![codecov](https://codecov.io/gh/Project-MONAI/MONAI/branch/dev/graph/badge.svg?token=6FTC7U1JJ4)](https://codecov.io/gh/Project-MONAI/MONAI)

MONAI is a [PyTorch](https://pytorch.org/)-based, [open-source](https://github.com/Project-MONAI/MONAI/blob/dev/LICENSE) framework for deep learning in healthcare imaging, part of [PyTorch Ecosystem](https://pytorch.org/ecosystem/).
Its ambitions are:
- developing a community of academic, industrial and clinical researchers collaborating on a common foundation;
- creating state-of-the-art, end-to-end training workflows for healthcare imaging;
- providing researchers with the optimized and standardized way to create and evaluate deep learning models.


## Features
> _Please see [the technical highlights](https://docs.monai.io/en/latest/highlights.html) and [What's New](https://docs.monai.io/en/latest/whatsnew.html) of the milestone releases._

- flexible pre-processing for multi-dimensional medical imaging data;
- compositional & portable APIs for ease of integration in existing workflows;
- domain-specific implementations for networks, losses, evaluation metrics and more;
- customizable design for varying user expertise;
- multi-GPU multi-node data parallelism support.


## Installation

To install [the current release](https://pypi.org/project/monai/), you can simply run:

```bash
pip install monai
```

Please refer to [the installation guide](https://docs.monai.io/en/latest/installation.html) for other installation options.

## Getting Started

[MedNIST demo](https://colab.research.google.com/drive/1wy8XUSnNWlhDNazFdvGBHLfdkGvOHBKe) and [MONAI for PyTorch Users](https://colab.research.google.com/drive/1boqy7ENpKrqaJoxFlbHIBnIODAs1Ih1T) are available on Colab.

Examples and notebook tutorials are located at [Project-MONAI/tutorials](https://github.com/Project-MONAI/tutorials).

Technical documentation is available at [docs.monai.io](https://docs.monai.io).

## Citation

If you have used MONAI in your research, please cite us! The citation can be exported from: https://arxiv.org/abs/2211.02701.

## Model Zoo
[The MONAI Model Zoo](https://github.com/Project-MONAI/model-zoo) is a place for researchers and data scientists to share the latest and great models from the community.
Utilizing [the MONAI Bundle format](https://docs.monai.io/en/latest/bundle_intro.html) makes it easy to [get started](https://github.com/Project-MONAI/tutorials/tree/main/model_zoo) building workflows with MONAI.

## Contributing
For guidance on making a contribution to MONAI, see the [contributing guidelines](https://github.com/Project-MONAI/MONAI/blob/dev/CONTRIBUTING.md).

## Community
Join the conversation on Twitter [@ProjectMONAI](https://twitter.com/ProjectMONAI) or join our [Slack channel](https://forms.gle/QTxJq3hFictp31UM9).

Ask and answer questions over on [MONAI's GitHub Discussions tab](https://github.com/Project-MONAI/MONAI/discussions).

## Links
- Website: https://monai.io/
- API documentation (milestone): https://docs.monai.io/
- API documentation (latest dev): https://docs.monai.io/en/latest/
- Code: https://github.com/Project-MONAI/MONAI
- Project tracker: https://github.com/Project-MONAI/MONAI/projects
- Issue tracker: https://github.com/Project-MONAI/MONAI/issues
- Wiki: https://github.com/Project-MONAI/MONAI/wiki
- Test status: https://github.com/Project-MONAI/MONAI/actions
- PyPI package: https://pypi.org/project/monai/
- conda-forge: https://anaconda.org/conda-forge/monai
- Weekly previews: https://pypi.org/project/monai-weekly/
- Docker Hub: https://hub.docker.com/r/projectmonai/monai
"
1,GoogleCloudPlatform/healthcare,Jupyter Notebook,"# Cloud Healthcare

This respository contains utilities used for Cloud Healthcare applications.
"
2,kakoni/awesome-healthcare,,"# Awesome Health [![Awesome](https://cdn.jsdelivr.net/gh/sindresorhus/awesome@d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)

Curated list of awesome open source healthcare software, libraries, tools and resources. Each link has been vetted to ensure the project is active and provides value to healthcare facilities, providers, developers, policy experts, and/or research scientists.

## Contents

- [EHR](#ehr)
- [Specifications](#specifications)
- [Prescribing](#prescribing)
- [Nursing](#nursing)
- [Imaging](#imaging)
- [Dental](#dental)
- [Laboratory](#laboratory)
- [Libraries](#libraries)
- [Frameworks](#frameworks)
- [Applications](#applications)
- [Personal Health Record](#phr)
- [Integration](#integration)
- [Research](#research)
- [Hardware](#hardware)
- [Bioinformatics](#bioinformatics)
- [Data](#data)
- [Datasets](#datasets)
- [Enterprise Master Patient Index](#empi)
- [Machine Learning](#machine-learning)
- [Compliance](#compliance)
- [Asset Management](#asset-management)
- [Logistics](#logistics)
- [Analytics](#analytics)

### EHR
  * [Bahmni](https://www.bahmni.org) - Electronic Medical Record and hospital system.
  * [Cottage Med](https://cottagemed.org/p/26/Download-Cottage-Med) - Electronic Medical Record software designed by physicians.
  * [GNU Health](https://www.gnuhealth.org) - Electronic Medical Record, Hospital Management, and Health Information System.
  * [GNUmed](https://www.gnumed.de/documentation/) - Electronic Medical Record software.
  * [EHRBase](https://ehrbase.org) OpenEHR Clinical Data Repository.
  * [EHRServer](https://github.com/ppazos/cabolabs-ehrserver) - CaboLabs EHRServer.
  * [ERPNext](https://erpnext.com/open-source-healthcare) - Modules that help manage patients, appointments, consultations, lab tests, and billing.
  * [FreeMedForms EMR](https://freemedforms.com/fr/start) - Electronic Medical Record software.
  * [HospitalRun](https://hospitalrun.io) - Helps provide the most modern Hospital Information System possible to the least resourced environments.
  * [HOSxP](https://hosxp.net/joomla25/) - Thai Hospital Information System that aims to ease the healthcare workflow of health centers and central hospitals.
  * [LibreHealth EHR](https://librehealth.io/projects/lh-ehr/) - Clinically-focused Electronic Health Record System.
  * [MedinTux](https://medintux.org/) - French Medical Practice Management System.
  * [Medplum](https://github.com/medplum/medplum) - Developer platform that enables flexible and rapid development of healthcare apps.
  * [Odoo Medical](https://github.com/OCA/vertical-medical) - Universal Health and Hospital Information System.
  * [OpenClinic](https://github.com/jact/openclinic) - Medical Records System.
  * [OpenEMR](https://www.open-emr.org) - Electronic Health Records and Medical Practice Management application.
  * [OpenEyes](https://openeyes.apperta.org) - Electronic Medical Record application for ophthalmology.
  * [Open Hospital](https://sourceforge.net/projects/openhospital/) - Electronic Medical Record software for underprivileged rural hospitals.
  * [openMAXIMS](https://github.com/IMS-MAXIMS/openMAXIMS) - Full Patient Administration System designed for the NHS.
  * [OpenMRS](https://openmrs.org) - Enterprise Electronic Medical Record System platform.
  * [OSCAR EMR](https://bitbucket.org/oscaremr/oscar) - OSCAR McMaster Project.
  * [Ozone HIS](https://www.ozone-his.com) - The entreprise-grade integrated health information system built with OpenMRS 3
  * [Ripple](https://www.ripple.foundation) -  NHS-funded, community led initiative working towards an integrated Digital Care Record Platform.

### Specifications
  * [FHIR](https://www.hl7.org/fhir/) - Fast Health Interoperability Resources.
  * [OpenEHR](https://www.openehr.org) - Open specification upon which software can be built.
  * [Open mHealth](https://www.openmhealth.org) - Open Standard For Mobile Health Data.
  * [SMART on FHIR](https://docs.smarthealthit.org/) - Open standards based technology platform.
  * [StandardHealthRecord](http://standardhealthrecord.org/) - Open specification for health record format, aiming to be more precise than existing formats.
  * [Continuity of Care Document](https://www.hl7.org/implement/standards/product_brief.cfm?product_id=7) - Continuity of Care Document specifications (free account required).
  * [Continuity of Care Record](httsp://hitsp.org/ConstructSet_Details.aspx?&PrefixAlpha=4&PrefixNumeric=32) - Specifications for the older form of CCD - sometimes called a ""C32"".
  * [HL7 Version 2](https://www.hl7.org/implement/standards/product_brief.cfm?product_id=185) - Specifications for all versions of HL7v2 (free account required).
  * [OHDSI OMOP Common Data Model](https://www.ohdsi.org/data-standardization/) - Standardized data model for many healthcare concepts, awesome Github presence including scripts for many major relational databases.
  * [Standard Health Record Collaborative](http://standardhealthrecord.org/shr/) - High quality, computable source of patient information provided by establishing a single target for health data standardization.
  * [DICOM Standards Browser](https://dicom.innolitics.com/ciods) - Provides an effective way to learn the DICOM standard and inspect DICOM attributes.
  
### Prescribing
  * [OpenEP](https://github.com/ehrscape/examples/tree/master/openep) - Suite of medicines management apps that improve the safety and efficiency of prescribing and medicines management.

### Nursing
  * [open-eObs](https://openeobs.github.io/) - Observation and clinical assessment platform that offers a real-time view of all patients across a ward.

### Imaging
  * [3D Slicer](https://www.slicer.org) - Cross-platform application for analyzing, visualizing and understanding medical image data.
  * [Cornerstone](https://github.com/cornerstonejs/cornerstone) - Open source project with a goal to deliver a complete web based medical imaging platform.
  * [dcm4che](https://www.dcm4che.org/) - Clinical Image and Object Management.
  * [Dicoogle](https://github.com/bioinformatics-ua/dicoogle) - Dicoogle is an extensible, platform-independent and open-source PACS
  * [Drishti](https://github.com/nci/drishti/wiki) - Tomography and electron-microscopy data visualizer for both scientists and lay people.
  * [DICOMcloud](https://github.com/DICOMcloud/DICOMcloud) - A standalone DICOMweb server with RESTful implementation of the DICOMweb/WADO services.
  * [DICOM Server](https://github.com/microsoft/dicom-server) - OSS Implementation of DICOMweb standard.
  * [DICOM Web Viewer](https://ivmartel.github.io/dwv/) - JavaScript/HTML5-based DICOM viewer with standard tools and a focus on supporting various screen sizes.
  * [Fiji](https://imagej.net/software/fiji/) - Open-source platform for biological-image analysis.
  * [Horos](https://horosproject.org) - Medical image viewer.
  * [InVesalius](https://invesalius.github.io) - Open source software for reconstruction of computed tomography and magnetic ressonance images.
  * [ITK](https://itk.org/) - Toolkit used for the development of image segmentation and image registration programs with leading-edge algorithms in 2 and 3 dimensions.
  * [ITK-SNAP](http://www.itksnap.org/pmwiki/pmwiki.php) - Interactive software for 3 dimensional image navigation, annotation, and automatic segmentation with an emphasis on user-friendliness.
  * [LibreHealth Radiology](https://librehealth.io/projects/lh-radiology/) - Customized version of LibreHealth Toolkit with additional tools for radiology and imaging professionals.
  * [Kaapana](https://github.com/kaapana/kaapana) - Open source toolkit for state of the art platform provisioning in the field of medical data analysis.
  * [Kheops](https://kheops.online) - Open source platform for sharing medical images
  * [OHIF](https://github.com/OHIF/Viewers) - OHIF zero-footprint DICOM viewer and oncology specific Lesion Tracker.
  * [Omero](https://github.com/ome/openmicroscopy) - open source client/server system written in Java for visualizing, managing, and annotating microscope images and metadata
  * [OpenREM](https://openrem.org/) - Radiation Exposure Monitoring for physicists.
  * [OpenSlide](https://github.com/openslide/openslide) - is a C library for reading whole slide image files.
  * [Orthanc](https://www.orthanc-server.com) - Lightweight DICOM server for healthcare and medical research.
  * [Papaya](https://github.com/rii-mango/Papaya) - Pure JavaScript medical research image viewer.
  * [Slim](https://github.com/ImagingDataCommons/slim) - Interoperable web viewer and annotation tool for computational pathology.
  * [Viv](https://github.com/hms-dbmi/viv) - multiscale visualization of high-resolution multiplexed bioimaging data on the web.
  * [VTK](https://vtk.org) - 3 dimensional visualization toolkit supporting a variety of algorithms and modeling techniques.

### Dental
  * [Open Dental](https://www.opendental.com) - Dental Practice Management Software.
  * [OpenMolar](https://openmolar.com/) - Dental Practice Management Software. 

### Laboratory
  * [OpenELIS](https://sites.google.com/site/openelisglobal/) - Laboratory Information System for Global Health.
  * [SENAITE](https://www.senaite.com) - Laboratory Information Management System.

### Frameworks
  * [API Server](https://github.com/smart-on-fhir/api-server) - FHIR Server to support patient- and clinician-facing apps.
  * [Blaze](https://github.com/samply/blaze) - A FHIR Store with internal, fast CQL Evaluation Engine
  * [CareKit](https://github.com/carekit-apple/CareKit/) - Open source software framework for creating apps that help people better understand and manage their health.
  * [Clinical Meteor project](https://github.com/clinical-meteor) - Meteor for FDA, HIPAA, and HL7 compliant applications.
  * [Clinical Quality Language](https://github.com/cqframework/clinical_quality_language) - Clinical Quality Language is a HL7 standard for the expression of clinical knowledge.
  * [FHIRBase](https://fhirbase.github.io) - Storage based on the FHIR Standard.
  * [FHIR Proxy](https://github.com/microsoft/fhir-proxy) - secure application that acts as an intermediary in the transfer of FHIR data to and from Azure API.
  * [FHIR Works on AWS](https://github.com/awslabs/fhir-works-on-aws-deployment) - FHIR Works on AWS deployment.
  * [FHIR Server for Azure](https://github.com/Microsoft/fhir-server) - A .NET Core implementation of the FHIR standard.
  * [Intervention Engine FHIR Server](https://github.com/intervention-engine/fhir) - Generic FHIR server implementation in GoLang.
  * [LinuxForHealth FHIR Server](https://github.com/LinuxForHealth/FHIR) - Modular Java implementation of version 4 of the HL7 FHIR specification.
  * [Medblocks UI](https://github.com/medblocks/medblocks-ui) - Web Components for rapid development of openEHR and FHIR systems.
  * [Opal](https://opal.openhealthcare.org.uk/) - Framework for building clinical applications.
  * [ResearchKit](https://github.com/ResearchKit/ResearchKit) - Software framework that makes it easy to create apps for medical research or for other research projects.
  * [Spark](https://github.com/FirelyTeam/spark) - Public domain FHIR server developed in C#.
  * [Sushi](https://github.com/FHIR/sushi) - a reference implementation command-line interpreter/compiler for FHIR
  * [Swift-SMART](https://github.com/smart-on-fhir/Swift-SMART) - Swift SMART on FHIR framework for iOS and OS X.

### Libraries
  * [Android FHIR SDK](https://github.com/google/android-fhir) - The Android FHIR SDK 
  * [Archie](https://github.com/openehr/archie) - OpenEHR Library written in Java.
  * [Asymmetrik FHIR API Server](https://github.com/bluehalo/node-fhir-server-core) - A secure REST implementation for the HL7 FHIR Specification.
  * [Datamol](https://github.com/datamol-io/datamol) - Molecular Manipulation Made Easy. A light Python wrapper build on top of RDKit.
  * [DCMTK](https://dicom.offis.de/dcmtk.php.en) - DICOM Toolkit.
  * [dicom](https://github.com/suyashkumar/dicom) - High Performance DICOM Medical Image Parser in GoLang.
  * [ehrapy](https://github.com/theislab/ehrapy/) - Electronic Health Record analysis in Python.
  * [Evil-DICOM](https://github.com/rexcardan/Evil-DICOM) - C# DICOM Library.
  * [Fellow Oak DICOM](https://github.com/fo-dicom/fo-dicom) - DICOM for .NET, .NET Core, Universal Windows, Android, iOS, Mono, and Unity.
  * [FHIRKit Client](https://github.com/Vermonster/fhir-kit-client) - Node FHIR client library.
  * [FHIRModels](https://github.com/apple/FHIRModels) - FHIRModels is a Swift library for FHIR resource data models.
  * [FHIR .NET API](https://github.com/FirelyTeam/firely-net-sdk) - The official .NET API for HL7 FHIR.
  * [fhir.js](https://github.com/FHIR/fhir.js) - JavaScript client for FHIR.
  * [FHIR protocol buffers](https://github.com/google/fhir) - A Google implementation of protocol buffers for FHIR.
  * [Graphir](https://github.com/microsoft/graphir) - GraphQL interface over FHIR API
  * [HAPI FHIR](https://github.com/hapifhir/hapi-fhir) - Java API for HL7 FHIR Clients and Servers.
  * [Hearth](https://github.com/jembi/hearth) - A fast FHIR-compliant server focused on longitudinal data stores.
  * [Health data standards](https://github.com/projectcypress/health-data-standards) - Ruby library for generating and consuming various healthcare related formats. These include HITSP C32, QRDA Category I, and QRDA Category III.
  * [Hermes](https://github.com/wardle/hermes) - a SNOMED CT terminology server. 
  * [MITK](https://www.mitk.org/wiki/The_Medical_Imaging_Interaction_Toolkit_(MITK)) - The Medical Imaging Interaction Toolkit.
  * [Node HL7](https://github.com/MatthewVita/node-hl7-complete) - Node module that is bridged with the Java Hapi HL7 library.
  * [Node-hl7-parser](https://github.com/RedoxEngine/redox-hl7-v2) - Open source version of Redox's HL7 v2 to schema-fied JSON parser.
  * [php-fhir](https://github.com/dcarbone/php-fhir) - Tools for creating PHP classes from the HL7 FHIR Specification.
  * [pynetdicom](https://github.com/pydicom/pynetdicom) - A Python implementation of the DICOM networking protocol.
  * [Python HL7](https://github.com/johnpaulett/python-hl7) - Simple library for parsing messages of HL7 version 2.x into Python objects.
  * [Python SMART on FHIR client](https://github.com/smart-on-fhir/client-py) - Flexible Python client for FHIR servers supporting the SMART on FHIR protocol.
  * [Python 835 Parser](https://github.com/keironstoddart/edi-835-parser) - A simple-to-use Python interface to EDI 835 Health Care Claim Payment and Remittance Advice files.
  * [Ruby FHIR](https://github.com/fhir-crucible/fhir_client) - FHIR client implementation in Ruby.
  * [Ruby HL7](https://github.com/segfault/ruby-hl7) - Ruby HL7 library.
  * [Rust FHIR](https://github.com/itsbalamurali/rust-fhir) - Rust SDK for HL7 FHIR
  * [TorchXRayVision](https://github.com/mlmed/torchxrayvision) - A library for chest X-ray datasets and models. Including pre-trained models.
  * [Z-Anatomy](https://www.z-anatomy.com) - The libre atlas of anatomy

### Applications
  * [Intervention Engine](https://github.com/intervention-engine/ie) - Provides a web-application for data-driven team huddles.
  * [SMART Pediatric Growth Chart](https://github.com/smart-on-fhir/growth-chart-app) - Pediatric growth charts.

### PHR
  * [Tidepool](https://github.com/tidepool-org) - Data platform to reduce the burden of Type 1 Diabetes.
  * [HealthLocker](https://github.com/healthlocker/healthlocker) - Elixir-based personal health record.

### Research
  * [i2b2](https://www.i2b2.org) - Research data warehouse.
  * [LabKey Server](https://www.labkey.org) - Platform for Translational Research.

### Integration
  * [FHIR Converter](https://github.com/microsoft/FHIR-Converter) - an open source project that enables conversion of health data from legacy formats to FHIR.
  * [Google HCLS Data Harmonization](https://github.com/GoogleCloudPlatform/healthcare-data-harmonization) - an engine that converts data of one structure to another
  * [NextGen Connect Integration Engine](https://github.com/nextgenhealthcare/connect) - The swiss army knife of healthcare integration.
  * [Open eHealth Integration Platform](https://github.com/oehf/ipf) - An extension of the Apache Camel routing and mediation engine
  * [OpenHIM](http://openhim.org/) - Health information mediator.
  * [Zato](https://zato.io/en/industry/healthcare/index.html) - A Python-based ESB and integration platform for healthcare interoperability, automation and orchestration.

### Hardware
  * [echOpen](https://www.echopen.org) - Low-cost (affordable) echo-stethoscope.
  * [Gluco](https://github.com/nebulabio/gluco) - Glucometer.
  * [Murgen](https://hackaday.io/project/9281-murgen-open-source-ultrasound-imaging) - Ultrasound imaging development kit.
  * [OpenAPS](https://openaps.org/) - The Open Artificial Pancreas System project is an open and transparent effort to make safe and effective basic Artificial Pancreas System.

### Bioinformatics
  * [ADAM](https://github.com/bigdatagenomics/adam) - Genomics analysis platform.
  * [Bcbio](https://github.com/bcbio/bcbio-nextgen) - Validated, scalable, community developed variant calling, RNA-seq and small RNA analysis.
  * [Galaxy](https://galaxyproject.org/) - Open web-based platform for data intensive biomedical research.
  * [Wregex](https://ehubio.ehu.eus/wregex/) - Amino acid motif searching software with optional Position-Specific Scoring Matrix.

### Data
  * [Atlas BI Library](https://github.com/atlas-bi/Library) The unified report library.
  * [Caisis](http://www.caisis.org/) - Oncology research software with a Patient Data Management System.
  * [Cedar](https://github.com/mitre/cedar) - Open source tool for testing the strength of Electronic Clinical Quality Measure.
  * [cTAKES](https://ctakes.apache.org/) - Natural Language Processing System for extraction of information from Electronic Medical Record clinical free-text.
  * [IHRIS](https://www.ihris.org/toolkit-new/) - Health Information System for management of human resources for health.
  * [Inferno](https://github.com/onc-healthit/inferno) - Open source tool that tests whether patients can access their health data through a standard interface.
  * [OpenSAFELY](https://www.opensafely.org) - Secure analytics platform for Electronic Health Records in the NHS.
  * [Snow Owl](https://github.com/b2ihealthcare/snow-owl) - Highly scalable, open source terminology server with revision-control capabilities and collaborative authoring platform features. 
  * [Synthea Patient Generator](https://github.com/synthetichealth/synthea) - Synthetic patient generator that models the medical history of synthetic patients.

### Datasets
  * [Medical Data for Machine Learning](https://github.com/beamandrew/medical-data) - Curated list of medical data for machine learning.

### EMPI
  * [MEDIC Client Registry RI](https://github.com/MohawkMEDIC/client-registry) - The Mohawk College MARC-HI/MEDIC Client Registry EMPI Implementation.
  
### Machine learning
  * [Healthcare.ai](https://healthcare.ai) - Python and R tools for healthcare machine learning.
  * [MONAI](https://github.com/Project-MONAI/MONAI) - AI Toolkit for Healthcare Imaging

### Asset Management
  * [Tapirx](https://github.com/virtalabs/tapirx) - Networked medical device discovery and identification.

### Logistics
  * [ID3C](https://github.com/seattleflu/id3c) - Data logistics system enabling real-time genomic epidemiology.
  * [OpenLMIS](https://openlmis.org) - Open source, web-based, electronic logistics management information system (LMIS) software, purpose-built to manage health commodity supply chains.
"
3,wanghaisheng/healthcaredatastandard,,"healthcaredatastandard
======================


looking for contributor 

请添加我的微信


## 概述

在09年新医改之后，国家层面上对卫生信息标准的重视程度也算是提高了，也有一些不错的进展，整体上还是偏慢，无法满足新形势下的医疗类应用和系统的开发。

目前国家层面上的卫生信息标准体系如下
![](overview.png)

目前已存在的数量  


| 年度  | 计划数 | 实际数 | 发布/报批数 | 送审数 | 正在研制数 |  
| ----  | ---- | ----  | ---- | ----  | ---- |   
2008  |     8  | 10  | 	10  | 	0  | 	0
2009  | 	7  | 	7  | 	7  | 	0  | 	0
2010  | 	8  | 	8  | 	8  | 	0  | 	0
2011  | 	108  | 	129  | 	126  | 	3  | 	0
2012  | 	7  | 	50  | 	49  | 	1  | 	0
2013  | 	22  | 	37  | 	17  | 	13  | 	7
2014  | 	7  | 	7  | 	0  | 	0  | 	7
2015  | 	20  | 	2  | 	0  | 	18  | 	/
2016  | 	13  | 	11  | 	0  | 	2  | 	87
2017  | 	5  | 	0  | 	5  | 	0  | 	18
2018  | 	  | 	  | 	  | 	  | 	  | 
合计| 283  | 	37  | 	5  | 	33  | 	209  | 


## 基础类

| 编号  | 名称 | 
| ----  | ---- | 
| WS/T 303-2009  | 卫生信息数据元标准化规则 | 
|  WS/T 304-2009  | 卫生信息数据模式描述指南 | 
|  WS/T 305-2009  | 卫生信息数据集元数据规范 | 
|  WS/T 306-2009  | 卫生信息数据集分类与编码规则 | 
|  WS/T 370-2012  | 卫生信息基本数据集编制规范 | 
|  WS/T 482-2016  | 卫生信息共享文档编制规范 | 


## 数据类
             
### 数据元

| 编号  | 名称 | 
| ----  | ---- | 
| WS 363-2011  | 卫生信息数据元目录 第1-17部分 | 
| WS 364-2011  | 卫生信息数据元值域代码 第1-17部分 | 

| 标准编号 |   标准中文名称 |  标识符范围 |  数据元数目 | 
| ----  | ---- |  ---- |  ---- | 
| WS363.1-2011| 卫生信息数据元目录第1部分:总则 	| 		| 	| 
| WS363.2-2011| 卫生信息数据元目录第2部分:标识	| DE01.00.001.00-DE01.00.015.00	| 13
| WS363.3-2011| 	卫生信息数据元目录第3部分:人口学及社会经济学特征	| DE02.01.001.00-DE02.01.058.00	| 62
| WS363.4-2011 |  	卫生信息数据元目录第4部分:健康史	| DE02.10.001.00-DE02.10.096.00	| 90
| WS363.5-2011 | 	卫生信息数据元目录第5部分:健康危险因素	| DE03.00.001.00-DE03.00.099.00	| 98
| WS363.6-2011 | 	卫生信息数据元目录第6部分:主诉与症状	| DE04.01.001.00-DE04.01.120.00	| 119
| WS363.7-2011 | 	卫生信息数据元目录第7部分:体格检查	| DE04.10.001.00-DE04.10.243.00	| 241
| WS363.8-2011 | 	卫生信息数据元目录第8部分:临床辅助检查	| DE04.30.001.00-DE04.30.051.00	| 51
| WS363.9-2011 | 	卫生信息数据元目录第9部分:实验室检查	| DE04.50.001.00-DE04.50.129.00	| 129
| WS363.10-2011| 	卫生信息数据元目录第10部分:医学诊断	| DE05.01.001.00-DE05.01.073.00	| 73
| WS363.11-2011	| 卫生信息数据元目录第11部分:医学评估	| DE05.10.001.00-DE05.10.128.00	| 127
| WS363.12-2011	| 卫生信息数据元目录第12部分:计划与干预	| DE06.00.001.00-DE06.00.177.00	| 175
| WS363.13-2011	| 卫生信息数据元目录第13部分:卫生费用	| DE07.00.001.00-DE07.00.010.00	| 10
| WS363.14-2011	| 卫生信息数据元目录第14部分:卫生机构	| DE08.10.001.00-DE08.10.053.00	| 53
| WS363.15-2011	| 卫生信息数据元目录第15部分:卫生人员	| DE08.30.001.00-DE08.30.031.00	| 31
| WS363.16-2011	| 卫生信息数据元目录第16部分:药品、设备与材料	| DE08.50.001.00-DE08.50.025.00	| 25
| WS363.17-2011	| 卫生信息数据元目录第17部分:卫生管理	| DE09.00.001.00-DE09.00.102.00	| 102

### 代码与编码

| 编号  | 名称 | 
| ----  | ---- | 
| WS 364-2011  | 卫生信息数据元值域代码 第1-17部分 | 
| WS xxx-2013  | 卫生统计指标目录 第1-10部分 | 
| GB/T 14396-2016疾病分类与代码  | 疾病分类与代码 | 
| WS 446-2014  |  居民健康档案医学检验项目常用代码 | 
| WS xxx-2013  |  医疗服务项目分类与编码 | 


### 数据集

| 编号  | 名称 | 性质 |  
| ----  | ---- |  ---- |      
| WS 365-2011  | 城乡居民健康档案基本数据集 | 
| WS 371-2012  | 基本信息基本数据集 个人信息 | 
| WS 372-2012  | 疾病管理基本数据集  第1-6部分 | 
| WS 373-2012  | 医疗服务基本数据集 第1-3部分 | 
| WS 374-2012  | 卫生管理基本数据集 第1-4部分 | 
| WS 375-2012  | 疾病控制基本数据集 第1-23部分 | 
| WS 376-2013  | 儿童保健基本数据集 第1-5部分 | 
| WS 377-2013  | 妇女保健基本数据集 第1-7部分 | 
| WS xxx-2013  | 卫生应急管理基本数据集 第1-5部分 | 
| WS 538-2017  | 医学数字影像通信基本数据集 | 强制性卫生行业标准    
| WS 539-2017  | 远程医疗信息基本数据集 | 强制性卫生行业标准     
| WS 540-2017  | 继续医学教育管理基本数据集 | 强制性卫生行业标准     
| WS 541-2017  | 新型农村合作医疗基本数据集 | 强制性卫生行业标准          
| WS 542-2017  | 院前医疗急救基本数据集 | 强制性卫生行业标准          
| WS 537-2017  | 居民健康卡数据集 | 强制性卫生行业标准       
| WS xxx-2013  | 居民健康卡注册管理信息系统基本数据集 | 





| 数据集名称	| 所属类别	| 所属标准编号	| 所属标准名称   |   
| ----  | ---- |  ---- |  ---- |       
| 个人基本信息	| 基本信息	| WS365	| 城乡居民健康档案基本数据集      | 
| 健康体检信息	| 健康体检	| WS365	| 城乡居民健康档案基本数据集      | 
| 新生儿家庭访视信息	| 儿童保健	| WS365	| 城乡居民健康档案基本数据集         | 
| 儿童健康检查信息	| 儿童保健	| WS365	| 城乡居民健康档案基本数据集       | 
| 产前随访服务信息	| 妇女保健	| WS365	| 城乡居民健康档案基本数据集     | 
| 产后访视服务信息	| 妇女保健	| WS365	| 城乡居民健康档案基本数据集      | 
| 产后42天健康体检信息	| 妇女保健	| WS365	| 城乡居民健康档案基本数据集|       
| 预防接种卡信息	| 疾病控制	| WS365	| 城乡居民健康档案基本数据集  |     
| 传染病报告卡信息	| 疾病控制	| WS365	| 城乡居民健康档案基本数据集| 
| 职业病报告卡信息	| 疾病控制	| WS365| 城乡居民健康档案基本数据集       |  
| 食源性疾病报告卡信息	| 疾病控制	| WS365	| 城乡居民健康档案基本数据集 |       
| 高血压患者随访信息	| 疾病管理	| WS365	| 城乡居民健康档案基本数据集 |      
| 2型糖尿病患者随访信息	| 疾病管理	| WS365	| 城乡居民健康档案基本数据集  |      
| 重性精神疾病患者管理信息	| 疾病管理	| WS365	| 城乡居民健康档案基本数据集   |        
| 门诊摘要信息	| 医疗服务	| WS365	| 城乡居民健康档案基本数据集   |    
| 住院摘要信息	| 医疗服务	| WS365	| 城乡居民健康档案基本数据集  |    
| 会诊信息	| 医疗服务	| WS365	| 城乡居民健康档案基本数据集      | 
| 转院(诊)信息	| 医疗服务	| WS365	| 城乡居民健康档案基本数据集  | 

强制性卫生行业标准         
         


| 标准编号 |   标准中文名称 | 数据元数目 | 性质 |  
| ----  | ---- |  ---- | ---- |  
| WS 371-2012 		| 基本信息基本数据集 个人信息		| 68
| WS 376.1-2013		| 儿童保健基本数据集 第1部分 出生医学证明		| 39
| WS 376.2-2013		| 儿童保健基本数据集 第2部分：儿童健康体检		| 61
| WS 376.3-2013		| 儿童保健基本数据集 第3部分：新生儿疾病筛查		| 41
| WS 376.4-2013		| 儿童保健基本数据集 第4部分：体弱儿童管理		| 33
| WS 376.5-2013		| 儿童保健基本数据集 第5部分：5岁以下儿童死亡报告		| 27
| WS 377.1-2013		| 妇女保健基本数据集 第1部分：婚前保健服务		| 122
| WS 377.2-2013		| 妇女保健基本数据集 第2部分 妇女病普查		| 74
| WS 377.3-2013		| 妇女保健基本数据集 第3部分计划生育技术服务		| 131
| WS 377.4-2013		| 妇女保健基本数据集 第4部分孕产期保健服务与高危管理		| 244
| WS 377.5-2013		| 妇女保健基本数据集 第5部分产前筛查与诊断		| 31
| WS 377.6-2013		| 妇女保健基本数据集 第6部分出生缺陷监测		| 48
| WS 377.7-2013		| 妇女保健基本数据集 第7部分孕产妇死亡报告		| 39
| WS 375.1-2012 	| 疾病控制基本数据集 第1部分：艾滋病综合防治		| 71
| WS 375.2-2012 	| 疾病控制基本数据集 第2部分：血吸虫病病人管理		| 115
| WS 375.3-2012		|  疾病控制基本数据集 第3部分：慢性丝虫病病人管理		| 73
| WS 375.4-2012	 	| 疾病控制基本数据集 第4部分：职业病报告		| 63
| WS 375.5-2012	    | 疾病控制基本数据集 第5部分：职业性健康监护		| 261
| WS 375.6-2012 	| 疾病控制基本数据集 第6部分：伤害监测报告		| 41
| WS 375.7-2012 	| 疾病控制基本数据集 第7部分：农药中毒报告		| 33
| WS 375.8-2012 	| 疾病控制基本数据集 第8部分：行为危险因素监测		| 56
| WS 375.9-2012 	| 疾病控制基本数据集 第9部分：死亡医学证明		| 49
| WS 375.10-2012 	| 疾病控制基本数据集 第10部分：传染病报告		| 33
| WS 375.11-2012 	| 疾病控制基本数据集 第11部分：结核病报告		| 78
| WS 375.12-2012 	| 疾病控制基本数据集 第12部分：预防接种		| 42    
| WS 375.13-2017 	| 疾病控制基本数据集 第13部分：职业病危害因素监测 |          
| WS 375.14-2016 	| 疾病控制基本数据集 第14部分：学校缺勤缺课监测报告 |          
| WS 375.15-2016 	| 疾病控制基本数据集 第15部分：托幼机构缺勤监测报告 |          
| WS 375.18-2016 	| 疾病控制基本数据集 第18部分：疑似预防接种异常反应报告 |          
| WS 375.19-2016 	| 疾病控制基本数据集 第19部分：疫苗管理 |        
| WS 375.20-2016 	| 疾病控制基本数据集 第20部分：脑卒中登记报告 |    
| WS 375.21-2016 	| 疾病控制基本数据集 第21部分：脑卒中病人管理 |    
| WS 375.22-2016 	| 疾病控制基本数据集 第22部分：宫颈癌筛查登记 |    
| WS 375.23-2016 	| 疾病控制基本数据集 第23部分：大肠癌筛查登记 |    
| WS 372.1-2012 	| 疾病管理基本数据集 第1部分：乙肝患者管理		| 106
| WS 372.2-2012		| 疾病管理基本数据集 第2部分：高血压患者健康管理	| 106
| WS 372.3-2012 	| 疾病管理基本数据集 第3部分：重性精神疾病患者管理		| 118
| WS 372.4-2012 	| 疾病管理基本数据集 第4部分：老年人健康管理		| 102
| WS 372.5-2012 	| 疾病管理基本数据集 第5部分：2型糖尿病患者健康管理		| 113
| WS 372.6-2012 	| 疾病管理基本数据集 第6部分：肿瘤病例管理		| 72
| WS 373.1-2012 	| 医疗服务基本数据集 第1部分：门诊摘要		| 62
| WS 373.2-2012 	| 医疗服务基本数据集 第2部分：住院摘要		| 72
| WS 373.3-2012	   | 医疗服务基本数据集 第3部分：成人健康体检		| 182
| WS 374.1-2012 		| 卫生管理基本数据集 第1部分：卫生监督检查与行政处罚		| 62
| WS 374.2-2012 		| 卫生管理基本数据集 第2部分：卫生监督行政许可与登记		|92
| WS 374.3-2012 		| 卫生管理基本数据集 第3部分：卫生监督监测与评价		|22
| WS 374.4-2012 		| 卫生管理基本数据集 第4部分：卫生监督机构与人员		|105




| 标准编号 |   标准中文名称 | 数据元数目 | 性质 | 
| ----  | ---- |  ---- | ---- |     
| WS 445.1-2014 		| 电子病历基本数据集 第1部分：病历概要  		|  xx               
| WS 445.2-2014 		| 电子病历基本数据集 第2部分：门（急）诊病历  		|  xx               
| WS 445.3-2014 		| 电子病历基本数据集 第3部分：门（急）诊处方  		|  xx               
| WS 445.4-2014 		| 电子病历基本数据集 第4部分：检查检验记录  		|  xx               
| WS 445.5-2014 		| 电子病历基本数据集 第5部分：一般治疗处置记录  		|  xx               
| WS 445.6-2014 		| 电子病历基本数据集 第6部分：助产记录  		|  xx               
| WS 445.7-2014 		| 电子病历基本数据集 第7部分：护理操作记录  		|  xx               
| WS 445.8-2014 		| 电子病历基本数据集 第8部分：护理评估与计划  		|  xx               
| WS 445.9-2014 		| 电子病历基本数据集 第9部分：知情告知信息  		|  xx               
| WS 445.10-2014 		| 电子病历基本数据集 第10部分：住院病案首页  		|  xx               
| WS 445.11-2014 		| 电子病历基本数据集 第11部分：中医住院病案首页  		|  xx               
| WS 445.12-2014 		| 电子病历基本数据集 第12部分：入院记录  		|  xx               
| WS 445.13-2014 		| 电子病历基本数据集 第13部分：住院病程记录  		|  xx               
| WS 445.14-2014 		| 电子病历基本数据集 第14部分：住院医嘱  		|  xx               
| WS 445.15-2014 		| 电子病历基本数据集 第15部分：出院小结  		|  xx               
| WS 445.16-2014 		| 电子病历基本数据集 第16部分：转诊(院)记录  		|  xx               
| WS 445.17-2014 		| 电子病历基本数据集 第17部分：医疗机构信息  		|  xx               


### 共享文档

## 技术类

### 功能规范

| 编号  | 名称 | 
| ----  | ---- | 
| WS/T 452-2014  | 卫生监督信息系统功能规范 | 
| WS/T xxx-2013  | 妇幼保健信息系统基本功能规范 | 
| WS/T xxx-2013  | 基层医疗卫生信息系统功能规范 | 
| WS/T 451-2014  | 院前医疗急救指挥信息系统基本功能规范 | 
| WS/T 450-2014  | 新型农村合作医疗信息系统基本功能规范 | 
| WS/T 449-2014  | 慢性病监测信息系统基本功能规范 | 
| WS/T 529-2016  | 远程医疗信息系统基本功能规范 | 推荐性卫生行业标准 |
| WS/T xxx-2013  | 免疫规划信息系统基本功能规范(征求意见稿) | 
| WS/T 547-2017  | 医院感染管理信息系统基本功能规范 | 推荐性卫生行业标准 |





### 技术规范

| 编号  | 名称 |  性质 | 
| ----  | ---- |   ---- |    
| WS/T 448-2014  | 基于健康档案的区域卫生信息平台技术规范 | 
| WS/T 447-2014  | 基于电子病历的医院信息平台技术规范 | 
| WS/T 545-2017  | 远程医疗信息系统技术规范 | 推荐性卫生行业标准 |
| WS/T 546-2017  | 远程医疗信息系统与统一通信平台交互规范 | 推荐性卫生行业标准 |
| WS/T 526-2016  | 妇幼保健服务信息系统技术规范 | 推荐性卫生行业标准 |
| WS/T 544-2017  | 医学数字影像中文封装与通信规范 | 推荐性卫生行业标准 |    
| WS/T 548-2017  | 医学数字影像通信（DICOM）中文标准符合性测试规范 | 推荐性卫生行业标准 |    
| WS/T xxx-2013  | 区域疾病控制业务应用子平台技术规范 | 推荐性卫生行业标准 |
| WS/T 517-2016  | 基层医疗卫生信息系统技术规范 | 推荐性卫生行业标准 |
| WS/T xxx-2013  | 远程医疗设备及统一通讯交互规范(征求意见稿) |  |
| WS/T xxx-2013  | 区域卫生信息平台交互规范(征求意见稿) |  |
| WS/T xxx-2013  | 医院信息平台交互规范(征求意见稿) |  |          
| WS/T 543.1-2017  | 居民健康卡技术规范 第1部分：总则 | 推荐性卫生行业标准 |            
| WS/T 543.2-2017  | 居民健康卡技术规范 第2部分：用户卡技术规范 | 推荐性卫生行业标准 |            
| WS/T 543.3-2017  | 居民健康卡技术规范 第3部分：用户卡应用规范 | 推荐性卫生行业标准 |            
| WS/T 543.4-2017  | 居民健康卡技术规范 第4部分：用户卡命令集 | 推荐性卫生行业标准 |            
| WS/T 543.5-2017  | 居民健康卡技术规范 第5部分：终端技术规范 | 推荐性卫生行业标准 |            
| WS/T 543.6-2017  | 居民健康卡技术规范 第6部分：用户卡及终端产品检测规范 | 推荐性卫生行业标准 |            






### 安全与隐私

### 传输与交换

| 编号  | 名称 |  性质 | 
| ----  | ---- |  ---- | 
| WS/T 483.1-2016  | 健康档案共享文档规范 第1部分：个人基本健康信息登记 | 推荐性卫生行业标准 |            
| WS/T 483.2-2016  | 健康档案共享文档规范 第2部分：出生医学证明 | 推荐性卫生行业标准 |            
| WS/T 483.3-2016  | 健康档案共享文档规范 第3部分：新生儿家庭访视 | 推荐性卫生行业标准 |            
| WS/T 483.4-2016  | 健康档案共享文档规范 第4部分：儿童健康体检 | 推荐性卫生行业标准 |            
| WS/T 483.5-2016  | 健康档案共享文档规范 第5部分：首次产前随访服务 | 推荐性卫生行业标准 |            
| WS/T 483.6-2016  | 健康档案共享文档规范 第6部分：产前随访服务 | 推荐性卫生行业标准 |            
| WS/T 483.7-2016  | 健康档案共享文档规范 第7部分：产后访视 | 推荐性卫生行业标准 |            
| WS/T 483.8-2016  | 健康档案共享文档规范 第8部分：产后42天健康检查 | 推荐性卫生行业标准 |            
| WS/T 483.9-2016  | 健康档案共享文档规范 第9部分：预防接种报告 | 推荐性卫生行业标准 |  
| WS/T 483.10-2016  | 健康档案共享文档规范 第10部分：传染病报告 | 推荐性卫生行业标准 |            
| WS/T 483.11-2016  | 健康档案共享文档规范 第11部分：死亡医学证明 | 推荐性卫生行业标准 |            
| WS/T 483.12-2016  | 健康档案共享文档规范 第12部分：高血压患者随访服务 | 推荐性卫生行业标准 |            
| WS/T 483.13-2016  | 健康档案共享文档规范 第13部分：2型糖尿病患者随访服务 | 推荐性卫生行业标准 |            
| WS/T 483.14-2016  | 健康档案共享文档规范 第14部分：重性精神疾病患者个人信息登记 | 推荐性卫生行业标准 |            
| WS/T 483.15-2016  | 健康档案共享文档规范 第15部分：重性精神疾病患者随访服务 | 推荐性卫生行业标准 |            
| WS/T 483.16-2016  | 健康档案共享文档规范 第16部分：成人健康体检 | 推荐性卫生行业标准 |            
| WS/T 483.17-2016  | 健康档案共享文档规范 第17部分：门诊摘要 | 推荐性卫生行业标准 |            
| WS/T 483.18-2016  | 健康档案共享文档规范 第18部分：住院摘要 | 推荐性卫生行业标准 |            
| WS/T 483.19-2016  | 健康档案共享文档规范 第19部分：会诊记录 | 推荐性卫生行业标准 |            
| WS/T 483.20-2016  | 健康档案共享文档规范 第20部分：转诊(院)记录 | 推荐性卫生行业标准 |            

| 编号  | 名称 |  性质 | 
| ----  | ---- |  ---- | 
| WS/T 500.1-2016  | 电子病历共享文档规范 第1部分：病历概要 | 推荐性卫生行业标准 |            
| WS/T 500.2-2016  | 电子病历共享文档规范 第2部分：门(急)诊病历 | 推荐性卫生行业标准 |            
| WS/T 500.3-2016  | 电子病历共享文档规范 第3部分：急诊留观病历 | 推荐性卫生行业标准 |            
| WS/T 500.4-2016  | 电子病历共享文档规范 第4部分：西药处方 | 推荐性卫生行业标准 |            
| WS/T 500.5-2016  | 电子病历共享文档规范 第5部分：中药处方 | 推荐性卫生行业标准 |            
| WS/T 500.6-2016  | 电子病历共享文档规范 第6部分：检查报告 | 推荐性卫生行业标准 |            
| WS/T 500.7-2016  | 电子病历共享文档规范 第7部分：检验报告 | 推荐性卫生行业标准 |            
| WS/T 500.8-2016  | 电子病历共享文档规范 第8部分：治疗记录 | 推荐性卫生行业标准 |            
| WS/T 500.9-2016  | 电子病历共享文档规范 第9部分：一般手术记录 | 推荐性卫生行业标准 |            
| WS/T 500.10-2016  | 电子病历共享文档规范 第10部分：麻醉术前访视记录 | 推荐性卫生行业标准 |            
| WS/T 500.11-2016  | 电子病历共享文档规范 第11部分：麻醉记录 | 推荐性卫生行业标准 |            
| WS/T 500.12-2016  | 电子病历共享文档规范 第12部分：麻醉术后访视记录 | 推荐性卫生行业标准 |            
| WS/T 500.13-2016  | 电子病历共享文档规范 第13部分：输血记录 | 推荐性卫生行业标准 |            
| WS/T 500.14-2016  | 电子病历共享文档规范 第14部分：待产记录 | 推荐性卫生行业标准 |            
| WS/T 500.15-2016  | 电子病历共享文档规范 第15部分：阴道分娩记录 | 推荐性卫生行业标准 |            
| WS/T 500.16-2016  | 电子病历共享文档规范 第16部分：剖宫产记录 | 推荐性卫生行业标准 |            
| WS/T 500.17-2016  | 电子病历共享文档规范 第17部分：一般护理记录 | 推荐性卫生行业标准 |            
| WS/T 500.18-2016  | 电子病历共享文档规范 第18部分：病重（病危）护理记录 | 推荐性卫生行业标准 |            
| WS/T 500.19-2016  | 电子病历共享文档规范 第19部分：手术护理记录 | 推荐性卫生行业标准 |            
| WS/T 500.20-2016  | 电子病历共享文档规范 第20部分：生命体征测量记录 | 推荐性卫生行业标准 |            
| WS/T 500.21-2016  | 电子病历共享文档规范 第21部分：出入量记录 | 推荐性卫生行业标准 |            
| WS/T 500.22-2016  | 电子病历共享文档规范 第22部分：高值耗材使用记录 | 推荐性卫生行业标准 |            
| WS/T 500.23-2016  | 电子病历共享文档规范 第23部分：入院评估 | 推荐性卫生行业标准 |            
| WS/T 500.24-2016  | 电子病历共享文档规范 第24部分：护理计划 | 推荐性卫生行业标准 |            
| WS/T 500.25-2016  | 电子病历共享文档规范 第25部分：出院评估与指导 | 推荐性卫生行业标准 |            
| WS/T 500.26-2016  | 电子病历共享文档规范 第26部分：手术知情同意书 | 推荐性卫生行业标准 |            
| WS/T 500.27-2016  | 电子病历共享文档规范 第27部分：麻醉知情同意书 | 推荐性卫生行业标准 |            
| WS/T 500.28-2016  | 电子病历共享文档规范 第28部分：输血治疗同意书 | 推荐性卫生行业标准 |            
| WS/T 500.29-2016  | 电子病历共享文档规范 第29部分：特殊检查及特殊治疗同意书 | 推荐性卫生行业标准 |            
| WS/T 500.30-2016  | 电子病历共享文档规范 第30部分：病危(重)通知书 | 推荐性卫生行业标准 |            
| WS/T 500.31-2016  | 电子病历共享文档规范 第31部分：其他知情告知同意书 | 推荐性卫生行业标准 |            
| WS/T 500.32-2016  | 电子病历共享文档规范 第32部分：住院病案首页 | 推荐性卫生行业标准 |            
| WS/T 500.33-2016  | 电子病历共享文档规范 第33部分：中医住院病案首页 | 推荐性卫生行业标准 |            
| WS/T 500.34-2016  | 电子病历共享文档规范 第34部分：入院记录 | 推荐性卫生行业标准 |            
| WS/T 500.35-2016  | 电子病历共享文档规范 第35部分：24小时内入出院记录 | 推荐性卫生行业标准 |            
| WS/T 500.36-2016  | 电子病历共享文档规范 第36部分：24小时内入院死亡记录 | 推荐性卫生行业标准 |            
| WS/T 500.37-2016  | 电子病历共享文档规范 第37部分：住院病程记录  首次病程记录 | 推荐性卫生行业标准 |            
| WS/T 500.38-2016  | 电子病历共享文档规范 第38部分：住院病程记录  日常病程记录 | 推荐性卫生行业标准 |            
| WS/T 500.39-2016  | 电子病历共享文档规范 第39部分：住院病程记录  上级医师查房记录 | 推荐性卫生行业标准 |            
| WS/T 500.40-2016  | 电子病历共享文档规范 第40部分：住院病程记录  疑难病例讨论记录 | 推荐性卫生行业标准 |            
| WS/T 500.41-2016  | 电子病历共享文档规范 第41部分：住院病程记录  交接班记录 | 推荐性卫生行业标准 |            
| WS/T 500.42-2016  | 电子病历共享文档规范 第42部分：住院病程记录 转科记录 | 推荐性卫生行业标准 |            
| WS/T 500.43-2016  | 电子病历共享文档规范 第43部分：住院病程记录 阶段小结 | 推荐性卫生行业标准 |            
| WS/T 500.44-2016  | 电子病历共享文档规范 第44部分：住院病程记录 抢救记录 | 推荐性卫生行业标准 |            
| WS/T 500.45-2016  | 电子病历共享文档规范 第45部分：住院病程记录 会诊记录 | 推荐性卫生行业标准 |            
| WS/T 500.46-2016  | 电子病历共享文档规范 第46部分：住院病程记录 术前小结 | 推荐性卫生行业标准 |           
| WS/T 500.47-2016  | 电子病历共享文档规范 第47部分：住院病程记录 术前讨论 | 推荐性卫生行业标准 |            
| WS/T 500.48-2016  | 电子病历共享文档规范 第48部分：住院病程记录术后 首次病程记录 | 推荐性卫生行业标准 |            
| WS/T 500.49-2016  | 电子病历共享文档规范 第49部分：住院病程记录 出院记录 | 推荐性卫生行业标准 |            
| WS/T 500.50-2016  | 电子病历共享文档规范 第50部分：住院病程记录 死亡记录 | 推荐性卫生行业标准 |            
| WS/T 500.51-2016  | 电子病历共享文档规范 第51部分：住院病程记录 死亡病例讨论记录 | 推荐性卫生行业标准 |            
| WS/T 500.52-2016  | 电子病历共享文档规范 第52部分：住院医嘱 | 推荐性卫生行业标准 |            
| WS/T 500.53-2016  | 电子病历共享文档规范 第53部分：出院小结 | 推荐性卫生行业标准 |            
          


## 管理类

### 建设指南

| 编号  | 名称 | 
| ----  | ---- | 
| WS/T xxx-2009  | 综合卫生管理信息平台建设指南（征求意见稿） | 


### 测试与评价

| 编号  | 名称 | 
| ----  | ---- | 
| WS/T 502-2016  | 电子健康档案与区域卫生信息平台标准符合性测试规范 | 
| WS/T 501-2016  | 电子病历与医院信息平台标准符合性测试规范 | 

### 运维管理

### 监理与验收

## 参考          

1、[国家卫生信息标准与实施评价 汤学军 CHINC2015]()       

2、[中国卫生信息标准网](http://www.chiss.org.cn/hism/wcmpub/hism1029/index/)    

3、[统计信息中心](http://www.moh.gov.cn/mohwsbwstjxxzx/s2907/new_list.shtml)     


## 更新日志


2018-04-28日更新

详情请参考本次所的readme文件
主要是增加了2016 17 年发布的一些标准文件
修正了原来表格展示的问题 


2017-03-07日更新
1.对于 README.md 中的标准编号进行了更新          
参考国卫通[2016]12号    


2014-11-13日更新
1.对于 ""数据集标准/Excel/WS365城乡居民健康档案基本数据集.xlsx""      
* 5.2.03新生儿家庭访视信息第56行 HDSD00.01,261 修改为 5.2.03新生儿家庭访视信息第56行 HDSD00.01.261(逗号改为点)       
* 5.2.01个人基本信息 第二行为空行 移除       
* 5.2.04儿童健康检查信息 第一列删除 与其他表单保持格式一致        
* 5.2.09传染病报告卡信息第23行 Hr)SD00.01.379  修改为 5.2.09传染病报告卡信息第23行 HDSD00.01.379                 
* 5.2.09传染病报告卡信息第33行 HDSD00. 01.407 修改为 5.2.09传染病报告卡信息第33行 HDSD00.01.407(00.01.407 原来01前面有空格)     
* 5.2.09传染病报告卡信息第38行 HDSD00. 01.412 修改为 5.2.09传染病报告卡信息第38行 HDSD00.01.412 (00.01.412原来01前面有空格)      
* 5.2.18转诊(院)信息第49行 HDSD00,01.571 修改为 5.2.18转诊(院)信息第49行 HDSD00.01.571(逗号改为点)      
2.对于""WS369-375卫生信息基本数据集.xlsx""      
* 儿童保健基本数据集 第2部分 儿童健康体检第62行 29  删除第62行                
* 疾病管理基本数据集 第1部分 乙肝患者管理第37行 HDSB04,01.037 修改为 疾病管理基本数据集 第1部分 乙肝患者管理第37行 HDSB04.01.037(逗号改为点)     
* 疾病管理基本数据集 第1部分 乙肝患者管理第97行  HDSB04,01.097  修改为   HDSB04.01.097  (逗号改为点)       
* 疾病管理基本数据集 第4部分 老年人健康管理第90行  HDSB04,04.090 修改为  HDSB04.04.090       
* 疾病管理基本数据集 第6部分 肿瘤病例管理第30行  HDSB04,06.030 修改为  HDSB04.06.030     
* 疾病管理基本数据集 第6部分 肿瘤病例管理第61行  HDSB04.06.06] 修改为  HDSB04.06.061(拿掉] )       
3.对于""数据元标准/Excel/卫生信息数据元目录.xlsx""          



"
4,HealthCatalyst/healthcareai-py,Python,"# healthcareai

[![Code Health](https://landscape.io/github/HealthCatalyst/healthcareai-py/master/landscape.svg?style=flat)](https://landscape.io/github/HealthCatalyst/healthcareai-py/master)
[![Appveyor build status](https://ci.appveyor.com/api/projects/status/github/HealthCatalyst/healthcareai-py?branch=master&svg=true)](https://ci.appveyor.com/project/CatalystAdmin/healthcareai-py/branch/master)
[![Build Status](https://travis-ci.org/HealthCatalyst/healthcareai-py.svg?branch=master)](https://travis-ci.org/HealthCatalyst/healthcareai-py)
<!--[![Anaconda-Server Badge](https://anaconda.org/catalyst/healthcareai/badges/version.svg)](https://anaconda.org/catalyst/healthcareai)
[![Anaconda-Server Badge](https://anaconda.org/catalyst/healthcareai/badges/installer/conda.svg)](https://conda.anaconda.org/catalyst)-->
[![PyPI version](https://badge.fury.io/py/healthcareai.svg)](https://badge.fury.io/py/healthcareai)
[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.999010.svg)](https://doi.org/10.5281/zenodo.999010)
[![GitHub license](https://img.shields.io/badge/license-MIT-blue.svg)](https://raw.githubusercontent.com/HealthCatalyst/healthcareai-py/master/LICENSE)

The aim of **healthcareai** is to streamline machine learning in healthcare. The package has two main goals:

-  Allow one to easily create models based on tabular data, and deploy a best model that pushes predictions to a database such as MSSQL, MySQL, SQLite or csv flat file.
-  Provide tools related to data cleaning, manipulation, and imputation.

## Installation

### Windows

- If you haven't, install 64-bit Python 3.5 via [the Anaconda distribution](https://repo.continuum.io/archive/Anaconda3-4.2.0-Windows-x86_64.exe)
    - **Important** When prompted for the **Installation Type**, select **Just Me (recommended)**. This makes permissions later in the process much simpler.
- Open the terminal (i.e., CMD or PowerShell, if using Windows)
- Run `conda install pyodbc`
- Upgrade to latest scipy (note that upgrade command took forever)
- Run `conda remove scipy`
- Run `conda install scipy`
- Run `conda install scikit-learn`
- Install healthcareai using **one and only one** of these three methods (ordered from easiest to hardest).
    <!--1. **Recommended:** Install the latest release with conda by running `conda install -c catalyst healthcareai`-->
    2. **Recommended:** Install the latest release with pip run `pip install healthcareai`
    3. If you know what you're doing, and instead want the bleeding-edge version direct from our github repo, run `pip install https://github.com/HealthCatalyst/healthcareai-py/zipball/master`

#### Why Anaconda?

We recommend using the Anaconda python distribution when working on Windows. There are a number of reasons:
- When running anaconda and installing packages using the `conda` command, you don't need to worry about [dependency hell](https://en.wikipedia.org/wiki/Dependency_hell), particularly because packages aren't compiled on your machine; `conda` installs pre-compiled binaries.
- A great example of the pain the using `conda` saves you is with the python package **scipy**, which, by [their own admission](http://www.scipy.org/scipylib/building/windows.html) *""is difficult""*.

### Linux

You may need to install the following dependencies:
- `sudo apt-get install python-tk`
- `sudo pip install pyodbc`
    - Note you'll might run into trouble with the `pyodbc` dependency. You may first need to run `sudo apt-get install
      unixodbc-dev` then retry `sudo pip install pyodbc`. Credit [stackoverflow](http://stackoverflow.com/questions/2960339/unable-to-install-pyodbc-on-linux)

Once you have the dependencies satisfied run `pip install healthcareai` or `sudo pip install healthcareai`

### macOS

- `pip install healthcareai` or `sudo pip install healthcareai`

### Linux and macOS (via docker)

- Install [docker](https://docs.docker.com/engine/installation/)
- Clone this repo (look for the green button on the repo main page)
- cd into the cloned directory
- run `docker build -t healthcareai .`
- run the docker instance with `docker run -p 8888:8888 healthcareai` 
- You should then have a jupyter notebook available on `http://localhost:8888`.

### Verify Installation

To verify that *healthcareai* installed correctly, open a terminal and run `python`. This opens an interactive python
console (also known as a [REPL](https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop)). Then enter this
command: `from healthcareai import SupervisedModelTrainer` and hit enter. If no error is thrown, you are ready to rock.

If you did get an error, or run into other installation issues, please [let us know](http://healthcare.ai/contact.html)
or better yet post on [Stack Overflow](http://stackoverflow.com/questions/tagged/healthcare-ai) (with the healthcare-ai
tag) so we can help others along this process.

## Getting started

1. Read through the [Getting Started](http://healthcareai-py.readthedocs.io/en/latest/getting_started/) section of the [healthcareai-py](http://healthcareai-py.readthedocs.io/en/latest/) documentation.

2. Read through the example files to learn how to use the healthcareai-py API.
    * For examples of how to train and evaluate a supervised model, inspect and run either `example_regression_1.py` or `example_classification_1.py` using our sample diabetes dataset.
    * For examples of how to use a model to make predictions, inspect and run either `example_regression_2.py` or `example_classification_2.py` after running one of the first examples.
    * For examples of more advanced use cases, inspect and run `example_advanced.py`.

3. To train and evaluate your own model, modify the queries and parameters in either `example_regression_1.py` or `example_classification_1.py` to match your own data.

4. Decide what type of prediction output you want. See [Choosing a Prediction Output Type](http://healthcareai-py.readthedocs.io/en/latest/prediction_types/) for details.

5. Set up your database tables to match the schema of the output type you chose. 
   * If you are working in a Health Catalyst EDW ecosystem (primarily MSSQL), please see the [Health Catalyst EDW Instructions](http://healthcareai-py.readthedocs.io/en/latest/catalyst_edw_instructions/) for setup.
   * Otherwise, please see [Working With Other Databases](http://healthcareai-py.readthedocs.io/en/latest/databases/)
    for details about writing to different databases (MSSQL, MySQL, SQLite, CSV)

6. Congratulations! After running one of the example files with your own data, you should have a trained model. To use your model to make predictions, modify either `example_regression_2.py` or `example_classification_2.py` to use your new model. You can then run it to see the results. 

## For Issues

- Double check that the code follows the examples [here](http://healthcareai-py.readthedocs.io/en/latest/)
- If you're still seeing an error, create a post in [Stack Overflow](http://stackoverflow.com/questions/tagged/healthcare-ai) (with the healthcare-ai tag) that contains
    * Details on your environment (OS, database type, R vs Py)
    * Goals (ie, what are you trying to accomplish)
    * Crystal clear steps for reproducing the error
- You can also log a new issue in the GitHub repo by clicking [here](https://github.com/HealthCatalyst/healthcareai-py/issues/new)
"
5,microsoft/HealthBotContainerSample,JavaScript,"# Health Bot Container

A simple web page that allows users to communicate with the [Azure Health Bot](https://azure.microsoft.com/en-us/services/bot-services/health-bot/) through a WebChat.

**Note:** In order to use this Web Chat with the Health Bot service, you will need to obtain your Web Chat secret by going to `Integration/Secrets` on the navigation panel.

![Secrets](/secrets.png)

1.Deploy the website:

[![Deploy to Azure](https://aka.ms/deploytoazurebutton)](https://portal.azure.com/#create/Microsoft.Template/uri/https%3A%2F%2Fraw.githubusercontent.com%2Fmicrosoft%2FHealthBotContainerSample%2Fmaster%2Fazuredeploy.json)

2.Set the following environment variables:

`APP_SECRET`

`WEBCHAT_SECRET`

3.Configure scenario invocation (optional):

The Health Bot service uses [language models](https://docs.microsoft.com/HealthBot/language_model_howto) to interpret end user utterances and trigger the relevant scenario logic in response.

Alternatively, you can programmaticaly invoke a scenario before the end user provides any input.

To implement this behavior, uncomment the following code from the `function initBotConversation()` in the `/public/index.js` file:
```javascript
triggeredScenario: {
    trigger: ""{scenario_id}"",
    args: {
        myVar1: ""{custom_arg_1}"",
        myVar2: ""{custom_arg_2}""
    }
}
```
Replace {scenario_id} with the scenario ID of the scenario you would like to invoke.
You can also pass different values through the ""args"" object. 

You can read more about programmatic client side scenario invocation [here](https://docs.microsoft.com/HealthBot/integrations/programmatic_invocation)


4.Set the Bot service direct line channel endpoint (optional)

In some cases it is required to set the endpoint URI so that it points to a specific geography. The geographies supported by the bot service each have a unique direct line endpoint URI:

- `directline.botframework.com` routes your client to the nearest datacenter. This is the best option if you do not know where your client is located.
- `asia.directline.botframework.com` routes only to Direct Line servers in Eastern Asia.
- `europe.directline.botframework.com` routes only to Direct Line servers in Europe.
- `northamerica.directline.botframework.com` routes only to Direct Line servers in North America.

Pass your preferred geographic endpoint URI by setting the environment variable: `DIRECTLINE_ENDPOINT_URI` in your deployment. If no variable is found it will default to `directline.botframework.com`

**Note:** If you are deploying the code sample using the ""Deploy to Azure"" option, you should add the above secrets to the application settings for your App Service.

## Agent webchat
If the agent webchat sample is also required, [switch to the live agent handoff branch](https://github.com/Microsoft/HealthBotContainerSample/tree/live_agent_handoff)
"
6,isaacmg/healthcare_ml,,"## Table Of Contents
- [Machine Learning for Healthcare](#machine-learning-for-healthcare)
    - [Introduction](#introduction)
    - [Genomics](#genomics)
    - [Precision Medicine/Drug Discovery](#precision-medicinedrug-discovery)
        - [Tools](#tools)
    - [Medical Imaging](#medical-imaging)
        - [Papers](#papers)
        - [Blogs, blog posts, and reddit discussions](#blogs-blog-posts-and-reddit-discussions)
        - [Conferences and Workshops](#conferences-and-workshops)
        - [Research Groups](#research-groups)
        - [Competitions](#competitions)
        - [Videos](#videos)
        - [Datasets](#datasets)
        - [Code Repositories](#code-repositories)
        - [Tools](#tools)
        - [Other](#other)
    - [Hospital Operations (i.e. OR Utilization, Scheduling, Discharge planning, HAIs...)](#hospital-operations-ie-or-utilization-scheduling-discharge-planning-hais)
    - [Signal processing, forecasting, and adverse event prediction](#signal-processing-forecasting-and-adverse-event-prediction)
        - [Papers](#papers)
    - [Other and Multiple Categories](#other-and-multiple-categories)
        - [Datasets](#datasets)
        - [Conferences](#conferences)
        - [Papers](#papers)
- [Companies](#companies)

# Machine Learning for Healthcare
This repository is a list of the all the relevant resources on applying machine learning to healthcare. If you see an article, repository, or other useful addition please make a pull request. At the moment structure of the repository is as follows: instead of being broken down by machine learning domains as you would technically expect (i.e. computer vision, NLP, audio...etc), it is broken down by application area (i.e. precision medicine, genomics, medical imaging/radiology, hospital operations...). Papers, conferences, tools, or courses that cover multiple areas of healthcare are moved to the ""other/overlapping"" category. If you think that this is confusing or there is a better way of doing things please post in the [issues discussion](https://github.com/isaacmg/healthcare_ml/issues/6)

## Introduction

## Genomics

[AffinityNet](https://arxiv.org/abs/1805.08905)

[Bayesian multi-domain learning for cancer subtype discovery from next-generation sequencing count data](https://arxiv.org/pdf/1810.09433.pdf)

[Machine Learning Genomic Medicine](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7347331)

[Deep learning for Genomics a Overview](https://arxiv.org/abs/1802.00810)

## Precision Medicine/Drug Discovery

[Assessing Disparate Impacts of Personalized Interventions: Identifiability and Bounds](https://arxiv.org/abs/1906.01552)

[Adapting Neural Networks for the Estimation of Treatment Effects](https://arxiv.org/pdf/1906.02120.pdf)

[Attentive State-Space Modeling of Disease Progression](https://nips.cc/Conferences/2019/Schedule?showEvent=14124)

[Dr. VAE](https://arxiv.org/pdf/1706.08203.pdf)

[Deep generative models of genetic variation capture the effects of mutations](https://arxiv.org/abs/1712.06527)

[Deep learning with multimodal representation for pancancer prognosis prediction](https://academic.oup.com/bioinformatics/article/35/14/i446/5529139)

[Deep RL for Radiation Therapy](https://aapm.onlinelibrary.wiley.com/doi/pdf/10.1002/mp.12625)

[GAMENet: Graph Augmented MEmory Networks for Recommending Medication Combination](https://github.com/sjy1203/GAMENet)

[The cornucopia of meaningful leads: Applying deep adversarial autoencoders for new molecule development in oncology](http://www.oncotarget.com/index.php?journal=oncotarget&page=article&op=view&path%5B0%5D=14073&path%5B1%5D=44886)

[End-to-end training of deep probabilistic CCA for
joint modeling of paired biomedical observations](http://bayesiandeeplearning.org/2018/papers/113.pdf)


[Fréchet ChemNet Distance: A metric for generative models for molecules in drug discovery](https://arxiv.org/pdf/1803.09518.pdf) 

[Lesson Learned from Natural Language Inference in the Clinical Domain](https://arxiv.org/pdf/1808.06752.pdf)


[Molecular De Novo design using Recurrent Neural Networks and Reinforcement Learning Code](https://github.com/MarcusOlivecrona/REINVENT)


[NAACL Paper on Cross Speciality Entity Recognition for Medicine](https://aclanthology.coli.uni-saarland.de/papers/N18-1001/n18-1001)

[ Natural Language Processing for Precision Medicine](https://www.microsoft.com/en-us/research/wp-content/uploads/2017/07/1707_tutorial.pdf) ACL 2017 Tutorial.

[Near-Optimal Reinforcement Learning in Dynamic Treatment Regimes](https://causalai.net/r48.pdf)

[Predicting drug response of tumors from integrated genomic profiles by deep neural networks](https://bmcmedgenomics.biomedcentral.com/articles/10.1186/s12920-018-0460-9)

[Regression tree methods for precision medicine](https://www.youtube.com/watch?v=jpUItf0Wt4Y) talk by Wei-Yin Loh
University of Wisconsin-Madison, USA.

[Survey of Computational Methods for Drug Discovery](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4719067/)

### Tools
[DeepChem](https://deepchem.io)


## Medical Imaging

### Papers

[A Two-Stream Mutual Attention Network for Semi-supervised Biomedical Segmentation with Noisy Labels](https://arxiv.org/abs/1807.11719)

[Clinically Applicable deep learning for retinal disease diagnosis and referal](https://lmb.informatik.uni-freiburg.de/Publications/2018/Ron18/paper-De_Fauw_et_al_2018_Nature_Medicine.pdf)

[CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning](https://arxiv.org/pdf/1711.05225.pdf)

[Domain Generalization via Model-Agnostic Learning of Semantic Features (with application to medical image segmentation](https://arxiv.org/abs/1910.13580)

[Dermatologist Level Skin Classification of skin cancer with deep neural networks](https://www.nature.com/articles/nature21056)

[Discrepancy Ratio: Evaluating Model Performance When Even Experts Disagree on the Truth](https://openreview.net/forum?id=Byg-wJSYDS)

[Explanation by Progressive Exaggeration](https://openreview.net/pdf?id=H1xFWgrFPS)


[Overview of Deep Learning in Medical Imaging](https://arxiv.org/pdf/1702.05747.pdf)

[On the Automatic Generation of Medical Imaging Reports](https://arxiv.org/abs/1711.08195)

[OBELISK - One Kernel to Solve Nearly Everything: Unified 3D Binary Convolutions for Image Analysis](https://openreview.net/forum?id=BkZu9wooz)

[PGANs: Personalized Generative Adversarial Networks for ECG Generation to improve Patient-Specific Deep ECG Classification](http://www.kiraradinsky.com/files/pgans-personalized-generative.pdf)

[Hybrid Retrieval-Generation Reinforced Agent for Medical Image Report Generation](https://arxiv.org/abs/1805.08298)


[Recurrent Registration Neural Networks for Deformable Image Registration](https://arxiv.org/abs/1906.09988)

[Robust breast cancer detection in mammography and digital breast tomosynthesis using annotation-efficient deep learning approach](https://arxiv.org/abs/1912.11027)

[Transfusion: Understanding Transfer Learning for Medical Imaging](http://arxiv.org/abs/1902.07208)

[Towards Deep Cellular Phenotyping in Placental Histology](https://arxiv.org/pdf/1804.03270.pdf)



### Blogs, blog posts, and reddit discussions

[Luke Oakden Rayner's blog](https://lukeoakdenrayner.wordpress.com)

[A case study of text annotation for medical imaging - LightTag](https://lighttag.io/blog/embrace-the-noise/)

### Conferences and Workshops

[Deep learning for healthcare video series MIT](https://www.youtube.com/watch?v=k0LacC4hyY8&list=PLdPz9_rcdD97b3iExKYmla8vjlsc_k1ee&index=5)

[Harvard Digital Doctor Symposium](https://youtu.be/CiqYtZWBXqE)

[Medical Imaging with deep learning MIDL](https://sites.google.com/view/midl)

[Medical Imaging meets NIPS](https://sites.google.com/view/med-nips-2017)

[Medical Imaging Summer School 2014](http://iplab.dmi.unict.it/miss14/)

[Medical Image Computing and Computer Assisted Intervention](http://www.miccai2017.org)

[Machine Learning in Medical Imaging](http://mlmi2016.web.unc.edu)

[SIM Conference on Machine Intelligence in Medical Imaging](http://siim.org/page/2017CMIMI)

[CVPR 2018 Medical Imaging Workshop](https://sites.google.com/site/cvprmcv18/)

### Research Groups
[Imperial University](https://biomedia.doc.ic.ac.uk)

[Images Science Institute at Utrecht](https://www.isi.uu.nl/Research/Publications/index.html)

### Competitions

[Digital Mammography Recall Challenge](https://www.synapse.org/#!Synapse:syn4224222)

[Kaggle 2017 Data Science Bowl-Lung diagnosis](https://www.kaggle.com/c/data-science-bowl-2017)

[NIPS 2018 Prothestics Challenge](https://www.crowdai.org/challenges/nips-2018-ai-for-prosthetics-challenge)

LUNA 16

[Kaggle 2016 Data Science Bowl-Measuring ejection fraction](https://www.kaggle.com/c/second-annual-data-science-bowl#description)

### Videos
[Learning to read deep learning papers -i.e. dicussion of ChexNet by Stanford](https://www.youtube.com/watch?v=xoUpKjxbeC0&t=2s)



### Datasets
[CheX-Ray14](https://nihcc.app.box.com/v/ChestXray-NIHCC)


### Code Repositories

### Tools
[DeepInfer](http://www.deepinfer.org)

### Other
[Medical Image Analysis Network (UK)](https://www.median.ac.uk/network)


## Hospital Operations (i.e. OR Utilization, Scheduling, Discharge planning, HAIs, EMRs...)

[Attend and Diagnose](https://arxiv.org/pdf/1711.03905.pdf)

[Adversarial Learning of Privacy-Preserving Text Representations for De-Identification of Medical Records](https://arxiv.org/abs/1906.05000)

[Detecting Hospital Acquired Infections with SVMs](http://journals.sagepub.com/doi/full/10.1177/1460458216656471)

[Deep EHR: a survey of recent deep learning techniques for EHR analysis](https://arxiv.org/pdf/1706.03446.pdf)

[Emergency Department Online Patient-Caregiver Scheduling](https://ojs.aaai.org//index.php/AAAI/article/view/3745)

[Few-Shot and Zero-Shot Multi-Label Learning for Structured Label Spaces (focuses on ICD Coding)](https://aclanthology.org/D18-1352.pdf)

[Learning to predict post-hospitalization VTE risk from EHR data](http://europepmc.org/articles/pmc3540493)

[Multitask Learning and Benchmarking with Clinical Time Series Data](https://arxiv.org/abs/1703.07771)

[Machine-learning Algorithm to Predict Hypotension Based on High- delity Arterial Pressure Waveform Analysis](https://sci-hub.tw/10.1097/ALN.0000000000002300#)

[Privacy-Preserving Classification of Personal Text Messages with Secure Multi-Party Computation](https://arxiv.org/abs/1906.02325) 

[Smart Hospital Hand Hygiene (Stanford)](http://ai.stanford.edu/~syyeung/resources/vision_hand_hh_nipsmlhc.pdf)

[Unsupervised Domain Adaptation for Clinical Negation Detection](http://www.aclweb.org/anthology/W17-2320)

[Vision Based Prediction of ICU Mobility with RNNs](https://www.semanticscholar.org/paper/Vision-Based-Prediction-of-ICU-Mobility-Care-using-Bianconi-Mehra/db6cf1ac611668fb61921cd98b9fb14525b7c2a6)

## Signal processing, forecasting, and adverse event prediction


### Papers

[Analysing and Improving the Diagnosis of Ischaemic Heart Disease with Machine Learning](https://www.ncbi.nlm.nih.gov/pubmed/10225345) NIH Article

[Asthma Incidence Prediction with DNN](https://www.medrxiv.org/content/10.1101/19012161v1)

[Doctor AI: Predicting Clinical Events via Recurrent Neural Network](https://arxiv.org/abs/1511.05942)s published in MLR

[Cardiologist level classification of arrhythmia (Stanford)](https://arxiv.org/pdf/1707.01836.pdf) 

[Dynamic Bayesian Flu Forecasting](https://arxiv.org/abs/1708.09481)

[Deep Self Organization with application to ICU](https://openreview.net/pdf?id=rygjcsR9Y7)

[Interpretable AI for beat-to-beat cardiac function assessment](https://www.medrxiv.org/content/10.1101/19012419v2)

[GRU-ODE-Bayes: Continuous modeling of sporadically-observed time series](https://arxiv.org/pdf/1905.12374v1.pdf)

[Manifold-regression to predict from MEG/EEG brain signals without source modeling](https://arxiv.org/abs/1906.02687)

[U-Time: A Fully Convolutional Network for Time Series Segmentation Applied to Sleep Staging](https://arxiv.org/abs/1910.11162)

[Forecasting Treatment Responses Over Time Using Recurrent Marginal Structural Networks](https://github.com/sjblim/rmsn_nips_2018)


## Other and Multiple Categories


### Datasets

[Clinical Case Reports Dataset for machine comprehension](https://github.com/clips/clicr)

[HEAD-QA: A Healthcare Dataset for Complex Reasoning](https://arxiv.org/abs/1906.04701)

[NLP Datasets from i2b2](https://www.i2b2.org/NLP/DataSets/Main.php)

[EBM-NLP 5,000 richly annotated abstracts of medical articles](http://www.ccis.northeastern.edu/home/bennye/EBM-NLP/browse.html)

[EMR-Question and Answering Code](https://github.com/panushri25/emrQA)

[OncoKB](http://oncokb.org/)

[MeDAL: A large medical text dataset curated for abbreviation disambiguation](https://github.com/BruceWen120/medal)

[MIMIC - Medical Information Mart for Intensive Care - A large dataset by MIT and made available through Github] (https://mimic.mit.edu/)



### Conferences

[BioNLP Workshops](https://aclweb.org/aclwiki/BioNLP_Workshop)

[Clinical NLP](https://clinical-nlp.github.io/2019/index.html)

[Machine Learning for Healthcare Conference](http://mucmd.org)

[HealthTac](http://healtex.org/healtac-2019/)

[Trec Clinical Decision Support](http://www.trec-cds.org)

[Machine Learning for Healthcare 2018](https://www.mlforhc.org)

[2017 ICML Healthcare Related Talks](https://2017.icml.cc/Conferences/2017/Schedule?showParentSession=1379)

[ICML AI and Health Workshop](http://sots.brookes.ac.uk/~p0072382/ai4h2018/)

[Ninth Workshop on Health Text Mining at EMNLP](https://louhi2018.fbk.eu)

[NAACL 2019 On Tutorial Applications of Natural Language Processing in Clinical Research and Practice](https://www.aclweb.org/anthology/attachments/N19-5006.Presentation.pdf)

[Rework Healthcare 2018](https://www.re-work.co/events/deep-learning-health-boston-2018)



### Papers

[Active Learning for Decision-Making from Imbalanced Observational Data (application to personalized treatment](https://arxiv.org/pdf/1904.05268.pdf)

[Adversarial Attacks Against Medical Deep Learning Systems](https://arxiv.org/pdf/1804.05296.pdf)

[Annotating a Large Representative Corpus of Clinical Notes for Parts of Speech](https://www.researchgate.net/publication/301404639_Annotating_a_Large_Representative_Corpus_of_Clinical_Notes_for_Parts_of_Speech)

[Automated Medical Scribe for recording clinical encounters](http://aclweb.org/anthology/N18-5003)

[Deep Learning for Healthcare Review, Opportunities, Challenges](https://www.ncbi.nlm.nih.gov/pubmed/28481991) published Oxford Academic.

[Deep Neural Models for Medical Concept Normalization in User-Generated Texts](link coming)

[Direct Uncertainty Prediction for Medical Second Opinions](https://arxiv.org/abs/1807.01771)

[EMER-QA A large corpus for question answering on electronic medical records](https://arxiv.org/pdf/1809.00732.pdf)

[GAMENet: Graph Augmented MEmory Networks for Recommending Medication Combination](https://arxiv.org/abs/1809.01852)

[Leveraging uncertainty information from deep neural networks for disease detection](https://www.nature.com/articles/s41598-017-17876-z)

[Label-aware Double Transfer Learning for Cross-Specialty Medical Named Entity Recognition](http://aclweb.org/anthology/N18-1001)

[Machine Learning for Medical Diagnosis](https://dl.acm.org/citation.cfm?id=2306356) PSU article 2006

[MiME: Multilevel Medical Embedding of Electronic Health Records for Predictive Healthcare](https://nips.cc/Conferences/2018/Schedule?showEvent=11448)

[Novel Exploration Techniques (NETs) for Malaria Policy Interventions](https://arxiv.org/pdf/1712.00428.pdf)

[Opportunistic Learning: Budgeted Cost-Sensitive Learning from Data Streams with application to diabetes](https://openreview.net/pdf?id=S1eOHo09KX)

[Patient2Vec: A Personalized Interpretable Deep Representation of the Longitudinal Electronic Health Record](https://arxiv.org/abs/1810.04793)

[Towards Automating Healthcare Question Answering in a Noisy Multilingual Low-Resource Setting](https://www.aclweb.org/anthology/P19-1090)

[Learning Phenotypes and Dynamic Patient Representations via RNN Regularized Collective Non-negative Tensor Factorization](https://dmas.lab.mcgill.ca/fung/pub/YQCFP19aaai_postprint.pdf)

[Uncertainty-Aware Attention for Reliable Interpretation and Prediction](https://nips.cc/Conferences/2018/Schedule?showEvent=11112)

### Additional Natural Language Processing for Healthcare Tools

[BioBERT](https://github.com/dmis-lab/biobert)

[Clinical Named Entity Recognition system (CliNER)](https://github.com/text-machine-lab/CliNER)

[Clinical Text Analysis Knowledge Extraction System (cTAKES)](http://ctakes.apache.org/)


### Courses

[Machine Learning for Medicine MIT Course](https://mlhc17mit.github.io)


# Companies
Companies are arranged alphabetical order.
![Image of stratups](https://cbi-blog.s3.amazonaws.com/blog/wp-content/uploads/2017/01/healthcare_AI_map_2016_1.png)

[Benevolent AI](https://benevolent.ai)

[Camereyes](http://camereyes.com)

[Center Clinical Data Science Mass General](https://www.ccds.io)

[Deep Genomics](https://www.deepgenomics.com)

[Etiometry](http://www.etiometry.com)

[Heartflow](https://www.google.com/search?client=opera&q=heartflow&sourceid=opera&ie=UTF-8&oe=UTF-8)

[Hemonitor](https://www.hemonitor.co)

[Healthcare at Google](https://research.google.com/teams/brain/healthcare/)

[Insitrio](http://www.insitro.com)

[Path.AI](http://path.ai)

[RadAI](https://www.crunchbase.com/organization/radai)

[Recursion Pharmaceuticals](https://www.recursionpharma.com)

[Siemens AI Document](http://www.usa.siemens.com/pool/news_events/innovation-day/10_usinnoday2017_artificial_intelligence.pdf)
"
7,TheAlphamerc/flutter_healthcare_app,Dart,"## flutter_healthcare_app ![Twitter URL](https://img.shields.io/twitter/url?style=social&url=https%3A%2F%2Ftwitter.com%2Fthealphamerc) [![GitHub stars](https://img.shields.io/github/stars/Thealphamerc/flutter_healthcare_app?style=social)](https://github.com/login?return_to=%2FTheAlphamerc%flutter_healthcare_app) ![GitHub forks](https://img.shields.io/github/forks/TheAlphamerc/flutter_healthcare_app?style=social) 

![Dart CI](https://github.com/TheAlphamerc/flutter_healthcare_app/workflows/Dart%20CI/badge.svg) ![GitHub pull requests](https://img.shields.io/github/issues-pr/TheAlphamerc/flutter_healthcare_app) ![GitHub closed pull requests](https://img.shields.io/github/issues-pr-closed/Thealphamerc/flutter_healthcare_app) ![GitHub last commit](https://img.shields.io/github/last-commit/Thealphamerc/flutter_healthcare_app)  ![GitHub issues](https://img.shields.io/github/issues-raw/Thealphamerc/flutter_healthcare_app) [![Open Source Love](https://badges.frapsoft.com/os/v2/open-source.svg?v=103)](https://github.com/Thealphamerc/flutter_healthcare_app) 


Healthcare app is a design implementaion of [Healthcare Mobile App](https://www.uplabs.com/posts/healthcare-mobile-app-d9081ded-e7b3-4705-8990-82ead42c22da) designed by [Chirag Chauhan](https://www.uplabs.com/chirag_designer2610)

## Download App ![GitHub All Releases](https://img.shields.io/github/downloads/Thealphamerc/flutter_healthcare_app/total?color=green)
<a href=""https://github.com/TheAlphamerc/flutter_healthcare_app/releases/download/v1.0.0/app-release.apk""><img src=""https://playerzon.com/asset/download.png"" width=""200""></img></a>
<img src=""https://github.com/TheAlphamerc/flutter_healthcare_app/blob/master/screenshots/HealthcareMobileApp.png?raw=true""  /> 

## Android Screenshots

  HomePage                 |    Detail Page        
:-------------------------:|:-------------------------:
![](https://github.com/TheAlphamerc/flutter_healthcare_app/blob/master/screenshots/screenshot_1.jpg?raw=true)|![](https://github.com/TheAlphamerc/flutter_healthcare_app/blob/master/screenshots/screenshot_2.jpg?raw=true)

## iOS Screenshots
  HomePage                 |    Detail Page      
:-------------------------:|:-------------------------:
![](https://github.com/TheAlphamerc/flutter_healthcare_app/blob/master/screenshots/screenshot_ios_1.png?raw=true)|![](https://github.com/TheAlphamerc/flutter_healthcare_app/blob/master/screenshots/screenshot_ios_2.png?raw=true)

## Directory Structure
```
|-- lib
|   |-- main.dart
|   '-- src
|       |-- config
|       |   '-- route.dart
|       |-- model
|       |   |-- dactor_model.dart
|       |   '-- data.dart
|       |-- pages
|       |   |-- detail_page.dart
|       |   |-- home_page.dart
|       |   '-- splash_page.dart
|       |-- theme
|       |   |-- extention.dart
|       |   |-- light_color.dart
|       |   |-- text_styles.dart
|       |   '-- theme.dart
|       '-- widgets
|           |-- coustom_route.dart
|           |-- progress_widget.dart
|           '-- rating_start.dart
|-- pubspec.yaml
|-- screenshots
|   |-- HealthcareMobileApp.png
|   |-- screenshot_1.jpg
|   |-- screenshot_2.jpg
|   |-- screenshot_ios_1.png
|   '-- screenshot_ios_2.png
'-- test
    '-- widget_test.dart
```
## Pull Requests

I welcome and encourage all pull requests. It usually will take me within 24-48 hours to respond to any issue or request.

## Flutter projects
 Project Name        |Stars        
:-------------------------|-------------------------
[Twitter clone](https://github.com/TheAlphamerc/flutter_twitter_clone)| [![GitHub stars](https://img.shields.io/github/stars/Thealphamerc/flutter_twitter_clone?style=social)](https://github.com/login?return_to=%2FTheAlphamerc%flutter_twitter_clone)
|[Ecommerce App](https://github.com/TheAlphamerc/flutter_ecommerce_app) |[![GitHub stars](https://img.shields.io/github/stars/Thealphamerc/flutter_ecommerce_app?style=social)](https://github.com/login?return_to=%2FTheAlphamerc%flutter_ecommerce_app)
|[Smart course](https://github.com/TheAlphamerc/flutter_smart_course) |[![GitHub stars](https://img.shields.io/github/stars/Thealphamerc/flutter_smart_course?style=social)](https://github.com/login?return_to=%2FTheAlphamerc%flutter_smart_course)
|[Pokedex](https://github.com/TheAlphamerc/flutter_pokedex)|[![GitHub stars](https://img.shields.io/github/stars/Thealphamerc/flutter_pokedex?style=social)](https://github.com/login?return_to=%2FTheAlphamerc%flutter_pokedex)
|[Authentication](https://github.com/TheAlphamerc/flutter_login_signup)|[![GitHub stars](https://img.shields.io/github/stars/Thealphamerc/flutter_login_signup?style=social)](https://github.com/login?return_to=%2FTheAlphamerc%flutter_login_signup)
|[Wallet App](https://github.com/TheAlphamerc/flutter_wallet_app)|[![GitHub stars](https://img.shields.io/github/stars/Thealphamerc/flutter_wallet_app?style=social)](https://github.com/login?return_to=%2FTheAlphamerc%flutter_wallet_app)
|[News App](https://github.com/TheAlphamerc/flutter_news_app)|[![GitHub stars](https://img.shields.io/github/stars/Thealphamerc/flutter_news_app?style=social)](https://github.com/login?return_to=%2FTheAlphamerc%flutter_news_app)
|[Watch App](https://github.com/TheAlphamerc/flutter_SoftUI_watchApp)|[![GitHub stars](https://img.shields.io/github/stars/Thealphamerc/flutter_SoftUI_watchApp?style=social)](https://github.com/login?return_to=%2FTheAlphamerc%flutter_SoftUI_watchApp)
|[Smart Home App](https://github.com/TheAlphamerc/flutter_smart_home_app)|[![GitHub stars](https://img.shields.io/github/stars/Thealphamerc/flutter_smart_home_app?style=social)](https://github.com/login?return_to=%2FTheAlphamerc%flutter_smart_home_app)
|[Yatch Booking App](https://github.com/TheAlphamerc/flutter_yatch_booking)|[![GitHub stars](https://img.shields.io/github/stars/Thealphamerc/flutter_yatch_booking?style=social)](https://github.com/login?return_to=%2FTheAlphamerc%flutter_yatch_booking)

## Flutter plugins
Plugin Name        | Stars        
:-------------------------|-------------------------
|[Empty widget](https://github.com/TheAlphamerc/empty_widget) |[![GitHub stars](https://img.shields.io/github/stars/Thealphamerc/empty_widget?style=social)](https://github.com/login?return_to=%2FTheAlphamerc%empty_widget)
|[Add Thumbnail](https://github.com/TheAlphamerc/flutter_plugin_add_thumbnail) |[![GitHub stars](https://img.shields.io/github/stars/Thealphamerc/flutter_plugin_add_thumbnail?style=social)](https://github.com/login?return_to=%2FTheAlphamerc%flutter_plugin_add_thumbnail)
|[Filter List](https://github.com/TheAlphamerc/flutter_plugin_filter_list)| [![GitHub stars](https://img.shields.io/github/stars/Thealphamerc/flutter_plugin_filter_list?style=social)](https://github.com/login?return_to=%2FTheAlphamerc%flutter_plugin_filter_list)

## Created & Maintained By

[Sonu Sharma](https://github.com/TheAlphamerc) ([Twitter](https://www.twitter.com/TheAlphamerc)) ([Youtube](https://www.youtube.com/user/sonusharma045sonu/)) ([Insta](https://www.instagram.com/_sonu_sharma__)) ([Dev.to](https://dev.to/thealphamerc))
  ![Twitter Follow](https://img.shields.io/twitter/follow/thealphamerc?style=social) 


> If you found this project helpful or you learned something from the source code and want to thank me, consider buying me a cup of :coffee:
>
> * [PayPal](https://paypal.me/TheAlphamerc/)

> You can also nominate me for Github Star developer program  https://stars.github.com/nominate


## Visitors Count

<img align=""left"" src = ""https://profile-counter.glitch.me/flutter_healthcare_app/count.svg"" alt =""Loading"">
"
8,nextgenhealthcare/connect,Java,"# Mirth® Connect by NextGen Healthcare

1. [Useful Links](#useful-links)
2. [General Information](#general-information)
3. [Installation and Upgrade](#installation-and-upgrade)
4. [Starting Mirth Connect](#starting-mirth-connect)
5. [Running Mirth Connect in Java 9 or greater](#java9)
6. [Java Licensing](#java-licensing)
7. [License](#license)

------------

<a name=""useful-links""></a>
## 1. Useful Links
- [Downloads](https://github.com/nextgenhealthcare/connect/releases) 
- [User Guide](https://docs.nextgen.com/)
- [Wiki](https://github.com/nextgenhealthcare/connect/wiki)
  - [FAQ](https://github.com/nextgenhealthcare/connect/wiki/Frequently-Asked-Questions)
  - [What's New in Mirth Connect](https://github.com/nextgenhealthcare/connect/wiki/Release-Notes)
- [Forums](https://forums.mirthproject.io/)
- [Slack Channel](https://mirthconnect.slack.com/) 
  - [Slack Registration](https://join.slack.com/t/mirthconnect/shared_invite/zt-1prqon9tg-UQ_~6AsV8IwdITTo3z1aoA)

------------

<a name=""general-information""></a>
## 2. General Information
##### The NextGen Solutions Mission
NextGen Solutions help many of the nation&apos;s largest, most respected healthcare entities streamline their care-management processes to satisfy the demands of a regulatory, competitive healthcare industry. With Mirth Solutions, NextGen Healthcare&apos;s goal is to provide the healthcare community with a secure, efficient, cost-effective means of sharing health information. The natural product of this aim is a family of applications &mdash; which includes Mirth Connect &mdash; flexible enough to manage patient information, from small practices to large HIEs, so our clients and users can work confidently and effectively within the healthcare-delivery system.
##### About Mirth Connect
Like an interpreter who translates foreign languages into the one you understand, Mirth Connect translates message standards into the one your system understands. Whenever a &quot;foreign&quot; system sends you a message, Mirth Connect&apos;s integration capabilities expedite the following:
- Filtering &mdash; Mirth Connect reads message parameters and passes the message to or stops it on its way to the transformation stage.
- Transformation &mdash; Mirth Connect converts the incoming message standard to another standard (e.g., HL7 to XML).
- Extraction &mdash; Mirth Connect can &quot;pull&quot; data from and &quot;push&quot; data to a database.
- Routing &mdash; Mirth Connect makes sure messages arrive at their assigned destinations.

Users manage and develop channels (message pathways) using the interface known as the Administrator:
![Administrator screenshot](https://i.imgur.com/tnoAENw.png)

------------

<a name=""installation-and-upgrade""></a>
## 3. Installation and Upgrade
Mirth Connect installers are available for individual operating systems (.exe for Windows, .rpm and .sh for Linux, and .dmg for Mac OS X). Pre-packaged distributions are also available for individual operating systems (ZIP for Windows, tar.gz for Linux, and tar.gz for Mac OS X). The installer allows you to automatically upgrade previous Mirth Connect installations (starting with version 1.5).

Mirth Connect installers also come with the option to install and start a service that will run in the background. You also have the option of installing and running the Mirth Connect Server Manager, which allows you to start and stop the service on some operating systems, change Mirth Connect properties and backend database settings, and view the server logs.

An optional Mirth Connect Command Line Interface can be installed, allowing you to connect to a running Mirth Connect Server using a command line. This tool is useful for performing or scripting server tasks without opening the Mirth Connect Administrator.

The Mirth Connect Administrator Launcher can also be installed, allowing you to manage connections to multiple Mirth Connect servers and configure options such as Java runtime, max heap size, and security protocols.

After the installation, the Mirth Connect directory layout will look as follows:

- /appdata/mirthdb: The embedded database (Do NOT delete if you specify Derby as your database). This will be created when the Mirth Connect Server is started. The path for appdata is defined by the dir.appdata property in mirth.properties.
- /cli-lib: Libraries for the Mirth Connect Command Line Interface (if installed)
- /client-lib: Libraries for the Mirth Connect Administrator
- /conf: Configuration files
- /custom-lib: Place your custom user libraries here to be used by the default library resource.
- /docs: This document and a copy of the Mirth Connect license
- /docs/javadocs: Generated javadocs for the installed version of Mirth Connect. These documents are also available when the server is running at `http://[server address]:8080/javadocs/` (i.e. `http://localhost:8080/javadocs/`).
- /extensions: Libraries and meta data for Plug-ins and Connectors
- /logs: Default location for logs generated by Mirth Connect and its sub-components
- /manager-lib: Libraries for the Mirth Connect Server Manager (if installed)
- /public_html: Directory exposed by the embedded web server
- /server-launcher-lib: Libraries in this directory will be loaded into the main Mirth Connect Server thread context classloader upon startup. This is required if you are using any custom log4j appender libraries.
- /server-lib: Mirth Connect server libraries
- /webapps: Directory exposed by the embedded web server to host webapps

------------

<a name=""starting-mirth-connect""></a>
## 4. Starting Mirth Connect
Once Mirth Connect has been installed, there are several ways to connect to launch the Mirth Connect Administrator. On a Windows installation, there is a Mirth Connect Administrator item in the Start Menu which launches the application directly.

If the option is not available, you can connect to the Mirth Connect Administrator launch page which by default should be available at `http://[server address]:8080` (i.e. `http://localhost:8080`). It is recommended to use the Administrator Launcher to start the Administrator, which can be downloaded by clicking on the Download Administrator Launcher button. Clicking the Launch Mirth Connect Administrator button will download the Java Web Start file for your server. Opening the file with the Administrator Launcher connects you to the server, which will be listening on `https://[server address]:8443` (i.e. `https://localhost:8443`). 

If running a new installation, the default username and password for the login screen is admin and admin. This should be changed immediately for security purposes.

If you are launching the administrator for the first time, you will notice that the libraries for the Mirth Connect Administrator will be loaded. This feature allows you run the Administrator from any remote Mirth Connect server without having to download and install a separate client.

You may also notice a security warning when starting the administrator (dialog box depends on browser being used). This is because by default Mirth Connect creates a self-signed certificate for its web server. For now click Run to continue launching the administrator, but check out the User Guide for instructions on how to replace the certificate.

------------

<a name=""java9""></a>
## 5. Running Mirth Connect in Java 9 or greater
In order to run Mirth Connect in Java 9 or greater, copy the options from `docs/mcservice-java9+.vmoptions` and append them to either mcserver.vmoptions or mcservice.vmoptions, depending on your deployment. Then restart Mirth Connect.

To run the Mirth Connect Command Line Interface, create a new file named mccommand.vmoptions in the Mirth Connect root directory. Copy all of the options from `docs/mcservice-java9+.vmoptions` into mccommand.vmoptions and save before launching the Command Line Interface.

------------

<a name=""java-licensing""></a>
## 6. Java Licensing
In 2019, Oracle significantly changed licensing for official Oracle Java releases. You must now purchase a license in order to receive updates to the commercial version of Oracle Java. In response to this change, we officially added support for OpenJDK in Mirth Connect. OpenJDK receives free updates from Oracle for a period of 6 months following each release. While the Oracle OpenJDK distribution is recommended for use with Mirth Connect, we strive to support third-party OpenJDK distributions as well such as AdoptOpenJDK, Azul Zulu and Amazon Corretto. Third party distributions may receive extended release updates from their respective communities, but these are not guaranteed.

------------

<a name=""license""></a>
## 7. License
Mirth Connect is released under the [Mozilla Public License version 2.0](https://www.mozilla.org/en-US/MPL/2.0/ ""Mozilla Public License version 2.0""). You can find a copy of the license in `server/docs/LICENSE.txt`.

All licensing information regarding third-party libraries is located in the `server/docs/thirdparty` folder.
"
9,OCA/vertical-medical,,"
[![Runboat](https://img.shields.io/badge/runboat-Try%20me-875A7B.png)](https://runboat.odoo-community.org/builds?repo=OCA/vertical-medical&target_branch=14.0)
[![Pre-commit Status](https://github.com/OCA/vertical-medical/actions/workflows/pre-commit.yml/badge.svg?branch=14.0)](https://github.com/OCA/vertical-medical/actions/workflows/pre-commit.yml?query=branch%3A14.0)
[![Build Status](https://github.com/OCA/vertical-medical/actions/workflows/test.yml/badge.svg?branch=14.0)](https://github.com/OCA/vertical-medical/actions/workflows/test.yml?query=branch%3A14.0)
[![codecov](https://codecov.io/gh/OCA/vertical-medical/branch/14.0/graph/badge.svg)](https://codecov.io/gh/OCA/vertical-medical)
[![Translation Status](https://translation.odoo-community.org/widgets/vertical-medical-14-0/-/svg-badge.svg)](https://translation.odoo-community.org/engage/vertical-medical-14-0/?utm_source=widget)

<!-- /!\ do not modify above this line -->

# Open Source Healthcare System for Odoo

TODO: add repo description.

<!-- /!\ do not modify below this line -->

<!-- prettier-ignore-start -->

[//]: # (addons)

This part will be replaced when running the oca-gen-addons-table script from OCA/maintainer-tools.

[//]: # (end addons)

<!-- prettier-ignore-end -->

## Licenses

This repository is licensed under [AGPL-3.0](LICENSE).

However, each module can have a totally different license, as long as they adhere to Odoo Community Association (OCA)
policy. Consult each module's `__manifest__.py` file, which contains a `license` key
that explains its license.

----
OCA, or the [Odoo Community Association](http://odoo-community.org/), is a nonprofit
organization whose mission is to support the collaborative development of Odoo features
and promote its widespread use.
"
10,HealthCatalyst/healthcareai-r,R,"---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit the .Rmd and knit it to generate the .md. -->

```{r, include = FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = ""# >"",
                      fig.height = 3, fig.width = 6, dpi = 96,
                      fig.path = ""man/figures/README-"")
options(tibble.print_max = 5)
library(healthcareai)
set.seed(6751)
```

# healthcareai <img src=""man/figures/logo.png"" align=""right"" />

[![Appveyor Build Status](https://ci.appveyor.com/api/projects/status/0xrpe233o9a16l4l/branch/master?svg=true)](https://ci.appveyor.com/project/CatalystAdmin/healthcareai-r/) 
[![Travis-CI Build Status](https://travis-ci.org/HealthCatalyst/healthcareai-r.svg?branch=master)](https://travis-ci.org/HealthCatalyst/healthcareai-r) 
[![codecov badge](https://codecov.io/gh/HealthCatalyst/healthcareai-r/branch/master/graph/badge.svg)](https://codecov.io/gh/HealthCatalyst/healthcareai-r) 
[![CRAN_Status_Badge](https://www.r-pkg.org/badges/version-last-release/healthcareai)](https://cran.r-project.org/package=healthcareai)
[![CRAN downloads badge](https://cranlogs.r-pkg.org/badges/grand-total/healthcareai)](https://cranlogs.r-pkg.org/badges/last-week/healthcareai)
[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://github.com/HealthCatalystSLC/healthcareai-r/blob/master/LICENSE)
[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.999334.svg)](https://doi.org/10.5281/zenodo.999334)

## Overview

The aim of `healthcareai` is to make machine learning in healthcare as easy as possible. It does that by providing functions to:

- Develop customized, reliable, high-performance machine learning models with minimal code
- Easily make and evaluate predictions and push them to a database
- Understand how a model makes its predictions
- Make data cleaning, manipulation, imputation, and visualization as simple as possible

## Usage

`healthcareai` can take you from messy data to an optimized model in one line of code:

```{r, message = FALSE}
models <- machine_learn(pima_diabetes, patient_id, outcome = diabetes)
models
```

Make predictions and examine predictive performance:

```{r plot_predictions}
predictions <- predict(models, outcome_groups = TRUE)
plot(predictions)
```

## Learn More

For details on what's happening under the hood and for options to customize data preparation and model training, see [Getting Started with healthcareai](https://docs.healthcare.ai/articles/site_only/healthcareai.html) as well as the helpfiles for individual functions such as `?machine_learn`, `?predict.model_list`, and `?explore`. 

Documentation of all functions as well as vignettes on various uses of the package are available at the package website: https://docs.healthcare.ai/.

Also, be sure to read our [blog](http://healthcare.ai/blog/) and watch our [broadcasts](https://www.youtube.com/channel/UCGZUobs_x712KbcL6RSzfnQ) to learn more about what's new in healthcare machine learning and how we are using this toolkit to put machine learning to work in real healthcare systems.

## Get Involved

We have a [Slack community](https://healthcare-ai.slack.com/) that is a great place to introduce yourself, share what you're doing with the package, ask questions, and troubleshoot your code.

### Contributing

If you are interested in contributing the package (great!), please read the [contributing](https://github.com/HealthCatalyst/healthcareai-r/blob/master/CONTRIBUTING.md) guide, and look for [issues with the ""help wanted"" tag](https://github.com/HealthCatalyst/healthcareai-r/labels/help%20wanted). Feel free to tackle any issue that interests you; those are a few issues that we feel would make a good place to start.

### Feedback

Your feedback is hugely appreciated. It is makes the package work well and helps us make it more useful to the community. Both feature requests and bug reports should be submitted as [Github issues](https://github.com/HealthCatalyst/healthcareai-r/issues/new). 

**Bug reports** should be filed with a [minimal reproducable example](https://gist.github.com/hadley/270442). The [reprex package](https://github.com/tidyverse/reprex) is extraordinarily helpful for this. Please also include the output of `sessionInfo()` or better yet, `devtools::session_info()`.

## Legacy

Version 1 of `healthcareai` has been retired. You can continue to use it, but its compatibility with changes in the R ecosystem are not guaranteed. You should always be able to install it from github with: `install.packages(""remotes""); remotes::install_github(""HealthCatalyst/healthcareai-r@v1.2.4"")`.

For an example of how to adapt v1 models to the v2 API, check out the [Transitioning vignettes](https://docs.healthcare.ai/articles/site_only/transitioning.html).
"
11,acoravos/healthcare-blockchains,,"_UPDATE: As of July 25, 2018, we have combined efforts with the Mt Sinai [Center for Biomedical Blockchain Research](http://biomedicalblockchain.org/) to launch an interactive landscape map and open-source registry of biomedical blockchains. [Check out the map](https://db.biomedicalblockchain.org/), and submit a new project [here](https://db.biomedicalblockchain.org/submit)._

_Learn more about why we took on this project in our [STAT News July 2018 Op-Ed](https://www.statnews.com/2018/07/25/blockchains-biomedicine-health-care-buyer-be-informed/)._

# Where are the healthcare-related blockchains?
![healthcare blockchain](healthcare-blockchain.png)
We've drafted an open-source landscape map for healthcare-related blockchains. This repository was inspired by conversations with [Paul](https://github.com/pfletcherhill) from [PatientBank](https://www.patientbank.us) and Chris from [Hashed Health](https://hashedhealth.com). We wanted to answer the question: *Who is working on blockchain-related technologies for our industry?*

## Overview & Methodology
There's a lot of opportunity to use blockchain technologies in healthcare -- [and there are a lot of myths, too](https://blog.andreacoravos.com/myth-busting-can-a-blockchain-save-healthcare-d398cdebf0c1).

We put together a first cut of this map and wanted to open it up to the community to share updates. Many of the companies on this list are early stage (e.g., vaporware). Over time, we hope to see more projects in production, but few are ready yet.

![landscape-map](hc-landscape-map-v14.png)

Have a better way of organizing the landscape? Did we miss a company? Submit a pull request. You can fork the [landscape map slide (Google Slides)](https://docs.google.com/presentation/d/1yJ9d4w0HpSJ8Wccc3hQQGNmZmqCSwExiFOFWXPVaPvY/edit?usp=sharing). *To add your company to the map, please add your logo to the [Logos folder](https://github.com/acoravos/healthcare-blockchains/tree/master/logos) when making a pull request or else we will be unable to accept your request.*

## Healthcare Projects using Blockchain Technologies
*Projects listed in alphabetical order*

To update this list, submit a pull request.

|  Project  | Background (400 characters or less) | Contact |
|:---|:---|:---|
|[Accenture](https://www.accenture.com/us-en/insight-perspectives-health-healthcare-innovation) | Accenture is a global professional services company that includes strategy, consulting, digital technology and operations services. Accenture partnered with Microsoft and Avanade to develop an identity prototype based on blockchain technology that could provide a digital identity for 1.1 billion people who don't have a formal ID. ||
|[Amchart](https://amchart.io/) | AMCHART is a patient driven EHR on a hybrid public/private blockchain with AI for analytics and an incentive drive model for better outcomes. The incentive drive model is based on maintenance of health records, wellness program participation, population health, and data sharing with certified partners for analytics and proactive healthcare management. |@AMCHART4ALL|
|[Astri](https://www.astri.org/) | The Chinese government formed Astri, formally known as the Hong Kong Applied Science and Technology Research Institute. Astri developed a health technology platform that aims to drive disruption in the traditional healthcare field with preventative health monitoring, medical computing and diagnostics.|corporate@astri.org|
|[BitMark](https://bitmark.com/) | UC Berkeley and Bitmark partner to bring data donation to public health studies. Bitmark technology allows users to take ownership of their digital lives and help advance the frontiers of public health. Read this [Medium post](https://blog.bitmark.com/uc-berkeley-and-bitmark-partner-to-bring-data-donation-to-public-health-studies-3e9a17891432) on the BitMark UC Berkeley partnership. |support@bitmark.com|
|[BLOCK M.D.](https://www.block-md.com/) | “BLOCK M.D.” is the platform for Health Information Exchange (HIE) and Electronic Health Records (EHR) on enterprise-grade, permissioned-based blockchain technology. This platform enables secure, high-data-integrity interoperability across hospitals, healthtech startups, labs, insurances, regulators and, definitely, patients through well-defined API and data standard. The company is partnering with Thai government for trial in 2018. |hello@smartcontractthailand.com|
|[Blockchain Health](https://blockchainhealth.co/) | Blockchain Health is a software company that provides healthcare organizations with HIPAA-compliant blockchain solutions. Users can share health data with researchers using the integrated platform, which creates a tamperproof chain of information custody.|info@blockchainhealth.co|
|[BlockCypher](https://blockcypher.com)|BlockCypher provides blockchain agnostic web services and infrastructure. Instead of forcing everyone to use one blockchain, BlockCypher enables healthcare organizations and patients to leverage multiple blockchains-- and use the blockchain best suited for a particular use case. For example, BlockCypher enables users to use the Patientory network to manage medical information and pay for services or medication using the Dash network. BlockCypher also provides a proof of patient identity across blockchains, e.g. Ethereum and Dash blockchains.|karen@blockcypher.com|
|[Blockpharma](https://www.blockpharma.com/) | Blockpharma is a French start-up focused on solutions to trace drug sales online. Blockpharma developed an application programming interface that can plug into pharmaceutical companies' information systems, so when the companies release product information and QR codes, the blockchain records subsequent transactions.|contact@blockpharma.com|
|[Bloq](http://bloq.com/) | Bloq produces enterprise grade blockchain technologies to organizations across industries. The company's bloqEnterprise software solution allows users to create, test, update and customize permissioned blockchains; bloqThink provides the strategic architecting, design, development and education for bloqEnterprise; and bloqLabs provides space for blockchain research and testing.|hello@bloq.com|
|[Bowhead Health](https://bowheadhealth.com/) | The Bowhead platform comprises of the Bowhead device which monitors a customer’s biometric data to dispense personalized supplements and medicine. The patent pending “Anonymized Health Token” allows customers and Bowhead token holders to be compensated for the leasing of medical data, and patients have full control of this by means of smart contracts. We believe patient data is some of the most valuable data in the world. The first health survey game is due during the third quarter of 2017 and Bowhead hardware device trial for 200 people due in the second quarter of 2018.||
|[Bron.tech](https://bron.tech/) | Bron.tech uses blockchain powered by Ethereum, a decentralized platform for applications, to create a decentralized infrastructure for data wallets. The company distributes data storage and ensures integrity while also rewarding users with a native digital currency managed on the blockchain. Users contribute data in exchange for the company's digital currency, cash or offers from business partners.|info@bron.tech|
|[burstIQ](http://www.burstiq.com/) | Founded in 2015, burstIQ's platform leverages blockchain and machine intelligence to bring together disparate data sources into a unified, HIPAA-compliant data repository. The platform is fully operational with multiple business customers; in 2016, the platform processed 25 billion data points. BurstIQ's HealthWallet allows users to buy, sell, donate, license or loan data; the LifeGraph platform brings together an individual's health data in one place and allows users to manage data through smart contracts. BurstChain is the company's big data blockchain platform for securely managing large, complex health data sets.||
|[CareChain](https://www.carechain.io) | CareChain is a European consortium to establish public permissioned infrastructure to manage health data owned and controlled by no one except the rightful owners - the individuals. |info@carechain.io|
|[Chronicled](https://www.chronicled.com/) | Chronicled launches pharma initiative.  Blockchain startup Chronicled and LinkLab have launched The MediLedger Project, a joint venture aimed at exploring blockchain solutions for the pharma industry. Genentech, a member of the Roche group, Pfizer, AmerisourceBergen, and McKesson have already signed on.|support@chronicled.com|
|[Chemonics](http://www.chemonics.com/Pages/Home.aspx) | Chemonics is an international development consulting firm spanning 70 countries and industries. In October 2016, Chemonics and BanQu partnered to establish the Blockchain for Development Solutions Lab to build, test and scale blockchain solutions that aim to reduce poverty and increase the effectiveness of social programs.||
|[CoverUS](https://www.coverus.io)| CoverUS is a social venture that leverages blockchain and other technologies to put people in control of their personal health data, helping to close the financial gap in healthcare and promote greater efficiency in the health systems that are of vital importance to society. ||
|[Chronicled](https://www.chronicled.com/) | Chronicled launches pharma initiative.  Blockchain startup Chronicled and LinkLab have launched The MediLedger Project, a joint venture aimed at exploring blockchain solutions for the pharma industry. Genentech, a member of the Roche group, Pfizer, AmerisourceBergen, and McKesson have already signed on.|support@chronicled.com|
|[Curisium](https://www.curisium.com/)|The Curisium platform deploys blockchain and secure computation technologies to allow payers, providers and life science companies to engage in patient-centric value-based contracts.|info@curisium.com|
|[DeepMind Health](https://deepmind.com/blog/trust-confidence-verifiable-data-audit/)| Google's DeepMind Health is working on a blockchain-like [""Verifiable Data Audit""](https://deepmind.com/blog/trust-confidence-verifiable-data-audit/) to ensure auditability, the ability to show and justify if logs are challenged. DeepMind sees Verifiable Data Audit as a powerful complement to this scrutiny, giving partner hospitals an additional real-time and fully proven mechanism to check how DeepMind is processing data.||
|[Doc.AI](https://doc.ai/) | Doc.AI's Robo-Genomics platform is a deep conversational agent designed to improve genetic data comprehension and provide decision support. The agent can converse on disease, traits, pharmacogenomics and family planning. Doc.Ai's founder Walter De Brouwer was one of three parties that executed the first life insurance contract on the public blockchain with bitcoin in January 2017.|info@doc.ai|
|[EncrypGen](https://www.encrypgen.com/)|Encrypgen provides next generation software for genomic data empowering patients and donors, facilitating health, business, and science in a safe environment.|drkoepsell@encrypgen.com|
|[Factom](https://www.factom.com/) | Factom is a blockchain-as-a-service technology company that received $8 million in Series A funding in April 2017. In November 2016, the Bill and Melinda Gates Foundation awarded Factom a grant to develop an infrastructure for medical records on the company's blockchain.||
|[Gem](https://gem.co/health/) | Gem is an enterprise blockchain company. The GemOS enterprise platform for healthcare allows all stakeholders secure access to shareable data with the right permissions. The platform is in compliance with HIPAA, streamlining communication along the continuum of care. Gem entered into a partnership with Philips in 2016 to explore how blockchain can support the patient-centered approach to care. At Gem, we're building towards a blockchain network for the global community of companies that take part in the continuum of healthcare. Blockchain technology addresses the trade-off between personalized care and operational costs by connecting the ecosystem to universal infrastructure. Shared infrastructure allows us to create global standards without compromising privacy and security.|hello@gem.co|
|[Guardtime](https://guardtime.com/) | Guardtime's platform is designed for data and systems security at the industrial level. The company partnered with the Estonian eHealth Foundation in February 2016 to accelerate the adoption of blockchain-based transparency and auditable lifecycle management for patient records. The partnership integrated KSI blockchain with existing Oracle databases for increased security, transparency, auditability and governance for electronic systems and patient records.||
|[Hashed Health](https://hashedhealth.com/) | Hashed Health is a blockchain development studio focused on building healthcare applications within a product-focused collaborative ecosystem. To empower its enterprise partners, Hashed Health provides value-added services such as product management, product development, business advisory, education, and technology support services for blockchain solutions and distributed networks.Based in Nashville, Tennessee, Hashed Health’s healthcare experts focus on ensuring that business problems drive the appropriate technical solutions. By convening existing networks with engaged developer communities actively exploring, piloting, and developing applications, we are able to launch new more effective and novel solutions.|info@hashedhealth.com|
|[healthbase](https://www.healtbase.digital) | healthbase started as an EMR software for dentists called smiledoc. With the prinicpals of creating a strong user experience to outclass the current legacy softwares on the market the co-founders realized that using blockchain would help bring this concept to a larger population. They have currently branched out to the larger EMR market to capture with the goal of allowing a patient to hold their own medical date as they move to different healthprofessionals. With a strong belief in userexperience and a backend that encorporates IPFS and the ethereum network healthbase is a project to watch carefully. Join our [Telegram](https://t.me/joinchat/Fsvr7g48R1utm-ajn0jaTw) to join in on our conversation.|info@healthbase.digital| 
|[Health Wizz](https://www.healthwizz.net/) | Health Wizz is a wellness application platform that acquired healthcare blockchain company kreateloT in January 2017. The combined company is working on Mercatus, a platform allowing individuals to build their own digital health portfolio and grant access to medical researchers, health data scientists, pharmaceutical companies and others in one marketplace to advance precision medicine. Mercatus would allow users to write smart contracts on Ethereum blockchain to trade health data for crypto-currency.||
|[Healthcoin](https://www.healthcoin.com/) (A ConsenSys Project) | Healthcoin is the world's first blockchain-enabled platform for diabetes prevention. Our mission is to allow employers, insurers and governments across the globe to incentivize and manage their population's lifestyle change. Unlike the vast majority of rewards programs, Healthcoin is biomarker-based. We measure the actual blood lab indicators of disease, rather than just correlates like steps or stress. Our blockchain uses these biomarkers to generate tokenized ""prevention certificates"" that any (permissioned) stakeholder can verify and reward. By accumulating biomarkers on the blockchain, we also create innovative data analytics: patient-owned health records with data viz, population health management tools, and a potentially vast longitudinal research trial.|info@healthcoin.com|
|[HealthCombix](http://www.healthcombix.com/) | HealthCombix's platform is a token-based healthcare payment and risk management network enabling payments, data asset monetization and risk adjustment. The platform preserves digital privacy while allowing for interoperable data exchange, giving patients and providers control over the data. The company believes blockchain technology will allow consumers to control the brokerage of their data for research, precision health, clinical trials, payment and disease intervention.|disrupt@healthcombix.com|
|[Health Linkages](http://healthlinkages.com/)|Health Linkages is the Data Provenance Company. We use blockchain-inspired technology to enable healthcare institutions to trust, protect and comfortably share their data.|info@HealthLinkages.com|
|[Hearthy](https://hearthy.co/) | Hearthy wants to create a decentralized, open and sustainable ecosystem to improve health care access to everyone, regardless of income. Hearthy’s ecosystem will make healthcare more efficient, agnostic to jurisdiction and patient-centered.|
|[HIE of One](https://http://hieofone.org/)|HIE of One is a free software project developing tools for patients to manage their own health records.[1] HIE stands for Health Information Exchange, an electronic network for sharing health information across different organizations, hospitals, providers, and patients. This is one of a growing number of tools for encrypted data exchange within the health care sphere. A proposal for using HIE of One in conjunction with blockchain technology was reviewed by the US Office of the National Coordinator (ONC), winning an award from the ONC. Code integrating Consensys uPort is on their GitHub.|agropper@healthurl.com|
|[HIT Foundation](https://hit.foundation/) | HIT Foundation offers an online marketplace for personal health data that allows users and patients to trace data usage and participate in its monetization. It is the first ecosystem that allows everybody to get paid for health information instead of paying others to process or store it. The distributed system supports the global execution of new or existing business cases for information seekers on top of the HIT platform without the need for intermediaries. |info@hit.foundation|
|[Hyperledger](https://www.hyperledger.org/) | The Hyperledger Healthcare Work Group identifies opportunities for open source software development projects to host on Hyperledger, an operating system for marketplaces, data sharing networks, micro-currencies and decentralized digital communities. In May 2017, Hyperledger hosted a Hyderabad Meetup to discuss the most beneficial blockchain applications in healthcare.||
|[IBM Blockchain](https://www.ibm.com/blockchain/) | IBM Blockchain is the first managed service for Hyperledger Fabric, enabling the creation of blockchain business networks that owners can control and distribute across different organizations. In August 2016, IBM won the HHS Office of the National Coordinator of Health Information Technology's blockchain health IT ideation challenge with a paper describing the potential impact blockchain could have on resolving interoperability, scalability and privacy challenges in healthcare.||
|[Iryo](https://iryo.io/)|Iryo network is the world's first participatory healthcare ecosystem build on standardised zero-knowledge electronic health record storage. Disrupting the landscape of traditional health IT by promoting standardised health-data archetypes, redefining medical data ownership and securing from unauthorised access.|info@iryo.io|
|[Luna](https://www.lunadna.com/)|A genomic and medical research database powered by the blockchain. Luna is a community owned database that rewards individuals Luna Coins for contributing their DNA and other medical information.|info@lunaDNA.com|
|[Lympo](https://lympo.io/)|Lympo.io is a fitness wallet that will utilise the data users track on their smartphones and wearables to reward LYM tokens for achieved fitness and mindfulness goals and build a healthy lifestyle ecosystem based on user-controlled fitness data. Its players will range from health insurances and employers incentivizing healthy lifestyle to developers submitting new data applications.|ada@lympo.io|
|[MediBloc](https://medibloc.org/) | MediBloc is creating a decentralized healthcare information ecosystem on blockchain where medical records can be kept safely and securely transferred by their rightful owners, the patients and not the hospitals.  MediBloc is the first healthcare blockchain company that targets Asia where PHR disruption makes much more sense than the US or European PHR market.||
|[Medicalchain](https://medicalchain.com/en/) | Medicalchain uses blockchain technology to store health records securely so physicians, hospitals, laboratories, pharmacists and health insurers can request a patient's permission to access the record as well as record transactions on the distributed ledger. Medicalchain is set to launch in September 2017.| contact@medicalchain.com |
|[Medichain](https://medichain.online/) | MediChain gives patients ownership of their own medical data. MediChain is a distributed ledger for patient’s medical data. It allows patients to store their own data in a secure way and gives access to specialists anywhere regardless of the payer network or EMR (Electronic Medical Record) used.| info@medichain.online |
|[MedRec](https://www.media.mit.edu/research/groups/1454/medrec) | Graduate student researchers at Massachusetts Institute of Technology in Boston developed MedRec, a system for managing medical records using the Ethereum, a decentralized platform for applications. MedRec is designed for patients to control their medical data, including clinical EHR records and data from personal health wearables like Fitbit. Patients can securely allow healthcare providers, researchers and family members to access their data. Medical researchers can also mine the data to sustain the blockchain authentication log and receive anonymous medical metadata in return.||
|[Microsoft](https://azure.microsoft.com/en-us/solutions/blockchain/) | In June, Microsoft partnered with Accenture to build a blockchain prototype for healthcare as well as other industries. The blockchain will create a digital identity for 1.1 billion people around the world who don't have a formal identity, including refugees. The current model builds on Accenture's blockchain and operates on Microsoft Azure's cloud platform.||
|[MintHealth](https://www.minthealth.io/) | MintHealth announced the launch of its self-sovereign health record platform at the Connected Health Conference in Boston in October 2017. Powered by blockchain technology, the service allows patients to access their health records in real-time through a mobile or web app, and features a specialized digital currency as an incentive for preferred patient behaviors.|info@minthealth.io|
|[Netki](https://netki.com/) | Netki aims to support blockchain use with the Open Source, Open Standards tools for digital identity. The company removes risk and compliance barriers to blockchain projects. In May 2017, Netki launched a digital identity service to make blockchain safe for business, finance and healthcare applications. The Digital ID works across public and private blockchains to reduce risk associated with blockchain transactions.||
|[NeuroMesh](http://www.neuromesh.co/) | A vaccine for your IoT. Neuromesh uses the Bitcoin blockchain to protect expensive equipment like X-Rays and MRI machines from attacks.||
|[OPAL/Enigma](https://www.trust.mit.edu/projects) | Published a paper on Blockchain and Health IT: Algorithms, Privacy and Data. Check out [the whitepaper](https://www.healthit.gov/sites/default/files/1-78-blockchainandhealthitalgorithmsprivacydata_whitepaper.pdf). | |
|[OpenMined](https://openmined.org/) | The OpenMined project is volunteer-only, open-source project aiming to create the world’s largest decentralized network of encrypted personal information. In this world, the user gets to own their information and store it themselves, while data scientists and developers pay for anonymized access to this information. The community has started to explore healthcare applications. Join the [Slack](https://openmined.slack.com/) for more details. | |
|[Patientory](https://patientory.com/) | Patientory was founded in 2016 through the Boomtown Health-Tech Accelerator in Boulder, Colo. Patientory collaborates with Denver-based Colorado Permanente Medical Group, a member of Oakland, Calif.-based Kaiser Permanente. Patientory allows users to create profiles on a mobile app to securely store, manage and share medical information. The solution is compatible with Epic, Cerner, Allscripts and Meditech, among other EHR systems.|info@patientory.com|
|[Peer Ledger](https://peerledger.com/) | Peer Ledger provides an identity Bridge product as an administrator portal to enable existing known IDs to be tightly coupled with blockchain user IDs, and ID management such as revocation, delegation, multiple factor authentication, registering/blacklisting of blockchain applications, and the secure management of private keys. The Bridge also provides a user portal to sign with blockchain keys (e.g. Hyperledger, Bitcoin, and Ethereum keys), and to create auxiliary workflows e.g. sign to consent or approve. This product enables organizations to on-board existing known users securely and conveniently on their corporate blockchain applications when those come into play later in 2018 - 2020. We have proven the product out in a collaboration with SAFE-BioPharma and Zentry/Synchronoss via strongly linking Verizon Universal IDs with blockchain IDs.|sales@peerledger.com|
|[PointNurse](https://www.pointnurse.com/) | Founded in 2014, PointNurse is a virtual and on-demand care platform that allows nurses to lead consumer-focused care outside of the hospital and clinic setting. The platform is a blockchain-based digital community enabling licensed professionals to engage in secure and private conversations with patients in remote locations.|team@pointnurse.com|
|[PokitDok](https://pokitdok.com/) | PokitDok provides a secure software development platform for the business of health. The company powers DokChain, a distributed network of transaction processors operating on financial and clinical data across the healthcare industry, integrated to PokitDok's clearinghouse and API platform with Identity, Personal Health Records and Crypto Asset framework components, as well as client frameworks for mobile and web. As of March 2017, the company had raised $48 million to develop DokChain.||
|[ProofWork](https://www.proof.work/)| Leveraging blockchain immutable trust to form the world's first patient-first healthcare ecosystem. We create one single version of truth in healthcare, always in sync. Practice management. Electronic Health Records. Medical research data exchange. ||
|[ScalaMed](http://www.scalamed.com/) | ScalaMed believes in centering and empowering the consumer on their healthcare journey. ScalaMed is building a scalable, integrated and secure platform for managing healthcare transactions and data. ScalaMed is beginning its healthcare revolution through providing a decentralized application for patients, doctors and pharmacists to manage, prescribe and dispense prescription medicines.||
|[Spiritus](http://www.spirituspartners.com/)|Spiritus offers cloud-based assurance software for safe, secure and compliant use of critical assets at the point of use and accountability. Overcome costly, inefficient siloes and gain necessary transparency, verifiability and auditability across an asset's service life through a blockchain-enabled, permissioned network. Rely on Spiritus to be sure an asset's in good order - from service providers and operators, upstream to manufacturers and distributors, and downstream to field service engineers, MROs and specialists in testing, inspection, certification and audit.  With support from the Scottish government, the company has undertaken a pilot with NHS Scotland and a leading cybersecurity researcher at Edinburgh Napier University.|sramonat@spirituspartners.com|
|[SimplyVital Health](https://www.simplyvitalhealth.com/) |Intentionally simple care coordination platform backed by Blockchain technology to create a tamper-proof audit trail. Providers use our tool to support care coordination in Bundle payments and to attain MACRA requirements.| LetsDoThis@simplyvitalhealth.com |
|[Tierion](https://tierion.com/) | Tierion's HashAPI allows developers to anchor up to 100 records per second on the blockchain for free, with time stamping and data security. Tierion was the first company to join Philips' Blockchain Lab to explore using blockchain in healthcare. The company has also partnered with Microsoft to build a service linking data to blockchain to prove the data's integrity and existence.||
|[YouBase](https://www.youbase.io/) | YouBase combines blockchain compatible technologies to deliver a secure and flexible container for independent data. The company's solution allows individuals to maintain their data and identity across networks and share data as they chose. Youbase.io is designed to decentralize sensitive consumer and personal information while compiling a single source of anonymous data.|info@youbase.io|
|[Shivom](http://www.shivom.io/) | Shivom combines genome sequencing, artificial intelligence, cryptogrpahy, and next-gen distributed ledger technology, aiming to build the world's largest genomics & precision medicine ecosystem. Other healthcare companies can 'dock' their solution (Apps, Service) to the Shivom ecosystem. In addition building a genetic counseling network and not-for-profit R&D organization.|info@shivom.io|
|[Zenome Platform](https://zenome.io/)| Zenome is a blockchain-based genomic ecosystem built on the interaction between three different types of information: genomic, personal, and financial data.| |

## Where are the Healthcare ICOs?
Thankfully [vincek39](https://github.com/vincek39) has come to our rescue and he's created a [Google Doc](https://docs.google.com/spreadsheets/d/1TANOZmuYtVhyn1C9PV6YLsOBlQNOEOBExB7u2_Kkork/edit#gid=0) of the ICOs and token sales in the healthcare industry, all 38 of them (as of 12/1/18).
"
12,itachi9604/healthcare-chatbot,Python,"# healthcare-chatbot
a chatbot based on sklearn where you can give a symptom and it will ask you questions and will tell you the details and give some advice.
"
13,prasadseemakurthi/Deep-Neural-Networks-HealthCare,Python,"# Deep Learning in Healthcare and Computational Biology

## NOTE/ANNOUNCEMENT to what we intend to do here!

---------------------------
All this stuff is collected from the github which was not well maintained. I will soon reorganize this to reflect recency (as a lot of work is happening in comp biology that CNNs are using lately -- hopefully CapsNETs too) and some easy to undrstand structure.

Key collaborators and researchers (besides me) will be some budding computational biologists such as [Huadong Liao](https://github.com/naturomics) who did an awesome job with recent Capsule Networks and will work with me to not only do awesome projects across the globe but also work and travel with me to deliver workshops for both for and non-profit organizations.

If you are a researcher, enthusiast or even someone just interested and  want to join computational biology researches with deep learning, then contact me at : tarry.singh@gmail.com

So stay tuned!!!

Thanks,

Tarry Singh

---------------------------

<img src='images/compbio.jpg'>

This is a list of implementations of deep learning methods to biology, originally published on [Follow the Data](https://followthedata.wordpress.com/). There is a slant towards genomics because that's the subfield that I follow most closely.

Please, contribute to this growing list, especially in categories that I haven't covered well! Also, do add your contributions to [GitXiv](http://gitxiv.com/) as well if you can.

You might also want to refer to the [curaterd list of deepbio work](#awesome-deep-biology) below.
* Data driven decision making
* Questions -> Data -> Models/Tools

# Table of Contents
1. [Overview](#overview)
2. [EHR data](#ehr-data)
3. [Insurance claims data](#claims)
4. [Clinical notes](#clinical-notes)
5. [Image data](#image-data)
6. [Time series data](#time-series-data)
7. [Genomics data](#genomics-data)
8. [Deep Learning Computational biology](#deep-computational-biology)
9. [Curated List](#awesome-deep-biology)




## Overview
|Data type|Models/Tools|Applications|
|---|---|---|
|-EHR data <br/>-Insurance claims data |ML(logistic regression,XGBoost)|Predict outcomes (disease, death, readmission etc.)|
|-Clinical notes <br/>-Conversation text data|-Rule based approach(regular expression)<br/>-Deep learning apporach|-Extract concepts from clinical notes <br/>-Knowledge graphs<br/>-Chat-bot<br/>-QA system|
|Medical image data (X-ray, CT, OCR image etc.)|CNN|-Detection: diagnosis of skin cancer lung nodule or diabetic reinopathy<br/>-Segmentation of tumor, histopathology|
|Time series data (EEG, ECG, vital sign data etc.)|HMM,RNN,CNN|-Heart disease<br/>-Sleep disorder(apnea)<br/>-ICU monitoring|
|Genomics data|GATK,QIIME|-Cancer mutation identification<br/>-Biomarker identification<br/>-Durg discovery |
|Other data (hospital operational data)|-ML(regression)<br/>-Queueing model|-Reduce operational cost<br/>-Improve patient experience<br/>-ER wait time and queueing|

## EHR data


|Prediction outcomes|Models/Tools|Data type|Sample size|Reference|Year|
|---|---|---|---|---|---|
|Review||||[Mining electronic health records: towards better research applications and clinical care](https://www.nature.com/nrg/journal/v13/n6/full/nrg3208.html)|2012|
|Review||||[Opportunities and challenges in developing risk prediction models with electronic health records data: a systematic review](https://academic.oup.com/jamia/article/24/1/198/2631444/Opportunities-and-challenges-in-developing-risk)|2016|
|heart failure|-logistic regression<br/>-random forest|longitudinal EHR data|1684 heart failure cases and 13525 matched controls|[Early Detection of Heart Failure Using Electronic Health Records](http://circoutcomes.ahajournals.org/content/9/6/649.long)|2016|
|heart failure (review)||||[Population Risk Prediction Models for Incident Heart Failure](http://circheartfailure.ahajournals.org/content/8/3/438.long)|2015|
|Kidney transplant graft failure|Cox regression|10-years EHR data|69,440 kidney transpants|[A comprehensive risk quantification score for deceased donor kidneys: the kidney donor risk index](https://insights.ovid.com/pubmed?pmid=19623019)|2009|


## Clinical notes
|Prediction outcomes|Models/Tools|Data type|Sample size|Reference|Year|
|---|---|---|---|---|---|
|Review||||[Realizing the full potential of electronic health records: the role of natural language processing](https://academic.oup.com/jamia/article-lookup/doi/10.1136/amiajnl-2011-000501)|2011|
|Review||||[Natural language processing: an introduction](https://academic.oup.com/jamia/article-lookup/doi/10.1136/amiajnl-2011-000464)|2011|
|Negation|Regular expression and rule-based approach|Clinical reports|2060 discharge summaries|[A simple algorithm for identifying negated findings and diseases in discharge summaries](http://www.sciencedirect.com/science/article/pii/S1532046401910299?via%3Dihub)|2001|
|||||[Using electronic health records to drive discovery in disease genomics](https://www.nature.com/nrg/journal/v12/n6/pdf/nrg2999.pdf)||
|NER||discharge summaries|826 notes|[A study of machine-learning-based approaches to extract clinical entities and their assertions from discharge summaries](https://academic.oup.com/jamia/article-lookup/doi/10.1136/amiajnl-2011-000163)|2011|




## Image data
|Prediction outcomes|Models/Tools|Data type|Sample size|Reference|Year|
|---|---|---|---|---|---|
|Diabetic retinopathy|CNN|retinal fundus images|128175 retinal images|[Development and Validation of a Deep Learning Algorithm for Detection of Diabetic Retinopathy in Retinal Fundus Photographs](http://jamanetwork.com/journals/jama/fullarticle/2588763)|2016|
|Skin cancer |CNN|skin images|129,450 skin images|[Dermatologist-level classification of skin cancer with deep neural networks](https://www.nature.com/nature/journal/v542/n7639/full/nature21056.html)|2017|
|Tumor|CNN|Pathology images|400+110 slides|[Detecting Cancer Metastases on Gigapixel Pathology Images](https://arxiv.org/abs/1703.02442)|2017|
|||||[Deep Learning Automates the Quantitative Analysis of Individual Cells in Live-Cell Imaging Experiments](http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005177)||



## Time series data
|Prediction outcomes|Models/Tools|Data type|Sample size|Reference|Year|
|---|---|---|---|---|---|
|sinus rhythm and atrial fibrillation|34-layer convolutional neural network (CNN)|single-lead ECG|-(Train) 64,121 ECG records from 29,163 patients<br/>-(Test) 336 records from 328 unique patients|[Cardiologist-Level Arrhythmia Detection with Convolutional Neural Networks](https://arxiv.org/abs/1707.01836)|2017|
|Hand movements|CNN|sEMG|67 intact subjects and 11 transradial amputees|[Deep Learning with Convolutional Neural Networks Applied to Electromyography Data: A Resource for the Classification of Movements for Prosthetic Hands](http://journal.frontiersin.org/article/10.3389/fnbot.2016.00009/full)|2016|
|Review||ICU data||[Machine Learning and Decision Support in Critical Care](http://ieeexplore.ieee.org/document/7390351/?part=1)|2017|



## Genomics data
|Prediction outcomes|Models/Tools|Data type|Sample size|Reference|Year|
|---|---|---|---|---|---|
|Genetic variants|Exome NGS|NGS&EHR data|50,726 individuals|[Distribution and clinical impact of functional variants in 50,726 whole-exome sequences from the DiscovEHR study](http://science.sciencemag.org/content/354/6319/aaf6814)|2016|
|Familial hypercholesterolemia|Exome NGS|NGS&EHR data|50,726 individuals|[Genetic identification of familial hypercholesterolemia within a single U.S. health care system](http://science.sciencemag.org/content/354/6319/aaf7000)|2016|


## Other
|Prediction outcomes|Models/Tools|Data type|Sample size|Reference|Year|
|---|---|---|---|---|---|
|Drug discovery|LSTM|Assay|12-27 assays|[Low data drug discovery with one-shot learning](http://pubs.acs.org/doi/full/10.1021/acscentsci.6b00367)|2017|
|Tutorial||Image||[Deep learning models for health care: challenges and solutions](http://www-bcf.usc.edu/~liu32/icml_tutorial.pdf)|2017|
|Tutorial||Image||[Deep learning in radiology: recent advances, challenges and future trends](https://ulasbagci.wordpress.com/2016/12/10/deep-learning-in-radiology-rsna-2016/)|2016|
|Tutorial||||[Big data analytics for healthcare](https://www.siam.org/meetings/sdm13/sun.pdf)|2013|
|Tutorial||Image||[Survey of deep learning in radiology](https://healthcare.ai/survey-of-deep-learning-in-radiology/)|2017|
|ER wait time||ER visit time||[Accurate ED Wait Time Prediction](https://web.stanford.edu/~bayati/papers/edwait.pdf)|2017|


## Deep Computational Biology

# deeplearning-biology

This is a list of implementations of deep learning methods to biology, originally published on [Follow the Data](https://followthedata.wordpress.com/). There is a slant towards genomics because that's the subfield that I follow most closely.

Please, contribute to this growing list, especially in categories that I haven't covered well! Also, do add your contributions to [GitXiv](http://gitxiv.com/) as well if you can.

You might also want to refer to the [curaterd list of deepbio work](#awesome-deep-biology) below.

## Table of contents
* [Reviews](#reviews)
* [Chemoinformatics and drug discovery](#chemo)
* [Proteomics](#proteomics)
* [Generic 'omics tools](#omics)
* [Genomics](#genomics)
  - [Gene expression](#genomics_expression)
  - [Predicting enhancers and regulatory elements](#genomics_enhancers)
  - [Methylation](#genomics_methylation)
  - [Single-cell applications](#genomics_single-cell)
  - [Non-coding RNA](#genomics_non-coding)
  - [Population genetics](#genomics_pop)
* [Neuroscience](#neuro)

## Reviews <a name=""reviews""></a>

These are not implementations as such, but contain useful pointers.

**Opportunities And Obstacles For Deep Learning In Biology And Medicine** [[bioRxiv preprint](http://biorxiv.org/content/early/2017/05/28/142760)]

This impressive collaborative review was written completely in the open on [Github](https://github.com/greenelab/deep-review). It is focused on discussing how deep learning may be able to transform patient classification and treatment as well as fundamental biological research in the future, and what the main obstacles are that could prevent it from happening. A lot of interesting points are brought up here. Together with the review listed below, which has a more technical slant, you will get a good overview of how deep learning is used and can be used in biology and medicine.

**Deep learning for computational biology** [[open access paper](http://msb.embopress.org/content/12/7/878)]

This is a very nice review of deep learning applications in biology. It primarily deals with convolutional networks and explains well why and how they are used for sequence (and image) classification.

**Deep learning for health informatics** [[open access paper](http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7801947)]

An overview of several types of deep nets and their applications in translational bioinformatics, medical imaging, ""pervasive sensing"", medical data and public health.

## Chemoinformatics and drug discovery <a name=""chemo""></a>

**Neural graph fingerprints** [[github](https://github.com/HIPS/neural-fingerprint)][[gitxiv](http://gitxiv.com/posts/DFtFytneou3SXLuSM/convolutional-networks-on-graphs-for-learning-molecular)]

A convolutional net that can learn features which are useful for predicting properties of novel molecules; “molecular fingerprints”. The net works on a graph where atoms are nodes and bonds are edges. Developed by the group of Ryan Adams, who co-hosts the very good [Talking Machines](http://www.thetalkingmachines.com/) podcast.

**Deep-learning models for Drug Discovery and Quantum Chemistry** [[github](https://github.com/deepchem/deepchem)][[Python library](http://deepchem.io/)][[preprint](https://arxiv.org/abs/1611.03199)]

This is a ""... [P]ython library that aims to make the use of machine-learning in drug discovery straightforward and convenient"" which checks a lot of boxes when it comes to advanced is deep learning: one-shot learning, graph convolutional networks, learning from less data, and LSTM embeddings. According to the GitHub site, ""DeepChem aims to provide a high quality open-source toolchain that democratizes the use of deep-learning in drug discovery, materials science, and quantum chemistry.""

## Generic 'omics tools <a name=""omics""></a>

**Continuous Distributed Representation of Biological Sequences for Deep Genomics and Deep Proteomics**[[github](https://github.com/ehsanasgari/Deep-Proteomics)][[paper](http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0141287)]

The GitHub summary reads: ""We introduce a new representation for biological sequences. Named bio-vectors (BioVec) to refer to biological sequences in general with protein-vectors (ProtVec) for proteins (amino-acid sequences) and gene-vectors (GeneVec) for gene sequences, this representation can be widely used in applications of deep learning in proteomics and genomics. Biovectors are basically n-gram character skip-gram wordvectors for biological sequences (DNA, RNA, and Protein). In this work, we have explored biophysical and biochemical meaning of this space. In addition, in variety of bioinformatics tasks we have shown the strength of such a sequence representation.""

## Proteomics <a name=""proteomics""></a>

**Pcons2 – Improved Contact Predictions Using the Recognition of Protein Like Contact Patterns** [[web interface](http://c2.pcons.net/)]

Here, a “deep random forest” with five layers is used to improve predictions of which residues (amino acids) in a protein are physically interacting which each other. This is useful for predicting the overall structure of the protein (a very hard problem.)

## Genomics <a name=""genomics""></a>

This category is divided into several subfields.

### Gene expression <a name='genomics_expression'></a>

In modeling gene expression, the inputs are typically numerical values (integers or floats) estimating how much RNA is produced from a DNA template in a particular cell type or condition.

**ADAGE – Analysis using Denoising Autoencoders of Gene Expression** [[github](https://github.com/greenelab/adage)][[gitxiv](http://gitxiv.com/posts/M9Dnc8HbKvNgsSp5D/adage-analysis-using-denoising-autoencoders-of-gene)]

This is a Theano implementation of stacked denoising autoencoders for extracting relevant patterns from large sets of gene expression data, a kind of feature construction approach if you will. I have played around with this package quite a bit myself. The authors initially published a [conference paper](http://www.worldscientific.com/doi/abs/10.1142/9789814644730_0014) applying the model to a compendium of breast cancer (microarray) gene expression data, and more recently posted a paper on [bioRxiv](http://biorxiv.org/content/early/2015/11/05/030650) where they apply it to all available expression data (microarray and RNA-seq) on the pathogen Pseudomonas aeruginosa. (I understand that this manuscript will soon be published in a journal.)

**Learning structure in gene expression data using deep architectures** [[paper](http://biorxiv.org/content/early/2015/11/16/031906)]

This is also about using stacked denoising autoencoders for gene expression data, but there is no available implementation (as far as I could tell). Included here for the sake of completeness (or something.)

**Gene expression inference with deep learning** [[github](https://github.com/uci-cbcl/D-GEX)][[paper](http://biorxiv.org/content/early/2015/12/15/034421)]

This deals with a specific prediction task, namely to predict the expression of specified target genes from a panel of about 1,000 pre-selected “landmark genes”. As the authors explain, gene expression levels are often highly correlated and it may be a cost-effective strategy in some cases to use such panels and then computationally infer the expression of other genes. Based on Pylearn2/Theano.

**Learning a hierarchical representation of the yeast transcriptomic machinery using an autoencoder model** [[paper](http://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-015-0852-1)]

The authors use stacked autoencoders to learn biological features in yeast from thousands of microarrays. They analyze the hidden layer representations and show that these encode biological information in a hierarchical way, so that for instance transcription factors are represented in the first hidden layer.

### Predicting enhancers and regulatory regions <a name='genomics_enhancers'></a>

Here the inputs are typically “raw” DNA sequence, and convolutional networks (or layers) are often used to learn regularities within the sequence. Hat tip to [Melissa Gymrek](http://melissagymrek.com/science/2015/12/01/unlocking-noncoding-variation.html) for pointing out some of these.

**DanQ: a hybrid convolutional and recurrent deep neural network for quantifying the function of DNA sequences** [[github](https://github.com/uci-cbcl/DanQ)][[gitxiv](http://gitxiv.com/posts/aqrWwLoyg75jqNAYX/danq-a-hybrid-convolutional-and-recurrent-deep-neural)]

Made for predicting the function of non-protein coding DNA sequence. Uses a convolution layer to capture regulatory motifs (i e single DNA snippets that control the expression of genes, for instance), and a recurrent layer (of the LSTM type) to try to discover a “grammar” for how these single motifs work together. Based on Keras/Theano.

**Basset – learning the regulatory code of the accessible genome with deep convolutional neural networks** [[github](https://github.com/davek44/Basset)][[gitxiv](http://gitxiv.com/posts/fhET6G7gnBrGS8S9u/basset-learning-the-regulatory-code-of-the-accessible-genome)]

Based on Torch, this package focuses on predicting the accessibility (or “openness”) of the chromatin – the physical packaging of the genetic information (DNA+associated proteins). This can exist in more condensed or relaxed states in different cell types, which is partly influenced by the DNA sequence (not completely, because then it would not differ from cell to cell.)

**DeepSEA – Predicting effects of noncoding variants with deep learning–based sequence model** [[web server](http://deepsea.princeton.edu/job/analysis/create/)][[paper](http://www.nature.com/nmeth/journal/v12/n10/full/nmeth.3547.html)]

Like the packages above, this one also models chromatin accessibility as well as the binding of certain proteins (transcription factors) to DNA and the presence of so-called histone marks that are associated with changes in accessibility. This piece of software seems to focus a bit more explicitly than the others on predicting how single-nucleotide mutations affect the chromatin structure. Published in a high-profile journal (Nature Methods).

**DeepBind – Predicting the sequence specificities of DNA- and RNA-binding proteins by deep learning** [[code](http://tools.genes.toronto.edu/deepbind/)][[paper](http://www.nature.com/nbt/journal/v33/n8/full/nbt.3300.html)]

This is from the group of Brendan Frey in Toronto, and the authors are also involved in the company Deep Genomics. DeepBind focuses on predicting the binding specificities of DNA-binding or RNA-binding proteins, based on experiments such as ChIP-seq, ChIP-chip, RIP-seq,  protein-binding microarrays, and HT-SELEX. Published in a high-profile journal (Nature Biotechnology.)

**DeeperBind - Enhancing Prediction of Sequence Specificities of DNA Binding Proteins** [[preprint](https://arxiv.org/pdf/1611.05777.pdf)]

This is an attempt to improve on DeepBind by adding a recurrent sequence learning module (LSTM) after the convolutional layer(s). In this way, the authors propose to capture a positional dimension that is lost in the pooling step in the original DeepBind design. They claim that benchmarking shows that this architecture leads to superior performance compared to previous work.

**DeepMotif - Visualizing Genomic Sequence Classifications** [[paper](https://arxiv.org/abs/1605.01133)]

This is also about learning and predicting binding specificities of proteins to certain DNA patterns or ""motifs"". However, this paper makes use of a combination of convolutional layers and [highway networks](https://arxiv.org/pdf/1505.00387v2.pdf), with more layers than the DeepBind network. The authors also show how a learned classifier can generate typical DNA motifs by input optimization; applying back-propagation with all the weights held constant in order to find an input pattern that maximally activates the appropriate output node in the network.

**Convolutional Neural Network Architectures for Predicting DNA-Protein Binding** [[code](http://cnn.csail.mit.edu/)][[paper](http://bioinformatics.oxfordjournals.org/content/32/12/i121.full)]

This work describes a systematic exploration of convolutional neural network (CNN) architectures for DNA-protein binding. It concludes that the convolutional kernels are very important for the success of the networks on motif-based tasks. Interestingly, the authors have provided a Dockerized implementation of DeepBind from the Frey lab (see above) and also provide EC2-laucher scripts and code for comparing different GPU enabled models programmed in Caffe.

**PEDLA: predicting enhancers with a deep learning-based algorithmic framework** [[code](https://github.com/wenjiegroup/PEDLA)][[paper](http://biorxiv.org/content/early/2016/01/07/036129)]

This package is for predicting enhancers (stretches of DNA that can enhance the expression of a gene under certain conditions or in a certain kind of cell, often working at a distance from the gene itself) based on heterogeneous data from (e.g.) the ENCODE project, using 1,114 features altogether.

**DEEP: a general computational framework for predicting enhancers** [[paper](http://nar.oxfordjournals.org/content/early/2014/11/05/nar.gku1058.full)][[code](http://cbrc.kaust.edu.sa/deep/)]

An ensemble prediction method for enhancers.

**Genome-Wide Prediction of cis-Regulatory Regions Using Supervised Deep Learning Methods** (and several other papers applying various kinds of deep networks to regulatory region prediction) [[code](https://github.com/yifeng-li/DECRES)] (one [[paper](http://biorxiv.org/content/early/2016/02/28/041616)] out of several)

Wyeth Wasserman’s group have made a kind of [toolkit](https://github.com/yifeng-li/DECRES) (based on the Theano tutorials) for applying different kinds of deep learning architectures to cis-regulatory element (DNA stretches that can modulate the expression of a nearby gene) prediction. They use a specific “feature selection layer” in their nets to restrict the number of features in the models. This is implemented as an additional sparse one-to-one linear layer between the input layer and the first hidden layer of a multi-layer perceptron.

**FIDDLE: An integrative deep learning framework for functional genomic data inference** [[paper](http://biorxiv.org/content/early/2016/10/17/081380)][[code](https://github.com/ueser/FIDDLE)[[Youtube talk](https://www.youtube.com/watch?v=pcLTUsOm5pc&feature=youtu.be&list=PLlMMtlgw6qNjROoMNTBQjAcdx53kV50cS&t=2411)]

The group predicted transcription start site and regulatory regions but claims this solution could be easily generalized and predict other features too. FIDDLE stands for Flexible Integration of Data with Deep LEarning. The idea (nicely explained by the author in the YouTube video above) is to model several genomic signals jointly using convolutional networks. This could be for example DNase-seq, ATAC-seq, ChIP-seq, TSS-seq, maybe RNA-seq signals (as in .wig files with one value per base in the genome).


### Non-coding RNA <a name='genomics_non-coding'></a>

**DeepLNC, a long non-coding RNA prediction tool using deep neural network** [[paper](http://link.springer.com/article/10.1007%2Fs13721-016-0129-2)] [[web server](http://bioserver.iiita.ac.in/deeplnc/)]

Identification of potential long non-coding RNA molecules from DNA sequence, based on k-mer profiles.

### Methylation <a name='genomics_methylation'></a>

**DeepCpG - Predicting DNA methylation in single cells**
[[paper](http://dx.doi.org/10.1186/s13059-017-1189-z)]
[[code](https://github.com/cangermueller/deepcpg)]
[[docs](http://deepcpg.readthedocs.io/en/latest/)]

DeepCpG is a deep neural network for predicting DNA methylation in multiple cells. DeepCpG has a modular architecture, consisting of a recurrent CpG module to account for correlations between CpG sites within and across cells, a convolutional DNA module to extract patterns from a wide DNA sequence window, and a Joint module that integrates the evidence from the CpG and DNA module to predict the methylation state of multiple cells for a target CpG site. DeepCpG yields accurate predictions, enables discovering DNA sequence motifs that are associated with DNA methylation states and cell-to-cell variability, and can be used for analyzing the effect of single-nucleotide mutations on DNA methylation. DeepCpG is implemented in Python and publicly available.

**Predicting DNA Methylation State of CpG Dinucleotide Using Genome Topological Features and Deep Networks** [[paper](http://www.nature.com/articles/srep19598)][[web server](http://dna.cs.usm.edu/deepmethyl/)]

This implementation uses a stacked autoencoder with a supervised layer on top of it to predict whether a certain type of genomic region called “CpG islands” (stretches with an overrepresentation of a sequence pattern where a C nucleotide is followed by a G) is methylated (a chemical modification to DNA that can modify its function, for instance methylation in the vicinity of a gene is often but not always related to the down-regulation or silencing of that gene.) This paper uses a network structure where the hidden layers in the autoencoder part have a much larger number of nodes than the input layer, so it would have been nice to read the authors’ thoughts on what the hidden layers represent.

### Single-cell applications <a name='genomics_single-cell'></a>

**DeepCpG - Predicting DNA methylation in single cells**
[[paper](http://dx.doi.org/10.1186/s13059-017-1189-z)]
[[code](https://github.com/cangermueller/deepcpg)]
[[docs](http://deepcpg.readthedocs.io/en/latest/)]

See above.

**CellCnn – Representation Learning for detection of disease-associated cell subsets**
[[code](https://github.com/eiriniar/CellCnn)][[paper](http://biorxiv.org/content/early/2016/03/31/046508)]

This is a convolutional network (Lasagne/Theano) based approach for “Representation Learning for detection of phenotype-associated cell subsets.” It is interesting because most neural network approaches for high-dimensional molecular measurements (such as those in the gene expression category above) have used autoencoders rather than convolutional nets.

**DeepCyTOF: Automated Cell Classification of Mass Cytometry Data by Deep Learning and Domain Adaptation**[[paper](http://biorxiv.org/content/biorxiv/early/2016/05/31/054411.full.pdf)]

Describes autoencoder approaches (stacked AE and multi-AE) to gating (assigning cells into discrete groups) with mass cytometry (CyTOF).

**Using Neural Networks To Improve Single-Cell RNA-Seq Data Analysis**[[preprint](http://biorxiv.org/content/early/2017/04/23/129759)]

Tests a variety of neural network architectures for obtaining a reduced representation of single-cell gene expression data. Introduces a database of tens of thousands of single-cell profiles which can be queried to infer a cell type or state based on this reduced representation.

**Removal of batch effects using distribution-matching residual networks**[[code](https://github.com/ushaham/BatchEffectRemoval)][[paper](https://academic.oup.com/bioinformatics/article-abstract/doi/10.1093/bioinformatics/btx196/3611270/Removal-of-Batch-Effects-using-Distribution)]

Most high-throughput assays in genomics, proteomics etc. are affected to some extent by systematic technical errors, so-called ""batch effects"". This paper uses a residual neural network to attenuate batch effects by trying to match the distributions of replicate experiments on e.g. single-cell RNA sequencing or mass cytometry. 

### Population genetics <a name='genomics_pop'></a>

**Deep learning for population genetic inference** [[code](https://sourceforge.net/projects/evonet/)][[paper](http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004845)]

**Diet networks: thin parameters for fat genomics** [[manuscript](http://openreview.net/pdf?id=Sk-oDY9ge)]

This weirdly-named paper addresses the frequently encountered problem in genomics where the number of features is much larger than the number of training examples. Here, it is addressed in the context of SNPs (single-nucleotide polymorphisms, genetic variations between individuals). The authors propose a new network parametrization that reduces the number of free parameters using a multi-task architecture which tries to learn a useful embedding of the input features.

## Neuroscience <a name='neuro'></a>

There are potentially lots of implementations that could go here.

**Deep learning for neuroimaging: a validation study** [[paper](http://journal.frontiersin.org/article/10.3389/fnins.2014.00229/abstract)]

**SPINDLE: SPINtronic deep learning engine for large-scale neuromorphic computing** [[paper](http://dl.acm.org/citation.cfm?id=2627625)]

## Awesome Deep Biology

A curated list of deep learning applications in the field of computational biology


- **2012-07** | Deep architectures for protein contact map prediction | *Pietro Di Lena, Ken Nagata and Pierre Baldi* [Bioinformatics](https://doi.org/10.1093/bioinformatics/bts475)

- **2012-10** | Predicting protein residue–residue contacts using deep networks and boosting | *Jesse Eickholt and Jianlin Cheng* | [Bioinformatics](https://doi.org/10.1093/bioinformatics/bts598)

- **2013-03** | DNdisorder: predicting protein disorder using boosting and deep networks | *Jesse Eickholt and Jianlin Cheng* | [BMC Bioinformatics](https://doi.org/10.1186/1471-2105-14-88)

- **2014-06** | Deep learning of the tissue-regulated splicing code | *Michael K. K. Leung, Hui Yuan Xiong, Leo J. Lee and Brendan J. Frey* | [Bioinformatics](https://doi.org/10.1093/bioinformatics/btu277)

- **2014-10** | DANN: a deep learning approach for annotating the pathogenicity of genetic variants  | *Daniel Quang, Yifei Chen and Xiaohui Xie* | [Bioinformatics](https://doi.org/10.1093/bioinformatics/btu703)

- **2014-11** | Pairwise input neural network for target-ligand interaction prediction | *Caihua Wang, Juan Liu, Fei Luo, Yafang Tan, Zixin Deng, Qian-Nan Hu* | [2014 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)](https://doi.org/10.1109/BIBM.2014.6999129)

- **2015-01** | Unsupervised feature construction and knowledge extraction from genome-wide assays of breast cancer with denoising autoencoders. | *Jie Tan, Matt Ung, Chao Cheng, Casey Greene* | [Pacific Symposium on Biocomputing (PSB)](https://doi.org/10.1142/9789814644730_0014) | [Models & Data](http://discovery.dartmouth.edu/~cgreene/da-psb2015/)

- **2015-01** | The human splicing code reveals new insights into the genetic determinants of disease  | *Hui Y. Xiong, Babak Alipanahi, Leo J. Lee, Hannes Bretschneider, Daniele Merico, Ryan K. C. Yuen, Yimin Hua, Serge Gueroussov, Hamed S. Najafabadi, Timothy R. Hughes, Quaid Morris, Yoseph Barash, Adrian R. Krainer, Nebojsa Jojic, Stephen W. Scherer, Benjamin J. Blencowe, Brendan J. Frey* | [Science](https://doi.org/10.1126/science.1254806)

- **2015-03** | Deep Feature Selection: Theory and Application to Identify Enhancers and Promoters | *Yifeng Li, Chih-Yu Chen, and Wyeth W. Wasserman* | [19th Annual International Conference, RECOMB 2015, Warsaw, Proceedings](https://doi.org/10.1007/978-3-319-16706-0_20)

- **2015-05** | Trans-species learning of cellular signaling systems with bimodal deep belief networks | *Lujia Chen, Chunhui Cai, Vicky Chen and Xinghua Lu* | [Bioinformatics](https://doi.org/10.1093/bioinformatics/btv315)

- **2015-05** | Deep convolutional neural networks for annotating gene expression patterns in the mouse brain | *Tao Zeng, Rongjian Li, Ravi Mukkamala, Jieping Ye and Shuiwang Ji* | [BMC Bioinformatics](https://doi.org/10.1186/s12859-015-0553-9)

- **2015-07** | DeepBind: Predicting the sequence specificities of DNA- and RNA-binding proteins by deep learning | *Babak Alipanahi,	 Andrew Delong,	Matthew T. Weirauch & Brendan J. Frey* | [Nature Biotechnology](https://doi.org/10.1038/nbt.3300)

- **2015-08** | Deep learning for regulatory genomics | *Yongjin Park & Manolis Kellis* | [Nature Biotechnology](https://doi.org/10.1038/nbt.3313)

- **2015-08** | DeepSEA: Predicting effects of noncoding variants with deep learning–based sequence model | *Jian Zhou & Olga G. Troyanskaya* | [Nature Methods: Short intro](https://doi.org/10.1038/nmeth.3604) & [Nature Methods](https://doi.org/10.1038/nmeth.3547)

- **2015-08** | Integrative Data Analysis of Multi-Platform Cancer Data with a Multimodal Deep Learning Approach | *Muxuan Liang, Zhizhong Li, Ting Chen, Jianyang Zeng* | [IEEE/ACM Transactions on Computational Biology and Bioinformatics (TCBB)](https://doi.org/10.1109/TCBB.2014.2377729)

- **2015-10** | A deep learning framework for modeling structural features of RNA-binding protein targets | *Sai Zhang, Jingtian Zhou, Hailin Hu, Haipeng Gong, Ligong Chen, Chao Cheng, and Jianyang Zeng* | [NAR](https://doi.org/10.1093/nar/gkv1025)

- **2015-10** | Basset: Learning the regulatory code of the accessible genome with deep convolutional neural networks | *David R. Kelley, Jasper Snoek, John Rinn* | [Biorxiv](https://doi.org/10.1101/028399) | [code](https://github.com/davek44/Basset)

- **2015-10** | Deep Learning for Drug-Induced Liver Injury | *Youjun Xu, Ziwei Dai, Fangjin Chen, Shuaishi Gao, Jianfeng Pei, and Luhua Lai* | [ASC Journal of Chemical Information and Modeling](https://doi.org/10.1021/acs.jcim.5b00238)

- **2016-01** | ADAGE-Based Integration of Publicly Available Pseudomonas aeruginosa Gene Expression Data with Denoising Autoencoders Illuminates Microbe-Host Interactions | [mSystems](https://dx.doi.org/10.1128/mSystems.00025-15) | [code](https://github.com/greenelab/adage)

- **2015-11** | De novo identification of replication-timing domains in the human genome by deep learning | *Feng Liu, Chao Ren, Hao Li, Pingkun Zhou, Xiaochen Bo and Wenjie Shu* | [Bioinformatics](https://doi.org/10.1093/bioinformatics/btv643)

- **2015-11** | Recurrent Neural Network Based Hybrid Model of Gene Regulatory Network | *Khalid Raza, Mansaf Alam* | [Arxiv](https://arxiv.org/abs/1408.5405v2)

- **2015-11** | Continuous Distributed Representation of Biological Sequences for Deep Proteomics and Genomics | *Ehsaneddin Asgari, Mohammad R. K. Mofrad* | [PloS one](http://dx.doi.org/10.1371/journal.pone.0141287)

- **2016-01** | Learning a hierarchical representation of the yeast transcriptomic machinery using an autoencoder model | *Lujia Chen, Chunhui Cai, Vicky Chen and Xinghua Lu* | [BMC Bioinformatics](https://doi.org/10.1186/s12859-015-0852-1)

- **2016-01** | PEDLA: predicting enhancers with a deep learning-based algorithmic framework | *Feng Liu, Hao Li, Chao Ren, Xiaochen Bo, Wenjie Shu* | [Biorxiv](https://doi.org/10.1101/036129)

- **2016-01** | TensorFlow: Biology’s Gateway to Deep Learning? | *Ladislav Rampasek, Anna Goldenberg* | [Cell Systems](https://doi.org/10.1016/j.cels.2016.01.009)

- **2016-01** | ADAGE-Based Integration of Publicly Available Pseudomonas aeruginosa Gene Expression Data with Denoising Autoencoders Illuminates Microbe-Host Interactions | [mSystems](https://doi.org/10.1128/mSystems.00025-15) | [code](https://github.com/greenelab/adage)

- **2016-01** | Deep Learning in Drug Discovery | *Erik Gawehn, Jan A. Hiss and Gisbert Schneider* | [Molecular Informatics](https://doi.org/10.1002/minf.201501008)

- **2016-02** | Gene expression inference with deep learning | *Yifei Chen, Yi Li, Rajiv Narayan, Aravind Subramanian, Xiaohui Xie* | [Bioinformatics](https://doi.org/10.1093/bioinformatics/btw074)

- **2016-02** | Semi-Supervised Learning of the Electronic Health Record for Phenotype Stratification | *Brett Beaulieu-Jones, Casey Greene* | [bioRxiv](https://doi.org/10.1101/039800)

- **2016-03** | Genome-Wide Prediction of cis-Regulatory Regions Using Supervised Deep Learning Methods | *Yifeng Li, Wenqiang Shi, Wyeth W Wasserman* | [Biorxiv](https://doi.org/10.1101/041616)

- **2016-03** | Applications of deep learning in biomedicine | *Polina Mamoshina, Armando Vieira, Evgeny Putin, and Alex Zhavoronkov* | [ACS Molecular Pharmaceutics](https://dx.doi.org/10.1021/acs.molpharmaceut.5b00982)

- **2016-03** | Deep Learning in Bioinformatics | *Seonwoo Min, Byunghan Lee, Sungroh Yoon* | [Arxiv](http://arxiv.org/abs/1603.06430)

- **2016-03** | DeepNano: Deep Recurrent Neural Networks for Base Calling in MinION Nanopore Reads | *Vladimír Boža, Broňa Brejová, Tomáš Vinař* | [Arxiv](http://arxiv.org/abs/1603.09195) | [code](https://bitbucket.org/vboza/deepnano)

- **2016-03** | deepTarget: End-to-end Learning Framework for microRNA Target Prediction using Deep Recurrent Neural Networks | *Byunghan Lee, Junghwan Baek, Seunghyun Park, Sungroh Yoon* | [Arxiv](http://arxiv.org/abs/1603.09123)

- **2016-03** | Deep Learning in Label-free Cell Classification | *Claire Lifan Chen, Ata Mahjoubfar, Li-Chia Tai, Ian K. Blaby, Allen Huang, Kayvan Reza Niazi & Bahram Jalali* | [Nature Scientific Reports](https://doi.org/10.1038/srep21471)

- **2016-04** | Accurate classification of protein subcellular localization from high throughput microscopy images using deep learning | *Tanel Pärnamaa, Leopold Parts* | [bioRxiv](http://dx.doi.org/10.1101/050757)

- **2016-04** | DanQ: a hybrid convolutional and recurrent deep neural network for quantifying the function of DNA sequences | *Daniel Quang & Xiaohui Xie* | [Nucleic Acids Research](https://doi.org/10.1093/nar/gkw226) | [code](https://github.com/uci-cbcl/DanQ)

- **2016-04** | deepMiRGene: Deep Neural Network based Precursor microRNA Prediction | *Seunghyun Park, Seonwoo Min, Hyun-soo Choi, and Sungroh Yoon* | [Arxiv](http://arxiv.org/abs/1605.00017)

- **2016-04** | Microscopy cell counting and detection with fully convolutional regression networks | *Weidi Xie, J. Alison Noble and Andrew Zisserman* | [Computer Methods in Biomechanics and Biomedical Engineering: Imaging & Visualization](https://doi.org/10.1080/21681163.2016.1149104)

- **2016-04** | Protein Secondary Structure Prediction Using Cascaded Convolutional and Recurrent Neural Networks | *Zhen Li and Yizhou Yu* | [Arxiv](https://arxiv.org/abs/1604.07176)

- **2016-05** | Denoising genome-wide histone ChIP-seq with convolutional neural networks | *Pang Wei Koh, Emma Pierson, Anshul Kundaje* | [Biorxiv](https://doi.org/10.1101/052118)

- **2016-05** | Deep Motif: Visualizing Genomic Sequence Classifications | *Jack Lanchantin, Ritambhara Singh, Zeming Lin, Yanjun Qi* | [Arxiv](http://arxiv.org/abs/1605.01133)

- **2016-05** | Not Just a Black Box: Learning Important Features Through Propagating Activation Differences | *Avanti Shrikumar, Peyton Greenside, Anna Shcherbina, Anshul Kundaje* | [Arxiv](https://arxiv.org/abs/1605.01713)

- **2016-05** | Deep biomarkers of human aging: Application of deep neural networks to biomarker development | *Evgeny Putin, Polina Mamoshina, Alexander Aliper, Mikhail Korzinkin, Alexey Moskalev, Alexey Kolosov, Alexander Ostrovskiy, Charles Cantor, Jan Vijg, and Alex Zhavoronkov* | [Aging](https://doi.org/10.18632/aging.100968)

- **2016-05** | Deep learning applications for predicting pharmacological properties of drugs and drug repurposing using transcriptomic data | *Alexander Aliper, Sergey Plis, Artem Artemov, Alvaro Ulloa, Polina Mamoshina, and Alex Zhavoronkov* | [ACS Molecular Pharmaceutics](https://doi.org/10.1021/acs.molpharmaceut.6b00248)

- **2016-05** | Accurate prediction of single-cell DNA methylation states using deep learning | *Christof Angermueller, Heather Lee, Wolf Reik, Oliver Stegle* | [Biorxiv](https://doi.org/10.1101/055715)

- **2016-05** | Deep Machine Learning provides state-of-the-art performance in image-based plant phenotyping | *Michael P. Pound, Alexandra J. Burgess, Michael H. Wilson, Jonathan A. Atkinson, Marcus Griffiths, Aaron S. Jackson, Adrian Bulat, Yorgos Tzimiropoulos, Darren M. Wells, Erik H. Murchie, Tony P. Pridmore, Andrew P. French* | [Biorxiv](https://doi.org/10.1101/053033)

- **2016-05** | Genetic Architect: Discovering Genomic Structure with Learned Neural Architectures | *Laura Deming, Sasha Targ, Nate Sauder, Diogo Almeida, Chun Jimmie Ye* | [Arxiv](https://arxiv.org/abs/1605.07156v1)

- **2016-05** | DeepCyTOF: Automated Cell Classification of Mass Cytometry Data by Deep Learning and Domain Adaptation | *Huamin Li, Uri Shaham, Yi Yao, Ruth Montgomery, Yuval Kluger* | [Biorxiv](https://doi.org/10.1101/054411)

- **2016-06** | Classifying and segmenting microscopy images with deep multiple instance learning | *Oren Z. Kraus, Jimmy Lei Ba and Brendan J. Frey* | [Bioinformatics](https://doi.org/10.1093/bioinformatics/btw252)

- **2016-06** | Convolutional neural network architectures for predicting DNA–protein binding | *Haoyang Zeng, Matthew D. Edwards, Ge Liu and David K. Gifford*  | [Bioinformatics](https://doi.org/10.1093/bioinformatics/btw255) | [code](http://cnn.csail.mit.edu)

- **2016-06** | DeepLNC, a long non-coding RNA prediction tool using deep neural network | *Rashmi Tripathi, Sunil Patel, Vandana Kumari, Pavan Chakraborty, Pritish Kumar Varadwaj* | [Network Modeling Analysis in Health Informatics and Bioinformatics](https://doi.org/10.1007/s13721-016-0129-2)

- **2016-06** | Virtual Screening: A Challenge for Deep Learning | *Javier Pérez-Sianes, Horacio Pérez-Sánchez, Fernando Díaz* | [10th International Conference on Practical Applications of Computational Biology & Bioinformatics](https://doi.org/10.1007/978-3-319-40126-3_2)

- **2016-07** | Deep learning for computational biology | *Christof Angermueller, Tanel Pärnamaa, Leopold Parts, Oliver Stegle* | [Molecular Systems Biology](https://doi.org/10.15252/msb.20156651)

- **2016-07** | Deep Learning in Bioinformatics | *Seonwoo Min, Byunghan Lee, Sungroh Yoon* | [Briefings in Bioinformatics](https://doi.org/10.1093/bib/bbw068)

- **2016-08** | DeepChrome: deep-learning for predicting gene expression from histone modifications | *Ritambhara Singh, Jack Lanchantin,  Gabriel Robins,  Yanjun Qi* | [Bioinformatics](https://doi.org/10.1093/bioinformatics/btw427)

- **2016-08** | Deep Artificial Neural Networks and Neuromorphic Chips for Big Data Analysis: Pharmaceutical and Bioinformatics Applications | *Lucas Antón Pastur-Romay, Francisco Cedrón, Alejandro Pazos and Ana Belén Porto-Pazos* | [International Journal of Molecular Sciences](https://doi.org/10.3390/ijms17081313)

- **2016-08** | Deep GDashboard: Visualizing and Understanding Genomic Sequences Using Deep Neural Networks | *Jack Lanchantin, Ritambhara Singh, Beilun Wang, Yanjun Qi* | [Arxiv](https://arxiv.org/abs/1608.03644v2)

- **2016-08** | Modeling translation elongation dynamics by deep learning reveals new insights into the landscape of ribosome stalling | *Sai Zhang, Hailin Hu, Jingtian Zhou, Xuan He and Jianyang Zeng* | [bioRxiv](http://dx.doi.org/10.1101/067108)

- **2016-08** | DeepWAS: Directly integrating regulatory information into GWAS using deep learning supports master regulator MEF2C as risk factor for major depressive disorder | *Gökcen Eraslan, Janine Arloth, Jade Martins, Stella Iurato, Darina Czamara, Elisabeth B. Binder, Fabian J. Theis, Nikola S. Mueller* | [bioRxiv](https://dx.doi.org/10.1101/069096)

- **2016-09** | The Next Era: Deep Learning in Pharmaceutical Research | *Sean Ekins* | [Pharmaceutical Research](https://dx.doi.org/10.1007/s11095-016-2029-7)

- **2016-09** | Accurate De Novo Prediction of Protein Contact Map by Ultra-Deep Learning Model | *Sheng Wang, Siqi Sun, Zhen Li, Renyu Zhang, Jinbo Xu* | [Arxiv](https://arxiv.org/abs/1609.00680)

- **2016-10** | Automatic chemical design using a data-driven continuous representation of molecules | *Rafael Gómez-Bombarelli, David Duvenaud, José Miguel Hernández-Lobato, Jorge Aguilera-Iparraguirre, Timothy D. Hirzel, Ryan P. Adams, Alán Aspuru-Guzik* | [Arxiv](https://arxiv.org/abs/1610.02415)

- **2016-10** | FIDDLE: An integrative deep learning framework for functional genomic data inference | *Umut Eser, L. Stirling Churchman* | [bioRxiv](http://dx.doi.org/10.1101/081380)

- **2016-10** | Deep Learning for Imaging Flow Cytometry: Cell Cycle Analysis of Jurkat Cells | *Philipp Eulenberg, Niklas Koehler, Thomas Blasi, Andrew Filby, Anne E. Carpenter, Paul Rees, Fabian J. Theis, F. Alexander Wolf* | [bioRxiv](http://dx.doi.org/10.1101/081364)

- **2016-10** | Leveraging uncertainty information from deep neural networks for disease detection | *Christian Leibig, Vaneeda Allken, Philipp Berens, Siegfried Wahl* | [bioRxiv](http://dx.doi.org/10.1101/084210)

- **2016-11** | Predicting Enhancer-Promoter Interaction from Genomic Sequence with Deep Neural Networks | *Shashank Singh, Yang Yang, Barnabas Poczos, Jian Ma* | [bioRxiv](https://doi.org/10.1101/085241)

- **2016-11** | RNA-protein binding motifs mining with a new hybrid deep learning based cross-domain knowledge integration approach | *Xiaoyong Pan, Hong-Bin Shen* | [bioRxiv](http://dx.doi.org/10.1101/085191)

- **2016-11** | Low Data Drug Discovery with One-shot Learning | *Han Altae-Tran, Bharath Ramsundar, Aneesh S. Pappu, Vijay Pande* | [Arxiv](https://arxiv.org/abs/1611.03199)

- **2016-11** | Diet Networks: Thin Parameters for Fat Genomic | *Adriana Romero, Pierre Luc Carrier, Akram Erraqabi, Tristan Sylvain, Alex Auvolat, Etienne Dejoie, Marc-André Legault, Marie-Pierre Dubé, Julie G. Hussin, Yoshua Bengio* | [Arxiv](https://arxiv.org/abs/1611.09340)

- **2016-11** | DeeperBind: Enhancing Prediction of Sequence Specificities of DNA Binding Proteins | *Hamid Reza Hassanzadeh, May D. Wang* | [Arxiv](https://arxiv.org/abs/1611.05777)

- **2016-11** | Accurate De Novo Prediction of Protein Contact Map by Ultra-Deep Learning Model | *Sheng Wang, Siqi Sun, Zhen Li, Renyu Zhang, Jinbo Xu* | [bioRxiv](https://doi.org/10.1101/073239)

- **2016-11** | Deep learning with feature embedding for compound-protein interaction prediction | *Fangping Wan, Jianyang Zeng* | [bioRxiv](https://doi.org/10.1101/086033)

- **2016-12** | Creating a universal SNP and small indel variant caller with deep neural networks | *Ryan Poplin, Dan Newburger, Jojo Dijamco, Nam Nguyen, Dion Loy, Sam S. Gross, Cory Y. McLean, Mark A. DePristo* | [bioRxiv](https://doi.org/10.1101/092890)

- **2016-12** | DeepCancer: Detecting Cancer through Gene Expressions via Deep Generative Learning | *Rajendra Rana Bhat, Vivek Viswanath, Xiaolin Li* | [Arxiv](http://arxiv.org/abs/1612.03211)

- **2016-12** | Cox-nnet: an artificial neural network Cox regression for prognosis prediction | *Travers Ching, Xun Zhu, Lana Garmire* | [bioRxiv](https://doi.org/10.1101/093021)

- **2016-12** | Deep learning is effective for the classification of OCT images of normal versus Age-related Macular Degeneration | *Cecilia S Lee, Doug M Baughman, Aaron Y Lee* | [bioRxiv](https://doi.org/10.1101/094276)

- **2016-12** | Partitioned learning of deep Boltzmann machines for SNP data | *Moritz Hess, Stefan Lenz, Tamara Blaette, Lars Bullinger, Harald Binder* | [bioRxiv](https://doi.org/10.1101/095638)

- **2016-12** | DeepAD: Alzheimer′s Disease Classification via Deep Convolutional Neural Networks using MRI and fMRI | *Saman Sarraf, John Anderson, Ghassem Tofighi, for the Alzheimer's Disease Neuroimaging Initiativ* | [bioRxiv](https://doi.org/10.1101/070441)

- **2016-12** | Training Genotype Callers with Neural Networks | *Rémi Torracinta, Fabien Campagne* | [bioRxiv](https://doi.org/10.1101/097469)

- **2016-12** | EP-DNN: A Deep Neural Network-Based Global Enhancer Prediction Algorithm | *Seong Gon Kim, Mrudul Harwani, Ananth Grama, Somali Chaterji* | [Nature Scientific Reports](https://doi.org/10.1038/srep38433)

- **2016-12** | EnhancerPred: a predictor for discovering enhancers based on the combination and selection of multiple features | *Cangzhi Jia, Wenying He* | [Nature Scientific Reports](https://doi.org/10.1038/srep38741)

- **2016-12** | DeepEnhancer: Predicting enhancers by convolutional neural networks | *Min, Xu, Ning Chen, Ting Chen, and Rui Jiang* | [2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)](https://doi.org/10.1109/BIBM.2016.7822593)

- **2016-12** | DeepSplice: Deep classification of novel splice junctions revealed by RNA-seq | *Zhang, Yi, Xinan Liu, James N. MacLeod, and Jinze Liu* | [2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)](https://doi.org/10.1109/BIBM.2016.7822541)

- **2016-12** | Deep convolutional neural networks for detecting secondary structures in protein density maps from cryo-electron microscopy | *Li, Rongjian, Dong Si, Tao Zeng, Shuiwang Ji, and Jing He* | [2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)](https://doi.org/10.1109/BIBM.2016.7822490)

- **2016-12** | Towards recognition of protein function based on its structure using deep convolutional networks | *Tavanaei, Amirhossein, Anthony S. Maida, Arun Kaniymattam, and Rasiah Loganantharaj* | [2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)](https://doi.org/10.1109/BIBM.2016.7822509)

- **2016-12** | Emotion recognition from multi-channel EEG data through Convolutional Recurrent Neural Network | *Li, Xiang, Dawei Song, Peng Zhang, Guangliang Yu, Yuexian Hou, and Bin Hu* | [2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)](https://doi.org/10.1109/BIBM.2016.7822545)

- **2016-12** | Coarse-to-Fine Stacked Fully Convolutional Nets for lymph node segmentation in ultrasound images | *Zhang, Yizhe, Michael TC Ying, Lin Yang, Anil T. Ahuja, and Danny Z. Chen* | [2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)](https://doi.org/10.1109/BIBM.2016.7822557)

- **2016-12** | CNNsite: Prediction of DNA-binding residues in proteins using Convolutional Neural Network with sequence features | *Zhou, Jiyun, Qin Lu, Ruifeng Xu, Lin Gui, and Hongpeng Wang* | [2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)](https://doi.org/10.1109/BIBM.2016.7822496)

- **2016-12** | A predictive model of gene expression using a deep learning framework | *Xie, Rui, Andrew Quitadamo, Jianlin Cheng, and Xinghua Shi* | [2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)](https://doi.org/10.1109/BIBM.2016.7822599)

- **2016-12** | Deep convolutional neural network for survival analysis with pathological images | *Zhu, Xinliang, Jiawen Yao, and Junzhou Huang* | [2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)](https://doi.org/10.1109/BIBM.2016.7822579)

- **2016-12** | Dependency-based convolutional neural network for drug-drug interaction extraction | *Liu, Shengyu, Kai Chen, Qingcai Chen, and Buzhou Tang* | [2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)](https://doi.org/10.1109/BIBM.2016.7822671)

- **2016-12** | Pervasive EEG diagnosis of depression using Deep Belief Network with three-electrodes EEG collector | *Cai, Hanshu, Xiaocong Sha, Xue Han, Shixin Wei, and Bin Hu* | [2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)](https://doi.org/10.1109/BIBM.2016.7822696)

- **2016-12** | Cardiac left ventricular volumes prediction method based on atlas location and deep learning | *Luo, Gongning, Suyu Dong, Kuanquan Wang, and Henggui Zhang* | [2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)](https://doi.org/10.1109/BIBM.2016.7822759)

- **2016-12** | A high-precision shallow Convolutional Neural Network based strategy for the detection of Genomic Deletions | *Wang, Jing, Cheng Ling, and Jingyang Gao* | [2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)](https://doi.org/10.1109/BIBM.2016.7822793)

- **2016-12** | The cornucopia of meaningful leads: Applying deep adversarial autoencoders for new molecule development in oncology | *Kadurin, Artur, Alexander Aliper, Andrey Kazennov, Polina Mamoshina, Quentin Vanhaelen, Kuzma Khrabrov, and Alex Zhavoronkov* | [Oncotarget](https://doi.org/10.18632/oncotarget.14073)

- **2016-12** | Medical Image Synthesis with Context-Aware Generative Adversarial Networks | *Dong Nie, Roger Trullo, Caroline Petitjean, Su Ruan, Dinggang Shen* | [Arxiv](https://arxiv.org/abs/1612.05362)

- **2016-12** | Unsupervised Learning from Noisy Networks with Applications to Hi-C Data | *Wang, Bo, Junjie Zhu, Armin Pourshafeie, Oana Ursu, Serafim Batzoglou, and Anshul Kundaje* | [Advances in Neural Information Processing Systems (NIPS 2016)](http://papers.nips.cc/paper/6291-unsupervised-learning-from-noisy-networks-with-applications-to-hi-c-data)

- **2016-12** | Deep Learning for Health Informatics | *Daniele Ravì, Charence Wong, Fani Deligianni, Melissa Berthelot, Javier Andreu-Perez, Benny Lo, and Guang-Zhong Yang* | [IEEE Journal of Biomedical and Health Informatics](https://doi.org/10.1109/JBHI.2016.2636665)

- **2017-01** | A Deep Learning Approach for Cancer Detection and Relevant Gene Identification | *Wang, Jing, Cheng Ling, and Jingyang Gao* | [Pacific Symposium on Biocomputing 2017](http://dx.doi.org/10.1142/9789813207813_0022)

- **2017-01** | Deep Motif Dashboard: Visualizing and Understanding Genomic Sequences Using Deep Neural Networks | *Lanchantin, Jack, Ritambhara Singh, Beilun Wang, and Yanjun Qi* | [Pacific Symposium on Biocomputing 2017](http://dx.doi.org/10.1142/9789813207813_0025)

- **2017-01** | HLA class I binding prediction via convolutional neural networks | *Yeeleng Scott Vang, Xiaohui Xie* | [bioRxiv](https://doi.org/10.1101/099358)

- **2017-01** | DeadNet: Identifying Phototoxicity from Label-free Microscopy Images of Cells using Deep ConvNets | *David Richmond, Anna Payne-Tobin Jost, Talley Lambert, Jennifer Waters, Hunter Elliott* | [arXiv](https://arxiv.org/abs/1701.06109)

- **2017-01** | Dermatologist-level classification of skin cancer with deep neural networks | *Andre Esteva, Brett Kuprel, Roberto A. Novoa, Justin Ko, Susan M. Swetter, Helen M. Blau & Sebastian Thrun* | [Nature](https://doi.org/10.1038/nature21056)

- **2017-01** | Understanding sequence conservation with deep learning | *Yi Li, Daniel Quang, Xiaohui Xie* | [Biorxiv](https://doi.org/10.1101/103929)

- **2017-01** | Learning the Structural Vocabulary of a Network | *Saket Navlakha* | [Neural Computation](https://doi.org/10.1162/NECO_a_00924)

- **2017-01** | Mining the Unknown: Assigning Function to Noncoding Single Nucleotide Polymorphisms | *Sierra S. Nishizaki, Alan P. Boyle* | [Trends in Genetics](http://dx.doi.org/10.1016/j.tig.2016.10.008)

- **2017-01** | Reverse-complement parameter sharing improves deep learning models for genomics | *Avanti Shrikumar, Peyton Greenside, Anshul Kundaje* | [bioRxiv](https://doi.org/10.1101/103663)

- **2017-01** | TIDE: predicting translation initiation sites by deep learning | *Sai Zhang, Hailin Hu, Tao Jiang, Lei Zhang, Jianyang Zeng* | [bioRxiv](https://doi.org/10.1101/103374)

- **2017-01** | Integrative Deep Models for Alternative Splicing | *Anupama Jha, Matthew R Gazzara, Yoseph Barash* | [bioRxiv](https://doi.org/10.1101/104869)

- **2017-01** | Deep Recurrent Neural Network for Protein Function Prediction from Sequence | *Xueliang Leon Liu* | [bioRxiv](https://doi.org/10.1101/103994)

- **2017-01** | Nucleotide sequence and DNaseI sensitivity are predictive of 3D chromatin architecture | *Jacob Schreiber, Maxwell Libbrecht, Jeffrey Bilmes, William Noble* | [bioRxiv](https://doi.org/10.1101/103614)

- **2017-02** | Imputation for transcription factor binding predictions based on deep learning | *Qian Qin, Jianxing Feng* | [PloS Computational Biology](http://dx.doi.org/10.1371/journal.pcbi.1005403)

- **2017-02** | Deep Learning based multi-omics integration robustly predicts survival in liver cancer | *Kumardeep Chaudhary, Olivier B. Poirion, Liangqun Lu, Lana Garmire* | [bioRxiv](https://doi.org/10.1101/114892)

- **2017-03** | Predicting the impact of non-coding variants on DNA methylation | *Zeng, Haoyang, and David K. Gifford* | [Nucleic Acids Research](https://doi.org/10.1093/nar/gkx177)

- **2017-03** | H&E-stained Whole Slide Image Deep Learning Predicts SPOP Mutation State in Prostate Cancer | *Andrew J Schaumberg, Mark A Rubin, Thomas J Fuchs* | [bioRxiv](https://doi.org/10.1101/064279)

### Contribution

Feel free to send a pull request.


"
14,pratik008/HealthCare_Twitter_Analysis,Python,"# Twitter-Healthcare-Analysis

I have written the source code as the core of the Twitter Healthcare Analysis Open Source project. If you have any questions, feel free to contact me at pratik008@gmail.com (Pratik Mehta) Please read the [Wiki](https://github.com/wywfalcon/Twitter-Healthcare-Analysis/wiki) for more information.

Good luck with your projects!
"
15,MoH-Malaysia/covid19-public,Jupyter Notebook,"# Open data on COVID-19 in Malaysia

**The scope and granularity of data in this repo will evolve over time.**
+ Documentation and data descriptions contained within subfolders. 
+ Submit pull requests to [share your work for the community](/CONTRIB.md#share-your-work) or [request more data](/CONTRIB.md#data-requests).

**All data is correct as of 2359 of date, unless stated otherwise.**

---

### Cases and Testing

1) [`cases_malaysia.csv`](/epidemic/cases_malaysia.csv): Daily recorded COVID-19 cases at country level.
2) [`cases_state.csv`](/epidemic/cases_state.csv): Daily recorded COVID-19 cases at state level.
3) [`clusters.csv`](/epidemic/clusters.csv): Exhaustive list of announced clusters with relevant epidemiological datapoints.
4) [`tests_malaysia.csv`](/epidemic/tests_malaysia.csv): Daily tests (note: not necessarily unique individuals) by type at country level.
4) [`tests_state.csv`](/epidemic/tests_malaysia.csv): Daily tests (note: not necessarily unique individuals) by type at state level.

### Healthcare

1) [`pkrc.csv`](/epidemic/pkrc.csv): Flow of patients to/out of Covid-19 Quarantine and Treatment Centres (PKRC), with capacity and utilisation.
2) [`hospital.csv`](/epidemic/hospital.csv): Flow of patients to/out of hospitals, with capacity and utilisation.
3) [`icu.csv`](/epidemic/icu.csv): Capacity and utilisation of intensive care unit (ICU) beds.

### Deaths

1) [`deaths_malaysia.csv`](/epidemic/deaths_malaysia.csv): Daily deaths due to COVID-19 at country level.
2) [`deaths_state.csv`](/epidemic/deaths_state.csv): Daily deaths due to COVID-19 at state level.

### Vaccinations

1) [`vax_malaysia.csv`](/vaccination/vax_malaysia.csv): Vaccinations (daily and cumulative, by dose type and brand) at country level.
2) [`vax_state.csv`](/vaccination/vax_state.csv): Vaccinations (daily and cumulative, by dose type and brand) at state level.
3) [`vax_district.csv`](/vaccination/vax_district.csv): Vaccinations (daily and cumulative, by dose type and brand) at district level.
4) [`vax_school.csv`](/vaccination/vax_school.csv): Vaccination coverage for public schools.
5) [`vax_demog_age.csv`'](/vaccination/vax_demog_age.csv): Vaccinations by age group, at district level.
6) [`vax_demog_age_children.csv`'](/vaccination/vax_demog_age_children.csv): Vaccinations by age group with single-year granularity for individuals < 18yo, at district level.
7) [`vax_demog_sex.csv`'](/vaccination/vax_demog_sex.csv): Vaccinations by sex, at district level.
8) [`vax_demog_ethnicity.csv`'](/vaccination/vax_demog_ethnicity.csv): Vaccinations by ethnicity, at district level.
9) [`vax_demog_nationality.csv`'](/vaccination/vax_demog_nationality.csv): Vaccinations by nationality, at district level.
10) [`vax_demog_highrisk.csv`'](/vaccination/vax_demog_highrisk.csv): Vaccinations for special categories (healthcare workers, OKU, individuals with comorbidities) at district level.

### Mobility and Contact Tracing

1) [`checkin_malaysia.csv`](/mysejahtera/checkin_malaysia.csv): Daily checkins on MySejahtera at country level.
2) [`checkin_state.csv`](/mysejahtera/checkin_state.csv): Daily checkins on MySejahtera at state level.
3) [`checkin_malaysia_time.csv`](/mysejahtera/checkin_malaysia_time.csv): Time distribution of daily checkins on MySejahtera at country level.
4) [`trace_malaysia.csv`](/mysejahtera/trace_malaysia.csv): Daily casual contacts traced and hotspots identified by HIDE, at country level.

### Static data

1) [`population.csv`](/static/population.csv) (last updated from DOSM 2020 census, as published in 2022): 
 - `idxs`: integer coding for states (employed in cases linelist, cluster file, and school vax file)
 - `pop`: total population (all other columns are subset of `pop`)
 - `pop_18`: population aged 18+
 - `pop_60`: population aged 60+, also a subset of `pop_18`
 - `pop_12`: population aged 12-17
 - `pop_5`: population aged 5-11

_Static data will remain unchanged unless there is an update from the source, e.g. if DOSM makes an update to population estimates. We provide this data here not to supersede the source, but rather to be transparent about the data we use to compute key statistics e.g. the % of the population that is vaccinated. We also hope this ensures synchronisation (across various independent analysts) of key statistics._
"
16,DataKind-SG/healthcare_ASEAN,Jupyter Notebook,"healthcare_ASEAN
==============================

Open data project on exploration of healthcare data for the ASEAN region, currently focusing on Malaria and Dengue. 

Social Coding board: https://github.com/DataKind-SG/healthcare_ASEAN/projects/1   

Slack Channel on DataKindSG (datakindsg.slack.com) team: #healthcare_asean  

The data folder has been uploaded to the github repo data\ folder.

Further information: 
docs\README.md

Granularity
------------
 * weekly data
 * location: state/province level 

Project Organization
------------

    ├── LICENSE
    ├── Makefile           <- Makefile with commands like `make data` or `make train`
    ├── README.md          <- The top-level README for developers using this project.
    ├── data
    │   ├── external       <- Data from third party sources.
    │   ├── interim        <- Intermediate data that has been transformed.
    │   ├── processed      <- The final, canonical data sets for modeling.
    │   └── raw            <- The original, immutable data dump.
    │
    ├── docs               <- A default Sphinx project; see sphinx-doc.org for details
    │
    ├── models             <- Trained and serialized models, model predictions, or model summaries
    │
    ├── notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),
    │                         the creator's initials, and a short `-` delimited description, e.g.
    │                         `1.0-jqp-initial-data-exploration`.
    ├── references         <- Data dictionaries, manuals, and all other explanatory materials.
    │
    ├── reports            <- Generated analysis as HTML, PDF, LaTeX, etc.
    │   └── figures        <- Generated graphics and figures to be used in reporting
    │
    ├── requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.
    │                         generated with `pip freeze > requirements.txt`
    │
    ├── src                <- Source code for use in this project.
    │   ├── __init__.py    <- Makes src a Python module
    │   │
    │   ├── data
    │   │   ├── download   <- Scripts for downloading from each raw data source
    │   │   │   └── logconf.ini <- setup for logging configuration for scripts in download/
    │   │   ├── download.py <- Script to download raw data using modules in `download/`
    │   │   │
    │   │   ├── clean      <- Scripts to clean raw data
    │   │   ├── clean.py   <- Script to clean raw data using modules in 'clean/'
    │   │   │
    │   │   └── logconf.ini <- setup for logging configuration for scripts in data/
    │   │
    │   ├── features       <- Scripts to turn raw data into features for modeling
    │   │   └── build_features.py
    │   │
    │   ├── models         <- Scripts to train models and then use trained models to make
    │   │   │                 predictions
    │   │   ├── predict_model.py
    │   │   └── train_model.py
    │   │
    │   └── visualization  <- Scripts to create exploratory and results oriented visualizations
    │       └── visualize.py
    ├── test               <- Directory for souce codes testing
    │   ├── func           <- Directory for souce codes functional testing
    │   │   ├── data
    │   │   ├── features
    │   │   └── models
    │   ├── unit           <- Directory for souce codes unit testing
    │   │   ├── data
    │   │   ├── features
    │   │   └── models
    └── tox.ini            <- tox file with settings for running tox; see tox.testrun.org
"
17,llSourcell/AI_for_healthcare,Jupyter Notebook,"# ChemGAN challenge


## Overview

This is the code for [this](https://www.youtube.com/watch?v=hY9Bc3mtphs) video on Youtube by Siraj Raval as part of the AI for business series. Find the original code and authors [here](https://github.com/mostafachatillon/ChemGAN-challenge). 

* Code for the paper: Benhenda, M. 2017. [ChemGAN challenge for drug discovery: can AI reproduce natural chemical diversity? arXiv preprint arXiv:1708.08227.](https://arxiv.org/abs/1708.08227)

* Related blog post: [https://medium.com/the-ai-lab/chemgan-challenge-for-drug-discovery-can-ai-reproduce-natural-chemical-diversity-8f1f2528ee22](https://medium.com/the-ai-lab/chemgan-challenge-for-drug-discovery-can-ai-reproduce-natural-chemical-diversity-8f1f2528ee22)

* Chat room: [https://gitter.im/Startcrowd/drugdiscovery](https://gitter.im/Startcrowd/drugdiscovery) 

* Requirements: Rdkit version 2017.03.3 from Anaconda, Tensorflow 1.0.1

* The code has not been cleaned, don't hesitate to post an issue if you don't find what you are looking for.
"
18,sunlabuiuc/PyHealth,Python,"Welcome to PyHealth!
====================================

.. image:: https://img.shields.io/pypi/v/pyhealth.svg?color=brightgreen
   :target: https://pypi.org/project/pyhealth/
   :alt: PyPI version


.. image:: https://readthedocs.org/projects/pyhealth/badge/?version=latest
   :target: https://pyhealth.readthedocs.io/en/latest/
   :alt: Documentation status
   

.. image:: https://img.shields.io/github/stars/sunlabuiuc/pyhealth.svg
   :target: https://github.com/sunlabuiuc/pyhealth/stargazers
   :alt: GitHub stars


.. image:: https://img.shields.io/github/forks/sunlabuiuc/pyhealth.svg?color=blue
   :target: https://github.com/sunlabuiuc/pyhealth/network
   :alt: GitHub forks


.. image:: https://pepy.tech/badge/pyhealth
   :target: https://pepy.tech/project/pyhealth
   :alt: Downloads


.. image:: https://img.shields.io/badge/Tutorials-Google%20Colab-red
   :target: https://pyhealth.readthedocs.io/en/latest/tutorials.html
   :alt: Tutorials


.. image:: https://img.shields.io/badge/YouTube-16%20Videos-red
   :target: https://www.youtube.com/playlist?list=PLR3CNIF8DDHJUl8RLhyOVpX_kT4bxulEV
   :alt: YouTube



.. -----


.. **Build Status & Coverage & Maintainability & License**

.. .. image:: https://travis-ci.org/yzhao062/pyhealth.svg?branch=master
..    :target: https://travis-ci.org/yzhao062/pyhealth
..    :alt: Build Status


.. .. image:: https://ci.appveyor.com/api/projects/status/1kupdy87etks5n3r/branch/master?svg=true
..    :target: https://ci.appveyor.com/project/yzhao062/pyhealth/branch/master
..    :alt: Build status


.. .. image:: https://api.codeclimate.com/v1/badges/bdc3d8d0454274c753c4/maintainability
..    :target: https://codeclimate.com/github/yzhao062/pyhealth/maintainability
..    :alt: Maintainability


.. .. image:: https://img.shields.io/github/license/yzhao062/pyhealth
..    :target: https://github.com/yzhao062/pyhealth/blob/master/LICENSE
..    :alt: License

PyHealth is designed for both **ML researchers and medical practitioners**. We can make your **healthcare AI applications** easier to deploy and more flexible and customizable. `[Tutorials] <https://pyhealth.readthedocs.io/>`_

 **[News!]** Our PyHealth is accepted by KDD 2023 Tutorial Track! We will present a 3-hour tutorial on PyHealth at `[KDD 2023] <https://kdd.org/kdd2023/>`_, August 6-10, Long Beach, CA.

.. image:: figure/poster.png
   :width: 810

..

1. Installation :rocket:
----------------------------

- You could install from PyPi:

.. code-block:: sh

    pip install pyhealth

- or from github source:

.. code-block:: sh

    pip install .


2. Introduction :book:
--------------------------
``pyhealth`` provides these functionalities (we are still enriching some modules):

.. image:: figure/overview.png
   :width: 770

You can use the following functions independently:

- **Dataset**: ``MIMIC-III``, ``MIMIC-IV``, ``eICU``, ``OMOP-CDM``, ``customized EHR datasets``, etc.
- **Tasks**: ``diagnosis-based drug recommendation``, ``patient hospitalization and mortality prediction``, ``length stay forecasting``, etc. 
- **ML models**: ``CNN``, ``LSTM``, ``GRU``, ``LSTM``, ``RETAIN``, ``SafeDrug``, ``Deepr``, etc.

*Building a healthcare AI pipeline can be as short as 10 lines of code in PyHealth*.


3. Build ML Pipelines :trophy:
---------------------------------

All healthcare tasks in our package follow a **five-stage pipeline**: 

.. image:: figure/five-stage-pipeline.png
   :width: 640

..

 We try hard to make sure each stage is as separate as possible, so that people can customize their own pipeline by only using our data processing steps or the ML models.

Module 1: <pyhealth.datasets>
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

``pyhealth.datasets`` provides a clean structure for the dataset, independent from the tasks. We support `MIMIC-III`, `MIMIC-IV` and `eICU`, etc. The output (mimic3base) is a multi-level dictionary structure (see illustration below).

.. code-block:: python

    from pyhealth.datasets import MIMIC3Dataset

    mimic3base = MIMIC3Dataset(
        # root directory of the dataset
        root=""https://storage.googleapis.com/pyhealth/Synthetic_MIMIC-III/"", 
        # raw CSV table name
        tables=[""DIAGNOSES_ICD"", ""PROCEDURES_ICD"", ""PRESCRIPTIONS""],
        # map all NDC codes to CCS codes in these tables
        code_mapping={""NDC"": ""CCSCM""},
    )

.. image:: figure/structured-dataset.png
   :width: 400

..

Module 2: <pyhealth.tasks>
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

``pyhealth.tasks`` defines how to process each patient's data into a set of samples for the tasks. In the package, we provide several task examples, such as ``drug recommendation`` and ``length of stay prediction``. **It is easy to customize your own tasks following our** `template <https://colab.research.google.com/drive/1r7MYQR_5yCJGpK_9I9-A10HmpupZuIN-?usp=sharing>`_.

.. code-block:: python

    from pyhealth.tasks import readmission_prediction_mimic3_fn

    mimic3sample = mimic3base.set_task(task_fn=readmission_prediction_mimic3_fn) # use default task
    mimic3sample.samples[0] # show the information of the first sample
    """"""
    {
        'visit_id': '100183',
        'patient_id': '175',
        'conditions': ['5990', '4280', '2851', '4240', '2749', '9982', 'E8499', '42831', '34600'],
        'procedures': ['0040', '3931', '7769'],
        'drugs': ['N06DA02', 'V06DC01', 'B01AB01', 'A06AA02', 'R03AC02', 'H03AA01', 'J01FA09'],
        'label': 0
    }
    """"""

    from pyhealth.datasets import split_by_patient, get_dataloader

    train_ds, val_ds, test_ds = split_by_patient(mimic3sample, [0.8, 0.1, 0.1])
    train_loader = get_dataloader(train_ds, batch_size=32, shuffle=True)
    val_loader = get_dataloader(val_ds, batch_size=32, shuffle=False)
    test_loader = get_dataloader(test_ds, batch_size=32, shuffle=False)

Module 3: <pyhealth.models>
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

``pyhealth.models`` provides different ML models with very similar argument configs.

.. code-block:: python

    from pyhealth.models import Transformer

    model = Transformer(
        dataset=mimic3sample,
        feature_keys=[""conditions"", ""procedures"", ""drug""],
        label_key=""label"",
        mode=""binary"",
    )

Module 4: <pyhealth.trainer>
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

``pyhealth.trainer`` can specify training arguments, such as epochs, optimizer, learning rate, etc. The trainer will automatically save the best model and output the path in the end.

.. code-block:: python
    
    from pyhealth.trainer import Trainer

    trainer = Trainer(model=model)
    trainer.train(
        train_dataloader=train_loader,
        val_dataloader=val_loader,
        epochs=50,
        monitor=""pr_auc_samples"",
    )

Module 5: <pyhealth.metrics>
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

``pyhealth.metrics`` provides several **common evaluation metrics** (refer to `Doc <https://pyhealth.readthedocs.io/en/latest/api/metrics.html>`_ and see what are available).

.. code-block:: python

    # method 1
    trainer.evaluate(test_loader)
    
    # method 2
    from pyhealth.metrics.binary import binary_metrics_fn

    y_true, y_prob, loss = trainer.inference(test_loader)
    binary_metrics_fn(y_true, y_prob, metrics=[""pr_auc"", ""roc_auc""])

4. Medical Code Map :hospital: 
---------------------------------

``pyhealth.codemap`` provides two core functionalities. **This module can be used independently.**

* For code ontology lookup within one medical coding system (e.g., name, category, sub-concept); 

.. code-block:: python

    from pyhealth.medcode import InnerMap

    icd9cm = InnerMap.load(""ICD9CM"")
    icd9cm.lookup(""428.0"")
    # `Congestive heart failure, unspecified`
    icd9cm.get_ancestors(""428.0"")
    # ['428', '420-429.99', '390-459.99', '001-999.99']
    
    atc = InnerMap.load(""ATC"")
    atc.lookup(""M01AE51"")
    # `ibuprofen, combinations`
    atc.lookup(""M01AE51"", ""drugbank_id"")
    # `DB01050`
    atc.lookup(""M01AE51"", ""description"")
    # Ibuprofen is a non-steroidal anti-inflammatory drug (NSAID) derived ...
    atc.lookup(""M01AE51"", ""indication"")
    # Ibuprofen is the most commonly used and prescribed NSAID. It is very common over the ...

* For code mapping between two coding systems (e.g., ICD9CM to CCSCM). 

.. code-block:: python

    from pyhealth.medcode import CrossMap

    codemap = CrossMap.load(""ICD9CM"", ""CCSCM"")
    codemap.map(""428.0"")
    # ['108']

    codemap = CrossMap.load(""NDC"", ""RxNorm"")
    codemap.map(""50580049698"")
    # ['209387']

    codemap = CrossMap.load(""NDC"", ""ATC"")
    codemap.map(""50090539100"")
    # ['A10AC04', 'A10AD04', 'A10AB04']

5. Medical Code Tokenizer :speech_balloon:
---------------------------------------------

``pyhealth.tokenizer`` is used for transformations between string-based tokens and integer-based indices, based on the overall token space. We provide flexible functions to tokenize 1D, 2D and 3D lists. **This module can be used independently.**

.. code-block:: python

    from pyhealth.tokenizer import Tokenizer

    # Example: we use a list of ATC3 code as the token
    token_space = ['A01A', 'A02A', 'A02B', 'A02X', 'A03A', 'A03B', 'A03C', 'A03D', \
            'A03F', 'A04A', 'A05A', 'A05B', 'A05C', 'A06A', 'A07A', 'A07B', 'A07C', \
            'A12B', 'A12C', 'A13A', 'A14A', 'A14B', 'A16A']
    tokenizer = Tokenizer(tokens=token_space, special_tokens=[""<pad>"", ""<unk>""])

    # 2d encode 
    tokens = [['A03C', 'A03D', 'A03E', 'A03F'], ['A04A', 'B035', 'C129']]
    indices = tokenizer.batch_encode_2d(tokens) 
    # [[8, 9, 10, 11], [12, 1, 1, 0]]

    # 2d decode 
    indices = [[8, 9, 10, 11], [12, 1, 1, 0]]
    tokens = tokenizer.batch_decode_2d(indices)
    # [['A03C', 'A03D', 'A03E', 'A03F'], ['A04A', '<unk>', '<unk>']]

    # 3d encode
    tokens = [[['A03C', 'A03D', 'A03E', 'A03F'], ['A08A', 'A09A']], \
        [['A04A', 'B035', 'C129']]]
    indices = tokenizer.batch_encode_3d(tokens)
    # [[[8, 9, 10, 11], [24, 25, 0, 0]], [[12, 1, 1, 0], [0, 0, 0, 0]]]

    # 3d decode
    indices = [[[8, 9, 10, 11], [24, 25, 0, 0]], \
        [[12, 1, 1, 0], [0, 0, 0, 0]]]
    tokens = tokenizer.batch_decode_3d(indices)
    # [[['A03C', 'A03D', 'A03E', 'A03F'], ['A08A', 'A09A']], [['A04A', '<unk>', '<unk>']]]
..

6. Tutorials :teacher:
----------------------------

.. image:: https://colab.research.google.com/assets/colab-badge.svg
    :target: https://pyhealth.readthedocs.io/en/latest/tutorials.html

..

 We provide the following tutorials to help users get started with our pyhealth. 

`Tutorial 0: Introduction to pyhealth.data <https://colab.research.google.com/drive/1y9PawgSbyMbSSMw1dpfwtooH7qzOEYdN?usp=sharing>`_  `[Video] <https://www.youtube.com/watch?v=Nk1itBoLOX8&list=PLR3CNIF8DDHJUl8RLhyOVpX_kT4bxulEV&index=2>`__  

`Tutorial 1: Introduction to pyhealth.datasets <https://colab.research.google.com/drive/18kbzEQAj1FMs_J9rTGX8eCoxnWdx4Ltn?usp=sharing>`_  `[Video] <https://www.youtube.com/watch?v=c1InKqFJbsI&list=PLR3CNIF8DDHJUl8RLhyOVpX_kT4bxulEV&index=3>`__  

`Tutorial 2: Introduction to pyhealth.tasks <https://colab.research.google.com/drive/1r7MYQR_5yCJGpK_9I9-A10HmpupZuIN-?usp=sharing>`_  `[Video] <https://www.youtube.com/watch?v=CxESe1gYWU4&list=PLR3CNIF8DDHJUl8RLhyOVpX_kT4bxulEV&index=4>`__  

`Tutorial 3: Introduction to pyhealth.models <https://colab.research.google.com/drive/1LcXZlu7ZUuqepf269X3FhXuhHeRvaJX5?usp=sharing>`_  `[Video] <https://www.youtube.com/watch?v=fRc0ncbTgZA&list=PLR3CNIF8DDHJUl8RLhyOVpX_kT4bxulEV&index=6>`__  

`Tutorial 4: Introduction to pyhealth.trainer <https://colab.research.google.com/drive/1L1Nz76cRNB7wTp5Pz_4Vp4N2eRZ9R6xl?usp=sharing>`_  `[Video] <https://www.youtube.com/watch?v=5Hyw3of5pO4&list=PLR3CNIF8DDHJUl8RLhyOVpX_kT4bxulEV&index=7>`__  

`Tutorial 5: Introduction to pyhealth.metrics <https://colab.research.google.com/drive/1Mrs77EJ92HwMgDaElJ_CBXbi4iABZBeo?usp=sharing>`_  `[Video] <https://www.youtube.com/watch?v=d-Kx_xCwre4&list=PLR3CNIF8DDHJUl8RLhyOVpX_kT4bxulEV&index=8>`__ 


`Tutorial 6: Introduction to pyhealth.tokenizer <https://colab.research.google.com/drive/1bDOb0A5g0umBjtz8NIp4wqye7taJ03D0?usp=sharing>`_ `[Video] <https://www.youtube.com/watch?v=CeXJtf0lfs0&list=PLR3CNIF8DDHJUl8RLhyOVpX_kT4bxulEV&index=10>`__ 


`Tutorial 7: Introduction to pyhealth.medcode <https://colab.research.google.com/drive/1xrp_ACM2_Hg5Wxzj0SKKKgZfMY0WwEj3?usp=sharing>`_ `[Video] <https://www.youtube.com/watch?v=MmmfU6_xkYg&list=PLR3CNIF8DDHJUl8RLhyOVpX_kT4bxulEV&index=9>`__  


 The following tutorials will help users build their own task pipelines.

`Pipeline 1: Drug Recommendation <https://colab.research.google.com/drive/10CSb4F4llYJvv42yTUiRmvSZdoEsbmFF?usp=sharing>`_ `[Video] <https://
www.youtube.com/watch?v=GGP3Dhfyisc&list=PLR3CNIF8DDHJUl8RLhyOVpX_kT4bxulEV&index=12>`__  

`Pipeline 2: Length of Stay Prediction <https://colab.research.google.com/drive/1JoPpXqqB1_lGF1XscBOsDHMLtgvlOYI1?usp=sharing>`_ `[Video] <https://
www.youtube.com/watch?v=GGP3Dhfyisc&list=PLR3CNIF8DDHJUl8RLhyOVpX_kT4bxulEV&index=12>`__  

`Pipeline 3: Readmission Prediction <https://colab.research.google.com/drive/1bhCwbXce1YFtVaQLsOt4FcyZJ1_my7Cs?usp=sharing>`_ `[Video] <https://
www.youtube.com/watch?v=GGP3Dhfyisc&list=PLR3CNIF8DDHJUl8RLhyOVpX_kT4bxulEV&index=12>`__  

`Pipeline 4: Mortality Prediction <https://colab.research.google.com/drive/1Qblpcv4NWjrnADT66TjBcNwOe8x6wU4c?usp=sharing>`_ `[Video] <https://
www.youtube.com/watch?v=GGP3Dhfyisc&list=PLR3CNIF8DDHJUl8RLhyOVpX_kT4bxulEV&index=12>`__ 

`Pipeline 5: Sleep Staging <https://colab.research.google.com/drive/1mpSeNCAthXG3cqROkdUcUdozIPIMTCuo?usp=sharing>`_ `[Video] <https://www.youtube.com/watch?v=ySAIU-rO6so&list=PLR3CNIF8DDHJUl8RLhyOVpX_kT4bxulEV&index=16>`__  


 We provided the advanced tutorials for supporting various needs. 

`Advanced Tutorial 1: Fit your dataset into our pipeline <https://colab.research.google.com/drive/1UurxwAAov1bL_5OO3gQJ4gAa_paeJwJp?usp=sharing>`_  `[Video] <https://www.youtube.com/watch?v=xw2hGLEQ4Y0&list=PLR3CNIF8DDHJUl8RLhyOVpX_kT4bxulEV&index=13>`__ 

`Advanced Tutorial 2: Define your own healthcare task <https://colab.research.google.com/drive/1gK6zPXvfFGBM1uNaLP32BOKrnnJdqRq2?usp=sharing>`_ 

`Advanced Tutorial 3: Adopt customized model into pyhealth <https://colab.research.google.com/drive/1F_NJ90GC8_Eq-vKTf7Tyziew4gWjjKoH?usp=sharing>`_  `[Video] <https://www.youtube.com/watch?v=lADFlcmLtdE&list=PLR3CNIF8DDHJUl8RLhyOVpX_kT4bxulEV&index=14>`__ 

`Advanced Tutorial 4: Load your own processed data into pyhealth and try out our ML models <https://colab.research.google.com/drive/1ZRnKch2EyJLrI3G5AvDXVpeE2wwgBWfw?usp=sharing>`_ `[Video] <https://www.youtube.com/watch?v=xw2hGLEQ4Y0&list=PLR3CNIF8DDHJUl8RLhyOVpX_kT4bxulEV&index=13>`__ 


7. Datasets :mountain_snow:
-----------------------------
We provide the processing files for the following open EHR datasets:

===================  =======================================  ========================================  ======================================================================================================== 
Dataset              Module                                   Year                                      Information                                                             
===================  =======================================  ========================================  ========================================================================================================
MIMIC-III            ``pyhealth.datasets.MIMIC3Dataset``      2016                                      `MIMIC-III Clinical Database <https://physionet.org/content/mimiciii/1.4//>`_    
MIMIC-IV             ``pyhealth.datasets.MIMIC4Dataset``      2020                                      `MIMIC-IV Clinical Database <https://physionet.org/content/mimiciv/0.4/>`_  
eICU                 ``pyhealth.datasets.eICUDataset``        2018                                      `eICU Collaborative Research Database <https://eicu-crd.mit.edu//>`_                 
OMOP                 ``pyhealth.datasets.OMOPDataset``                                                  `OMOP-CDM schema based dataset <https://www.ohdsi.org/data-standardization/the-common-data-model/>`_    
SleepEDF             ``pyhealth.datasets.SleepEDFDataset``    2018                                      `Sleep-EDF dataset <https://physionet.org/content/sleep-edfx/1.0.0/>`_
SHHS                 ``pyhealth.datasets.SHHSDataset``        2016                                      `Sleep Heart Health Study dataset <https://sleepdata.org/datasets/shhs>`_   
ISRUC                ``pyhealth.datasets.ISRUCDataset``       2016                                      `ISRUC-SLEEP dataset <https://sleeptight.isr.uc.pt/?page_id=48>`_                               
===================  =======================================  ========================================  ========================================================================================================


8. Machine/Deep Learning Models and Benchmarks :airplane:
------------------------------------------------------------

==================================    ================  =================================  ======  ============================================================================================================================================================================  =======================================================================================================================================================================================
Model Name                            Type              Module                             Year    Summary                                                                                                                                                                       Reference
==================================    ================  =================================  ======  ============================================================================================================================================================================  =======================================================================================================================================================================================
Multi-layer Perceptron                deep learning     ``pyhealth.models.MLP``            1986    MLP treats each feature as static                                                                                                                                             `Backpropagation: theory, architectures, and applications <https://www.taylorfrancis.com/books/mono/10.4324/9780203763247/backpropagation-yves-chauvin-david-rumelhart>`_
Convolutional Neural Network (CNN)    deep learning     ``pyhealth.models.CNN``            1989    CNN runs on the conceptual patient-by-visit grids                                                                                                                             `Handwritten Digit Recognition with a Back-Propagation Network <https://proceedings.neurips.cc/paper/1989/file/53c3bce66e43be4f209556518c2fcb54-Paper.pdf>`_
Recurrent Neural Nets (RNN)           deep Learning     ``pyhealth.models.RNN``            2011    RNN (includes LSTM and GRU) can run on any sequential level (e.g., visit by visit sequences)                                                                                  `Recurrent neural network based language model <http://www.fit.vutbr.cz/research/groups/speech/servite/2010/rnnlm_mikolov.pdf>`_
Transformer                           deep Learning     ``pyhealth.models.Transformer``    2017    Transformer can run on any sequential level (e.g., visit by visit sequences)                                                                                                  `Atention is All you Need <https://arxiv.org/abs/1706.03762>`_
RETAIN                                deep Learning     ``pyhealth.models.RETAIN``         2016    RETAIN uses two RNN to learn patient embeddings while providing feature-level and visit-level importance.                                                                     `RETAIN: An Interpretable Predictive Model for Healthcare using Reverse Time Attention Mechanism <https://arxiv.org/abs/1608.05745>`_
GAMENet                               deep Learning     ``pyhealth.models.GAMENet``        2019    GAMENet uses memory networks, used only for drug recommendation task                                                                                                          `GAMENet: Graph Attention Mechanism for Explainable Electronic Health Record Prediction <https://arxiv.org/abs/1809.01852>`_
MICRON                                deep Learning     ``pyhealth.models.MICRON``         2021    MICRON predicts the future drug combination by instead predicting the changes w.r.t. the current combination, used only for drug recommendation task                          `Change Matters: Medication Change Prediction with Recurrent Residual Networks <https://www.ijcai.org/proceedings/2021/0513>`_
SafeDrug                              deep Learning     ``pyhealth.models.SafeDrug``       2021    SafeDrug encodes drug molecule structures by graph neural networks, used only for drug recommendation task                                                                    `SafeDrug: Dual Molecular Graph Encoders for Recommending Effective and Safe Drug Combinations <https://arxiv.org/abs/2105.02711>`_
MoleRec                               deep Learning     ``pyhealth.models.MoleRec``        2023    MoleRec encodes drug molecule in a substructure level as well as the patient's information into a drug combination representation, used only for drug recommendation task     `MoleRec: Combinatorial Drug Recommendation with Substructure-Aware Molecular Representation Learning <https://dl.acm.org/doi/10.1145/3543507.3583872>`_
Deepr                                 deep Learning     ``pyhealth.models.Deepr``          2017    Deepr is based on 1D CNN. General purpose.                                                                                                                                    `Deepr : A Convolutional Net for Medical Records <https://arxiv.org/abs/1607.07519>`_
ContraWR Encoder (STFT+CNN)           deep Learning     ``pyhealth.models.ContraWR``       2021    ContraWR encoder uses short time Fourier transform (STFT) + 2D CNN, used for biosignal learning                                                                               `Self-supervised EEG Representation Learning for Automatic Sleep Staging <https://arxiv.org/abs/2110.15278>`_
SparcNet (1D CNN)                     deep Learning     ``pyhealth.models.SparcNet``       2023    SparcNet is based on 1D CNN, used for biosignal learning                                                                                                                      `Development of Expert-level Classification of Seizures and Rhythmic and Periodic Patterns During EEG Interpretation <#>`_
TCN                                   deep learning     ``pyhealth.models.TCN``            2018    TCN is based on dilated 1D CNN. General purpose                                                                                                                               `Temporal Convolutional Networks <https://arxiv.org/abs/1803.01271>`_
AdaCare                               deep learning     ``pyhealth.models.AdaCare``        2020    AdaCare uses CNNs with dilated filters to learn enriched patient embedding. It uses feature calibration module to provide the feature-level and visit-level interpretability  `AdaCare: Explainable Clinical Health Status Representation Learning via Scale-Adaptive Feature Extraction and Recalibration <https://arxiv.org/abs/1911.12205>`_
ConCare                               deep learning     ``pyhealth.models.ConCare``        2020    ConCare uses transformers to learn patient embedding and calculate inter-feature correlations.                                                                                `ConCare: Personalized Clinical Feature Embedding via Capturing the Healthcare Context <https://arxiv.org/abs/1911.12216>`_
StageNet                              deep learning     ``pyhealth.models.StageNet``       2020    StageNet uses stage-aware LSTM to conduct clinical predictive tasks while learning patient disease progression stage change unsupervisedly                                    `StageNet: Stage-Aware Neural Networks for Health Risk Prediction <https://arxiv.org/abs/2001.10054>`_
Dr. Agent                             deep learning     ``pyhealth.models.Agent``          2020    Dr. Agent uses two reinforcement learning agents to learn patient embeddings by mimicking clinical second opinions                                                            `Dr. Agent: Clinical predictive model via mimicked second opinions <https://academic.oup.com/jamia/article/27/7/1084/5858308>`_
GRASP                                 deep learning     ``pyhealth.models.GRASP``          2021    GRASP uses graph neural network to identify latent patient clusters and uses the clustering information to learn patient                                                      `GRASP: Generic Framework for Health Status Representation Learning Based on Incorporating Knowledge from Similar Patients <https://ojs.aaai.org/index.php/AAAI/article/view/16152>`_
==================================    ================  =================================  ======  ============================================================================================================================================================================  =======================================================================================================================================================================================

* Check the `interactive map on benchmark EHR predictive tasks <https://pyhealth.readthedocs.io/en/latest/index.html#benchmark-on-healthcare-tasks>`_.

9. Citing PyHealth :handshake:
----------------------------------

.. code-block:: bibtex

    @inproceedings{pyhealth2023yang,
        author = {Yang, Chaoqi and Wu, Zhenbang and Jiang, Patrick and Lin, Zhen and Gao, Junyi and Danek, Benjamin and Sun, Jimeng},
        title = {{PyHealth}: A Deep Learning Toolkit for Healthcare Predictive Modeling},
        url = {https://github.com/sunlabuiuc/PyHealth},
        booktitle = {Proceedings of the 27th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD) 2023},
        year = {2023}
    }

"
19,llSourcell/How_to_Build_a_healthcare_startup,Dart,"


## Overview

This is the code for [this](https://youtu.be/b8xlCNzkX5w) video on Youtube by Siraj Raval on ""How to Build a Healthcare Startup"". The app uses PoseNet to detect human poses and a text to speech engine to speak to you. This emulates the role of a Yoga instructor! This code is unfinished, but meant to give you a starting point and guide so that you can build a profitable business using it or a similar idea. 

## Dependencies

All of these can be downloaded in a single command, see below. 

- PoseNet Model 
- Tensorflow Lite
- Stripe
- RazorPay
- Flutter Text to Speech

## Instructions

First install [Flutter](https://flutter.dev/docs/get-started/install). 

After download, from command line run this to install the dependencies
```
flutter packages get
```
Then run this command to run the app

```
flutter run
```
Alternatively you can open the app as a new flutter project in Android Studio after installing the Flutter plugin. See the video for instructions on how to do that. 

## TODO - please make a PR if you fix any of these

- Firebase is integrated, but it still needs to be properly wired up to the login and signup pages.
- Stripe and RazorPay are integrated, but each still need to be wired up to the Credit/Debit Card view i created.
- Generate some text everytime a pose is detected, not just on startup.
- Make the personal 0/10 score some meaningful metric, store it in Firebase.
- PoseNet is integrated, but still needs to be replaced by YogaNet. 

## Wait what's YogaNet?

[this](https://github.com/smellslikeml/YogAI) is YogaNet. This person retrained a neural network to detect yoga poses and outputted the result as a TFLite file in their /models folder. Notice how in this flutter app, there is space to import TF Lite models. Integrate the Yoga Model into the app by replacing the existing posenet model. 

## Credits

Thanks to [shaqian](https://github.com/shaqian/flutter_realtime_detection) for her starter code. 
"
20,GoogleCloudPlatform/healthcare-data-harmonization,Go,"# Google HCLS Data Harmonization

## Summary

This is an engine that converts data of one structure to another, based on a
configuration file which describes how.

The configuration file can be written in either the native
[protobuf](https://developers.google.com/protocol-buffers/docs/overview) format
or a condensed
[Whistle Data Transformation Language](http://github.com/GoogleCloudPlatform/healthcare-data-harmonization/blob/master/mapping_language)
which is transpiled to protobuf configs for you.

The engine accepts data in JSON format and outputs it in JSON format. For
information on the mapping configuration, look at the protobuf files in the
proto directory.

## Overview

This repository is organized into several packages that together enable you to
author Whistle configs, extend existing mapping configurations, and test configs
within a Jupyter notebook environment.

*   [Mapping Engine](http://github.com/GoogleCloudPlatform/healthcare-data-harmonization/blob/master/mapping_engine/README.md)
*   [Mapping Language](http://github.com/GoogleCloudPlatform/healthcare-data-harmonization/blob/master/mapping_language/README.md)
*   [Mapping Configs](http://github.com/GoogleCloudPlatform/healthcare-data-harmonization/blob/master/mapping_configs/README.md)
*   [Jupyter Notebook](http://github.com/GoogleCloudPlatform/healthcare-data-harmonization/blob/master/tools/notebook/README.md)

## Getting Started

We highly recommend that you start by setting up your
[Jupyter Notebook](http://github.com/GoogleCloudPlatform/healthcare-data-harmonization/blob/master/tools/notebook/README.md)
environment using the published docker images and executing the
[example notebook](http://github.com/GoogleCloudPlatform/healthcare-data-harmonization/blob/master/tools/notebook/examples/demo-sample.ipynb).
Once setup, work through the
[Whistle Data Transformation Language Codelab](http://github.com/GoogleCloudPlatform/healthcare-data-harmonization/blob/master/mapping_language/doc/codelab.md)
to get yourself familiar with Whistle. As you author more Whistle configs, use
the
[Whistle Data Transformation Language Reference](http://github.com/GoogleCloudPlatform/healthcare-data-harmonization/blob/master/mapping_language/doc/reference.md)
to deepen your understanding of the language.

### Details

This project consists of three components, the mapping engine, the mapping
language, and Jupyter notebook UI extensions and magic commands. **If you want
to build the mapping engine and mapping language packages:**

Make sure you have installed and added to PATH

1.  [Golang](https://golang.org/dl/) (>= 1.13)
1.  [Java JDK](https://openjdk.java.net/install/) (>= 8)
1.  [Protobuf Compiler `protoc`](https://github.com/protocolbuffers/protobuf/releases/tag/v3.11.4)
    (>= 3.11.4)
1.  [Clang](https://clang.llvm.org/get_started.html) (>= 11.0.1-2)

Then run `build_all.sh`.

This command will build and run the tests of the above packages. In addition,
there are a set of JupyterLab UI extensions and magic commands that simplify the
authoring workflow. The extensions are packaged into a set of pre-built and
published docker images that contain and Jupyter notebook extensions/magic
commands and does not require you to build the mapping engine and mapping
library packages. For more details about each package, please refer to their
individual READMEs for more information.

### Language Reference

A language reference is available:
[Whistle Data Transformation Language Reference](http://github.com/GoogleCloudPlatform/healthcare-data-harmonization/blob/master/mapping_language/doc/reference.md)

### Codelab

Please refer to the
[Whistle Data Transformation Language Codelab](http://github.com/GoogleCloudPlatform/healthcare-data-harmonization/blob/master/mapping_language/doc/codelab.md)
for instructions on how to run the mapping engine and for getting familiar with
the mapping language.

### Sample pipelines

Whistle configs can be executed in [Apache Beam](https://beam.apache.org/).
Please refer to the
[Whistle Dataflow Pipelines Repo](https://github.com/GoogleCloudPlatform/healthcare-data-harmonization-dataflow)
for sample pipelines.

### Feedback

Want to help the Google Cloud Healthcare and Life Sciences team improve Whistle?
Please email: whistle-feedback@google.com to connect with the Whistle team for a
further discussion on your experience with Whistle.

## License

Apache License, Version 2.0
"
21,vsharathchandra/AI-Healthcare-chatbot,Python,"# AI-Healthcare-chatbot
Through a series of questions about symptoms it diagnosis the health condition of patient. <br />
Language     : python. <br />
modules used : scikit-learn,pandas,numpy <br />
Model        : Decision Tree

"
22,Rishabh42/HealthCare-Insurance-Ethereum,JavaScript,"# Medical Insurance claiming DApp (for ConsenSys)
Problem statement:
1) Patient logs in, uploads medical/lab test bills and submits it for insurance. Notifications are sent to hospital and lab admin.
2) Hospital admin logs in, verifies and approves the bills. This approval is stored on the smart contract
3) Lab admin approves the lab test bills. This approval is also stored on the smart contract
4) Once both of them approve, notification are sent to insurance admin.
5) Insurance admin can check for approvals of hospital and lab after which he will calculate the claim amount and do the claim.

 `HealthCare.sol` contract maintains the logic for this DApp.  
  The web pages found in the `Web-client` folder are used to communicate with the deployed smart contract and also allow logging in for each specific user

## Steps to deploy and interact with the contract:
1. Copy and paste the contract code on https://remix.ethereum.org/
2. Run an instance of ganache-cli on your local machine and connect your metamask wallet to it. Also, add the first 3 accounts from ganache to your metamask by importing their private keys and assign the following names to it:  
    account 1: Hospital admin  
    account 2: Lab admin  
    account 3: Patient  
3. Pass the Lab Admin's address as an argument in the constructor while deploying the contract
4. Select `Injected Web3` in the `Environment` field and make sure your Metamask wallet is unlocked. This will connect Remix to the first account(Hospital admin) in your Metamask wallet.
5. Deploy the contract
6. Select Account 3(Patient) and created a new medical record by calling the `newRecord` function with the respective fields.
7. You can check if the record was created and it's details by calling the `_records` mapping with index 1.
8. To sign the record, switch back to account 1(Hospital admin) in Metamask, enter the record's `_ID` in the `signRecord` function and click on transact.
9. Repeat the same steps using account 2(Lab Admin) from metamask.
10. Now the record is approved and you can verify the same by calling the `_records` mapping again where you can see that the `signatureCount` has incremented. 

Note that you can not sign the record using the patient's account from metamask and neither can the same account sign a record twice.

Update:  
With Remix's new interface, you need to change the account address from the `ACCOUNT` drop down on the `Deploy and Run` tab (required in step 8):  

<img width=""369"" alt=""Screenshot 2021-05-02 at 2 10 52 PM"" src=""https://user-images.githubusercontent.com/20457952/117578650-f00c6480-b10c-11eb-906e-c5ff79252585.png"">

## Known issues:  
- The table on the React front end doesn't display the records created by the user (Issue #1).  

The main focus of this project at the time of making was the smart contract logic, I just made the front end in a jiffy as I had some extra time left after implementing the contracts.  

Contributions to fix the open issues are welcome, you'll receive some DOGE as well 😏

## Steps to contribute  
1. Fork this repo.
2. Commit your changes.
3. Send a PR to this project's `master` branch and add me as a reviewer


"
23,PacktPublishing/Machine-Learning-for-Healthcare-Analytics-Projects,HTML,"


# Machine Learning for Healthcare Analytics Projects

<a href=""https://www.packtpub.com/big-data-and-business-intelligence/machine-learning-healthcare-analytics-projects?utm_source=github&utm_medium=repository&utm_campaign=9781789536591 ""><img src=""https://d255esdrn735hr.cloudfront.net/sites/default/files/imagecache/ppv4_main_book_cover/cover_8.png"" alt=""Machine Learning for Healthcare Analytics Projects"" height=""256px"" align=""right""></a>

This is the code repository for [Machine Learning for Healthcare Analytics Projects](https://www.packtpub.com/big-data-and-business-intelligence/machine-learning-healthcare-analytics-projects?utm_source=github&utm_medium=repository&utm_campaign=9781789536591), published by Packt.

**Build smart AI applications using neural network methodologies across the healthcare vertical market**

## What is this book about?

This book covers the following exciting features:
* Explore super imaging and natural language processing (NLP) to classify DNA sequencing 
* Detect cancer based on the cell information provided to the SVM 
* Apply supervised learning techniques to diagnose autism spectrum disorder (ASD) 
* Implement a deep learning grid and deep neural networks for detecting diabetes 
* Analyze data from blood pressure, heart rate, and cholesterol level tests using neural networks 
* Use ML algorithms to detect autistic disorders 

If you feel this book is for you, get your [copy](https://www.amazon.com/dp/1789536596) today!

<a href=""https://www.packtpub.com/?utm_source=github&utm_medium=banner&utm_campaign=GitHubBanner""><img src=""https://raw.githubusercontent.com/PacktPublishing/GitHub/master/GitHub.png"" 
alt=""https://www.packtpub.com/"" border=""5"" /></a>

## Instructions and Navigations
All of the code is organized into folders. For example, Chapter02.

The code will look like the following:

import sys
import pandas as pd
import sklearn
import keras
print 'Python: {}'.format(sys.version)
print 'Pandas: {}'.format(pd.__version__)
print 'Sklearn: {}'.format(sklearn.__version__)
print 'Keras: {}'.format(keras.__version__)


*Following is what you need for this book:*
Machine Learning for Healthcare Analytics Projects is for data scientists, machine learning engineers, and healthcare professionals who want to implement machine learning algorithms to build smart AI applications. Basic knowledge of Python or any programming language is expected to get the most from this book.

With the following software and hardware list you can run all code files present in the book (Chapter 1-5).
### Software and Hardware List
| Chapter | Software required | OS required |
| -------- | ------------------------------------ | ----------------------------------- |
| All | Python 3.6 or later | Windows, Mac OS X, and Linux (Any) |
|  | Anaconda 5.2 | Windows, Mac OS X, and Linux (Any) |
|  | Jupyter Notebook | Windows, Mac OS X, and Linux (Any) |


We also provide a PDF file that has color images of the screenshots/diagrams used in this book. [Click here to download it](https://www.packtpub.com/sites/default/files/downloads/9781789536591_ColorImages.pdf).

### Related products
* Healthcare Analytics Made Simple  [[Packt]](https://www.packtpub.com/big-data-and-business-intelligence/healthcare-analytics-made-simple?utm_source=github&utm_medium=repository&utm_campaign=) [[Amazon]](https://www.amazon.com/dp/1787286703)


## Get to Know the Author
*Eduonix Learning Solutions*
creates and distributes high-quality technology training content. Our team of industry professionals has been developing workforces for more than a decade. We aim to teach technology the way it is used in industry and the professional world. We have a professional team of trainers for technologies ranging from mobility, web enterprises, and database and server administration.


## Other books by the authors
[Learn to Create WordPress Themes by Building 5 Projects](https://www.packtpub.com/web-development/learn-create-wordpress-themes-building-5-projects?utm_source=github&utm_medium=repository&utm_campaign=9781787286641 )

[Learn Node.js by Building 6 Projects](https://www.packtpub.com/web-development/learn-nodejs-building-6-projects?utm_source=github&utm_medium=repository&utm_campaign=9781788293631 )



### Suggestions and Feedback
[Click here](https://docs.google.com/forms/d/e/1FAIpQLSdy7dATC6QmEL81FIUuymZ0Wy9vH1jHkvpY57OiMeKGqib_Ow/viewform) if you have any feedback or suggestions.
### Download a free PDF

 <i>If you have already purchased a print or Kindle version of this book, you can get a DRM-free PDF version at no cost.<br>Simply click on the link to claim your free PDF.</i>
<p align=""center""> <a href=""https://packt.link/free-ebook/9781789536591"">https://packt.link/free-ebook/9781789536591 </a> </p>"
24,GoogleCloudPlatform/healthcare-dicom-dicomweb-adapter,Java,"# DICOM Adapter

The DICOM adapter is a set of components that translate between traditional DICOM DIMSE protocols (e.g., C-STORE) and the RESTful DICOMweb protocols (e.g., STOW-RS). There are
two components, namely import and export adapter.

Table of Contents
=================

   * [DICOM Adapter](#dicom-adapter)
      * [Import Adapter](#import-adapter)
      * [Export Adapter](#export-adapter)
      * [Stackdriver Monitoring](#stackdriver-monitoring)
      * [DICOM Redactor](#dicom-redactor)
      * [Deployment using Kubernetes](#deployment-using-kubernetes)
         * [Requirements](#requirements)
         * [Deploying Docker Images to GKE](#deploying-docker-images-to-gke)
      * [Local Deployment](#local-deployment)
      * [Deployment using Data Protection Toolkit](#deployment-using-data-protection-toolkit)
      * [Building from source](#building-from-source)
         * [Building and publishing Docker Images](#building-and-publishing-docker-images)
      * [Wiki](#wiki)
      * [Troubleshooting](#troubleshooting)

## Import Adapter

The Import Adapter converts incoming DIMSE requests to corresponding DICOMWeb requests and passes the converted results back to the DIMSE client. The following requests are supported:
- C-STORE to STOW-RS
- C-FIND to QIDO-RS
- C-MOVE uses QIDO-RS to determine which instances to transfer, then for each instance executes a 
WADO-RS request to fetch the instance and a C-STORE request to transfer it to the C-MOVE destination
- Storage commitment service to QIDO-RS

Note that any C-FIND query on the ModalitiesInStudy tag will result in 1 QIDO-RS query per modality.

Available AET destinations for the C-MOVE and storage commitment services are configured via an AET dictionary json file, 
which can be specified either by using the ""--aet_dictionary"" command line parameter or 
specifying the ""ENV_AETS_JSON"" environment variable.

The following configuration needs to be added to the dicom-adapter.yaml file to use CMOVE. 
Please see the [Deployment using Kubernetes](#deployment-using-kubernetes) section for more information.
```yaml
env:
- name: ENV_AETS_JSON
  valueFrom:
    configMapKeyRef:
      name: aet-dictionary
      key: AETs.json
```

Here is an example JSON dictionary:
```shell
[
	{
		""name"": ""DEVICE_A"", 
		""host"": ""localhost"", 
		""port"": 11113
	},
	{
		""name"": ""DEVICE_B"", 
		""host"": ""192.168.0.1"", 
		""port"": 11114
	},
	...
]
```

And command to create configmap from it:

```shell
kubectl create configmap aet-dictionary --from-file=AETs.json
```

The AET dictionary JSON can also be specified directly via the ""--aet_dictionary_inline"" parameter.

For the list of command line flags, see [here](import/src/main/java/com/google/cloud/healthcare/imaging/dicomadapter/Flags.java)

## Export Adapter

The Export Adapter listens to [Google Cloud Pub/Sub](https://cloud.google.com/pubsub/)
for new instances, fetches them using WADO-RS, then sends them to the client.
This binary can be configured to output either C-STORE or STOW-RS via command
line flags.

To use [Google Cloud Pub/Sub](https://cloud.google.com/pubsub/), you require a [Google Cloud project](https://cloud.google.com). Furthermore, [Cloud Pubsub API](https://console.cloud.google.com/apis/api/pubsub.googleapis.com/overview) must be enabled in your Google project. The binary expects that each Cloud Pub/Sub notification consists of the WADO-RS path for the DICOM instance that is to be exported (e.g. `/studies/<STUDY_UID>/series/<SERIES_UID>/instances/<INSTANCE_UID>`).

For the list of command line flags, see [here](export/src/main/java/com/google/cloud/healthcare/imaging/dicomadapter/Flags.java)

## Stackdriver Monitoring

Both the Import and Export adapter include support for Stackdriver Monitoring.
It is enabled by specifying the --monitoring_project_id parameter, which must be the same project in which the adapter is running.
For the list of events logged to Stackdriver for the Export Adapter, see [here](export/src/main/java/com/google/cloud/healthcare/imaging/dicomadapter/monitoring/Event.java). 
For the list of events logged to Stackdriver for the Import Adapter, see [here](import/src/main/java/com/google/cloud/healthcare/imaging/dicomadapter/monitoring/Event.java).

The monitored resource is configured as k8s_container, with values set from a combination of environment variables configured via Downward API (pod name, pod namespace and container name) and GCP Metadata (project id, cluster name and location). Defaults to the global resource, if k8s_container can't be configured.

The following configuration needs to be added to the dicom-adapter.yaml file to configure the 
stackdriver monitoring resource. Please see the [Deployment using Kubernetes](#deployment-using-kubernetes) section 
for more information.
```yaml
env:
- name: ENV_POD_NAME
  valueFrom:
    fieldRef:
      fieldPath: metadata.name
- name: ENV_POD_NAMESPACE
  valueFrom:
    fieldRef:
      fieldPath: metadata.namespace
- name: ENV_CONTAINER_NAME
  value: *containerName # referencing earlier anchor in same yaml
```

## DICOM Redactor

The Import Adapter can be configured to use the [DICOM Redactor Library](https://github.com/GoogleCloudPlatform/healthcare-deid/tree/master/offline_tools/redactor) to redact sensitive data contained in DICOM tags during a C-STORE upload.
The user can configure which tags to redact/remove in one of 3 ways:
- redact_keep_list - a list of DICOM tags to keep untouched. Other tags are removed.
- redact_remove_list - a list of DICOM tags to remove. Other tags are kept untouched.
- redact_filter_profile - a predefined profile that will keep and remove particular tags.

If enabled via one of the above options, the redactor also always regenerates the following UIDs:
- StudyInstanceUID
- SeriesInstanceUID
- SOPInstanceUID
- MediaStorageSOPInstanceUID 

## Deployment using Kubernetes

The adapters can be deployed to Google Cloud Platform using [GKE] (https://cloud.google.com/kubernetes-engine/). We have published prebuilt Docker images for the both adapters to [Google Container Registry](https://cloud.google.com/container-registry/).

- Import Adapter: `gcr.io/cloud-healthcare-containers/healthcare-api-dicom-dicomweb-adapter-import`
- Export Adapter: `gcr.io/cloud-healthcare-containers/healthcare-api-dicom-dicomweb-adapter-export`

### Requirements

- A [Google Cloud project](https://cloud.google.com).
- Installed [gcloud](https://cloud.google.com/sdk/gcloud/) and [kubectl](https://kubernetes.io/docs/tasks/tools/install-kubectl/) command line tools.

### Deploying Docker Images to GKE

Create a local file called `dicom_adapter.yaml`. This file will contain the
configuration specifying the number of adapters to deploy, along with their
command line flags.

To deploy an Import Adapter, add the following to `dicom_adapter.yaml`. Modify
the flags for your use case.

```yaml
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: dicom-adapter
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: dicom-adapter
    spec:
      containers:
        - name: dicom-import-adapter
          image: gcr.io/cloud-healthcare-containers/healthcare-api-dicom-dicomweb-adapter-import:0.2.29
          ports:
            - containerPort: 2575
              protocol: TCP
              name: ""port""
          args:
            - ""--dimse_aet=IMPORTADAPTER""
            - ""--dimse_port=2575""
            - ""--dicomweb_address=https://healthcare.googleapis.com/v1/projects/myproject/locations/us-central1/datasets/mydataset/dicomStores/mydicomstore/dicomWeb""
```

**The yaml configuration has changed slightly from version 0.1 to 0.2. Please see the [upgrade guide](https://github.com/GoogleCloudPlatform/healthcare-dicom-dicomweb-adapter/wiki/DICOM-Adapter-Upgrade-Guide#to-version-020) for instructions on how to upgrade your configuration.**

The dicomweb_addr and dicomweb_stow_path parameters have been deprecated, please use the dicomweb_address parameter instead as shown above.
The old address parameters will not work with C-FIND, C-MOVE, and storage commitment.

If needed, to additionally include an Export Adapter, you can add the to the
containers in `dicom_adapter.yaml`. Modify the flags for your use case.

```yaml
        - name: dicom-export-adapter
          image: gcr.io/cloud-healthcare-containers/healthcare-api-dicom-dicomweb-adapter-export:0.2.29
          args:
            - ""--peer_dimse_aet=PEERAET""
            - ""--peer_dimse_ip=localhost""
            - ""--peer_dimse_port=104""
            - ""--project_id=myproject""
            - ""--subscription_id=mysub""
            - ""--dicomweb_addr=https://healthcare.googleapis.com/v1""
            - ""--oauth_scopes=https://www.googleapis.com/auth/pubsub""
```

The peer_dicomweb_addr and peer_dicomweb_stow_path parameters have been deprecated, please use the peer_dicomweb_address parameter instead.

To deploy the configuration to GKE cluster, execute the following:

```shell
gcloud container clusters create dicom-adapter --zone=us-central1-a --scopes https://www.googleapis.com/auth/cloud-healthcare,https://www.googleapis.com/auth/pubsub
kubectl create -f dicom_adapter.yaml
```

If you are deploying an Import Adapter, you can expose the DIMSE port internally
(e.g. 2575 here). This can be done through a load
balancer. Create a `dicom_adapter_load_balancer.yaml`, and add the following:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: dicom-adapter-load-balancer
  # The ""Internal"" annotation will result in an load balancer that can only
  # be accessed from within the VPC the Kubernetes cluster is in.
  # You can remove this annotation to get an externally accessible load balancer.
  annotations:
    cloud.google.com/load-balancer-type: ""Internal""
spec:
  ports:
  - port: 2575
    targetPort: 2575
    protocol: TCP
    name: port
  selector:
    app: dicom-adapter
  type: LoadBalancer
```

To deploy the load balancer, execute the following:

```shell
kubectl create -f dicom_adapter_load_balancer.yaml
```

The status and IP address of load balancer can be seen by executing:

```shell
kubectl get service dicom-adapter-load-balancer
```
## Local Deployment

Instructions on how to run the Import Adapter Docker image locally are available on the [wiki](https://github.com/GoogleCloudPlatform/healthcare-dicom-dicomweb-adapter/wiki/Running-Docker-image-locally).

## Deployment using Data Protection Toolkit

The adapters can be deployed as a gke_workload using the [data protection toolkit](https://github.com/GoogleCloudPlatform/healthcare/tree/master/deploy). Sample configuration may be found in this [folder.](https://github.com/GoogleCloudPlatform/healthcare-dicom-dicomweb-adapter/tree/master/samples) 

## Building from source

As an alternative to using the prebuilt Docker images, you can build the adapters from source code. Both adapters exist as separate binaries and are built using [Gradle](https://gradle.org/). Please refer to these [instructions](https://gradle.org/install/) to build Gradle for your system.

For example, to build Import Adapter:

```shell
cd import
gradle build
```

For example, to additionally execute Import Adapter locally:

```shell
gradle run -Dexec.args=""--dimse_aet=IMPORTADAPTER --dimse_port=4008 --dicomweb_address=http://localhost:80""
```

### Building and publishing Docker Images

To build and upload Import Adapter Docker images:

```shell
cd import
PROJECT=<Your Google Cloud Project>
TAG=gcr.io/${PROJECT}/dicom-import-adapter
gradle dockerBuildImage -Pdocker_tag=${TAG}
docker push ${TAG}
```

To build and upload Export Adapter Docker images:

```shell
cd export
PROJECT=<Your Google Cloud Project>
TAG=gcr.io/${PROJECT}/dicom-export-adapter
gradle dockerBuildImage -Pdocker_tag=${TAG}
docker push ${TAG}
```

## Wiki

For addition documentation please see the [Wiki](https://github.com/GoogleCloudPlatform/healthcare-dicom-dicomweb-adapter/wiki).
The wiki includes information on advanced features such as:
* [C-Store Retries and File Backup](https://github.com/GoogleCloudPlatform/healthcare-dicom-dicomweb-adapter/wiki/C-STORE-Backup-and-Retries)
* [Routing to Multiple DICOM Stores](https://github.com/GoogleCloudPlatform/healthcare-dicom-dicomweb-adapter/wiki/Routing-to-multiple-DICOM-stores)
* [C-Store In-Transit Transcoding](https://github.com/GoogleCloudPlatform/healthcare-dicom-dicomweb-adapter/wiki/In-transit-transcoding)

## Troubleshooting

Both the Import and Export adapter output server logs that can be used to diagnose issues. When running on GKE, these server logs show up in Cloud Logging. You can view these logs by navigating to https://console.cloud.google.com/kubernetes/workload, clicking on dicom-adapter deployment and following the link titled ""Container logs"". Alternatively you can view the logs via `kubectl logs <pod-name>` where `<pod-name>` can be found by running `kubectl get pods`.
"
25,newmediamedicine/CollaboRhythm,ActionScript,"CollaboRhythm
=============

CollaboRhythm is an open-source platform for patient-centered care research.

<http://newmed.media.mit.edu/collaborhythm>

<http://groups.google.com/group/collaborhythm-developers?hl=en>


Developers
----------

Instructions for developers are maintained on our [wiki](https://github.com/newmediamedicine/CollaboRhythm/wiki).
Please see the following pages to get started:

1. [Preparing Your Machine for CollaboRhythm Development](https://github.com/newmediamedicine/CollaboRhythm/wiki/Preparing-Your-Machine-for-CollaboRhythm-Development)

2. [Forking CollaboRhythm](https://github.com/newmediamedicine/CollaboRhythm/wiki/Forking-CollaboRhythm)

3. [Cloning and Using a Fork of CollaboRhythm](https://github.com/newmediamedicine/CollaboRhythm/wiki/Cloning-and-Using-a-Fork-of-CollaboRhythm)

4. [Pulling Upstream Changes from the Main CollaboRhythm Repository](https://github.com/newmediamedicine/CollaboRhythm/wiki/Pulling-Upstream-Changes-from-the-Main-CollaboRhythm-Repository)

Copyright and License
---------------------

Copyright 2012 John Moore, Scott Gilroy

This file is part of CollaboRhythm.

CollaboRhythm is free software: you can redistribute it and/or modify it under the terms of the GNU General Public
License as published by the Free Software Foundation, either version 2 of the License, or (at your option) any later
version.

CollaboRhythm is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied
warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more
details.

You should have received a copy of the GNU General Public License along with CollaboRhythm.  If not, see
<http://www.gnu.org/licenses/>."
26,neee/healthcare-service,Java,"# Сервис медицинских показаний

В классе Main, создаются несколько тестовых данных о пациентах и записываются в файл (репозиторий)
"
27,openhealthcare/opal,JavaScript,"Opal
====

![Build](https://github.com/openhealthcare/opal/workflows/.github/workflows/build.yml/badge.svg)

[![Coverage Status](https://coveralls.io/repos/github/openhealthcare/opal/badge.svg?branch=v0.11.0)](https://coveralls.io/github/openhealthcare/opal?branch=v0.11.0)

[![PyPI version](https://badge.fury.io/py/opal.svg)](https://badge.fury.io/py/opal)

Opal is a full stack web framework that makes building digital tools for health care easy.

It builds on established open source technologies with a track record of helping developers
build easy to maintain, robust applications.

Most notably, it makes use of [Django](https://djangoproject.com/), [AngularJS](https://angularjs.org/)
and [Bootstrap](http://getbootstrap.com/).

From there, Opal provides you with a common batteries-included architecture for writing healthcare
applications, and a composable modular framework that takes advantage of generic, re-usable components.

Opal is entirely open ([source](https://github.com/openhealthcare/opal) &
[governance](https://github.com/openhealthcare/opal/issues)) as are the wide library of plugins.

Opal was created by [Open Health Care UK](http://openhealthcare.org.uk), because it makes Healthcare IT Less Bad.

We'd love you to get involved by using what we make, reporting bugs/suggesting improvements, and fixing bugs/updating documentation/making improvements.

## Documentation

Documentation is available at: [http://opal.openhealthcare.org.uk/docs/](http://opal.openhealthcare.org.uk/docs/).
(The source is in this repository at `./doc`)

If you're just getting started we suggest:

* [Installation instructions](http://opal.openhealthcare.org.uk/docs/installation/)
* [The introductory tutorial](http://opal.openhealthcare.org.uk/docs/tutorial/)
* Reading through some [High level topic guides](http://opal.openhealthcare.org.uk/docs/guides/topic-guides/)

The documentation is updated frequently, and we welcome any feedback or contributions to it. If you find any problems,
or feel that anything needs clarifying in any way, please take 30 seconds to fill out a new issue [here](https://github.com/openhealthcare/opal/issues/new).

Documentation for old and development branches are available at e.g. [http://opal.openhealthcare.org.uk/docs/v0.7.1/](http://opal.openhealthcare.org.uk/docs/v0.7.1/)

## Getting more help

If you're looking for help and support, feel free to post to our [Mailing list](https://groups.google.com/forum/?ohc-dev#!forum/ohc-opal)

You could also tweet us at [@opalframework](http://twitter.com/opalframework) - although it can be hard to give long form support there !

## Contributing

Check out [CONTRIBUTING.md](./CONTRIBUTING.md) for information about getting involved.

## Open source

Opal is Licensed under the GNU Affero GPLv3

## Communications

* Email: hello@openhealthcare.org.uk
* Twitter: [@opalframework](https://twitter.com/opalframework)
* Mailing List: https://groups.google.com/forum/?ohc-dev#!forum/ohc-opal
"
28,SoumyaRSethi/Data-Science-Capstone-Healthcare,Jupyter Notebook,"# Data-Science-Capstone-Healthcare
 Data Science Capstone Project Using Python and Tableau 10

DESCRIPTION

Problem Statement
NIDDK (National Institute of Diabetes and Digestive and Kidney Diseases) research creates knowledge about and treatments for the most chronic, costly, and consequential diseases.
The dataset used in this project is originally from NIDDK. The objective is to predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset.
Build a model to accurately predict whether the patients in the dataset have diabetes or not.
Dataset Description
The datasets consists of several medical predictor variables and one target variable (Outcome). Predictor variables includes the number of pregnancies the patient has had, their BMI, insulin level, age, and more.

 

Variables	Description
Pregnancies	Number of times pregnant
Glucose	Plasma glucose concentration in an oral glucose tolerance test
BloodPressure	Diastolic blood pressure (mm Hg)
SkinThickness	Triceps skinfold thickness (mm)
Insulin	Two hour serum insulin
BMI	Body Mass Index
DiabetesPedigreeFunction	Diabetes pedigree function
Age	Age in years
Outcome	Class variable (either 0 or 1). 268 of 768 values are 1, and the others are 0
Project Task: Week 1
Data Exploration:

1. Perform descriptive analysis. Understand the variables and their corresponding values. On the columns below, a value of zero does not make sense and thus indicates missing value:

• Glucose

• BloodPressure

• SkinThickness

• Insulin

• BMI

2. Visually explore these variables using histograms. Treat the missing values accordingly.

3. There are integer and float data type variables in this dataset. Create a count (frequency) plot describing the data types and the count of variables. 

Project Task: Week 2
Data Exploration:

1. Check the balance of the data by plotting the count of outcomes by their value. Describe your findings and plan future course of action.

2. Create scatter charts between the pair of variables to understand the relationships. Describe your findings.

3. Perform correlation analysis. Visually explore it using a heat map.

 

Project Task: Week 3
Data Modeling:

1. Devise strategies for model building. It is important to decide the right validation framework. Express your thought process.

2. Apply an appropriate classification algorithm to build a model. Compare various models with the results from KNN algorithm.

 

Project Task: Week 4

Data Modeling:

1. Create a classification report by analyzing sensitivity, specificity, AUC (ROC curve), etc. Please be descriptive to explain what values of these parameter you have used.

Data Reporting:

2. Create a dashboard in tableau by choosing appropriate chart types and metrics useful for the business. The dashboard must entail the following:

a. Pie chart to describe the diabetic or non-diabetic population

b. Scatter charts between relevant variables to analyze the relationships

c. Histogram or frequency charts to analyze the distribution of the data

d. Heatmap of correlation analysis among the relevant variables

e. Create bins of these age values: 20-25, 25-30, 30-35, etc. Analyze different variables for these age brackets using a bubble chart.



Tableau Screen Shot-

![Tableau](https://github.com/SoumyaRSethi/Data-Science-Capstone-Healthcare/blob/d7b148f5b8ee701c43adde87660856b8e6095215/Tableau%20dashbord.PNG)
"
29,pramodramdas/digital_healthcare,JavaScript,"# digital_healthcare
electronic health records on blockchain

#### demo: http://digital-healthcare.herokuapp.com/
##### Note: Demo url to work you need to have metamask extension installed in your browser and to buy fake tickets you need to have fake ethers from rinkeby faceut.
##### Optimized contract can be found in contracts/optimized_healthCare.sol

### Summary
Project stores patient records on blockchain(hybrid). Hybrid because files are not stored on blockchain, but access information is stored on blockchain. There will be two participants doctor and patient.  
- Doctor register by providing name.  
- Patient register by providing name and age.
- Patient uploads files and provides random nounce to encrypt the file, file will be uploaded to IPFS and secret is stored in ethereum.
- Patient provides access to particular doctor.
- Once doctor is given access by patient, he will be able to see patient's address in his home page.
- Doctor can get all files ipfs hash of patient and send request to node app for file view.
- Node app will fetch file from ipfs and get secret from blockchain, decrypt file and send it to doctor.

### Note
Code has been tested only with ganache, not with any testnet.

### Project setup
HTTP_PROVIDER = provider url ex: http://127.0.0.1:7545  
IPFS_HOST = currently infura (can be changed to local node as well)

**1. Start Ganache**  
&nbsp;&nbsp;&nbsp;Contract can be deployed to any network, In my case ganache.
Update CONTRACT_DEPLOYED_PORT in env, which can be found in build -> contracts -> HealthCare.json -> ""networks"".  

**2. Start react server**  
&nbsp;&nbsp;&nbsp;`npm run start`  
&nbsp;&nbsp;&nbsp; visit http://localhost:3000  

**3. Start node app**   
&nbsp;&nbsp;&nbsp;`npm run server`  

**4. Connect metamask to ganache and Import ganache accounts to metamask**  
&nbsp;&nbsp;&nbsp;ex: http://localhost:7545  

___High Level Use Case___  

![Alt text](readme_images/high_level.png?raw=true ""high_level"")  

___Sign In___  

&nbsp;&nbsp;&nbsp; User should sign challenge to login, after which jwt token will be issued  

![Alt text](readme_images/2nd.png?raw=true ""sign_in"")  

___Upload Files___  

&nbsp;&nbsp;&nbsp; Here we have two layer of security 
1. hash provided by ipfs(ie. files can be accessed only if file hash is known)
2. file uploaded to ipfs is encrypted by secret (however secret is not encrypted in ethereum, should be done in future)

![Alt text](readme_images/3rd.png?raw=true ""upload_files"")  

___Access Files___  

![Alt text](readme_images/4th.png?raw=true ""access_files"")  

### TODO  
- Test cases, Currently deployment and registation tests has been written.
- Encrypt file secret while saving on ethereum (can be encrypted or NuCypher etc)
"
30,loutfialiluch/HealthCare,Java,"# HealthCare
<b>Healthcare</b> is an application that makes the communication between doctors and patients much easier.
<pre>
<img src=""Images/1.png"" height = ""500px"" width= ""250px"">    <img src=""Images/2.png"" height = ""500px"" width= ""250px"">    <img src=""Images/3.png"" height = ""500px"" width= ""250px""> <br/></br>
<img src=""Images/4.png"" height = ""500px"" width= ""250px"">    <img src=""Images/5.png"" height = ""500px"" width= ""250px"">    <img src=""Images/6.png"" height = ""500px"" width= ""250px""> <br/></br>
<img src=""Images/7.png"" height = ""500px"" width= ""250px"">    <img src=""Images/8.png"" height = ""500px"" width= ""250px"">    <img src=""Images/9.png"" height = ""500px"" width= ""250px""> <br/></br>
<img src=""Images/10.png"" height = ""500px"" width= ""250px"">
</pre>
"
31,grfiv/healthcare_twitter_analysis,Jupyter Notebook,"Healthcare Twitter Analysis  
===========================  

#### The use of social media data and data science to gain insights into health care and medicine. 

The current **status report** is in the main folder and you would do well to start by at least skimming it. 

[![DOI](https://zenodo.org/badge/5738/grfiv/healthcare_twitter_analysis.png)](http://dx.doi.org/10.5281/zenodo.11426)

-------------------------------
####RESTful interface to the MongoDB database

Under the `RESTful Interface` folder you will find the entire file structure required to run a Chrome web browser app that makes queries to a MongoDB database with all of the project's ~4 million json documents.

The instructions for running the project after you have installed the files  are under the `Instructions` tab of the main web page `HTAinterface.html` which you can simply load into your Chrome browser (Ctrl+o). The most-current instructions are contained here and will be updated as the project evolves.

The Status Report has a section with some of the technical details of Bottle, jQuery and Ajax

-------------------------------
####The Status Report `Status Report.pdf` in the main folder
 
- a comprehensive explanation of the dataset  
- examples of analyses done with this dataset  
- a list of references to other healthcare-related Twitter analyses  
- instructions for using Amazon Web Services
- sample programs using this file with Python, R and MongoDB.
- technical details of the RESTful interface. 


-------------------------------
####Complete dataset of the tweets for this project

Numerous files were created in the course of this project. They can be viewed at and downloaded from the Amazon S3 bucket where they have been archived at this web address: http://healthcare-twitter-analysis.com.s3-website-us-west-1.amazonaws.com/ 

All of the tweets for this project have been processed and consolidated into a single file **HTA_noduplicates.gz** that can be found by entering the file name in the search box at http://healthcare-twitter-analysis.com.s3-website-us-west-1.amazonaws.com/


Each of the 4 million rows in this file is a tweet in json format.

* Every record contains the following information:
    - All the Twitter data in exactly the json format of the original  
    - Unix time stamp  
    - data from the original files:  
        - originating file name  
        - score  
        - author screen name  
        - URLs  


* In addition, 60% of the records have geographic information
    - Latitude & Longitude  
    - Country name & ISO2 country code  
    - City  
    - For country code ""US""  
      - Zipcode  
      - Telephone area code  
      - Square miles inside the zipcode  
      - 2010 Census population of the zipcode  
      - County & FIPS code  
      - State name & USPS abbreviation   

The basic technique for using this file in Python is the following:


    import json
    
    with open(""HTA_noduplicates.json"", ""r"") as f:
        # convert each row in turn into json format and process
        for row in f:
            tweet = json.loads(row)
            text  = tweet[""text""]      # text of original tweet
            ...                        # etc.
            

The Status Report includes instructions for loading the json text file into a MongoDB database collection; I keep mine on an external hard drive and I start the MongoDB server as follows:

    mongod --dbpath ""E:\HTA""

The database is HTA and the collection is grf. In that case the Python code would look like this:

    import json
    from pymongo import MongoClient

    # start up MongoDB
    # ================
    client = MongoClient()  # assuming you have the MongoDB server running ...

    db     = client['HTA']   # reference the database
    tweets = db.grf          # reference the collection

    for tweet in tweets.find():
        text  = tweet[""text""]
        if tweet['geo']:
            (...)

"
32,instamed/healthcare-payments-blockchain,TypeScript,"PROJECT IS DEPRECIATED. CODE PROVIDED FOR REFERENCE ONLY.

------------


# Healthcare Payments on Blockchain

__This is a prototype useful for exploring blockchain or as a basis for a project. It is not intended for production use without further modification and testing.__

In the InstaMed Innovation Lab, we built a blockchain prototype focused on healthcare payments among providers, payers and patients. One of the prototype’s purposes is to evaluate the value of blockchain in driving a better healthcare payments experience for all stakeholders. [Learn more about the project](https://developers.instamed.com/healthcare-payments-blockchain/)

This is a [Hyperledger Fabric](https://www.hyperledger.org/projects/fabric) blockchain project that implements the FHIR Financial module. It is built with [Convector](https://github.com/worldsibu/convector) and follows the [FHIR spec](https://www.hl7.org/fhir/). A Vuejs demo frontend app is included in the project in /packages/frontend. 

~~The live demo can be found at: https://blockchain-demo.instamed.com/~~

~~The live network block browser can be found at: https://blockchain-demo.instamed.com:8443/~~

A video describing this flow can be found at: https://vimeo.com/325931177/e21834462d

## Prerequisites

* [Node](https://nodejs.org/en/download/) 8.11.0
* [Docker Community Edition](https://www.docker.com/community-edition)
* [npx](https://www.npmjs.com/package/npx) 
* If you are running in Ubuntu, make sure you meet all the prerequisites for Fabric and Convector - [Prerequisites Ubuntu](https://docs.worldsibu.com/article/120-install-on-ubuntu)

## How to run the project

~~Detailed instructions for installing on Ubuntu can be found here: https://developers.instamed.com/healthcare-payments-blockchain/install-blockchain-on-linux/~~

### Start from scratch

```bash
# Install dependencies
npm install

# Start the blockchain and the server
npm start

# Create some mock data automatically to setup the network
npm run mockData

# Start the server
npm run server:start

# You can now run transactions (there's a Postman file included to help you talk to the endpoints ""./Fhir Financial.postman_collection.json"")
# Read first the section ""Identities on the project"" of this README
# You should send transactions all transactions from postman_collection.json in the order defined before install the remaining views
# Views are associated to databases and Fabric doesn't generate them until at least 1 value was saved there
npm run views:install
```

This will:

* Install a development *Hyperledger Fabric Network* (and remove any previous one) with [Hurley](https://github.com/worldsibu/hurley).
* Install the chaincode with the name `financial` in the network.
* Start the NodeJS server.
* Install CouchDB views.
* Instantiate the chaincode servers.
* Create some mock data for you.

To get the **front end** to work properly, you need to run the postman added in the repository by configuring the fingerprints correctly.

Go to the Postman collection settings and set the value to the variable `patientFingerprint` to use the same for every transaction after you run `npm run user:fingerprint -- $HOME/hyperledger-fabric-network/.hfc-org1/user1` then go and set the value of `consortiumAdminFingerprint` to `npm run user:fingerprint -- $HOME/hyperledger-fabric-network/.hfc-org2/user1` and then value of `providerFingerprint` to `npm run user:fingerprint -- $HOME/hyperledger-fabric-network/.hfc-org3/user1`.

### Individual tasks

* Just start the server in dev mode `npm run server:start`. Run this in case after the `npm start` you close the terminal. This won't install the network again, just the NodeJS server.

### Enable the block browser capabilities

The front end project makes it possible to visualize blocks in the network as well as its contents.

![Blocks](/images/blocks.png)

The current project uses the [Byzantine Browser](https://github.com/in-the-keyhole/byzantine-browser)'s API to get the blocks from the transactions to the ledger in realtime. For now it uses a fork from [WorldSibu that enables TLS in the server](https://github.com/worldsibu/byzantine-browser).

Make sure you already started the blockchain (healthcare-payments-blockchain) with `npm start` so a blockchain network is running on your computer with [Hurley](https://github.com/worldsibu/hurley).

You have to run npm install twice for the backend and the frontend.

```bash
# Go outside this folder and clone the repo
git clone https://github.com/worldsibu/byzantine-browser.git
cd byzantine-browser
npm install
cd ui
npm install
npm run build
cd ..
```
Copy the keys from the hyperledger-fabric-network directory. We're assuming here you have installed the byzantine-browser in that same parent directory as the blockchain.


```
cp $HOME/hyperledger-fabric-network/.hfc-org1/* ./hfc-key-store
```

Replace the `.env` in the root of the Byzantine Browser folder (or create it if it doesn't exist) with the information below. 

```bash
USERID=user1
NETWORK_URL=grpc://localhost:7051
EVENT_URL=grpc://localhost:7052
```

Use your favorite text editor or use Nano

```
nano .env
(copy text from above and right click to paste into terminal)
control-O
control-X

```

Run the Byzantine server

```
./runApiServer.sh

```


## Explore the project

### Code structure

* `packages/financial-cc`: contains the whole smart contract with all its models and controllers.
* `packages/server`: contains the server calling the blockchain.
* `chaincode.config.json`: links the controllers and packages the config for the smart contract.
* `dev-env` a folder containing development environment needed files like the CouchDB views and the installation script.
* `Fhir Financial.postman_collection.json`: import this file into Postman to see the queries to the database, follow the numbers in the tasks to create a full flow.

### Identities on the project

`Payer Organizations`, `Provider Organizations`, and `Consumer Participants` are identified in the blockchain through a **fingerprint** of a certificate generated from the Certificate authority.

The logic goes as follows:

* A identity (user) is created in the Certificate Authority.
* That user is enrolled in the blockchain network (in the case of the development environment the identity is registered and then enrolled by default).
* Extract the fingerprint from the cert by calling:

```bash
# I.e.: npm run user:fingerprint -- $HOME/hyperledger-fabric-network/.hfc-org1/user1
npm run user:fingerprint -- $HOME/hyperledger-fabric-network/.hfc-<org>/<user>
```

* The result fingerprint looks like `A5:EB:E4:1E:8E:86:03:72:00:3F:EA:CA:D2:9D:98:08:CA:70:24:F6`.
* That same fingerprint will be validated when a transaction is signed by a identity from the blockchain.
* Be sure to pass it throught Postman when registering a new `Payer Organization` or `Consumer Participant` as a param called `fingerprint`. Transactions will validate that the right identity is trying to perform requests.
* For example, to create a Consumer Participant, the following JSON is valid:

```json
{
    ""participant"": {
        ""id"": ""Consumer::Bob""
    },
    ""fingerprint"": ""A5:EB:E4:1E:8E:86:03:72:00:3F:EA:CA:D2:9D:98:08:CA:70:24:F6""
}
```

You will need two different identities. One can be shared between the Payer and InstaMed (working on behalf of the patients) and the other one for a provider. The reason for this is that some data is stored only accessible to some identities (look for Private Collections later in this document), therefore a switch in the identity is made.

Go to the Postman collection settings and set the value to the variable `patientFingerprint` to use the same for every transaction after you run `npm run user:fingerprint -- $HOME/hyperledger-fabric-network/.hfc-org1/user1` then go and set the value of `consortiumAdminFingerprint` to `npm run user:fingerprint -- $HOME/hyperledger-fabric-network/.hfc-org2/user1` and then value of `providerFingerprint` to `npm run user:fingerprint -- $HOME/hyperledger-fabric-network/.hfc-org3/user1`.

#### Private Collections

For this project running locally, organizations are related to **Hurley organizations** in the followin order:

|Organization|Hurley Org|
|---|---|
|ABC_HEALTHCARE|org1MSP|
|INSTAMED (Patient)|org2MSP|
|XYZ_PROVIDER|org3MSP|

### Routing the server to query the different collections

To *query* the private collections from the nodejs server you can pass the id of the user's nodes you'd like to access (any value of './packages/server/src/config/identities.json' and the server will route the read query to those nodes). 

* I.e.: `GET https://----/----/----?user=payer` will send a transaction and look for data inside of the payer's nodes
* I.e.: `GET https://----/----/----?user=provider` will send a transaction and look for data inside of the provider's nodes
* I.e.: `GET https://----/----/----?user=patient` will send a transaction and look for data inside of the patient's nodes

#### A practical example

Get the fingerprint of the user1 in the org1

```bash
$ npm run user:fingerprint -- $HOME/hyperledger-fabric-network/.hfc-org1/user1
A5:EB:E4:1E:8E:86:03:72:00:3F:EA:CA:D2:9D:98:08:CA:70:24:F6
```

Be sure that your server is using the identity of user1 in org1, defined in `./packages/server/src/config/identities.json`

Every transaction sent from the server will be signed with the user1 in org1 identity, so the chaincode can safely check for the fingerprint through the `this.sender`

Except for the transaction made by the provider (mark the payment as made) through another certificate in `org2`.

### Running local environment

* Call the server located in `http://localhost:8080`
* Check the CouchDB server provisioned at http://localhost:5084/_utils/#/database/ch1_financial/_all_docs

## Architecture

![Development Environment](images/devenv.png?raw=true ""Development Environment"")

![Production Environment](images/prodenv.png?raw=true ""Production Environment"")

## Tests

### Run unit tests

#### Optional - debugging

By default the project will run unit tests in debug mode. To explore the code go to a new Chrome window and put the address to `chrome://inspect`. Add the server as a connection in the tab (top of the screen) ""Connection"", then click the button ""Add Connection"" and add `localhost:9229`.

Write `debugger;` in the code line you'd like the debugger to stop and run the tests.

#### Start unit tests

```bash
# Include npx if you use NPX for package management
[npx] lerna run test --scope financial-cc --stream
```

### Install in the blockchain

```bash
# Be sure you started the blockchain before with `npm run env:restart`
npm run cc:start
```

### Upgrade your chaincode to the blockchain

```bash
# I.e.: npm run cc:upgrade -- 1.2
npm run cc:upgrade -- <version>
```

--

Edits are done by InstaMed Development user
"
33,sarveshraj/blockchain-for-healthcare,JavaScript,"# Blockchain for Healthcare: A Proof of Concept

> **Note**: A lot has changed in the Ethereum world since this project was completed and the setup instructions might not work now. If you, being a good samaritan, run into an error during setup and are able to fix it, please raise a pull request to help others. Big big thanks from me!

## Installation

The projects requires NodeJS and npm to work. Instructions to install all other dependencies are given below.
> Note: The instructions given below are for Linux (specifically Ubuntu 18.04). You should be able to find similar instructions for MacOS and Windows. Although support is available for Windows, I recommend using Linux or MacOS. Windows has some difficulty playing with npm.

### Node modules

1. Move to the project directory and open it in your terminal.
2. Run `npm install`.

### Ganache

1. Go to [Ganache homepage](https://truffleframework.com/ganache) and download. 
2. If you are on Linux, you must have received an _.appimage_ file. Follow installation instructions available [here.](https://itsfoss.com/use-appimage-linux/)

### IPFS

1. Go to the [download page](https://docs.ipfs.io/introduction/install/) of IPFS and follow the instructions given.

### Local server

1. You can use any local server to deploy the web application.
2. I used PHP but feel free to choose anything of your liking.
3. To install PHP on your Linux machine, run `sudo apt-get install php`. Detailed instructions available [here.](https://thishosting.rocks/install-php-on-ubuntu/)
4. One more great option is lite-server which is available as a node module.
5. Install lite-server by running the following command on your terminal `npm install -g lite-server`

### Metamask

1. Metamask is a browser extension available for Google Chrome, Mozilla Firefox and Brave Browser.
2. Go to the this [link](http://metamask.io/) and add Metamask to your browser.

## Getting the dApp running

### Configuration

#### 1. Ganache
  - Open Ganache and click on settings in the top right corner.
  - Under **Server** tab:
    - Set Hostname to 127.0.0.1 -lo
    - Set Port Number to 8545
    - Enable Automine
  - Under **Accounts & Keys** tab:
    - Enable Autogenerate HD Mnemonic

#### 2. IPFS
  - Fire up your terminal and run `ipfs init`
  - Then run 
    ```
    ipfs config --json API.HTTPHeaders.Access-Control-Allow-Origin ""['*']""
    ipfs config --json API.HTTPHeaders.Access-Control-Allow-Credentials ""['true']""
    ipfs config --json API.HTTPHeaders.Access-Control-Allow-Methods ""['PUT', 'POST', 'GET']""
    ```
#### 3. Metamask
  - After installing Metamask, click on the metamask icon on your browser.
  - Click on __TRY IT NOW__, if there is an announcement saying a new version of Metamask is available.
  - Click on continue and accept all the terms and conditions after reading them.
  - Stop when Metamask asks you to create a new password. We will come back to this after deploying the contract in the next section.
  
### Deploying the contract

I purposely haven't used any development framework so as to keep the code as raw as possible. This will also be easier to understand for any newcomer who is already having a tough time understanding the many technologies the application is built on.

#### 1. Starting your local development blockchain
  - Open Ganache.
  - Make sure to configure it the way mentioned above.
  
Moving on, to deploy the contract on the blockchain you have two options:
  - Use any available development framework for dApps. I recommend the [Truffle](https://truffleframework.com/truffle) framework. [Embark](https://embark.status.im/) is another great alternative.
  - Go full on geek mode and deploy it yourself with a few lines of code.

I'll be explaining the second method here.

#### 2. Deploying the contract and linking it to the frontend
  - Fire up your terminal and move to the project directory
  - Now open up `/YOUR_PROJECT_DIRECTORY/src/js/run.js` in your favourite text editor
  - You have to make two changes:
    1. Make sure the address in line number 3 is the same as your RPC server address on Ganache.
    If you have configured Ganache as instructed above, the code should look like this:
    
    ```
    var web3 = new Web3(new Web3.providers.HttpProvider(""http://localhost:8545""));
    ```
    2. The path in this line should point to where your solidity contract is located:
    
    ```
    var code = fs.readFileSync('/YOUR_PROJECT_DIRECTORY/contracts/Agent.sol').toString();
    ```
  - Go back to your terminal, type `node` and hit enter
  - Copy and paste all the contents of `run.js` to the terminal
  - If all goes well, you should see some few lines as output of the command
    ```
    console.log(compiledCode.contracts[':Agent'].interface);
    ```
  - This is the ABI of the contract, copy and paste these lines in line number 10 of `app.js`. The code should look like:
    ``` 
    abi = JSON.parse('PASTE_YOUR_ABI_HERE')
    ```
  - Go back to the terminal and type `deployedContract.address;`, which is also the last command of your `run.js` file. The     output is the address where the contract is deployed on the blockchain.
  - Copy the output and paste it on line number 13 of `app.js`. The code should look like:
    ```
    contractInstance = AgentContract.at('PASTE_YOUR_ADDRESS_HERE');
    ```
  - That's it for this part. Now lets set up Metamask.
  
### Running the dApp

#### 1. Connecting Metamask to our local blockchain
  - Let's go back to the configuration section of Metamask.
  - If done correctly, you would have stopped at the part where Metamask asks you to create a new password.
  - Just below the __CREATE__ button, click on the __Import with seed phrase__.
  - A form should open up, asking you to enter __Wallet Seed__.
  - Open Ganache, copy the twelve words that make up the __MNEMONIC__ on the __ACCOUNTS__ tab. 
  - Paste the twelve words in __Wallet Seed__. Create a new password and click __IMPORT__.

#### 2. Starting IPFS 
  - Open a new terminal window.
  - Make sure you have configured IPFS as mentioned above.
  - Run `ipfs daemon`.
  
#### 3. Start a local server
  - Open a new terminal window and navigate to `/YOUR_PROJECT_DIRECTORY/src/`.
  - Run `php -S locahost:3000`.
  - Open `localhost:3000/register.html` on your browser.
  - That's it! The dApp is up and running locally.
"
34,STRML/Healthcare.gov-Marketplace,JavaScript,"**Note**: There has been some confusion between this and the late CMSGov/healthcare.gov repository.

There were two contractors working on healthcare.gov, each with separate responsibilities. The CMSGov
repository had one section. This repository contains the other.

***CMSGov Repository***
- Frontend Blog Files
- No Marketplace application code
- Relatively bug-free
- Completed by [Development Seed](http://developmentseed.org/)

***This repository***
- Marketplace application code
- Numerous bugs and poor coding practices
- Completed by [CGI Federal](http://www.cgi.com/en/us-federal/services-solutions)
- This is the code that has been on the news.

As of this writing, this is **the only repository on GitHub with this data.**

What This Is
------------

This repository is an unofficial bug tracker and pull request target for fixes
to [healthcare.gov/marketplace](https://healthcare.gov/marketplace/global/en_US/registration),
the much-maligned backend piece created by CGI Federal. Please post issues you've been having
with the marketplace here. As there is no other publicly available bugtracker, this is the place
to post issues and bugs.

This repository attempts to be a working fork of the marketplace. You should be able to run this
on a local web server and access healthcare.gov in the same way.

As of this time, the login page and much of the basic application will function correctly from
your local machine, making this repository great for testing and bugfixes.


What This Isn't
---------------

This is not an *official* repository. For all we know, nobody is listening.

This is not a clone of the CMSGov/healthcare.gov repository.

I have created this in hopes that there are some concerned programmers at CGI Federal who want to see
the project succeed. Sourcing fixes from the users of healthcare.gov is one way to achieve that goal.

See [the pull request](http://webcache.googleusercontent.com/search?q=cache:Tqg9LB2D2aYJ:https://github.com/CMSgov/healthcare.gov/pull/31+&cd=3&hl=en&ct=clnk) that started this idea. 
(Google Cache)

See the [open issues](https://github.com/STRML/Healthcare.gov-Marketplace/issues) and 
[closed issues](https://github.com/STRML/Healthcare.gov-Marketplace/issues?page=1&state=closed).


How To Run
----------

Prerequisites: `node`.

```bash
git clone git@github.com:STRML/Healthcare.gov-Marketplace.git # or download ZIP
cd Healthcare.gov-Marketplace
npm install
npm start # Starts local proxy server & launches browser
```

Tests
-----

There are no tests at this time. Please submit some in your favorite test framework. I lean towards QUnit but 
I won't refuse adding any worthwhile test code.


TODO
----

[Open Issues](https://github.com/STRML/Healthcare.gov-Marketplace/issues)
* ~~Redirect API calls to their actual destination so this fork works~~
* ~~Rewrite incoming redirects so we don't get moved back to healthcare.gov on login.~~
* Add any missing JS/CSS from other sections of the site
* Add unit tests and TravisCI integration
* Pass JSHint (good luck)


Contributing
------------

If healthcare.gov frustrates you, please contribute! My hope is that this repository becomes large enough
to attract some real attention, not just from CGI Federal but from Health & Human Services. They have been thoroughly
embarassed by this boondoggle and with luck will be looking for a way to reform the system and save face.

See the TODO list above.

While the existing source does not pass jshint, please make sure that any contributions do (we have to start somewhere).
Unit tests would be greatly appreciated. Please place them inside the `test/` folder, prefixed by unit test framework
(qunit, jasmine). Please just make sure they pass, and feel free to use your favorite test framework. I will take care
of wiring them into Grunt and TravisCI.

See the [baseline](https://github.com/STRML/Healthcare.gov-Marketplace/tree/baseline) branch for unmodified
upstream files. If you notice a change in the Healthcare.gov Marketplace, please commit it to that branch. Changes
will be merged from baseline to master when possible.

Development
-----------

If you want to run without minification for development, use `grunt develop`. Be sure to install grunt globally
if you haven't already, using `npm install -g grunt`.
"
35,medtorch/awesome-healthcare-ai,,"# awesome-healthcare-ai [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)
A curated list of awesome open source healthcare tools, machine learning algorithms, datasets and research papers.

Disclaimer :exclamation: I am not a medical specialist, and there might be mistakes. :exclamation:


## Contents

- :zap: [Medical specialties](#medical-specialties)
- :cyclone: [Medical tasks](#medical-tasks)
- :key: [Medical privacy](#medical-privacy)
- :book: [References](#references)

### Medical specialties
  * [Generic resources](resources/medical-specialties/generic.md)
  * [Allergy, Immunology, & Rheumatology](resources/medical-specialties/allergy-immunology-rheumatology.md)
  * [Anesthesiology](resources/medical-specialties/anesthesiology.md)
  * [Cardiovascular Health](resources/medical-specialties/cardiovascular-health.md)
  * [Complimentary Medicine](resources/medical-specialties/complimentary-medicine.md)
  * [Critical Care](resources/medical-specialties/critical-care.md)
  * [Dermatology](resources/medical-specialties/dermatology.md)
  * [Emergency Medicine & Trauma](resources/medical-specialties/emergency-medicine.md)
  * [Endocrinology & Metabolism](resources/medical-specialties/endocrinology.md)
  * [Family Medicine & Community Health](resources/medical-specialties/family-medicine.md)
  * [Gastroenterology & Hepatology](resources/medical-specialties/gastroenterology.md)
  * [Genetics & Genomics](resources/medical-specialties/genetics-genomics.md)
  * [Gerontology](resources/medical-specialties/gerontology.md)
  * [Hematology](resources/medical-specialties/hematology.md)
  * [Infectious Disease & Global Health](resources/medical-specialties/infectious-disease.md)
  * [Internal Medicine](resources/medical-specialties/internal-medicine.md)
  * [Nephrology](resources/medical-specialties/nephrology.md)
  * [Neurologic Surgery](resources/medical-specialties/neurologic-surgery.md)
  * [Neurology](resources/medical-specialties/neurology.md)
  * [Obstetrics & Gynecology](resources/medical-specialties/obstetrics-gynecology.md)
  * [Occupational Therapy](resources/medical-specialties/occupational-therapy.md)
  * [Oncology](resources/medical-specialties/oncology.md)
  * [Ophthalmology](resources/medical-specialties/ophthalmology.md)
  * [Orthopedics & Sports Medicine](resources/medical-specialties/orthopedics.md)
  * [Otolaryngology (ENT)](resources/medical-specialties/otolaryngology.md)
  * [Pain Medicine](resources/medical-specialties/anesthesiology.md)
  * [Pathology & Laboratory Medicine](resources/medical-specialties/pathology-laboratory.md)
  * [Pediatrics](resources/medical-specialties/pediatrics.md)
  * [Physical Therapy](resources/medical-specialties/physical-therapy.md)
  * [Plastic Surgery](resources/medical-specialties/plastic-surgery.md)
  * [Preventative Medicine & Nutrition](resources/medical-specialties/preventative-medicine.md)
  * [Psychiatry & Behavioral Sciences](resources/medical-specialties/psychiatry.md)
  * [Pulmonology](resources/medical-specialties/pulmonology.md)
  * [Radiology](resources/medical-specialties/radiology.md)
  * [Sleep Medicine](resources/medical-specialties/sleep-medicine.md)
  * [Social Welfare](resources/medical-specialties/social-welfare.md)
  * [Speech Pathology](resources/medical-specialties/speech-pathology.md)
  * [Surgery](resources/medical-specialties/surgery.md)
  * [Urology](resources/medical-specialties/urology.md)
  
### Medical tasks
  * [Semantic Segmentation](https://paperswithcode.com/area/medical/semantic-segmentation)
  * [Medical Image Segmentation](https://paperswithcode.com/area/medical/medical-image-segmentation)
  * [3D](https://paperswithcode.com/area/medical/3d)
  * [EEG](https://paperswithcode.com/area/medical/eeg)
  * [3D Absolute Human Pose Estimation](https://paperswithcode.com/area/medical/3d-absolute-human-pose-estimation)
  * [Drug discovery](https://paperswithcode.com/area/medical/drug-discovery)
  * [Electrocardiography (ECG)](https://paperswithcode.com/area/medical/electrocardiography-ecg)
  * [Medical Diagnosis](https://paperswithcode.com/area/medical/medical-diagnosis)
  * [Medical Image Registration](https://paperswithcode.com/area/medical/medical-image-registration)
  * [Cancer Detection](https://paperswithcode.com/area/medical/cancer)
  * [Disease Prediction](https://paperswithcode.com/area/medical/disease-prediction)
  * [Sleep Quality prediction](https://paperswithcode.com/area/medical/sleep-quality-prediction)
  * [Mortality Prediction](https://paperswithcode.com/area/medical/mortality-prediction)
  * [Synthetic Data Generation](https://paperswithcode.com/area/medical/synthetic-data-generation)
  * [Epidemiology](https://paperswithcode.com/area/medical/epidemiology)
  * [Skin diseases](https://paperswithcode.com/area/medical/skin)
  * [Medical Image Generation](https://paperswithcode.com/area/medical/medical-image-generation)
  * [Length-of-Stay prediction](https://paperswithcode.com/area/medical/length-of-stay-prediction)
  * [Pneumonia Detection](https://paperswithcode.com/area/medical/pneumonia-detection)
  * [Seizure Detection](https://paperswithcode.com/area/medical/seizure-detection)
  * [Breast Tumour Classification](https://paperswithcode.com/area/medical/breast-tumour-classification)
  * [Diabetic Retinopathy Detection](https://paperswithcode.com/area/medical/diabetic-retinopathy-detection)
  * [Protein Secondary Structure Prediction](https://paperswithcode.com/area/medical/protein-secondary-structure-prediction)
  * [Medical Relation Extraction](https://paperswithcode.com/area/medical/medical-relation-extraction)
  * [Electromyography (EMG)](https://paperswithcode.com/task/electromyography-emg)
  * [Tomography](https://paperswithcode.com/task/tomography)
  * [Patient Outcomes](https://paperswithcode.com/task/patient-outcomes)
  * [Computational Phenotyping](https://paperswithcode.com/task/computational-phenotyping)
  * [Lung Nodule Classification](https://paperswithcode.com/task/lung-nodule-classification)
  * [Mitosis Detection](https://paperswithcode.com/task/mitosis-detection)
  * [Mammogram](https://paperswithcode.com/task/mammogram)
  * [Histopathological Image Classification](https://paperswithcode.com/task/histopathological-image-classification)
  * [Seizure prediction](https://paperswithcode.com/task/seizure-prediction)
  * [Lung Disease Classification](https://paperswithcode.com/task/lung-disease-classification)
  * [Lung Nodule Detection](https://paperswithcode.com/task/lung-nodule-detection)
  * [Magnetic Resonance Fingerprinting](https://paperswithcode.com/task/magnetic-resonance-fingerprinting)
  * [Multi-Label Classification Of Biomedical Texts](https://paperswithcode.com/task/multi-label-classification-of-biomedical)
  * [Readmission Prediction](https://paperswithcode.com/task/readmission-prediction)
  * [X-Ray subtasks](https://paperswithcode.com/area/medical/x-ray)
  * [Automatic Sleep Stage Classification](https://paperswithcode.com/task/automatic-sleep-stage-classification)
  * [Diabetic Foot Ulcer Detection](https://paperswithcode.com/task/diabetic-foot-ulcer-detection)
  * [ECG Classification](https://paperswithcode.com/task/photoplethysmography-ppg)
  * [Immune Repertoire Classification](https://paperswithcode.com/task/immune-repertoire-classification)
  * [Participant Intervention Comparison Outcome Extraction](https://paperswithcode.com/task/participant-intervention-comparison-outcome)
  * [Protein Function Prediction](https://paperswithcode.com/task/protein-function-prediction)
  * [Surgical Gesture Recognition](https://paperswithcode.com/task/surgical-gesture-recognition)
  * [Surgical Skills Evaluation](https://paperswithcode.com/task/surgical-skills-evaluation)
  * [Ultrasound](https://paperswithcode.com/task/ultrasound)
  * [Cancer Metastasis Detection](https://paperswithcode.com/task/cancer-metastasis-detection)
  * [Chemical Reaction Prediction](https://paperswithcode.com/task/chemical-reaction-prediction)
  * [Diabetes prediction](https://paperswithcode.com/task/diabetes-prediction)
  * [Epilepsy Prediction](https://paperswithcode.com/task/epilepsy-prediction)
  * [Knee Osteoarthritis Prediction](https://paperswithcode.com/task/knee-osteoarthritis-prediction)
  * [Medical Report Generation](https://paperswithcode.com/task/medical-report-generation)
  * [Medical Super-Resolution](https://paperswithcode.com/task/medical-super-resolution)
  * [Molecule Interpretation](https://paperswithcode.com/task/molecule-interpretation)
  * [Pain Intensity Regression](https://paperswithcode.com/task/pain-intensity-regression)
  * [Pulmonary Embolism Detection](https://paperswithcode.com/task/pulmonary-embolism-detection)
  * [Single-cell modeling](https://paperswithcode.com/task/single-cell-modeling)
  * [White Matter Fiber Tractography](https://paperswithcode.com/task/white-matter-fiber-tractography)
  * [Breast density classification](https://paperswithcode.com/task/breast-density-classification)
  * [Atrial Fibrillation](https://paperswithcode.com/task/atrial-fibrillation)
  * [Age-Related Macular Degeneration Classification](https://paperswithcode.com/task/classification-of-age-related-macular)
  * [ECG Risk Stratification](https://paperswithcode.com/task/ecg-risk-stratification)
  * [Malaria Risk Exposure Prediction](https://paperswithcode.com/task/malaria-risk-exposure-prediction)
  * [Medical Code Prediction](https://paperswithcode.com/task/medical-code-prediction)
  * [Multi Diseases Detection](https://paperswithcode.com/task/multi-diseases-detection)
  * [Muscular Movement Recognition](https://paperswithcode.com/task/muscular-movement-recognition)
  * [Sequential Diagnosis](https://paperswithcode.com/task/sequential-diagnosis)
  * [Medical VQA](https://github.com/aioz-ai/MICCAI19-MedVQA)

### Medical Privacy 
  * Safe harbour
  * Anonymization
  * De-identification
     - [Customize Deep Learning-based De-Identification Systems Using Local Clinical Notes - A Study of Sample Size](https://www.medrxiv.org/content/10.1101/2020.08.09.20171231v1)
     - [deidentify](https://github.com/nedap/deidentify)
  * Cryptography

### References 
  * [Stanford Medicine](https://stanford.cloud-cme.com/default.aspx)
  * [Awesome Machine Learning in Biomedical Healthcare Imaging](https://github.com/XindiWu/Awesome-Machine-Learning-in-Biomedical-Healthcare-Imaging)
  * [Papers With Code](https://paperswithcode.com/area/medical)
  * [Awesome Healthcare](https://github.com/kakoni/awesome-healthcare)
  * [Awesome Healthmetrics](https://github.com/leandromineti/awesome-healthmetrics)
  * [Medical Data for Machine Learning](https://github.com/beamandrew/medical-data)
  * [Awesome mental health](https://github.com/dreamingechoes/awesome-mental-health)
"
36,microsoft/InnerEye-DeepLearning,Python,"# InnerEye-DeepLearning

[![Build Status](https://innereye.visualstudio.com/InnerEye/_apis/build/status/InnerEye-DeepLearning/InnerEye-DeepLearning-PR?branchName=main)](https://innereye.visualstudio.com/InnerEye/_build?definitionId=112&branchName=main)

InnerEye-DeepLearning (IE-DL) is a toolbox for easily training deep learning models on 3D medical images. Simple to run both locally and in the cloud with [AzureML](https://docs.microsoft.com/en-gb/azure/machine-learning/), it allows users to train and run inference on the following:

- Segmentation models.
- Classification and regression models.
- Any PyTorch Lightning model, via a [bring-your-own-model setup](docs/source/md/bring_your_own_model.md).

In addition, this toolbox supports:

- Cross-validation using AzureML, where the models for individual folds are trained in parallel. This is particularly important for the long-running training jobs often seen with medical images.
- Hyperparameter tuning using [Hyperdrive](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters).
- Building ensemble models.
- Easy creation of new models via a configuration-based approach, and inheritance from an existing architecture.

## Documentation

For all documentation, including setup guides and APIs, please refer to the [IE-DL Read the Docs site](https://innereye-deeplearning.readthedocs.io/#).

## Quick Setup

This quick setup assumes you are using a machine running Ubuntu with Git, Git LFS, Conda and Python 3.7+ installed. Please refer to the [setup guide](docs/source/md/environment.md) for more detailed instructions on getting InnerEye set up with other operating systems and installing the above prerequisites.

1. Clone the InnerEye-DeepLearning repo by running the following command:

   ```shell
   git clone --recursive https://github.com/microsoft/InnerEye-DeepLearning && cd InnerEye-DeepLearning
   ```

2. Create and activate your conda environment:

   ```shell
   conda env create --file environment.yml && conda activate InnerEye
   ```

3. Verify that your installation was successful by running the HelloWorld model (no GPU required):

   ```shell
   python InnerEye/ML/runner.py --model=HelloWorld
   ```

If the above runs with no errors: Congratulations! You have successfully built your first model using the InnerEye toolbox.

If it fails, please check the
[troubleshooting page on the Wiki](https://github.com/microsoft/InnerEye-DeepLearning/wiki/Issues-with-code-setup-and-the-HelloWorld-model).

## Full InnerEye Deployment

We offer a companion set of open-sourced tools that help to integrate trained CT segmentation models with clinical
software systems:

- The [InnerEye-Gateway](https://github.com/microsoft/InnerEye-Gateway) is a Windows service running in a DICOM network,
that can route anonymized DICOM images to an inference service.
- The [InnerEye-Inference](https://github.com/microsoft/InnerEye-Inference) component offers a REST API that integrates
with the InnerEye-Gateway, to run inference on InnerEye-DeepLearning models.

Details can be found [here](docs/source/md/deploy_on_aml.md).

![docs/deployment.png](docs/source/images/deployment.png)

## Benefits of InnerEye-DeepLearning

In combiniation with the power of AzureML, InnerEye provides the following benefits:

- **Traceability**: AzureML keeps a full record of all experiments that were executed, including a snapshot of the code. Tags are added to the experiments automatically, that can later help filter and find old experiments.
- **Transparency**: All team members have access to each other's experiments and results.
- **Reproducibility**: Two model training runs using the same code and data will result in exactly the same metrics. All sources of randomness are controlled for.
- **Cost reduction**: Using AzureML, all compute resources (virtual machines, VMs) are requested at the time of starting the training job and freed up at the end. Idle VMs will not incur costs. Azure low priority nodes can be used to further reduce costs (up to 80% cheaper).
- **Scalability**: Large numbers of VMs can be requested easily to cope with a burst in jobs.

Despite the cloud focus, InnerEye is designed to be able to run locally too, which is important for model prototyping, debugging, and in cases where the cloud can't be used. Therefore, if you already have GPU machines available, you will be able to utilize them with the InnerEye toolbox.

## Licensing

[MIT License](/LICENSE)

**You are responsible for the performance, the necessary testing, and if needed any regulatory clearance for
 any of the models produced by this toolbox.**

## Acknowledging usage of Project InnerEye OSS tools

When using Project InnerEye open-source software (OSS) tools, please acknowledge with the following wording:

> This project used Microsoft Research's Project InnerEye open-source software tools ([https://aka.ms/InnerEyeOSS](https://aka.ms/InnerEyeOSS)).

## Contact

If you have any feature requests, or find issues in the code, please create an
[issue on GitHub](https://github.com/microsoft/InnerEye-DeepLearning/issues).

Please send an email to InnerEyeInfo@microsoft.com if you would like further information about this project.

## Publications

Oktay O., Nanavati J., Schwaighofer A., Carter D., Bristow M., Tanno R., Jena R., Barnett G., Noble D., Rimmer Y., Glocker B., O’Hara K., Bishop C., Alvarez-Valle J., Nori A.: Evaluation of Deep Learning to Augment Image-Guided Radiotherapy for Head and Neck and Prostate Cancers. JAMA Netw Open. 2020;3(11):e2027426. [doi:10.1001/jamanetworkopen.2020.27426](https://pubmed.ncbi.nlm.nih.gov/33252691/)

Bannur S., Oktay O., Bernhardt M, Schwaighofer A., Jena R., Nushi B., Wadhwani S., Nori A., Natarajan K., Ashraf S., Alvarez-Valle J., Castro D. C.: Hierarchical Analysis of Visual COVID-19 Features from Chest Radiographs. ICML 2021 Workshop on Interpretable Machine Learning in Healthcare. [https://arxiv.org/abs/2107.06618](https://arxiv.org/abs/2107.06618)

Bernhardt M., Castro D. C., Tanno R., Schwaighofer A., Tezcan K. C., Monteiro M., Bannur S., Lungren M., Nori S., Glocker B., Alvarez-Valle J., Oktay. O: Active label cleaning for improved dataset quality under resource constraints. [https://www.nature.com/articles/s41467-022-28818-3](https://www.nature.com/articles/s41467-022-28818-3). Accompanying code [InnerEye-DataQuality](https://github.com/microsoft/InnerEye-DeepLearning/blob/1606729c7a16e1bfeb269694314212b6e2737939/InnerEye-DataQuality/README.md)

## Contributing

This project welcomes contributions and suggestions.  Most contributions require you to agree to a
Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us
the rights to use your contribution. For details, visit [https://cla.opensource.microsoft.com](https://cla.opensource.microsoft.com).

When you submit a pull request, a CLA bot will automatically determine whether you need to provide
a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions
provided by the bot. You will only need to do this once across all repos using our CLA.

This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).
For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or
contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.

## Maintenance

This toolbox is maintained by the [Microsoft Medical Image Analysis team](https://www.microsoft.com/en-us/research/project/medical-image-analysis/).
"
37,Project-Based-Learning-IT/healthcare-appointment-scheduling-app,JavaScript,"## healthcare-appointment-scheduling-app

**Frontend**- https://healthcareapp.netlify.app/

**Backend** - https://hospitalappointmentbooking.herokuapp.com/

## Patient Guide: 

### Patient Login
![Patient Login](https://github.com/Project-Based-Learning-IT/healthcare-appointment-scheduling-app/blob/calendar/Software-Engineering/Screenshots/original_login%20patient.jpg)

### Patient Personal Details
![Patient Personal Details](https://github.com/Project-Based-Learning-IT/healthcare-appointment-scheduling-app/blob/calendar/Software-Engineering/Screenshots/original_patient_personal%20details.png)

### Search
![Search](https://github.com/Project-Based-Learning-IT/healthcare-appointment-scheduling-app/blob/calendar/Software-Engineering/Screenshots/original_search%20doctor.jpg)

### Select Date
![Select date](https://github.com/Project-Based-Learning-IT/healthcare-appointment-scheduling-app/blob/calendar/Software-Engineering/Screenshots/original_select%20date.jpg)

### Select Slot
![Select Slot](https://github.com/Project-Based-Learning-IT/healthcare-appointment-scheduling-app/blob/calendar/Software-Engineering/Screenshots/original_booking%20status.jpg)

### Payment
![Payment](https://github.com/Project-Based-Learning-IT/healthcare-appointment-scheduling-app/blob/calendar/Software-Engineering/Screenshots/original_payment.jpg)

![Address](https://github.com/Project-Based-Learning-IT/healthcare-appointment-scheduling-app/blob/calendar/Software-Engineering/Screenshots/original_address%20details.jpg)

![Card details](https://github.com/Project-Based-Learning-IT/healthcare-appointment-scheduling-app/blob/calendar/Software-Engineering/Screenshots/original_card%20details.jpg)

### Appointment Status
![Appointment Status](https://github.com/Project-Based-Learning-IT/healthcare-appointment-scheduling-app/blob/calendar/Software-Engineering/Screenshots/original_appointment%20status.jpg)

### Previous Appointments
![Previous Appointments](https://github.com/Project-Based-Learning-IT/healthcare-appointment-scheduling-app/blob/calendar/Software-Engineering/Screenshots/original_previous%20appointments.jpg)

### Patient Feedback
![Patient Feedback](https://github.com/Project-Based-Learning-IT/healthcare-appointment-scheduling-app/blob/calendar/Software-Engineering/Screenshots/original_patient%20feedback.jpg)

## Doctor Guide: 
![Hompage doctor login](https://github.com/Project-Based-Learning-IT/healthcare-appointment-scheduling-app/blob/calendar/Software-Engineering/Screenshots/original_login%20both.jpg)

### Doctor Login
![Doctor login](https://github.com/Project-Based-Learning-IT/healthcare-appointment-scheduling-app/blob/calendar/Software-Engineering/Screenshots/original_doctor%20login.jpg)

### Doctor's Today's Schedule
![Doctors today's schedule](https://github.com/Project-Based-Learning-IT/healthcare-appointment-scheduling-app/blob/calendar/Software-Engineering/Screenshots/original_todays%20schedule.png)

### Doctor's Personal Details
![doctor's personal details](https://github.com/Project-Based-Learning-IT/healthcare-appointment-scheduling-app/blob/calendar/Software-Engineering/Screenshots/original_doctor%20personal%20details.jpg)

### Doctor's Previous Appointments
![Doctor's previous appointments](https://github.com/Project-Based-Learning-IT/healthcare-appointment-scheduling-app/blob/calendar/Software-Engineering/Screenshots/original_doctor%20previous%20appointments.png)

### Doctor View Feedback
![Doctor's View feedback](https://github.com/Project-Based-Learning-IT/healthcare-appointment-scheduling-app/blob/calendar/Software-Engineering/Screenshots/original_doctor%20feedback.jpg)
"
38,edaaydinea/AI-Projects-for-Healthcare,Jupyter Notebook,"# AI-Projects-for-Healthcare

This repository is included artificial intelligence, machine learning, data science, computer vision projects related to healthcare.

Information about completion: ✅(Complete), 🚧 (Work in Progress), ❌ (Incomplete)

## Table of Contents

- [AI-Projects-for-Healthcare](#ai-projects-for-healthcare)
  - [Table of Contents](#table-of-contents)
  - [Projects in Bootcamp Education](#projects-in-bootcamp-education)
  - [Projects in Healthcare + Artificial Intelligence Education](#projects-in-healthcare--artificial-intelligence-education)
  - [Research Projects](#research-projects)

## Projects in Bootcamp Education

- **[Breast Cancer Classification ✅](https://github.com/edaaydinea/AI-Projects-for-Healthcare/blob/master/Breast%20Cancer%20Classification/%20Breast_Cancer_Classification.ipynb):** The aim of this project is classification the tumors into malignant or benign with machine learning techniques.
- **[Detecting COVID-19 with Chest X-ray using PyTorch ✅](https://github.com/edaaydinea/AI-Projects-for-Healthcare/blo/731619a7f8e041059d15832d56c1ca1df540a221/Detecting%20COVID-19%20with%20Chest%20X-Ray%20using%20PyTorch/Detecting%20COVID-19%20with%20Chest%20X-Ray%20using%20PyTorch.ipynb):** The aim of this project is detection
  COVID-19 on the chest x-ray images by using PyTorch. The [dataset](https://www.kaggle.com/datasets/tawsifurrahman/covid19-radiography-database) is taken from Kaggle.
- **[Diabetes Prediction with PySpark MLLIB ✅](https://github.com/edaaydinea/AI-Projects-for-Healthcare/blob/731619a7f8e041059d15832d56c1ca1df540a221/Diabetes%20Prediction%20With%20Pyspark%20MLLIB/Diabetes_Prediction.ipynb):** The aim of this project is to build logistic regression model using PySpark MLLIB
  to classify patients as either diabetic or non-diabetic. This project is a Guided project([Link](https://www.coursera.org/projects/diabetes-prediction-with-pyspark-mllib)) available on Coursera.
- **[Heart Failure Data Analysis ✅](https://jovian.ai/edaaydinea/health-failure-prediction):** The aim of this project is to make a detailed exploratory data analysis on the Heart Failure Prediction [dataset](https://www.kaggle.com/datasets/andrewmvd/heart-failure-clinical-data) which is taken from Kaggle by using the plotly library.
- **[Relationship between COVID-17 & Happiness in that Country ✅](https://github.com/edaaydinea/AI-Projects-for-Healthcare/blob/master/Relationship%20between%20COVID-19%20%20%26%20Happiness%20in%20that%20Country/covid19%20data%20analysis%20notebook.ipynb):** The aim of this project is to work on whether
  where is any relationship between the spread of the coronavirus in a country and how happy people are living in
  that country or not. The dataset is taken from COVID-19 dataset published by Johns Hopkins University and World
  Happiness Report.

## Projects in Healthcare + Artificial Intelligence Education

- **[DNA Classification Project ✅](https://github.com/edaaydinea/AI-Projects-for-Healthcare/blob/master/DNA%20Classification%20Project/DNA%20Classification.ipynb):** The aim of this project is to find out whether the DNA sequence is the promoter.
- **[Heart Disease Classification Project ✅](https://github.com/edaaydinea/AI-Projects-for-Healthcare/blob/master/Heart%20Disease%20Classification%20Project/Heart%20Disease%20Classification.ipynb):** The aim of this project is to predict  the condition of her/his disease throughout a classification algorithm based on a neural network. The dataset is taken from [UCI Machine learning Respiratory](https://archive.ics.uci.edu/ml/datasets/Heart+Disease).
- **[Diagnosing Coronary Artery Disease Project ✅](https://github.com/edaaydinea/AI-Projects-for-Healthcare/blob/master/Diagnosing%20Coronary%20Artery%20Disease%20Project/Diagnosing%20Coronary%20Artery%20Disease.ipynb):** The aim of this project is to predict the condition of her/his disease throughout a classification algorithm based on a neural network.
- **[Breast Cancer Detection ✅](https://github.com/edaaydinea/AI-Projects-for-Healthcare/blob/master/Breast%20Cancer%20Detection/Breast_Cancer_Detection.ipynb):** The aim of this project is to predict the breast cancer from a digitized image of a fine needle aspirate (FNA) of a breast muscles

## Research Projects

- The projects here are included in different repository.
- **[Chest X-Ray Image Classification by using PyTorch, CNN (Pneumonia)✅](https://github.com/edaaydinea/Chest-Xray-Image-Classification-by-using-PyTorch-CNN)**
- **[Pneumonia Detection on Chest X-ray Images with Deep Learning (Keras) ✅](<https://github.com/edaaydinea/Pneumonia-Detection-on-Chest-Xray-Images-with-Deep-Leaning>)**
- **[Estimating the Probability of Confirmed COVID-19 Cases Taking into the Intensive Care Unit (ICU) ✅](<https://github.com/edaaydinea/Estimating-the-Probability-of-Confirmed-COVID-19-Cases-Taking-into-the-Intensive-Care-Unit-ICU>)**
- **[OP1 - Prediction of the Different Progressive Levels of Alzheimer's Disease ✅](<https://github.com/edaaydinea/OP1-Prediction-of-the-Different-Progressive-Levels-of-Alzheimer-s-Disease>)**
- **[OP2 - Prediction of the Different Progressive Levels of Alzheimer's Disease with MRI data ✅](<https://github.com/edaaydinea/OP2-Prediction-of-the-Different-Progressive-Levels-of-Alzheimer-s-Disease-with-MRI-data>)**
- **[Low Grade Glioma Segmentation ✅](<https://github.com/edaaydinea/Low-Grade-Glioma-Segmentation>)**
- **[Multiple Sclerosis Lesion Segmentation from Brain Magnetic Resonance Images via Fully Convolutional Neural Network 🚧](<https://github.com/edaaydinea/Multiple-Sclerosis-Lesion-Segmentation-from-Brain-Magnetic-Resonance-Images-via-Fully-Convolutional>)**
- **[Magnetic Resonance Imaging Comparisons of Demented and Non-demented Adults 🚧](<https://github.com/edaaydinea/Magnetic-Resonance-Imaging-Comparisons-of-Demented-and-Non-demented-Adults>)**
"
39,IBMStreams/streamsx.health,Java,"# Streams Healthcare Analytics Platform

Welcome to the Streams Healthcare Analytics Platform!

Our goal is to make it easy to create real-time healthcare analytics application using IBM Streams.  We want our users to be able to rapidly develop, test and validate healthcare analytics. Researchers and clinicians should focus on the analytics part of an application, while the platform should take care of the necessary plumbing and infrastructure work.

## Getting Started

**NEW Release v0.1 is now available [here](https://github.com/IBMStreams/streamsx.health/releases/tag/v0.1)!**  See this [post](https://github.com/IBMStreams/streamsx.health/wiki/First-Release-Overview) to learn more about this release!

Follow the [**Getting Started Guide**]https://github.com/IBMStreams/streamsx.health/wiki/Getting-Started) to learn about how to leverage the services from the Streams Healthcare Analytics Platform

## Streams Healthcare Demos

### Python Jupyter Notebook Demo

As part of our initial work for this platform, we have developed a real-time ECG monitoring sample, using the Physionet Ingest Service, Python and Jupyter notebook.  

[<img src=""https://github.com/IBMStreams/streamsx.health/blob/master/samples/HealthcareJupyterDemo/images/Healthcare_Demo.png"" alt=""Healthcare Jupyter Notebook Demo"" width=""600"">](https://github.com/IBMStreams/streamsx.health/blob/master/samples/HealthcareJupyterDemo/)

To see this sample in action, you can run this sample using [**IBM Data Science Experience**](https://datascience.ibm.com/) and [**Streaming Analytics Service**](https://console.ng.bluemix.net/docs/services/StreamingAnalytics/index.html) on Bluemix.  See this [notebook](https://datascience.ibm.com/exchange/public/entry/view/9fc33ce7301f10e21a9f92039cad29a6
) for details.

To run this sample in Streams Quick Start Edition:

1.  Get the Streams Quick Start Edition VM from [here](https://www-01.ibm.com/marketing/iwm/iwm/web/preLogin.do?source=swg-ibmistvi&S_TACT=000000VP&S_OFF_CD=10000737).
1.  Clone this repository.
1.  Follow the instructions from here to run the demo:  [Healthcare Python Streaming Application Demo](https://github.com/IBMStreams/streamsx.health/tree/master/samples/HealthcareJupyterDemo)

### Population Health and Patient Monitoring

This sample demonstrates how we can use IBM Streams and the Streams Healthcare Anallytics Platform to monitor patient status in real-time. The sample generates vitals and ECG data for 100 patients. Patient data is fed into an analytics application that checks if a patient's vitals are in the normal range. If the vitals exceed the normal ranges, an alert is raised and is displayed on the dashboard.

[<img src=""https://github.com/IBMStreams/streamsx.health/blob/develop/samples/PatientsMonitoringDemo/images/patientsMonitoring.jpeg"" alt=""Population Health and Patient Monitoring"" width=""600"">](https://github.com/IBMStreams/streamsx.health/tree/develop/samples/PatientsMonitoringDemo)

To run this sample in Streams Quick Start Edition:

1.  Get the Streams Quick Start Edition VM from [here](https://www-01.ibm.com/marketing/iwm/iwm/web/preLogin.do?source=swg-ibmistvi&S_TACT=000000VP&S_OFF_CD=10000737).
1.  Clone this repository.
1.  Follow the instructions from here to run the demo:  [Population Health and Patient Monitoring Demo](https://github.com/IBMStreams/streamsx.health/tree/develop/samples/PatientsMonitoringDemo)


## Platform Design and Roadmap

[<img src=""https://github.com/IBMStreams/streamsx.health/blob/wiki/img/healthroadmap.jpg"" alt=""Streams Healthcare Analytics Platform Roadmap"" width=""600"">](https://github.com/IBMStreams/streamsx.health/blob/master/samples/HealthcareJupyterDemo/)

This diagram shows what we think a typical Streams healthcare application will look like and its major components.  The blue boxes represent components that should be provided by the platform.  The purple box represents an area where our end-user should focus on.  (i.e. developing advanced analytics).  

For details on the design and roadmap of this platform, please refer to here:

https://github.com/IBMStreams/streamsx.health/wiki

Our design and roadmap are always up for discussions and we welcome your feedback and contribution.  Please submit an [issue](https://github.com/IBMStreams/streamsx.health/issues) if you have any feedback for us.

## Repository Organization

The platform is designed to employ the microservice architecture.  A microservice is a small application written in SPL, Java, or Python that fulfills a specific task in a bigger healthcare application.  An application is made up of one or more of microservices, loosely connected to each other using the dynamic connection feature (Import/Export operators) in Streams.  To learn more about the microservice architecture in Streams, refer to this [post](https://developer.ibm.com/streamsdev/2016/09/02/analytics-microservice-architecture-with-ibm-streams/).

The repository is set up to accomodate this architecture.  The top level folders represent major functional components of the platform.  Under each folder, you will find one or more microservices for that component.  Each of the services can be built independently using gradle.  You can build them by following the build instructions below.  

To run the services, follow instructions as documented in their respective README.md files.

## Build Instructions

This repository is set up to build using [Gradle](https://gradle.org/).

All of the services can be built from the root folder by running **`gradle build`**.

If gradle is not installed on your system, the project is shipped with a gradle wrapper.  You can build the projects by using this wrapper and running **`gradlew build`**.

Similarly, individual components and  services can be built by navigating to either the component or service directory and running **`gradle build`**. 

All projects can be cleaned from either the root folder, a component folder or a service folder by running **`gradle clean`**

# The Contributors

Thank you to all our contributors.  This platform is made available from their contributions and valuable feedback/advises.

| Name | Company |
|------|------|
| Brandon Swink | [IBM](https://www.ibm.com/analytics/us/en/technology/stream-computing/) |
| Gergens Polynice | [CleMetric](http://www.clemetric.com/)
| James Cancilla | [IBM](https://www.ibm.com/analytics/us/en/technology/stream-computing/) |
| Jonathan Lachman  | [True Process](http://www.trueprocess.com/)|
| Peter Nicholls | [IBM](https://www.ibm.com/analytics/us/en/technology/stream-computing/) |
| Samantha Chan | [IBM](https://www.ibm.com/analytics/us/en/technology/stream-computing/) |
| Sharath Cholleti | [CleMetric](http://www.clemetric.com/)


[<img src=""images/logo.png"" alt=""CleMetric"" width=""200"">](http://www.clemetric.com/)      [<img src=""images/TP-Logo-Default.png"" alt=""True Process"" width=""200"">](http://www.trueprocess.com/)      [<img src=""images/ibmpos_blue.jpg"" alt=""IBM"" width=""200"">](https://www.ibm.com/analytics/us/en/technology/stream-computing/)         

## Learn more about Streams

To learn more about Streams:

* [IBM Streams on Github](http://ibmstreams.github.io)
* [Introduction to Streams Quick Start Edition](http://ibmstreams.github.io/streamsx.documentation/docs/4.1/qse-intro/)
* [Streams Getting Started Guide](http://ibmstreams.github.io/streamsx.documentation/docs/4.1/qse-getting-started/)
* [StreamsDev](https://developer.ibm.com/streamsdev/)
"
40,vanderschaarlab/mlforhealthlabpub,Python,"# van der Schaar Lab
__Note__ : For the most recent papers and code, checkout https://github.com/vanderschaarlab.

__Legacy code__ : This repository contains the implementations of algorithms developed
by the [van der Schaar Lab](https://www.vanderschaar-lab.com/) for papers before 2023.



## Content
An overview of the content of this repository is as below:
```python
.
├── alg/        # Directory contains algorithms.
├── app/        # Directory contains apps.
├── cfg/        # Directory contains common config.
├── doc/        # Directory contains common docs.
├── init/       # Directory contains algorithms.
├── template/   # Directory contains templates.
└── util/       # Directory contains common utilities.
```

## Publications
The publications and the corresponding locations in the repo are listed below:

Paper [[Link]](#) | Journal/Conference | Code
--- | --- | ---
Bayesian Inference of Individualized Treatment Effects using Multi-task Gaussian Processes [[Link]](https://proceedings.neurips.cc/paper/2017/hash/6a508a60aa3bf9510ea6acb021c94b48-Abstract.html) | NIPS 2017 | [alg/causal_multitask_gaussian_processes_ite](alg/causal_multitask_gaussian_processes_ite)
Deep Multi-task Gaussian Processes for Survival Analysis with Competing Risks [[Link]](https://proceedings.neurips.cc/paper/2017/hash/861dc9bd7f4e7dd3cccd534d0ae2a2e9-Abstract.html) | NIPS 2017 | [alg/dgp_survival](alg/dgp_survival)
AutoPrognosis: Automated Clinical Prognostic Modeling via Bayesian Optimization with Structured Kernel Learning [[Link]](https://icml.cc/Conferences/2018/Schedule?showEvent=2050) | ICML 2018 | [alg/autoprognosis](alg/autoprognosis)
Limits of Estimating Heterogeneous Treatment Effects: Guidelines for Practical Algorithm Design [[Link]](http://proceedings.mlr.press/v80/alaa18a.html) | ICML 2018 | [alg/causal_multitask_gaussian_processes_ite](alg/causal_multitask_gaussian_processes_ite)
GAIN: Missing Data Imputation using Generative Adversarial Nets [[Link]](http://proceedings.mlr.press/v80/yoon18a.html) | ICML 2018 | [alg/gain](alg/gain)
RadialGAN: Leveraging multiple datasets to improve target-specific predictive models using Generative Adversarial Networks [[Link]](http://proceedings.mlr.press/v80/yoon18b.html) | ICML 2018 | [alg/RadialGAN](alg/RadialGAN)
GANITE: Estimation of Individualized Treatment Effects using Generative Adversarial Nets [[Link]](https://openreview.net/forum?id=ByKWUeWA-) | ICLR 2018 | [alg/ganite](alg/ganite)
Deep Sensing: Active Sensing using Multi-directional Recurrent Neural Networks [[Link]](https://openreview.net/forum?id=r1SnX5xCb) | ICLR 2018 | [alg/DeepSensing (MRNN)](alg/DeepSensing%20(MRNN))
DeepHit: A Deep Learning Approach to Survival Analysis with Competing Risks [[Link]](https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16160/15945) | AAAI 2018 | [alg/deephit](alg/deephit)
INVASE: Instance-wise Variable Selection using Neural Networks [[Link]](https://openreview.net/forum?id=BJg_roAcK7) | ICLR 2019 | [alg/invase](alg/invase)
PATE-GAN: Generating Synthetic Data with Differential Privacy Guarantees [[Link]](https://openreview.net/forum?id=S1zk9iRqF7) | ICLR 2019 | [alg/pategan](alg/pategan)
KnockoffGAN: Generating Knockoffs for Feature Selection using Generative Adversarial Networks [[Link]](https://openreview.net/forum?id=ByeZ5jC5YQ) | ICLR 2019 | [alg/knockoffgan](alg/knockoffgan)
ASAC: Active Sensing using Actor-Critic Models [[Link]](https://arxiv.org/abs/1906.06796) | MLHC 2019 | [alg/asac](alg/asac)
Demystifying Black-box Models with Symbolic Metamodels [[Link]](https://papers.nips.cc/paper/2019/hash/567b8f5f423af15818a068235807edc0-Abstract.html) | NeurIPS 2019 | [alg/symbolic_metamodeling](alg/symbolic_metamodeling)
Differentially Private Bagging: Improved Utility and Cheaper Privacy than Subsample-and-Aggregate [[Link]](https://papers.nips.cc/paper/2019/hash/5dec707028b05bcbd3a1db5640f842c5-Abstract.html) | NeurIPS 2019 | [alg/dpbag](alg/dpbag)
Time-series Generative Adversarial Networks [[Link]](https://papers.nips.cc/paper/2019/hash/c9efe5f26cd17ba6216bbe2a7d26d490-Abstract.html) | NeurIPS 2019 | [alg/timegan](alg/timegan)
Attentive State-Space Modeling of Disease Progression [[Link]](https://papers.nips.cc/paper/2019/hash/1d0932d7f57ce74d9d9931a2c6db8a06-Abstract.html) | NeurIPS 2019 | [alg/attentivess](alg/attentivess)
Conditional Independence Testing using Generative Adversarial Networks [[Link]](https://arxiv.org/abs/1907.04068) | NeurIPS 2019 | [alg/gcit](alg/gcit)
Dynamic-DeepHit: A Deep Learning Approach for Dynamic Survival Analysis with Competing Risks based on Longitudinal Data [[Link]](https://ieeexplore.ieee.org/document/8681104) | IEEE | [alg/dynamic_deephit](alg/dynamic_deephit)
Temporal Quilting for Survival Analysis [[Link]](http://proceedings.mlr.press/v89/lee19a.html) | AISTATS 2019 | [alg/survivalquilts](alg/survivalquilts)
Estimating Counterfactual Treatment Outcomes over Time through Adversarially Balanced Representations [[Link]](https://openreview.net/forum?id=BJg866NFvB) | ICLR 2020 | [alg/counterfactual_recurrent_network](alg/counterfactual_recurrent_network)
Contextual Constrained Learning for Dose-Finding Clinical Trials [[Link]](https://arxiv.org/abs/2001.02463) | AISTATS 2020 | [alg/c3t_budgets](alg/c3t_budgets)
Learning Overlapping Representations for the Estimation of Individualized Treatment Effects [[Link]](https://arxiv.org/abs/2001.04754) | AISTATS 2020 | [alg/dklite](alg/dklite)
Learning Dynamic and Personalized Comorbidity Networks from Event Data using Deep Diffusion Processes [[Link]](https://arxiv.org/abs/2001.02585) | AISTATS 2020 | [alg/dynamic_disease_network_ddp](alg/dynamic_disease_network_ddp)
Stepwise Model Selection for Sequence Prediction via Deep Kernel Learning [[Link]](https://arxiv.org/abs/2001.03898) | AISTATS 2020 | [alg/smsdkl](alg/smsdkl)
Temporal Phenotyping using Deep Predicting Clustering of Disease Progression [[Link]](http://proceedings.mlr.press/v119/lee20h.html) | ICML 2020 | [alg/ac_tpc](alg/ac_tpc)
Time Series Deconfounder: Estimating Treatment Effects over Time in the Presence of Hidden Confounders [[Link]](http://proceedings.mlr.press/v119/bica20a.html) | ICML 2020 | [alg/time_series_deconfounder](alg/time_series_deconfounder)
Discriminative Jackknife: Quantifying Uncertainty in Deep Learning via Higher-Order Influence Functions [[Link]](http://proceedings.mlr.press/v119/alaa20a.html) | ICML 2020 | [alg/discriminative-jackknife](alg/discriminative-jackknife)
Frequentist Uncertainty in Recurrent Neural Networks via Blockwise Influence Functions [[Link]](http://proceedings.mlr.press/v119/alaa20b.html) | ICML 2020 | [alg/rnn-blockwise-jackknife](alg/rnn-blockwise-jackknife)
Unlabelled Data Improves Bayesian Uncertainty Calibration under Covariate Shift [[Link]](http://proceedings.mlr.press/v119/chan20a.html) | ICML 2020 | [alg/transductive_dropout](alg/transductive_dropout)
Anonymization Through Data Synthesis Using Generative Adversarial Networks (ADS-GAN) [[Link]](https://ieeexplore.ieee.org/document/9034117) | IEEE | [alg/adsgan](alg/adsgan)
When and How to Lift the Lockdown? Global COVID-19 Scenario Analysis and Policy Assessment using Compartmental Gaussian Processes [[Link]](https://vanderschaar-lab.com/papers/NeurIPS2020_CGP.pdf) | NeurIPS 2020 | [alg/compartmental_gp](alg/compartmental_gp)
Strictly Batch Imitation Learning by Energy-based Distribution Matching [[Link]](https://arxiv.org/abs/2006.14154) | NeurIPS 2020 | [alg/edm](alg/edm)
Gradient Regularized V-Learning for Dynamic Treatment Regimes [[Link]](https://vanderschaar-lab.com/papers/NeurIPS2020_GRV.pdf) | NeurIPS 2020 | [alg/grv](alg/grv)
CASTLE: Regularization via Auxiliary Causal Graph Discovery [[Link]](https://arxiv.org/abs/2009.13180) | NeurIPS 2020 | [alg/castle](alg/castle)
OrganITE: Optimal transplant donor organ offering using an individual treatment effect [[Link]](https://vanderschaar-lab.com/papers/NeurIPS2020_OrganITE.pdf) | NeurIPS 2020 | [alg/organite](alg/organite)
Robust Recursive Partitioning for Heterogeneous Treatment Effects with Uncertainty Quantification [[Link]](https://arxiv.org/abs/2006.07917) | NeurIPS 2020 | [alg/r2p-hte](alg/r2p-hte)
Estimating the Effects of Continuous-valued Interventions using Generative Adversarial Networks [[Link]](https://arxiv.org/abs/2002.12326) | NeurIPS 2020 | [alg/scigan](alg/scigan)
Learning outside the Black-Box: The pursuit of interpretable models [[Link]](https://arxiv.org/abs/2011.08596) | NeurIPS 2020 | [alg/Symbolic-Pursuit](alg/Symbolic-Pursuit)
VIME: Extending the Success of Self- and Semi-supervised Learning to Tabular Domain [[Link]](https://papers.nips.cc/paper/2020/hash/7d97667a3e056acab9aaf653807b4a03-Abstract.html) | NeurIPS 2020 | [alg/vime](alg/vime)
Scalable Bayesian Inverse Reinforcement Learning [[Link]](https://openreview.net/pdf?id=4qR3coiNaIv) | ICLR 2021 | [alg/scalable-birl](alg/scalable-birl)
Nonparametric Estimation of Heterogeneous Treatment Effects: From Theory to Learning Algorithms [[Link]](https://arxiv.org/abs/2101.10943) | AISTATS 2021 | [alg/CATENets](https://github.com/vanderschaarlab/CATENets)
Learning Matching Representations for Individualized Organ Transplantation Allocation [[Link]](https://arxiv.org/abs/2101.11769) | AISTATS 2021| [alg/MatchingRep](alg/MatchingRep)
Explaining by Imitating: Understanding Decisions by Interpretable Policy Learning [[Link]](https://openreview.net/forum?id=unI5ucw_Jk) | ICLR 2021 | [alg/interpole](alg/interpole)
Inverse Decision Modeling: Learning Interpretable Representations of Behavior [[Link]](http://proceedings.mlr.press/v139/jarrett21a.html) | ICML 2021 | [alg/ibrc](alg/ibrc)
Policy Analysis using Synthetic Controls in Continuous-Time [[Link]](http://proceedings.mlr.press/v139/bellot21a/bellot21a.pdf) | ICML 2021 | [alg/Synthetic-Controls-in-Continuous-Time](https://github.com/vanderschaarlab/Synthetic-Controls-in-Continuous-Time/)
Learning Queueing Policies for Organ Transplantation Allocation using Interpretable Counterfactual Survival Analysis [[Link]](http://proceedings.mlr.press/v139/berrevoets21a/berrevoets21a.pdf) | ICML 2021 | [alg/organsync](https://github.com/vanderschaarlab/organsync/)
Explaining Time Series Predictions with Dynamic Masks [[Link]](http://proceedings.mlr.press/v139/crabbe21a.html) | ICML 2021 | [alg/Dynamask](https://github.com/vanderschaarlab/Dynamask/)
Generative Time-series Modeling with Fourier Flows [[Link]](https://openreview.net/forum?id=PpshD0AXfA) | ICLR 2021 | [alg/Fourier-flows](https://github.com/vanderschaarlab/Fourier-flows/)
On Inductive Biases for Heterogeneous Treatment Effect Estimation [[Link]](https://arxiv.org/pdf/2106.03765.pdf) | NeurIPS 2021 | [alg/CATENets](https://github.com/vanderschaarlab/CATENets/)
Really Doing Great at Estimating CATE? A Critical Look at ML Benchmarking Practices in Treatment Effect Estimation [[Link]](https://openreview.net/pdf?id=FQLzQqGEAH) | NeurIPS 2021 | [alg/CATENets](https://github.com/vanderschaarlab/CATENets/)
The Medkit-Learn(ing) Environment: Medical Decision Modelling through Simulation [[Link]](https://arxiv.org/abs/2106.04240) | NeurIPS 2021 | [alg/medkit-learn](https://github.com/vanderschaarlab/medkit-learn)
MIRACLE: Causally-Aware Imputation via Learning Missing Data Mechanisms [[Link]](https://neurips.cc/Conferences/2021/ScheduleMultitrack?event=27670) | NeurIPS 2021 | [alg/MIRACLE](https://github.com/vanderschaarlab/MIRACLE)
DECAF: Generating Fair Synthetic Data Using Causally-Aware Generative Networks [[Link]](https://neurips.cc/Conferences/2021/ScheduleMultitrack?event=27552) | NeurIPS 2021 | [alg/DECAF](https://github.com/vanderschaarlab/DECAF)
Explaining Latent Representations with a Corpus of Examples [[Link]](https://arxiv.org/abs/2110.15355) | NeurIPS 2021 | [alg/Simplex](https://github.com/vanderschaarlab/Simplex)
Closing the loop in medical decision support by understanding clinical decision-making: A case study on organ transplantation [[Link]](https://neurips.cc/Conferences/2021/ScheduleMultitrack?event=26815) | NeurIPS 2021 | [alg/iTransplant](https://github.com/vanderschaarlab/iTransplant)
Integrating Expert ODEs into Neural ODEs: Pharmacology and Disease Progression [[Link]](https://papers.neurips.cc/paper/2021/hash/5ea1649a31336092c05438df996a3e59-Abstract.html) | NeurIPS 2021 | [alg/Hybrid-ODE-NeurIPS-2021](https://github.com/vanderschaarlab/Hybrid-ODE-NeurIPS-2021)
SyncTwin: Treatment Effect Estimation with Longitudinal Outcomes [[Link]](https://proceedings.neurips.cc/paper/2021/hash/19485224d128528da1602ca47383f078-Abstract.html) | NeurIPS 2021 | [alg/SyncTwin-NeurIPS-2021](https://github.com/vanderschaarlab/SyncTwin-NeurIPS-2021)
Conformal Time-series Forecasting [[Link]](https://proceedings.neurips.cc/paper/2021/hash/312f1ba2a72318edaaa995a67835fad5-Abstract.html) | NeurIPS 2021 | [alg/conformal-rnn](https://github.com/vanderschaarlab/conformal-rnn/tree/master)
Estimating Multi-cause Treatment Effects via Single-cause Perturbation [[Link]](https://proceedings.neurips.cc/paper/2021/hash/c793b3be8f18731f2a4c627fb3c6c63d-Abstract.html) | NeurIPS 2021 | [alg/Single-Cause-Perturbation-NeurIPS-2021](https://github.com/vanderschaarlab/Single-Cause-Perturbation-NeurIPS-2021/)
Invariant Causal Imitation Learning for Generalizable Policies [[Link]](https://papers.nips.cc/paper/2021/file/204904e461002b28511d5880e1c36a0f-Paper.pdf) | NeurIPS 2021 | [alg/Invariant-Causal-Imitation-Learning](https://github.com/vanderschaarlab/Invariant-Causal-Imitation-Learning/tree/main)
Inferring Lexicographically-Ordered Rewards from Preferences [[Link]](https://ojs.aaai.org/index.php/AAAI/article/view/20516) | AAAI 2022 | [alg/lori](https://github.com/vanderschaarlab/lori)
Inverse Online Learning: Understanding Non-Stationary and Reactionary Policies [[Link]](https://openreview.net/forum?id=DYypjaRdph2) | ICLR 2022 | [alg/inverse-online](https://github.com/vanderschaarlab/inverse-online)
D-CODE: Discovering Closed-form ODEs from Observed Trajectories [[Link]](https://openreview.net/forum?id=wENMvIsxNN) | ICLR 2022 | [alg/D-CODE-ICLR-2022](https://github.com/vanderschaarlab/D-CODE-ICLR-2022)
Neural graphical modelling in continuous-time: consistency guarantees and algorithms [[Link]](https://openreview.net/forum?id=SsHBkfeRF9L) | ICLR 2022 | [alg/Graphical-modelling-continuous-time](https://github.com/vanderschaarlab/Graphical-modelling-continuous-time)
Label-Free Explainability for Unsupervised Models [[Link]](https://proceedings.mlr.press/v162/crabbe22a) | ICML 2022 | [alg/Label-Free-XAI](https://github.com/vanderschaarlab/Label-Free-XAI)
Inverse Contextual Bandits: Learning How Behavior Evolves over Time [[Link]](https://proceedings.mlr.press/v162/huyuk22a.html) | ICML 2022 | [alg/invconban](https://github.com/vanderschaarlab/invconban)
Data-SUITE: Data-centric identification of in-distribution incongruous examples [[Link]](https://proceedings.mlr.press/v162/seedat22a.html) | ICML 2022 | [alg/Data-SUITE](https://github.com/vanderschaarlab/Data-SUITE)
Continuous-Time Modeling of Counterfactual Outcomes Using Neural Controlled Differential Equations [[Link]](https://proceedings.mlr.press/v162/seedat22b) | ICML 2022 | [alg/TE-CDE](https://github.com/vanderschaarlab/TE-CDE)
Concept Activation Regions: A Generalized Framework For Concept-Based Explanations[[Link]](https://arxiv.org/abs/2209.11222) | NeurIPS 2022 | [alg/CARs](https://github.com/vanderschaarlab/CARs)
Benchmarking Heterogeneous Treatment Effect Models through the Lens of Interpretability[[Link]](https://arxiv.org/abs/2206.08363) | NeurIPS 2022 | [alg/ITErpretability](https://github.com/vanderschaarlab/ITErpretability)
Transfer Learning on Heterogeneous Feature Spaces for Treatment Effects Estimation[[Link]](https://arxiv.org/abs/2210.06183) | NeurIPS 2022 | [alg/HTCE-learners](https://github.com/vanderschaarlab/HTCE-learners)
Synthetic Model Combination: An Instance-wise Approach to Unsupervised Ensemble Learning[[Link]](https://arxiv.org/abs/2210.05320) | NeurIPS 2022 | [alg/HTCE-learners](https://github.com/vanderschaarlab/synthetic-model-combination)
<br/>

Details of apps and other software is listed below:

App/Software [[Link]](#) | Description | Publication | Code
--- | --- | --- | ---
Adjutorium COVID-19 [[Link]](https://www.vanderschaar-lab.com/paper-on-covid-19-hospital-capacity-planning-published-in-machine-learning/) | Adjutorium COVID-19: an AI-powered tool that accurately predicts how COVID-19 will impact resource needs (ventilators, ICU beds, etc.) at the individual patient level and the hospital level | - | [app/adjutorium-covid19-public](app/adjutorium-covid19-public)
Clairvoyance [[Link]](https://www.vanderschaar-lab.com/clairvoyance-alpha-the-first-unified-end-to-end-automl-pipeline-for-time-series-data/) | Clairvoyance: A Pipeline Toolkit for Medical Time Series | [ICML 2021](https://openreview.net/forum?id=xnC8YwKUE3k) | [clairvoyance repository](https://github.com/vanderschaarlab/clairvoyance)
Clairvoyance2 [[Link]](https://github.com/vanderschaarlab/clairvoyance2) | `clairvoyance2`: a Unified Toolkit for Medical Time Series | - | [clairvoyance2 repository](https://github.com/vanderschaarlab/clairvoyance2)
Hide-and-Seek Privacy Challenge [[Link]](http://www.vanderschaar-lab.com/privacy-challenge/) | Hide-and-Seek Privacy Challenge: Synthetic Data Generation vs. Patient Re-identification with Clinical Time-series Data | [NeurIPS 2020 competition track](https://arxiv.org/abs/2007.12087) | [app/hide-and-seek](app/hide-and-seek)

## Citations
Please cite the *the applicable papers* and [van der Schaar Lab repository](https://github.com/vanderschaarlab/mlforhealthlabpub/) if you use the software.

## Breakdown by category

**See breakdown [here](https://github.com/vanderschaarlab/.github/tree/main/profile).**

## License
Copyright **2019-2022** van der Schaar Lab.

This software is released under the [3-Clause BSD license](https://opensource.org/licenses/BSD-3-Clause) unless mentioned otherwise by the respective algorithms and apps.

## Installation instructions
*See individual algorithm and app directories for installation instructions.*

See also [doc/install.md](doc/install.md) for common installation instructions.

## Tutorials and or examples
*See individual algorithm and app directories for tutorials and examples.*

## Data
Data files (as well as other large files such as saved models etc.) can be downloaded as per instructions in the `DATA-*.md` (see e.g. [DATA-PUBLIC.md](./DATA-PUBLIC.md)) files found in the corresponding directories.

## More info
For more information on the van der Schaar Lab’s work, visit [our homepage](https://www.vanderschaar-lab.com/).

## References
*See individual algorithm and app directories for references.*
"
41,MichaelAllen1966/1804_python_healthcare,Jupyter Notebook,"# 1804_python_healthcare
pdf, py, and jupyter notebook files for https://pythonhealthcare.org/
"
42,IBM-MIL/IBM-Ready-App-for-Healthcare,Objective-C,"![](README_assets/banner.png)
# IBM Ready App for Healthcare

### Overview

IBM Ready App for Healthcare is the first of the IBM Ready App Series. 


This app 
* improves patient recovery timeframes 
* increases patient adherence to at-home physical therapy programs 
* tracks patient progress regardless of wearable utilized
* gives patients access to a customized, at-home exercise library that can be accessed anywhere
* enables patients to track and manage pain levels throughout the recovery process

With this app, patients can also fill out medical questionnaires and progress reports from any place with their mobile device prior to their in-clinic appointments.

### Getting started
Please visit the [Getting Started page](http://lexdcy040194.ecloud.edst.ibm.com/physio_1_0_2/getting_started) to set up the project.

### Documentation
Please visit [this page](http://lexdcy040194.ecloud.edst.ibm.com/physio_1_0_2/home) for access to the full documentation.

### License
IBM Ready App for Healthcare is available under the IBM Ready Apps License Agreement. See the [License file](https://github.com/IBM-MIL/IBM-Ready-App-for-Healthcare/blob/master/License.txt) for more details.
"
43,qgzang/ComputationalHealthcare,Python,"# Computational Healthcare Library 
This repository contains Computational Healthcare library (chlib), the underlying library used in [Computational Healthcare](http://www.computationalhealthcare.com/). 
Computational Healthcare library is designed to allow computer scientists to use large healthcare claims databases. Using chlib you can easily load & process large healthcare databases with millions of patients. 

## Analyze up to 200 Million visits & 70 Million patients

Currently we support following three databases:

 1. [Texas Inpatient public use data file 2006-2009](https://www.dshs.texas.gov/thcic/hospitals/Inpatientpudf.shtm): This database contains approximately 11 Million de-identified inpatient visits from Texas during 2006-2009, this data is available as free download. Inpatients visits in this database lack patient identifier.
   
 2. [HCUP Nationwide Readmission database for 2013](https://www.hcup-us.ahrq.gov/nrdoverview.jsp): This database contains de-identified inpatients visits during 2013 & 14. Unlike Texas database all inpatient visits are associated with a patient identifier and its possible to track patient through multiple visits.
 
 3. [HCUP State Inpatient, ED & SASD database](http://www.hcup-us.ahrq.gov/sidoverview.jsp): This is one of the largest logitudinal database of medical claims in the world. Acquiring this database typically takes several weeks and can cost few 100$ to ~10,000$ depending number of states/years/types. We currently support data from California, Florida & New York. If you are interested in using Computational Healthcare with this dataset please contact us.
          
**Please note that this repository does not contains any data, nor do we provide any data. You should acquire the datasets on your own 
  from AHRQ and/or other state agencies.**         

## Architecture & Data Model
A quick overview of data model, architecture is available in this [presentation](https://docs.google.com/presentation/d/1Oh_-FShr3BCGiCSqghI2dQYnyKvVOeiOqkIjaaEOPwc/edit?usp=sharing).

- The library uses Protocol buffers for storing [raw data (visits & patients)](/chlib/entity/protocols/pvisit.proto) and [aggregate statistics](/chlib/entity/protocols/pstat.proto).
- Categorical fields-values are represented as [enums](/chlib/entity/protocols/penums.proto) using Protocol buffers. 
- Raw data is stored in a levelDB database
- Protocol Buffers and LevelDB makes it easy to use any programming language
- We provide code to compute aggregate statistics in privacy preserving manner
- Integrated with TensorFlow for building machine learning models
 
## Installation & Setup

- The [docker folder](docker/) contains a Dockerfile with all dependencies specified. 
It also contains script for building docker image, starting container, preparing databases from user supplied files.

- Once you have obtained data you should modify [docker/prepare_nrd.sh](docker/prepare_nrd.sh) script with correct path to .CSV file and run the script.

- For Texas dataset modify/run the [prepare_tx.sh](docker/prepare_tx.sh).

- The dockerfile uses TensorFlow version 0.11 docker image as a starting point. Thus in addition to Computational Healthcare library it 
also contains a Jupyter notebook server which runs automatically when the container is started. Once the preparation step is 
complete you can use the jupyter notebook server running (inside the container) on port 8888 of your local machine.


## Quick overview  

```python
    import chlib
    NRD = chlib.data.Data.get_from_config('../config.json','HCUPNRD')
    # patients
    for p_key,patient in NRD.iter_patients():
        break
    print p_key,patient
    
    # visits
    for p_key,patient in NRD.iter_patients():
        for v in patient.visits:
            break
        break
    print v
```

#### output (fake)

````
123213213 patient_key: ""213213213""
visits {
  key: ""123213""
  patient_key: ""213123213213""
  dataset: ""NRD_2011""
  state: ""NRD""
  facility: ""1232131""
  vtype: IP
  age: 23
  sex: FEMALE
  race: R_UNKNOWN
  source: S_ED
  disposition: D_ROUTINE
  los: 0
  death: ALIVE
  payer: PRIVATE
  primary_diagnosis: ""D80""
  primary_procedure {
    pcode: ""P86""
    pday: 0
    ctype: ICD
  }
  drg: ""DG05""
  prs {
    pcode: ""P8659""
    pday: -1
    ctype: ICD
    occur: 1
  }
  year: 2013
  month: 10
  quarter: 1
  zip: Z_THIRD
  dnr: DNR_UNAVAILABLE
  charge: 229.0
}
raw: ""<>""
linked: true

  key: ""123213""
  patient_key: ""213213213123""
  dataset: ""NRD_2011""
  state: ""NRD""
  facility: ""1232131""
  vtype: IP
  age: 65
  sex: FEMALE
  race: R_UNKNOWN
  source: S_ED
  disposition: D_ROUTINE
  los: 0
  death: ALIVE
  payer: PRIVATE
  primary_diagnosis: ""D80""
  primary_procedure {
    pcode: ""P86""
    pday: 0
    ctype: ICD
  }
  drg: ""DG05""
  dxs: ""D709""
  prs {
    pcode: ""P8659""
    pday: -1
    ctype: ICD
    occur: 1
  }
  year: 2013
  day: 5151
  month: 10
  quarter: 1
  zip: Z_THIRD
  dnr: DNR_UNAVAILABLE
  charge: 229.0
````
      
### Text description of codes and enums      
```python
    coder =  chlib.codes.Coder() 
    print 'D486',coder['D486'] # ICD-9 diagnosis codes are prepended with 'D'
    print 'P9971',coder['P9971'] # ICD-9 procedure codes are prepended with 'P'
    print coder[chlib.entity.enums.D_AMA] # You can also print string representation of Enums            
```
#### output
````
D486 Pneumonia, organism unspecified
P9971 Therapeutic plasmapheresis
Against medical advice
````

### Retrieve list of patients with particular diagnosis or procedure

```python 
    patients_undergoing_plasmapheresis = [p for _,p in NRD.iter_patients_by_code('P9971')]
    # You can speed this up by precomputing list of patients for each codes, using 'fab precompute'
    print len(patients_undergoing_plasmapheresis)
    for v in patients_undergoing_plasmapheresis[0].visits:
        print v.key,v.day,v.prs
```   

## Tutorials / Articles

1. [Computational Healthcare for reproducible machine learning: building embedding from million inpatient visits](blog/introduction.ipynb)
 
2. [Analyzing long term outcomes of Ventriculostomy in pediatric patients](blog/ventriculostomy.ipynb)

3. [Exploring OHDSI common data model, comparison with Computational Healthcare (currently writing)](blog/ohdsi.ipynb)

## Issues & Bugs
To minimize chances of visit/patient level information leaking via Exceptions messages or Traceback, we have not enabled
issues on github repo. If you find any bugs, make sure that your bug report/question does not contains any visit or patient
 level information. To file a bug please email us at address provided below.

## Contact
For more information, comments or if you plan on citing Computational Healthcare library please contact Akshay Bhat at aub3@cornell.edu.
 
## Copyright
Copyright Cornell University 2016; All rights reserved;
Please contact us for more information.
"
44,microsoft/healthcare-shared-components,C#,"
# Health Care Shared Components
[![Build Status](https://microsofthealthoss.visualstudio.com/SharedComponents/_apis/build/status/CI-Build-OSS?branchName=main)](https://microsofthealthoss.visualstudio.com/SharedComponents/_build/latest?definitionId=83&branchName=main)

This repository is a collection of components used by the Microsoft Health Care team which develops services such as
the [FHIR Server for Azure](https://github.com/microsoft/fhir-server), the [IoMT FHIR Connector for Azure](https://github.com/microsoft/iomt-fhir),
and the [Medical Imaging Server for DICOM](https://github.com/microsoft/dicom-server).

# Contributing

This project welcomes contributions and suggestions.  Most contributions require you to agree to a
Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us
the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.

When you submit a pull request, a CLA bot will automatically determine whether you need to provide
a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions
provided by the bot. You will only need to do this once across all repos using our CLA.

This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).
For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or
contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.

# Privacy
Microsoft values your privacy. See the [Microsoft Privacy Statement](http://go.microsoft.com/fwlink/?LinkId=518021) for more information
"
45,bluehalo/node-fhir-server-core,JavaScript,"# Asymmetrik FHIR API Server

> A Secure Rest implementation for the [HL7 FHIR Specification](https://www.hl7.org/fhir/). For API documentation, please see [our documents](https://github.com/Asymmetrik/node-fhir-server-core/tree/master/docs).

[![Build Status](https://travis-ci.org/Asymmetrik/node-fhir-server-core.svg?branch=develop)](https://travis-ci.org/Asymmetrik/node-fhir-server-core) [![Known Vulnerabilities](https://snyk.io/test/github/asymmetrik/node-fhir-server-core/badge.svg?targetFile=package.json)](https://snyk.io/test/github/asymmetrik/node-fhir-server-core?targetFile=package.json)

The Asymmetrik Extensible Server Framework for Healthcare allows organizations to build secure, interoperable solutions that can aggregate and expose healthcare resources via a common HL7® FHIR®-compatible REST API. This server framework currently supports **DSTU2** (1.0.2), **STU3** (3.0.1), and **R4** (4.0.0) simultaneously. You can decide to support all three or just one by editing the configuration.

The framework defines a core server, `node-fhir-server-core`, a simple, secure Node.js module built according to the FHIR specification and compliant with the [US Core](http://www.hl7.org/fhir/us/core/) implementation.

For an example implementation using MongoDB, please refer to our Github repository that we used for the ONC FHIR Secure API Server Showdown Challenge: [https://github.com/Asymmetrik/node-fhir-server-mongo](https://github.com/Asymmetrik/node-fhir-server-mongo).

<img src=""https://www.asymmetrik.com/wp-content/uploads/2018/01/FHIR-Server-Architecture_Update.png"" width=""800"">

## node-fhir-server-core@2.0.0

Please view the [Migration Guide](https://github.com/Asymmetrik/node-fhir-server-core/blob/master/docs/MIGRATION_2.0.0.md) for version `2.0.0`. We **will absolutely** continue supporting previous versions but **will prioritize** new features going to `2.0.0` unless we receive requests to retrofit them to older versions.

## Prerequisites

[Node.js](https://nodejs.org/en/) version later than `>7.6` is required, **but** you should **NOT** use `8.5` (see [Attention](#attention)). A basic understanding of [promises](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise) and a familiarity of the FHIR specification is not required, but will be very helpful.

## Getting Started

Please see our [Getting Started](./docs/GettingStarted.md) guide for a walkthrough of how to set up our FHIR server.

## Frequently Asked Questions

- [What configurations does `FHIRServer.initialize()` accept?](./docs/ServerConfiguration.md)
- [How do I configure a ""profile""?](./docs/ConfiguringProfiles.md)
- [Can I add more loggers or customize how the logger works?](./docs/CustomizeLogging.md)
- [How do I customize the capability statement?](./docs/CustomCapability.md)
- [How do I add custom operations?](./docs/CustomOperations.md)
- [How do I enable/disable/customize access control (authentication)?](./docs/AccessControl.md)

## Philosophy

Our project vision is to build an easy to use FHIR server that supports all resource profiles defined in the [US Core implementation guide](http://www.hl7.org/fhir/us/core/) and is built with security in mind from the ground up. We decided to use a plugin style architecture so implementors could focus on writing queries and not worry about all the other technical difficulties of securing the server. As this project matures, we plan to support more resources, custom extensions, versions, write capabilities, etc.

We believe in establishing a robust security, especially when it comes to health information. Part of the ONC Secure API Server Challenge was to stand up a server and let penetration testers have a go at it (you can see their results [here](https://github.com/Asymmetrik/node-fhir-server-core/issues?utf8=%E2%9C%93&q=label%3A%22ONC+FHIR+Challenge+Vulnerability%22+)). We are committed to continuing this practice and we will continue fixing any vulnerabilities discovered so we can do our best to make this server as secure as possible. For authentication, we are actively working on methods for simplifying integration with [SMART on FHIR](http://docs.smarthealthit.org/).

## Contributing

Please see [CONTRIBUTING.md](https://github.com/Asymmetrik/node-fhir-server-core/blob/master/CONTRIBUTING.md) for more details regarding contributing issues or code.

## Questions

If you are experiencing a bug, please feel free to file an [issue](https://github.com/Asymmetrik/node-fhir-server-core/issues). For general questions, please post them to [StackOverflow](https://stackoverflow.com/) with the tag `node-fhir-server-core` or `javascript-fhir`.

## Attention

This library makes use of node's path module. This is potentially exploitable in node version `8.5`, see [here](https://nodejs.org/en/blog/vulnerability/september-2017-path-validation/). When deploying this, you need to deploy with a node version later than `>7.6` but **NOT** `8.5`.

## License

`@asymmetrik/node-fhir-server-core` is [MIT licensed](https://github.com/Asymmetrik/node-fhir-server-core/blob/master/LICENSE).
"
46,CMSgov/HealthCare.gov-Styleguide,CSS,"**WARNING:** This website is no longer being updated or supported. Please refer to the [CMS Design System](https://design.cms.gov).

# [styleguide.healthcare.gov](https://styleguide.healthcare.gov)

To get started with the HealthCare.gov assets library, you’ll need to use the required HTML, grid system framework, JavaScript, and CSS.

More detail info can be found at [styleguide.healthcare.gov](https://styleguide.healthcare.gov)

## Table of contents

- [Quick start](#quick-start)
- [What's included](#whats-included)
- [Bugs and feature requests](#bugs-and-feature-requests)
- [Documentation](#documentation)
- [Running documentation locally](#running-documentation-locally)
- [Contributing](#contributing)
- [Copyright and license](#copyright-and-license)

## Quick start

A couple of quick start options are available:

- [Download the latest release](https://github.com/CMSgov/HealthCare.gov-Styleguide/archive/master.zip).
- Clone the repo: `git clone https://github.com/CMSgov/HealthCare.gov-Styleguide.git`.

Read the [Assets landing page](https://styleguide.healthcare.gov/assets/) for information on the framework contents, templates and examples, and more.

### What's included

Within the download you'll find the following directories and files, logically grouping common assets. You'll see something like this:

```
assets-components/
├── css/
│   ├── bootstrap/
│   ├── cards/
│   ├── components/
│   ├── forms/
│   ├── layouts/
│   ├── all.less
│   └── style.css
└── fonts/
    ├── Bitter-Bold.eot
    ├── Bitter-Italic.eot
    ├── Bitter-Regular.eot
    ├── glyphicons-halflings-regular.eot
    ├── OpenSans-Bold-webfont.eot
    ├── OpenSans-Italic-webfont.eot
    ├── OpenSans-Regular-webfont.eot
    └── OpenSans-Semibold-webfont.eot
```

We provide compiled CSS (`style.css`), as well as the CSS Less source. Glyphicon fonts are also included. Since this styleguide's functionality is built directly on top of Bootstrap, you will need to include references to our jQuery and Bootstrap code bases in your html file:

- `https://assets.healthcare.gov/resources/libs/jquery/1.11/js/jquery.min.js`
- `https://assets.healthcare.gov/resources/libs/bootstrap/3.1.1/js/bootstrap.min.js`

**Note**: [Assets.healthcare.gov](https://assets.healthcare.gov) gives you Section 508 compliant, cross-browser compatible UI components that you can use in your accessible web site or web application. Assets is an accessible, responsive, and modern framework.

## Bugs and feature requests

Have a bug to report or a feature to request? Please  read our [contribution policy](https://github.com/CMSgov/HealthCare.gov-Styleguide/blob/master/CONTRIBUTING.md) and search for existing and closed issues. If your problem or idea is not addressed yet, you can [open a new issue](https://github.com/CMSgov/HealthCare.gov-Styleguide/issues/new).


## Documentation

HealthCare.gov's Styleguide documentation, included in this repo in the gh-pages branch root directory, is built with [Jekyll](http://jekyllrb.com) and publicly hosted on GitHub Pages at <https://styleguide.healthcare.gov/>. The docs may also be run locally.

### Running documentation locally

1. If necessary, [install Jekyll](http://jekyllrb.com/docs/installation) (requires version 2.5.x).
  - **Windows users:** Read [this unofficial guide](http://jekyll-windows.juthilo.com/) to get Jekyll up and running without problems.
2. From the gh-pages branch root directory, run `jekyll serve` in the command line.
3. Open <http://localhost:9001> in your browser, and you should see the entire Styleguide documentation run locally.

## Contributing

Please read through our [contribution guidelines](https://github.com/CMSgov/HealthCare.gov-Styleguide/blob/master/CONTRIBUTING.md). Included are directions for opening issues, coding standards, and notes on development.

## Copyright and license

As a work of the United States Government, this project is in the public domain within the United States.

[Full license can be found here](https://github.com/CMSgov/HealthCare.gov-Styleguide/blob/master/LICENSE.md).
"
47,medplum/medplum,TypeScript,"# [Medplum](https://www.medplum.com) &middot; [![GitHub license](https://img.shields.io/badge/license-Apache-blue.svg)](https://github.com/medplum/medplum/blob/main/LICENSE.txt) [![npm version](https://img.shields.io/npm/v/@medplum/core.svg?color=blue)](https://www.npmjs.com/package/@medplum/core) [![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=medplum_medplum&metric=alert_status&token=207c95a43e7519809d6d336d8cc7837d3e057acf)](https://sonarcloud.io/dashboard?id=medplum_medplum) [![Coverage Status](https://coveralls.io/repos/github/medplum/medplum/badge.svg?branch=main)](https://coveralls.io/github/medplum/medplum?branch=main)

![Medplum](packages/docs/static/img/cover.webp)

Medplum is a developer platform that enables flexible and rapid development of healthcare apps.

- **Medplum Auth** - End-to-end identity solution for easy user authentication, sign-in, and permissions using OAuth, OpenID, and SMART-on-FHIR.
- **Medplum Clinical Data Repository (CDR)** - Backend server that hosts your healthcare data in a secure, compliant, and standards based repository.
- **Medplum API** - FHIR-based API for sending, receiving, and manipulating data.
- **Medplum SDK** - Client libraries that simplify the process of interacting with the **Medplum API**.
- **Medplum App** - Web application where you can view your data, perform basic editing tasks. You can also use the Medplum App to manage basic workflows.
- **Medplum Bots** - Write and run application logic server-side without needing to set up your own server.
- **UI Component Library** - React components designed to help you quickly develop custom healthcare applications.

## Docs

- [Contributing](#contributing)
  - [Ground Rules](#ground-rules)
  - [Codebase](#codebase)
    - [Technologies](#technologies)
    - [Folder Structure](#folder-structure)
  - [First time setup](#first-time-setup)

## Contributing

**We heartily welcome any and all contributions that match our engineering standards!**

That being said, this codebase isn't your typical open source project because it's not a library or package with a limited scope -- it's our entire product.

### Ground Rules

#### Contributions and discussion guidelines

By making a contribution to this project, you are deemed to have accepted the [Developer Certificate of Origin](https://developercertificate.org/) (DCO).

All conversations and communities on Medplum agree to GitHub's [Community Guidelines](https://help.github.com/en/github/site-policy/github-community-guidelines) and [Acceptable Use Policies](https://help.github.com/en/github/site-policy/github-acceptable-use-policies). This code of conduct also applies to all conversations that happen within our contributor community here on GitHub. We expect discussions in issues and pull requests to stay positive, productive, and respectful. Remember: there are real people on the other side of that screen!

#### Reporting a bug or discussing a feature idea

If you found a technical bug on Medplum or have ideas for features we should implement, the issue tracker is the best place to share your ideas. Make sure to follow the issue template and you should be golden! ([click here to open a new issue](https://github.com/medplum/medplum/issues/new))

#### Fixing a bug or implementing a new feature

If you find a bug on Medplum and open a PR that fixes it we'll review it as soon as possible to ensure it matches our engineering standards.

If you want to implement a new feature, open an issue first to discuss what it'd look like and to ensure it fits in our roadmap and plans for the app.

If you want to contribute but are unsure to start, we have [a ""good first issue"" label](https://github.com/medplum/medplum/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22) which is applied to newcomer-friendly issues. Take a look at [the full list of good first issues](https://github.com/medplum/medplum/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22) and pick something you like!

Want to fix a bug or implement an agreed-upon feature? Great, jump to the [local setup instructions](#first-time-setup)!

### Codebase

#### Technologies

With the ground rules out of the way, let's talk about the coarse architecture of this mono repo:

- **Full-stack TypeScript**: We use Node.js to power our servers, and React to power our frontend apps. Almost all of the code you'll touch in this codebase will be TypeScript.

Here is a list of all the big technologies we use:

- **PostgreSQL**: Data storage
- **Redis**: Background jobs and caching
- **Express**: API server
- **TypeScript**: Type-safe JavaScript
- **React**: Frontend React app

#### Folder structure

```sh
medplum/
├── packages
│   ├── app          # Frontend web app
│   ├── bot-layer    # AWS Lambda Layer for Bots
│   ├── cdk          # AWS CDK infra as code
│   ├── cli          # Command line interface
│   ├── core         # Core shared library
│   ├── definitions  # Data definitions
│   ├── docs         # Documentation
│   ├── examples     # Example code used in documentation
│   ├── fhir-router  # FHIR URL router
│   ├── fhirtypes    # FHIR TypeScript definitions
│   ├── generator    # Code generator utilities
│   ├── graphiql     # Preconfigured GraphiQL
│   ├── mock         # Mock FHIR data for testing
│   ├── react        # React component library
│   └── server       # Backend API server
└── scripts          # Helper bash scripts
```

### First time setup

See developer setup documentation: https://www.medplum.com/docs/contributing

## License

[Apache 2.0](LICENSE.txt)

Copyright &copy; Medplum 2023

FHIR&reg; is a registered trademark of HL7.

SNOMED&reg; is a registered trademark of the International Health Terminology Standards Development Organisation.

LOINC&reg; is a registered trademark of Regenstrief Institute, Inc.

DICOM&reg; is the registered trademark of the National Electrical Manufacturers Association (NEMA).
"
48,nickls/awesome-healthcare-datasets,,"# Awesome Healthcare Datasets
A curated list of awesome healthcare datasets in the public domain.


## Contents
- [Provider Data](#provider-data)
- [Electronic Health Record Systems](#eletronic-health-record-systems)
- [Drugs](#drugs)
- [Medicare Advantage Plans](#medicare-advantage-plans)

- - -

## Provider Data
* [National Provider Identifier](http://download.cms.gov/nppes/NPI_Files.html) - gives a unique ID for all health care providers and organizations in the US. - [ZIP (578M)](http://download.cms.gov/nppes/NPPES_Data_Dissemination_June_2016.zip)
  * Provider Details (name, credentials, gender, etc.)
  * Organizations Details (name, type, etc.)
  * Practice Address
  * Speciality / Healthcare Taxonomy
  * State License
* [List of Excluded Individuals and Entities](http://oig.hhs.gov/exclusions/exclusions_list.asp) - the list you do not want to be on, excluded from all Federally funded health care programs - [ZIP (11M)](http://oig.hhs.gov/exclusions/downloadables/UPDATED.csv)
  * Provider Details (NPI, etc)
  * Exclusion Details
* [Physician Compare](https://data.medicare.gov/data/physician-compare) - gives education and affiliation details for providers - [CSV (196M)](https://data.medicare.gov/api/views/s63f-csi6/rows.csv?accessType=DOWNLOAD)
  * Provider Details (NPI, name, credentials, gender, etc.)
  * Credentials (Medical School, Year attended, Speciality)
  * Group Practices (legal name, PAC ID, address, etc.)
* [Medicare Utilization](https://www.cms.gov/Research-Statistics-Data-and-Systems/Statistics-Trends-and-Reports/Medicare-Provider-Charge-Data/Physician-and-Other-Supplier.html) - Medicare Provider Utilization and Payment Data - lists procedures and payments for individual providers -  [ZIP (1.9G)](http://download.cms.gov/Research-Statistics-Data-and-Systems/Statistics-Trends-and-Reports/Medicare-Provider-Charge-Data/Downloads/Medicare_Provider_Util_Payment_PUF_CY2014.zip)
  * Provider Details (NPI, name, credentials, gender, etc.)
  * Procedure Code (HCPCS)
  * Procedure Description
  * Number of procedures
  * Reimbursement Details
* [Open Payments](https://www.cms.gov/OpenPayments/Explore-the-Data/Dataset-Downloads.html) - Direct and indirect payments to Physicians by device and drug manufacturers
  * Provider Details (name, id, etc.)
  * Manufacturer Details (name, id)
  * Product Details (drug or device name)
  * Payment details (type, dollar value, etc)
* [Physician Referral](https://questions.cms.gov/faq.php?faqId=7977) - Referrals of medicare beneficiaries between providers
  * Initial NPI
  * Secondary NPI
  * Share Count & unique beneficiary count

<!-- ## Hospital Data
* [Hospital Compare](https://data.medicare.gov/data/hospital-compare) -  -->


## Electronic Health Record Systems
* [EHR Attestation Program](http://dashboard.healthit.gov/datadashboard/documentation/ehr-products-mu-attestation-data-documentation.php) - Meaningful Use EHR Attestation Data -- [CSV  (234M)](http://dashboard.healthit.gov/datadashboard/data/MU_REPORT.csv)
  * Certification IDs
  * Vendor and Product Name
  * Usage Details (State, Provider Type, Specialty, NPI, etc.)  
* [Certified Health IT Product List](http://oncchpl.force.com/ehrcert) - certification details for EHRs - [XSL (7M)](http://oncchpl.force.com/ehrcert/DownloadReport)
  * Product Details
  * Certification Criteria
  * Clinical Quality Measures

## Drugs
* [FAERS Data Files](http://www.fda.gov/Drugs/GuidanceComplianceRegulatoryInformation/Surveillance/AdverseDrugEffects/ucm082193.htm) - FDA Adverse Event Reporting System (FAERS) Data Files - [XML (73M)](http://www.fda.gov/downloads/Drugs/GuidanceComplianceRegulatoryInformation/Surveillance/UCM477218.zip)
* [Drug Code Directory](http://www.fda.gov/Drugs/InformationOnDrugs/ucm142438.htm) - Drug name, dosage, code and label details, for all drugs - [ZIP (19M)](http://www.accessdata.fda.gov/cder/ndc.zip)  
* [Pill Identification](https://pillbox.nlm.nih.gov/developer.html#data) - pill names, images, shapes and imprints - [TAB (40M)](https://pillbox.nlm.nih.gov/downloads/pillbox_engine_20150511.tab)


## Medicare Advantage
* [MA Plan Directory](https://www.cms.gov/Research-Statistics-Data-and-Systems/Statistics-Trends-and-Reports/MCRAdvPartDEnrolData/MA-Plan-Directory.html) - Listing of all Medicare Advantage companies and contracts - [ZIP (190K)](https://www.cms.gov/Research-Statistics-Data-and-Systems/Statistics-Trends-and-Reports/MCRAdvPartDEnrolData/Downloads/MA-Plan-Directory.zip)



- - -

Todo:
* Hospital Data
* ACOs
* Medicaid Managed Care
* Clinical Trials dataset
* Health Exchange Data (https://www.healthcare.gov/health-and-dental-plan-datasets-for-researchers-and-issuers/)
* National Electronic Injury Surveillance System (NEISS)
http://www.cpsc.gov/en/Research--Statistics/NEISS-Injury-Data/

Inspiration From:
* [Awesome Python](https://github.com/vinta/awesome-python)
* [Awesome Public Datasets](https://github.com/caesar0301/awesome-public-datasets)
* [Meta Awesome](https://github.com/sindresorhus/awesome)
"
49,Conservatory/healthcare.gov-2013-10-01,CSS,"# Restored HealthCare.gov repository from 1 Oct 2013.

This repository originally lived at [github.com/CMSgov/healthcare.gov](https://github.com/CMSgov/healthcare.gov), but apparently disappeared from there sometime on 12 Oct 2013.  There is [reason to believe](http://www.wired.com/wiredenterprise/2013/10/obamacare-github/) that the repository's owners pulled it down mainly because they didn't want to handle misdirected bug reports being filed against it -- bug reports that were really about the back-end systems that this code merely interfaced with but had no control over.

(There was also a problem with the original repository's commit history.  The repository as originally posted -- i.e., what this is a clone of -- contained only one commit, a ""top-skim"" style import of the code, and was thus missing the true commit history.  An issue [had been opened](https://www.google.com/search?q=%22benbalter%22+healthcare.gov+%22contributor+information%22+%22commit+history%22) against it, asking for the problem to be fixed, but the repository was taken down before that had a chance to be addressed.)

A possibly better course would have been for them to [rename](https://help.github.com/articles/renaming-a-repository) the repository to ""healthcare.gov-web-front-end"" or something like that, and update the README.md file to prominently state which kinds of bug reports would be appropriate to file there and which wouldn't.  I hope that after the brouhaha dies down, the repository is restored, with properly historicized commit history.

In the meantime, the repository's disappearance was widely noticed.  Lauren C. Still saw a [tweet](https://twitter.com/kfogel/status/389134395694526464) of mine asking about it, and [replied](https://twitter.com/laurencstill/status/389181641689534464) that there was a git bundle at [archive.org/details/healthcare-gov-gitrepo](https://archive.org/details/healthcare-gov-gitrepo) preserving this repository as of 1 Oct 2013.  That's what's imported here.  The contents of the original README.md follow.

-Karl Fogel (@kfogel), for the [Conservatory](http://conservatory.github.io/)

--------------------------------------------------------------------------
# HealthCare.gov-Open-Source-Release

This project includes the source code and content for the healthcare.gov website. For more information, please visit https://www.healthcare.gov/developers

## Local Installation Requirements

- Linux, Unix, Windows or Mac OS X
- [Ruby](http://www.ruby-lang.org/en/downloads/)
- [RubyGems](http://rubygems.org/pages/download)
- [Jekyll](http://jekyllrb.com)


## Ruby

### To install ruby on unix:

`yum install ruby` (or `sudo apt-get install ruby1.9.1`)


### To install ruby on Mac OS X:

`curl -L https://get.rvm.io | bash -s stable --ruby`

Visit the following links for more detailed information on how to set up Ruby using a method applicable to your environment:

Three Ways of Installing Ruby (Linux/Unix)
http://www.ruby-lang.org/en/downloads/
 
RubyInstaller for Windows
http://rubyinstaller.org/

How to Install Ruby on a Mac
http://net.tutsplus.com/tutorials/ruby/how-to-install-ruby-on-a-mac/


## Install rubygems: 

- `cd ~/`
- `wget http://production.cf.rubygems.org/rubygems/rubygems-1.8.24.tgz`
- `tar xzvf rubygems-1.8.24.tgz`
- `cd rubygems-1.8.24`
- `ruby setup.rb`


## Managing Dependencies Using Bundler

We recommend using Bundler to manage dependencies. Once you have Ruby installed, install Bundler by running the following command: 'gem install bundler'

Once Bundler is installed, you install/update depencies by simply running 'bundle install' within your project folder.

More information on Bundler may be found here: http://gembundler.com/


## Install Jekyll

- `cd healthcare.gov` (or the location of your cloned repository)
- `bundle install`

For more information and detailed documentation on Jekyll, visit the following sites:

Jekyll Project Home
http://jekyllrb.com

Jekyll on GitHub
https://github.com/mojombo/jekyll


## Clone the repository

- `cd /var/www/html` (or the location you would like the compiled site to live)
- `git clone https://github.com/CMSgov/HealthCare.gov-Open-Source-Release.git healthcare.gov`


## Generate the site and serve

- `jekyll serve`
- Browse to [localhost:4000](http://localhost:4000) to view the site"
0,AileenNielsen/OReillyHealthcareData,Jupyter Notebook,"[{""name"":"".gitignore"",""path"":"".gitignore"",""sha"":""e43b0f988953ae3a84b00331d0ccf5f7d51cb3cf"",""size"":10,""url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/.gitignore?ref=master"",""html_url"":""https://github.com/wanghaisheng/healthcaredatastandard/blob/master/.gitignore"",""git_url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/e43b0f988953ae3a84b00331d0ccf5f7d51cb3cf"",""download_url"":""https://raw.githubusercontent.com/wanghaisheng/healthcaredatastandard/master/.gitignore"",""type"":""file"",""_links"":{""self"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/.gitignore?ref=master"",""git"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/e43b0f988953ae3a84b00331d0ccf5f7d51cb3cf"",""html"":""https://github.com/wanghaisheng/healthcaredatastandard/blob/master/.gitignore""}},{""name"":""README.md"",""path"":""README.md"",""sha"":""fc6bd9a7b0a339af5ee38d7481d24302a18d395c"",""size"":29010,""url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/README.md?ref=master"",""html_url"":""https://github.com/wanghaisheng/healthcaredatastandard/blob/master/README.md"",""git_url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/fc6bd9a7b0a339af5ee38d7481d24302a18d395c"",""download_url"":""https://raw.githubusercontent.com/wanghaisheng/healthcaredatastandard/master/README.md"",""type"":""file"",""_links"":{""self"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/README.md?ref=master"",""git"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/fc6bd9a7b0a339af5ee38d7481d24302a18d395c"",""html"":""https://github.com/wanghaisheng/healthcaredatastandard/blob/master/README.md""}},{""name"":""overview.png"",""path"":""overview.png"",""sha"":""5e49110c0ac25125bf0f277548f85389bd9178da"",""size"":559586,""url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/overview.png?ref=master"",""html_url"":""https://github.com/wanghaisheng/healthcaredatastandard/blob/master/overview.png"",""git_url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/5e49110c0ac25125bf0f277548f85389bd9178da"",""download_url"":""https://raw.githubusercontent.com/wanghaisheng/healthcaredatastandard/master/overview.png"",""type"":""file"",""_links"":{""self"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/overview.png?ref=master"",""git"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/5e49110c0ac25125bf0f277548f85389bd9178da"",""html"":""https://github.com/wanghaisheng/healthcaredatastandard/blob/master/overview.png""}},{""name"":""standard number -201506.png"",""path"":""standard number -201506.png"",""sha"":""10d20f19dadd0de6c6740685c16ad3d98bceb4eb"",""size"":552959,""url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/standard%20number%20-201506.png?ref=master"",""html_url"":""https://github.com/wanghaisheng/healthcaredatastandard/blob/master/standard%20number%20-201506.png"",""git_url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/10d20f19dadd0de6c6740685c16ad3d98bceb4eb"",""download_url"":""https://raw.githubusercontent.com/wanghaisheng/healthcaredatastandard/master/standard%20number%20-201506.png"",""type"":""file"",""_links"":{""self"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/standard%20number%20-201506.png?ref=master"",""git"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/10d20f19dadd0de6c6740685c16ad3d98bceb4eb"",""html"":""https://github.com/wanghaisheng/healthcaredatastandard/blob/master/standard%20number%20-201506.png""}},{""name"":""基础类标准"",""path"":""基础类标准"",""sha"":""945a3b3a1831fbad09264b9dea530af3f0fb737a"",""size"":0,""url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E5%9F%BA%E7%A1%80%E7%B1%BB%E6%A0%87%E5%87%86?ref=master"",""html_url"":""https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E5%9F%BA%E7%A1%80%E7%B1%BB%E6%A0%87%E5%87%86"",""git_url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/945a3b3a1831fbad09264b9dea530af3f0fb737a"",""download_url"":null,""type"":""dir"",""_links"":{""self"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E5%9F%BA%E7%A1%80%E7%B1%BB%E6%A0%87%E5%87%86?ref=master"",""git"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/945a3b3a1831fbad09264b9dea530af3f0fb737a"",""html"":""https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E5%9F%BA%E7%A1%80%E7%B1%BB%E6%A0%87%E5%87%86""}},{""name"":""已整理材料"",""path"":""已整理材料"",""sha"":""e9f14bd3afda272e5e3f310b779e115d0c125d29"",""size"":0,""url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E5%B7%B2%E6%95%B4%E7%90%86%E6%9D%90%E6%96%99?ref=master"",""html_url"":""https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E5%B7%B2%E6%95%B4%E7%90%86%E6%9D%90%E6%96%99"",""git_url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/e9f14bd3afda272e5e3f310b779e115d0c125d29"",""download_url"":null,""type"":""dir"",""_links"":{""self"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E5%B7%B2%E6%95%B4%E7%90%86%E6%9D%90%E6%96%99?ref=master"",""git"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/e9f14bd3afda272e5e3f310b779e115d0c125d29"",""html"":""https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E5%B7%B2%E6%95%B4%E7%90%86%E6%9D%90%E6%96%99""}},{""name"":""技术类标准"",""path"":""技术类标准"",""sha"":""de30b9a40cd054b6d7fb7fcebbe6f7e01b5e5770"",""size"":0,""url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E6%8A%80%E6%9C%AF%E7%B1%BB%E6%A0%87%E5%87%86?ref=master"",""html_url"":""https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E6%8A%80%E6%9C%AF%E7%B1%BB%E6%A0%87%E5%87%86"",""git_url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/de30b9a40cd054b6d7fb7fcebbe6f7e01b5e5770"",""download_url"":null,""type"":""dir"",""_links"":{""self"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E6%8A%80%E6%9C%AF%E7%B1%BB%E6%A0%87%E5%87%86?ref=master"",""git"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/de30b9a40cd054b6d7fb7fcebbe6f7e01b5e5770"",""html"":""https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E6%8A%80%E6%9C%AF%E7%B1%BB%E6%A0%87%E5%87%86""}},{""name"":""数据类标准"",""path"":""数据类标准"",""sha"":""b07085f5d932d491dc4776309fc799305e1b4838"",""size"":0,""url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E6%95%B0%E6%8D%AE%E7%B1%BB%E6%A0%87%E5%87%86?ref=master"",""html_url"":""https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E6%95%B0%E6%8D%AE%E7%B1%BB%E6%A0%87%E5%87%86"",""git_url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/b07085f5d932d491dc4776309fc799305e1b4838"",""download_url"":null,""type"":""dir"",""_links"":{""self"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E6%95%B0%E6%8D%AE%E7%B1%BB%E6%A0%87%E5%87%86?ref=master"",""git"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/b07085f5d932d491dc4776309fc799305e1b4838"",""html"":""https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E6%95%B0%E6%8D%AE%E7%B1%BB%E6%A0%87%E5%87%86""}},{""name"":""标准化测评相关规范"",""path"":""标准化测评相关规范"",""sha"":""5bf75d1217960dfa55654ed55bb07f644330a763"",""size"":0,""url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E6%A0%87%E5%87%86%E5%8C%96%E6%B5%8B%E8%AF%84%E7%9B%B8%E5%85%B3%E8%A7%84%E8%8C%83?ref=master"",""html_url"":""https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E6%A0%87%E5%87%86%E5%8C%96%E6%B5%8B%E8%AF%84%E7%9B%B8%E5%85%B3%E8%A7%84%E8%8C%83"",""git_url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/5bf75d1217960dfa55654ed55bb07f644330a763"",""download_url"":null,""type"":""dir"",""_links"":{""self"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E6%A0%87%E5%87%86%E5%8C%96%E6%B5%8B%E8%AF%84%E7%9B%B8%E5%85%B3%E8%A7%84%E8%8C%83?ref=master"",""git"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/5bf75d1217960dfa55654ed55bb07f644330a763"",""html"":""https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E6%A0%87%E5%87%86%E5%8C%96%E6%B5%8B%E8%AF%84%E7%9B%B8%E5%85%B3%E8%A7%84%E8%8C%83""}},{""name"":""管理类标准"",""path"":""管理类标准"",""sha"":""697c02441646c251192f32f1bdf86ea52042e7e4"",""size"":0,""url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E7%AE%A1%E7%90%86%E7%B1%BB%E6%A0%87%E5%87%86?ref=master"",""html_url"":""https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E7%AE%A1%E7%90%86%E7%B1%BB%E6%A0%87%E5%87%86"",""git_url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/697c02441646c251192f32f1bdf86ea52042e7e4"",""download_url"":null,""type"":""dir"",""_links"":{""self"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E7%AE%A1%E7%90%86%E7%B1%BB%E6%A0%87%E5%87%86?ref=master"",""git"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/697c02441646c251192f32f1bdf86ea52042e7e4"",""html"":""https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E7%AE%A1%E7%90%86%E7%B1%BB%E6%A0%87%E5%87%86""}}]"
1,informatici/openhospital,Makefile,"# ![](./OH-icon.png) Open Hospital

[![GitHub release](https://img.shields.io/github/v/release/informatici/openhospital?color=orange&label=latest%20release)](https://github.com/informatici/openhospital/releases/latest)
[![License](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://github.com/informatici/openhospital/blob/master/LICENSE)
![Release Date](https://img.shields.io/github/release-date/informatici/openhospital?label=Released)

**[Open Hospital][openhospital]** is a free and open-source Health Information Management System (HIMS) software application.

**This repository is used to assemble the portable (or all-in-one) packages of Open Hospital, which you can download also [here][download].**

## Download

[![Latest release](https://img.shields.io/github/v/release/informatici/openhospital?color=orange&label=download%20latest)](https://github.com/informatici/openhospital/releases/latest)

[[Download latest release from github](https://github.com/informatici/openhospital/releases/latest)] [ [All releases](https://github.com/informatici/openhospital/releases) ]

[[Download latest release from sourceforge](https://sourceforge.net/projects/openhospital/files/latest/download)] [ [All releases](https://sourceforge.net/projects/openhospital/files/) ]

### Download stats

![GitHub all releases](https://img.shields.io/github/downloads/informatici/openhospital/total?label=GitHub%20Downloads)
![GitHub release (latest by date)](https://img.shields.io/github/downloads/informatici/openhospital/latest/total?label=latest)

![SourceForge](https://img.shields.io/sourceforge/dt/openhospital?label=Sourceforge%20downloads)
![SourceForge](https://img.shields.io/sourceforge/dm/openhospital?label=this%20month)
![SourceForge](https://img.shields.io/sourceforge/dt/openhospital/v1.13.0?color=33ccff&label=latest&logoColor=33ccff)

## Software

Open Hospital (OH) is deployed as a desktop application that can be used in a standalone, single user mode (PORTABLE mode)
or in a client / server network configuration (CLIENT mode), where multiple clients and users connect to the same database server.
OH is developed in Java and it is based on open-source tools and libraries; it runs on any computer, requires low resources and is designed to work without an internet connection.
For more information check the online documentation [here][documentation].

Open Hospital is composed by the following components, hosted in separated repositories:

 - [OH Core][core], a library that contains the business logic and the data abstraction layer
 - [OH GUI][gui], which provides a graphical user interface (GUI) made with Java Swing
 - [OH Doc][doc], which contains the user and admin documentation in Asciidoc format
 - [OH API][api], a web server that exposes REST APIs over the Core component, and it's used by the UI component [*WIP*]. 
 - [OH UI][ui], a web user interface that consists of a React SPA (single page application) [*WIP*]

## How to contribute

There are several ways in which you can contribute to Open Hospital:

- try the [desktop application][releases] or the early versions of the [web UI][ui]
- request new features or report issues on [JIRA][jira] ([here][good-first]'s a list of *good-first-issues*)
- improve the [documentation][doc]
- contribute code patches to one of the components

## Documentation

Read on about Open Hospital:

 - on the official [website][openhospital]
 - [user][user-man] and [admin][admin-man] manuals
 - [wiki]
 - [FAQ][faq]

## Community

You can reach out to the community of contributors by joining 
our [Slack workspace][slack] or by subscribing to our [mailing list][ml].


## How to create OH packages

<details><summary>:construction_worker: :package:</summary>
To create the Open Hospital packages,
make sure to have installed the following dependencies on a Linux machine:
JDK 8+, Maven, asciidoctor-pdf, zip, GNU make.

Then follow these simple steps:

 1. Clone this repository:

        git clone https://github.com/informatici/openhospital

 2. Run the script that compiles the components of Open Hospital, and assembles the portable distributions:

        cd openhospital
        make
    
    You can also parallelize some make tasks by using the `-j` flag (e.g. `make -j4`)
    or use intermediate targets to build single parts of the distribution -
    use `make help` to see a list of available targets.
</details>

 [openhospital]: https://www.open-hospital.org/
 [documentation]: https://www.open-hospital.org/documentation
 [download]: https://www.open-hospital.org/download
 [core]: https://github.com/informatici/openhospital-core
 [gui]: https://github.com/informatici/openhospital-gui
 [ui]: https://github.com/informatici/openhospital-ui
 [api]: https://github.com/informatici/openhospital-api
 [doc]: https://github.com/informatici/openhospital-doc
 [releases]: https://github.com/informatici/openhospital/releases
 [jira]: https://openhospital.atlassian.net/browse/OP
 [good-first]: https://openhospital.atlassian.net/browse/OP-188?filter=10206
 [user-man]: https://github.com/informatici/openhospital-doc/blob/master/doc_user/UserManual.adoc
 [admin-man]: https://github.com/informatici/openhospital-doc/blob/master/doc_admin/AdminManual.adoc
 [faq]: https://openhospital.atlassian.net/wiki/spaces/OH/pages/568951013/Getting+Started+FAQ
 [wiki]: https://openhospital.atlassian.net/wiki/spaces/OH/overview
 [slack]: https://join.slack.com/t/openhospitalworkspace/shared_invite/enQtOTc1Nzc0MzE2NjQ0LWIyMzRlZTU5NmNlMjE2MDcwM2FhMjRkNmM4YzI0MTAzYTA0YTI3NjZiOTVhMDZlNWUwNWEzMjE5ZDgzNWQ1YzE
 [ml]: https://sourceforge.net/projects/openhospital/lists/openhospital-devel
"
2,coronasafe/care,Python,"# Care Backend

<p align=""center"">
  <a href=""https://ohc.network"">
    <picture>
      <source media=""(prefers-color-scheme: dark)"" srcset=""./care/static/images/logos/light-logo.svg"">
      <img alt=""care logo"" src=""./care/static/images/logos/black-logo.svg""  width=""300"">
    </picture>
  </a>
</p>

[![Deploy Care](https://github.com/coronasafe/care/actions/workflows/deployment.yaml/badge.svg)](https://github.com/coronasafe/care/actions/workflows/deployment.yaml)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)
[![Cookiecutter Django](https://img.shields.io/badge/built%20with-Cookiecutter%20Django-ff69b4.svg)](https://github.com/pydanny/cookiecutter-django/)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![Chat](https://img.shields.io/badge/-Join%20us%20on%20slack-7b1c7d?logo=slack)](https://slack.coronasafe.in/)

This is the backend for care. an open source platform for managing patients, health workers, and hospitals.

## Features

Care backend makes the following features possible:

- Realtime Analytics of Beds, ICUs, Ventilators, Oxygen and other resources in hospitals
- Facility Management with Inventory Monitoring
- Integrated Tele-medicine & Triage
- Patient Management and Consultation History
- Realtime video feed and vitals monitoring of patients
- Clinical Data Visualizations.

## Getting Started

### Docs and Guides

You can find the docs at https://care-be-docs.coronasafe.network

### Staging Deployments

Staging instances for testing are automatically deployed on every commit to the `master` branch. The staging instances
are available at:

- https://careapi.ohc.network

### Self hosting

#### Compose

docker compose is the easiest way to get started with care.
put the required environment variables in a `.env` file and run:

```bash
make up
```

> ⚠️ If you are unable to compose up care in windows, ensure line endings are set to `LF` (`docker-entrypoint.sh` won't
> work with `CRLF` line endings).
> ```
> git config core.autocrlf false
> ```

#### Docker

Prebuilt docker images for server deployments are available
on [ghcr](https://github.com/coronasafe/care/pkgs/container/care)

## Contributing

We welcome contributions from everyone. Please read our [contributing guidelines](./CONTRIBUTING.md) to get started.
"
3,technext/HealthCare,HTML,"HealthCare
==========

A responsive theme for commercial medical purpose. Built with HTML5, CSS3, Bootstrap framework. Google fonts, Font Awesome Icon integrated

==========

Bootstrap3 Powered
Backgroundg Slider
Multiple Page Options
Code & Content Optimized for Speed
Responsive Layout
Clean Code
Cross-browser Compatibility
CSS3 Animations
100% Fully Customisable
No Hardcoded Options
Sticky Header Options
Super Easy Installation & Setup With One Click Demo Installation
Custom Background
Font Awesome Icon Integration
Google Fonts
Advanced Typography Options
Extensive Documentation
Built with HTML5 & CSS3
Strong focus on Typography, Usability and Overall User Experience
Clean and Modern Design – can be used for any type of website
Lifetime Update & Free Support
"
4,GoogleCloudPlatform/healthcare-deid,Python,"# Healthcare De-Id

This project contains tools to run various tools for de-identifying medical
records on Google Cloud Platform.

For example, see physionet/README.md for info on running PhysioNet De-Id.
"
5,microsoft/healthcare-apis-samples,Jupyter Notebook,"# Healthcare APIs Samples

This repo contains samples for Healthcare APIs, including FHIR, DICOM, IoT Connector and data related services. The workspace is a top level logical container that is created first within a resource group.

![image.png](/docs/images/workspace.png)

All sample scripts have been tested in the Rest Client in Visual Studio Code, unless otherwise noted.

- [How to deploy the Healthcare APIs](/docs/HowToDeploy.md)
- [How to load data to the Healthcare APIs](/docs/HowToLoadData.md)
- [How to access data in the Healthcare APIs](/docs/HowToAccessData.md)
- [How to convert HL7v2 and C-CDA data](https://docs.microsoft.com/en-us/azure/healthcare-apis/azure-api-for-fhir/convert-data)
- [How to export de-identified data](https://docs.microsoft.com/en-us/azure/healthcare-apis/fhir/de-identified-export)
- [How to run performance tests using JMeter](/docs/HowToRunPerformanceTest.md)


## Contributing

This project welcomes contributions and suggestions.  Most contributions require you to agree to a
Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us
the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.

When you submit a pull request, a CLA bot will automatically determine whether you need to provide
a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions
provided by the bot. You will only need to do this once across all repos using our CLA.

This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).
For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or
contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.

## Trademarks

This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft 
trademarks or logos is subject to and must follow 
[Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).
Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.
Any use of third-party trademarks or logos are subject to those third-party's policies.
"
6,coronasafe/care_fe,TypeScript,"<a href=""https://ohc.network/"">
  <p align=""center"">
    <picture>
      <source media=""(prefers-color-scheme: dark)"" srcset=""https://cdn.coronasafe.network/light-logo.svg"">
      <img alt=""CARE Logo"" src=""https://user-images.githubusercontent.com/25143503/193396107-27e0d587-b195-4e95-a795-5d0663d5cd81.svg"">
    </picture>
  </p>
</a>
<p align=""center""><b>Our goal is to continuously improve the quality and accessibility of public healthcare services using digital tools.</b></p>
<h2></h2>
<h3 align=""center""><a href=""https://care.ohc.network"" target=""_blank"">🚀 Staging Deploy</a></h3>
<p align=""center""><img src=""https://api.netlify.com/api/v1/badges/fd123f42-ef65-448c-9b03-39959d60e60b/deploy-status""></p>
<p align=""center"">Auto deployed to <a href=""https://care.ohc.network/"">care.ohc.network</a> for <code>develop</code> branch. All pull requests have preview builds powered by <a href=""https://netlify.com"">Netlify</a>.</p>

[![](https://sourcerer.io/fame/tomahawk-pilot/coronasafe/care_fe/images/0)](https://sourcerer.io/fame/tomahawk-pilot/coronasafe/care_fe/links/0)[![](https://sourcerer.io/fame/tomahawk-pilot/coronasafe/care_fe/images/1)](https://sourcerer.io/fame/tomahawk-pilot/coronasafe/care_fe/links/1)[![](https://sourcerer.io/fame/tomahawk-pilot/coronasafe/care_fe/images/2)](https://sourcerer.io/fame/tomahawk-pilot/coronasafe/care_fe/links/2)[![](https://sourcerer.io/fame/tomahawk-pilot/coronasafe/care_fe/images/3)](https://sourcerer.io/fame/tomahawk-pilot/coronasafe/care_fe/links/3)[![](https://sourcerer.io/fame/tomahawk-pilot/coronasafe/care_fe/images/4)](https://sourcerer.io/fame/tomahawk-pilot/coronasafe/care_fe/links/4)[![](https://sourcerer.io/fame/tomahawk-pilot/coronasafe/care_fe/images/5)](https://sourcerer.io/fame/tomahawk-pilot/coronasafe/care_fe/links/5)[![](https://sourcerer.io/fame/tomahawk-pilot/coronasafe/care_fe/images/6)](https://sourcerer.io/fame/tomahawk-pilot/coronasafe/care_fe/links/6)[![](https://sourcerer.io/fame/tomahawk-pilot/coronasafe/care_fe/images/7)](https://sourcerer.io/fame/tomahawk-pilot/coronasafe/care_fe/links/7)

[![Storybook](https://raw.githubusercontent.com/storybooks/brand/master/badge/badge-storybook.svg)](https://careui.coronasafe.in)
[![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=coronasafe_care_fe&metric=alert_status)](https://sonarcloud.io/summary/new_code?id=coronasafe_care_fe)
![Code scanning - action](https://github.com/coronasafe/care_fe/workflows/Code%20scanning%20-%20action/badge.svg)
![OSSAR](https://github.com/coronasafe/care_fe/workflows/OSSAR/badge.svg)
[![Cypress Tests](https://github.com/coronasafe/care_fe/actions/workflows/cypress.yaml/badge.svg)](https://github.com/coronasafe/care_fe/actions/workflows/cypress.yaml)
![Staging Release](https://github.com/coronasafe/care_fe/workflows/CARE%20Develop%20Registry/badge.svg)
![Production Release](https://github.com/coronasafe/care_fe/workflows/Production%20Release/badge.svg)
[![Codacy Badge](https://api.codacy.com/project/badge/Grade/200482ab117e4b5397ff3f5ae5719aa2)](https://www.codacy.com/gh/coronasafe/care_fe?utm_source=github.com&utm_medium=referral&utm_content=coronasafe/care_fe&utm_campaign=Badge_Grade)
[![CircleCI](https://circleci.com/gh/coronasafe/care_fe.svg?style=svg)](https://circleci.com/gh/coronasafe/care_fe)
[![Maintainability](https://api.codeclimate.com/v1/badges/f1438f693aa459805301/maintainability)](https://codeclimate.com/github/coronasafe/care_fe/maintainability)

## Getting started

- 💬 Comment on the issue if you are willing to take it up, and link the pull request with the issue.
- 🏷️ Tag `@coronasafe/code-reviewers` for faster resolution.
- 📸 Attach screenshots in the pull requests showing the changes made in the UI.

#### Install the required dependencies

```sh
npm install --legacy-peer-deps
```

#### 🏃 Run the app in development mode

```sh
npm run dev
```

Once the development server has started, open [localhost:4000](http://localhost:4000) in your browser. The page will be automatically reloaded when you make edits and save. You will also see any lint errors in the console.

#### 🔑 Staging API Credentials

Authenticate to staging API with any of the following credentials

```yaml
- username: devdistrictadmin
  password: Coronasafe@123
  role: District Admin

- username: staff-dev
  password: Coronasafe@123
  role: Staff

- username: doc-dev
  password: Coronasafe@123
  role: Doctor
```

#### 🏷️ Make use labels to update the PR/issue status

- Mark your PRs as `work-in-progress` if it's still being worked on.
- Once you have solved the related issue, mark your PR with `need testing` and `need review` labels.
- When you’re making a PR with lots of code changes that affects multiple functionalities, or is likely to break, make sure you tag it with `Major Code Change` label.

#### 🧪 Run cypress tests

Ensure that the development server is running and then run the cypress tests in either of the ways described below.

```sh
$ npm run cypress:run        # To run all tests in headless mode.
$ npm run cypress:run:gui    # To run all tests in headed mode.
$ npm run cypress:open       # To debug and run tests individually.
```

- Failed test screenshots are saved in `cypress/screenshots`
- All test videos are saved in `cypress/videos`

## 📖 Documentations

- [CARE Documentation](https://docs.coronasafe.network/coronasafe-care-documentation/)
- [Swagger API Documentation](https://careapi.ohc.network/swagger/)
- [Storybook component library](https://careui.coronasafe.in/)

## 🚀 Production

#### Build the app for production

```sh
npm run build
```

Builds the app for production to the `build` folder. It correctly bundles React in production mode and optimizes the build for the best performance.

#### Start a production `http-server`

```sh
npm run preview
```

Starts a production http-server in local to run the project with Service worker.
The build is minified and the filenames include the hashes.

**🚀 Your app is ready to be deployed!**
"
7,openboxes/openboxes,Groovy,"[![Build Status](https://travis-ci.org/openboxes/openboxes.svg?branch=develop)](https://travis-ci.org/openboxes/openboxes)
[![Documentation Status](https://readthedocs.org/projects/openboxes/badge/?version=develop)](https://readthedocs.org/projects/openboxes/?badge=develop)
[![Financial Contributors on Open Collective](https://opencollective.com/openboxes/all/badge.svg?label=financial+contributors)](https://opencollective.com/openboxes) 
[![Slack Signup](http://slack-signup.openboxes.com/badge.svg)](http://slack-signup.openboxes.com)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com) [![Join the chat at https://gitter.im/openboxes/openboxes](https://badges.gitter.im/openboxes/openboxes.svg)](https://gitter.im/openboxes/openboxes?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)

OpenBoxes
=========

## About

OpenBoxes is an Open Source Inventory and Supply Chain Management System. The initial implementation of OpenBoxes will occur at Partners In Health-supported facilities in Haiti.

## Contributors

### Code Contributors

This project exists thanks to all the people who contribute. [[Contribute](CONTRIBUTING.md)].
<a href=""https://github.com/openboxes/openboxes/graphs/contributors""><img src=""https://opencollective.com/openboxes/contributors.svg?width=890&button=false"" /></a>

### Financial Contributors

Become a financial contributor and help us sustain our community. [[Contribute](https://opencollective.com/openboxes/contribute)]

#### Individuals

<a href=""https://opencollective.com/openboxes""><img src=""https://opencollective.com/openboxes/individuals.svg?width=890""></a>

#### Organizations

Support this project with your organization. Your logo will show up here with a link to your website. [[Contribute](https://opencollective.com/openboxes/contribute)]

<a href=""https://opencollective.com/openboxes/organization/0/website""><img src=""https://opencollective.com/openboxes/organization/0/avatar.svg""></a>
<a href=""https://opencollective.com/openboxes/organization/1/website""><img src=""https://opencollective.com/openboxes/organization/1/avatar.svg""></a>
<a href=""https://opencollective.com/openboxes/organization/2/website""><img src=""https://opencollective.com/openboxes/organization/2/avatar.svg""></a>
<a href=""https://opencollective.com/openboxes/organization/3/website""><img src=""https://opencollective.com/openboxes/organization/3/avatar.svg""></a>
<a href=""https://opencollective.com/openboxes/organization/4/website""><img src=""https://opencollective.com/openboxes/organization/4/avatar.svg""></a>
<a href=""https://opencollective.com/openboxes/organization/5/website""><img src=""https://opencollective.com/openboxes/organization/5/avatar.svg""></a>
<a href=""https://opencollective.com/openboxes/organization/6/website""><img src=""https://opencollective.com/openboxes/organization/6/avatar.svg""></a>
<a href=""https://opencollective.com/openboxes/organization/7/website""><img src=""https://opencollective.com/openboxes/organization/7/avatar.svg""></a>
<a href=""https://opencollective.com/openboxes/organization/8/website""><img src=""https://opencollective.com/openboxes/organization/8/avatar.svg""></a>
<a href=""https://opencollective.com/openboxes/organization/9/website""><img src=""https://opencollective.com/openboxes/organization/9/avatar.svg""></a>

## License

Copyright (c) 2012 Partners In Health.  All rights reserved.
The use and distribution terms for this software are covered by the
Eclipse Public License 1.0 (http://opensource.org/licenses/eclipse-1.0.php)
which can be found in the file epl-v10.html at the root of this distribution.
By using this software in any fashion, you are agreeing to be bound by
the terms of this license.
You must not remove this notice, or any other, from this software.

## Deploy to your Azure VPC

*Deploy to Azure* button will bring you to Azure portal, where after filling a few of the properties you can get your OpenBoxes environment in a matter of minutes. In the Azure setup screen, look at each property's tooltip description to understand its purpose.

For more information and step-by-step instructions go to:
https://openboxes.atlassian.net/wiki/spaces/OBW/pages/1719435265/Push-button+deployment

*Deploy to Azure* uses the ARM template defined in [openboxes-devops](https://github.com/openboxes/openboxes-devops/tree/master/arm-template) repository.

[![Deploy to Azure](https://aka.ms/deploytoazurebutton)](https://portal.azure.com/#create/Microsoft.Template/uri/https%3A%2F%2Fraw.githubusercontent.com%2Fopenboxes%2Fopenboxes-devops%2Fmaster%2Farm-template%2Fopenboxes-arm.json)

*Visualize* will open armviz.io to display graph of all of the Azure resources, which the deployment will provision.

[![Visualize](https://raw.githubusercontent.com/Azure/azure-quickstart-templates/master/1-CONTRIBUTION-GUIDE/images/visualizebutton.svg?sanitize=true)](http://armviz.io/#/?load=https%3A%2F%2Fraw.githubusercontent.com%2Fopenboxes%2Fopenboxes-devops%2Fmaster%2Farm-template%2Fopenboxes-arm.json)


## Setup development environment

### Install Dependencies

#### Required
* [Java 7 (must install Java 7)](https://www.azul.com/downloads/?version=java-7-lts&package=jdk)
* [MySQL 5.7](https://downloads.mysql.com/archives/community/)
  * Mac users: 5.7.31 is the latest 5.7.x with a pre-built installer and works fine
* [SDK Man](https://sdkman.io/install)
* [Grails 1.3.9](https://grails.org/download.html)
* NPM 6.14.6
* Node 14+

#### Optional
* [IntelliJ IDEA 14.1](https://www.jetbrains.com/idea/download/)
* Chrome

### Basic setup instructions for developers

These instructions are for developers only.  If you are a user/implementer, please check out our 
[Installation](http://docs.openboxes.com/en/latest/installation/) documentation.

#### 1. Install Dependencies
Install required dependencies above

#### 2. Install Grails
Check that you have SDK Man installed properly (otherwise follow instructions on the skdman install page).
```
$ sdk version
SDKMAN 5.13.2
```

Install Grails 1.3.9
```
$ sdk install grails 1.3.9
```

#### 3. Clone repository 
If you are a core contributor:
```
git clone git@github.com:openboxes/openboxes.git      
```
If you are a not core contributor, fork [openboxes git repository](https://github.com/openboxes/openboxes)
and replace git url with the one of your forked repository
```
git clone git@github.com:<gitusername>/openboxes.git      
```

#### 4. Create database 
Create openboxes database
```
mysql -u root -p -e 'create database openboxes default charset utf8;'
```

Create openboxes user 
```
mysql -u root -p -e 'grant all on openboxes.* to ""openboxes""@""localhost"" identified by ""openboxes"";'
```

#### 5. Create Openboxes configuration file 
Edit `$HOME/.grails/openboxes-config.properties`

```
# Database connection settings
# You can use dataSource.url when you are using a non-dev/non-test database (test-app may not run properly).
# If you want to run $ grails test-app you should comment out the dataSource.url below and create a new 
# openboxes_test database.  Eventually, we will move to an in-memory H2 database for testing, but we're 
# currently stuck with MySQL because I'm using some MySQL-specific stuff in the Liquibase changesets.  My bad.

dataSource.url=jdbc:mysql://localhost:3306/openboxes
dataSource.username=openboxes
dataSource.password=openboxes

# OpenBoxes mail settings (disabled by default)
grails.mail.enabled=false
```
NOTE: If you are running in development mode with a copy of an existing production database, you will need to
instruct the application to not setup test fixtures automatically by uncommenting the above property:
```
openboxes.fixtures.enabled=false
```

#### 6. Install NPM dependencies
```    
npm config set engine-strict true
npm install
```

#### 7. Build React frontend
You can build React frontend with this command, but it will be automatically build when starting the application.
```    
npm run bundle
```

#### 8. React frontend Hot-Reload
When using this command React fronted will be rebuild automatically after any change, you just need to refresh the 
browser to see the effect.
```    
npm run watch
```

#### 9. Upgrade the project to the currently installed grails version 
Either of the following actions (upgrade, compile, run-app) should generate the all important Spring configuration 
(`/WEB-INF/applicationContext.xml`) and start the dependency resolution process.  

```    
grails upgrade
```
OR

```    
grails compile
```

The `grails compile` step is not necessary since `grails run-app` will invoke the compilation step, but it doesn't 
hurt anything.

If you see any errors, run the command again.  

**IMPORTANT** That last line is important.  Because of some quirkiness with the way older versions of Grails resolve 
dependencies and generates config files, you may need to run either of these commands multiple times in order to 
resolve all dependencies and generate the config files.

Once the dependency resolution phase has completed, all dependencies will be stored in a local ivy cache (usually 
under `$USER_HOME/.grails/ivy-cache`).  You do not have to worry about this, just know that the dependencies are now 
on your machine and Grails will attempt to find them there before it tries to resolve them in a remote repository. 

#### 10. Start application in development mode
The application can be run in development mode.  This starts the application running in an instance of Tomcat within 
the Grails console.
You may need to run 'grails run-app' several times in order to download all dependencies.
```
grails run-app
```

#### 11. Open application in Google Chrome 
```
http://localhost:8080/openboxes
```

#### 12. Log into OpenBoxes 
You can use the default accounts (manager:password OR admin:password). Once you are logged in as an admin, you can 
create own account. Or you can use the signup form to create a new account.

#### 13. React tests
To run new frontend (React) tests type:
```
npm test
```

#### 14. Grails tests
To run Grails tests type:
```
grails test-app
```

#### 15. React documentation
Start a style guide dev server:
```
npm run styleguide
```
View your style guide in the browser:
```
http://localhost:6060
```

## Troubleshooting

### How to Debug 
* Run Grails in debug mode
    ```
    grails-debug run-app
    ```
* In Intellij navigate to Run > Edit Configurations
* Create a new Remote Debug Configuration
    * Name: openboxes-debug
    * Transport: Socket
    * Debugger mode: Attach
    * Host: localhost
    * Port: 5005
* Command line arguments should look something like this: 
    ```
    -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005
    ```


### Problem
```
Caused by: java.io.FileNotFoundException: Could not open ServletContext resource [/WEB-INF/applicationContext.xml]
```
### Solution
Execute the grails upgrade command in order to generate the files nece
```
$ grails upgrade
```
See the following stackoverflow article:
http://stackoverflow.com/questions/24243027/grails-spring-security-sample-application-not-working
"
8,hyperledger-labs/sawtooth-healthcare,Python,"# Medical Insurance

# About

This is blockchain project based on Hyperledger Sawtooth. This project focuses on interaction between Insurer, 
Insured Person (Patient), and Medical Facility. It covers data gathering flow and manages data access based on 
client’s role.

# Features

## Functional

- Create main participants (like Patient, Doctor, Clinic Desk, Lab and Insurance)
- Clinic Desk registers/closes claim only if with patient’s consent
- Doctor updates existing claim only if with patient’s consent
- Insurance company creates contract with patient/receive an invoice when the claim resolved
- Patient allows/revokes consent to access his data by Clinic Desk/Doctor
- Patient adds pulse items from hardware (Android smartphone in our case)
- Patient adds lab test items
- Any participant has data access according to granted roles/permissions

## Technical

- Private key to store/read data (every participant uses his own private key to store data, and public key to read data)
- Private data access management (every participant has a role assigned with corresponding permissions)
- Docker compliance (every component of this project has separate docker image and fully isolated)
- Various network representation (blockchain network has few options (1 node/Dev-Mode consensus, 3 nodes/PoET consensus/single VM, 3 nodes/PoET consensus/3 separate VMs)
- IoT (android client to send data to blockchain and manage consent)
- Unit tests (automated regression testing)
- Load tests

# Components

- **Consent/Identity/Authorization Management** smart contract (responsible to operate with identity/permission related data)
- **Data Management** smart contract (responsible to handle EHR patient’s data)
- **Insurance/Contract Management** smart contract (responsible to operate with insurance related data)
- **Finance/Invoice Management** smart contract (responsible to operate with finances/invoices)
- **REST-API service** (provides interface between client and blockchain network)
- **Web client** (web page where a participant can operate as one of predefined roles such as doctor, patient etc)
- **Android client** (application link to Play Market for patient to add pulse items and manage consent for own data)
- **CLI client** (command line service to perform basic operations)

# Architecture

![Infrastructure](https://github.com/hyperledger-labs/sawtooth-healthcare/blob/master/MedicalInsurance.png)

# Technology stack

Python/Hyperledger Sawtooth/Docker/Docker-Composer/Protobuf/Setuptools/Sanic/Shell/JMeter/Webpack

# How to setup and run infrastructure (1 node/Dev-Mode consensus)

- Go to root project’s directory
- Clone this repo (if not cloned yet))
- Ensure all containers stopped: “docker-compose down --remove-orphans”
- Get recent data from the repo: “git pull”
- Start new containers: “docker-compose up”

# Demo

TBD
"
9,chvlyl/ML_in_Biomed,,"# Machine Learning in Healthcare and Biomedical Applications

* Data driven decision making
* Questions -> Data -> Models/Tools

# Table of Contents
1. [Overview](#overview)
2. [EHR data](#ehr-data)
3. [Insurance claims data](#claims)
4. [Clinical notes](#clinical-notes)
5. [Image data](#image-data)
6. [Time series data](#time-series-data)
7. [Genomics data](#genomics-data)




## Overview
|Data type|Models/Tools|Applications|
|---|---|---|
|-EHR data <br/>-Insurance claims data |ML(logistic regression,XGBoost)|Predict outcomes (disease, death, readmission etc.)|
|-Clinical notes <br/>-Conversation text data|-Rule based approach(regular expression)<br/>-Deep learning apporach|-Extract concepts from clinical notes <br/>-Knowledge graphs<br/>-Chat-bot<br/>-QA system|
|Medical image data (X-ray, CT, OCR image etc.)|CNN|-Detection: diagnosis of skin cancer lung nodule or diabetic reinopathy<br/>-Segmentation of tumor, histopathology|
|Time series data (EEG, ECG, vital sign data etc.)|HMM,RNN,CNN|-Heart disease<br/>-Sleep disorder(apnea)<br/>-ICU monitoring|
|Genomics data|GATK,QIIME|-Cancer mutation identification<br/>-Biomarker identification<br/>-Durg discovery |
|Other data (hospital operational data)|-ML(regression)<br/>-Queueing model|-Reduce operational cost<br/>-Improve patient experience<br/>-ER wait time and queueing|

## EHR data


|Prediction outcomes|Models/Tools|Data type|Sample size|Reference|Year|
|---|---|---|---|---|---|
|Review||||[Mining electronic health records: towards better research applications and clinical care](https://www.nature.com/nrg/journal/v13/n6/full/nrg3208.html)|2012|
|Review||||[Opportunities and challenges in developing risk prediction models with electronic health records data: a systematic review](https://academic.oup.com/jamia/article/24/1/198/2631444/Opportunities-and-challenges-in-developing-risk)|2016|
|heart failure|-logistic regression<br/>-random forest|longitudinal EHR data|1684 heart failure cases and 13525 matched controls|[Early Detection of Heart Failure Using Electronic Health Records](http://circoutcomes.ahajournals.org/content/9/6/649.long)|2016|
|heart failure (review)||||[Population Risk Prediction Models for Incident Heart Failure](http://circheartfailure.ahajournals.org/content/8/3/438.long)|2015|
|Kidney transplant graft failure|Cox regression|10-years EHR data|69,440 kidney transpants|[A comprehensive risk quantification score for deceased donor kidneys: the kidney donor risk index](https://insights.ovid.com/pubmed?pmid=19623019)|2009|


## Clinical notes
|Prediction outcomes|Models/Tools|Data type|Sample size|Reference|Year|
|---|---|---|---|---|---|
|Review||||[Realizing the full potential of electronic health records: the role of natural language processing](https://academic.oup.com/jamia/article-lookup/doi/10.1136/amiajnl-2011-000501)|2011|
|Review||||[Natural language processing: an introduction](https://academic.oup.com/jamia/article-lookup/doi/10.1136/amiajnl-2011-000464)|2011|
|Negation|Regular expression and rule-based approach|Clinical reports|2060 discharge summaries|[A simple algorithm for identifying negated findings and diseases in discharge summaries](http://www.sciencedirect.com/science/article/pii/S1532046401910299?via%3Dihub)|2001|
|||||[Using electronic health records to drive discovery in disease genomics](https://www.nature.com/nrg/journal/v12/n6/pdf/nrg2999.pdf)||
|NER||discharge summaries|826 notes|[A study of machine-learning-based approaches to extract clinical entities and their assertions from discharge summaries](https://academic.oup.com/jamia/article-lookup/doi/10.1136/amiajnl-2011-000163)|2011|




## Image data
|Prediction outcomes|Models/Tools|Data type|Sample size|Reference|Year|
|---|---|---|---|---|---|
|Diabetic retinopathy|CNN|retinal fundus images|128175 retinal images|[Development and Validation of a Deep Learning Algorithm for Detection of Diabetic Retinopathy in Retinal Fundus Photographs](http://jamanetwork.com/journals/jama/fullarticle/2588763)|2016|
|Skin cancer |CNN|skin images|129,450 skin images|[Dermatologist-level classification of skin cancer with deep neural networks](https://www.nature.com/nature/journal/v542/n7639/full/nature21056.html)|2017|
|Tumor|CNN|Pathology images|400+110 slides|[Detecting Cancer Metastases on Gigapixel Pathology Images](https://arxiv.org/abs/1703.02442)|2017|
|||||[Deep Learning Automates the Quantitative Analysis of Individual Cells in Live-Cell Imaging Experiments](http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005177)||



## Time series data
|Prediction outcomes|Models/Tools|Data type|Sample size|Reference|Year|
|---|---|---|---|---|---|
|sinus rhythm and atrial fibrillation|34-layer convolutional neural network (CNN)|single-lead ECG|-(Train) 64,121 ECG records from 29,163 patients<br/>-(Test) 336 records from 328 unique patients|[Cardiologist-Level Arrhythmia Detection with Convolutional Neural Networks](https://arxiv.org/abs/1707.01836)|2017|
|Hand movements|CNN|sEMG|67 intact subjects and 11 transradial amputees|[Deep Learning with Convolutional Neural Networks Applied to Electromyography Data: A Resource for the Classification of Movements for Prosthetic Hands](http://journal.frontiersin.org/article/10.3389/fnbot.2016.00009/full)|2016|
|Review||ICU data||[Machine Learning and Decision Support in Critical Care](http://ieeexplore.ieee.org/document/7390351/?part=1)|2017|



## Genomics data
|Prediction outcomes|Models/Tools|Data type|Sample size|Reference|Year|
|---|---|---|---|---|---|
|Genetic variants|Exome NGS|NGS&EHR data|50,726 individuals|[Distribution and clinical impact of functional variants in 50,726 whole-exome sequences from the DiscovEHR study](http://science.sciencemag.org/content/354/6319/aaf6814)|2016|
|Familial hypercholesterolemia|Exome NGS|NGS&EHR data|50,726 individuals|[Genetic identification of familial hypercholesterolemia within a single U.S. health care system](http://science.sciencemag.org/content/354/6319/aaf7000)|2016|


## Other
|Prediction outcomes|Models/Tools|Data type|Sample size|Reference|Year|
|---|---|---|---|---|---|
|Drug discovery|LSTM|Assay|12-27 assays|[Low data drug discovery with one-shot learning](http://pubs.acs.org/doi/full/10.1021/acscentsci.6b00367)|2017|
|Tutorial||Image||[Deep learning models for health care: challenges and solutions](http://www-bcf.usc.edu/~liu32/icml_tutorial.pdf)|2017|
|Tutorial||Image||[Deep learning in radiology: recent advances, challenges and future trends](https://ulasbagci.wordpress.com/2016/12/10/deep-learning-in-radiology-rsna-2016/)|2016|
|Tutorial||||[Big data analytics for healthcare](https://www.siam.org/meetings/sdm13/sun.pdf)|2013|
|Tutorial||Image||[Survey of deep learning in radiology](https://healthcare.ai/survey-of-deep-learning-in-radiology/)|2017|
|ER wait time||ER visit time||[Accurate ED Wait Time Prediction](https://web.stanford.edu/~bayati/papers/edwait.pdf)|2017|




"
10,abuanwar072/Production-Ready-Doctor-Consultant-App-UI-,Dart,"# Production-Ready Doctor Consultant App - Flutter UI

## [Watch it on YouTube](https://youtube.com/playlist?list=PLxUBb2A_UUy9rvCoLXopsYQJTTnuW0NIq)

**Packages we are using:**

- flutter_svg: [link](https://pub.dev/packages/flutter_svg)

## [Complete Source code (Patreon)](https://cutt.ly/DmKF5HP)

In this full series, we will show you how to Building Production-Ready Healthcare/ Doctor Consult Android and iOS app UI using Flutter. This full app contains more than 15 screens like Splash Screen, log in & Sign up page. In episode one we will show you how to create those three screens even show you how to validate the form field on flutter for example email validation, password validation, or username is required.
That's not all we also learn how to show custom keyboard like when you are on email field it shows the @ sign, or on phone number text field it only shows numbers.

### Doctor Consultant App Final UI

![Preview](/gif.gif)

![App Full UI](/previews/1.png)
![Episode 1 - Splash and Auth Page](/previews/2.png)

**List Of Screens:**

- Splash
- Sign in (With form validation)
- Sign up (With form validation)
- Home
- Appointment 
- BottomNavigationBar 
- Profile
- List of Doctors
- Settings"
11,amanjeetsahu/AI-for-Healthcare-Nanodegree,Jupyter Notebook,"# AI for Healthcare

#### NANODEGREE PROGRAM SYLLABUS


## Overview

```
Play a critical role in enhancing clinical decision-making with machine learning to build the treatments of
the future. Learn to build, evaluate, and integrate predictive models that have the power to transform
patient outcomes. Begin by classifying and segmenting 2D and 3D medical images to augment diagnosis
and then move on to modeling patient outcomes with electronic health records to optimize clinical trial
testing decisions. Finally, build an algorithm that uses data collected from wearable devices to estimate the
wearer’s pulse rate in the presence of motion.
```
```
A graduate of this program will be able to:
```
- Recommend appropriate imaging modalities for common clinical applications of 2D medical imaging
- Perform exploratory data analysis (EDA) on 2D medical imaging data to inform model training and
explain model performance
- Establish the appropriate ‘ground truth’ methodologies for training algorithms to label medical images
- Extract images from a DICOM dataset
- Train common CNN architectures to classify 2D medical images
- Translate outputs of medical imaging models for use by a clinician
- Plan necessary validations to prepare a medical imaging model for regulatory approval
- Detect major clinical abnormalities in a DICOM dataset
- Train machine learning models for classification tasks using real-world 3D medical imaging data
- Integrate models into a clinician’s workflow and troubleshoot deployments
- Build machine learning models in a manner that is compliant with U.S. healthcare data security and
privacy standards
- Use the TensorFlow Dataset API to scalably extract, transform, and load datasets that are aggregated
at the line, encounter, and longitudinal (patient) data levels
- Analyze EHR datasets to check for common issues (data leakage, statistical properties, missing values,
high cardinality) by performing exploratory data analysis with TensorFlow Data Analysis and Validation
library
- Create categorical features from Key Industry Code Sets (ICD, CPT, NDC) and reduce dimensionality for
high cardinality features
- Use TensorFlow feature columns on both continuous and categorical input features to create derived
features (bucketing, cross-features, embeddings)
- Use Shapley values to select features for a model and identify the marginal contribution for each
selected feature
- Analyze and determine biases for a model for key demographic groups
- Use the TensorFlow Probability library to train a model that provides uncertainty range predictions in
order to allow for risk adjustment/prioritization and triaging of predictions
- Preprocess data (eliminate “noise”) collected by IMU, PPG, and ECG sensors based on mechanical,
physiology and environmental effects on the signal.
- Create an activity classification algorithm using signal processing and machine learning techniques
- Detect QRS complexes using one-dimensional time series processing techniques
- Evaluate algorithm performance without ground truth labels
- Generate a pulse rate algorithm that combines information from the PPG and IMU sensor streams


```
Prerequisites :
Intermediate
Python, and
Experience with
Machine Learning
```
**Flexible Learning** :
Self-paced, so
you can learn on
the schedule that
works best for you.

**Estimated Time** :
4 Months at
15 hours / week

```
Need Help?
udacity.com/advisor
Discuss this program
with an enrollment
advisor.
```

## Course 1: Applying AI to 2D Medical Imaging

## Data

2D imaging, such as X-ray, is widely used when making critical decisions about patient care and accessible by
most healthcare centers around the world. With the advent of deep learning for non-medical imaging data
over the past half decade, the world has quickly turned its attention to how AI could be specifically applied to
medical imaging to improve clinical decision-making and to optimize workflows. Learn the fundamental skills
needed to work with 2D medical imaging data and how to use AI to derive clinically-relevant insights from
data gathered via different types of 2D medical imaging such as x-ray, mammography, and digital pathology.
Extract 2D images from DICOM files and apply the appropriate tools to perform exploratory data analysis
on them. Build different AI models for different clinical scenarios that involve 2D images and learn how to
position AI tools for regulatory approval.

##### Course Project

##### Pneumonia Detection

##### from Chest X-Rays

```
Chest X-ray exams are one of the most frequent and cost-effective
types of medical imaging examinations. Deriving clinical diagnoses
from chest X-rays can be challenging, however, even by skilled
radiologists. When it comes to pneumonia, chest X-rays are the best
available method for point-of-care diagnosis. More than 1 million
adults are hospitalized with pneumonia and around 50,000 die
from the disease every year in the US alone. The high prevalence
of pneumonia makes it a good candidate for the development of a
deep learning application for two reasons: 1) Data availability in a
high enough quantity for training deep learning models for image
classification 2) Opportunity for clinical aid by providing higher
accuracy image reads of a difficult-to-diagnose disease and/or reduce
clinical burnout by performing automated reads of very common
scans. In this project, you will analyze data from the NIH Chest
X-ray dataset and train a CNN to classify a given chest X-ray for the
presence or absence of pneumonia. First, you’ll curate training and
testing sets that are appropriate for the clinical question at hand from
a large collection of medical images. Then, you will create a pipeline
to extract images from DICOM files that can be fed into the CNN for
model training. Lastly, you’ll write an FDA 501(k) validation plan that
formally describes your model, the data that it was trained on, and a
validation plan that meets FDA criteria in order to obtain clearance of
the software being used as a medical device.
```

###### LEARNING OUTCOMES

###### LESSON ONE

```
Introduction to
AI for 2D Medical
Imaging
```
- Explain what AI for 2D medical imaging is and why it is relevant.

###### LESSON TWO

```
Clinical
Foundations of 2D
Medical Imaging
```
- Learn about different 2D medical imaging modalities and their
clinical applications
- Understand how different types of machine learning
algorithms can be applied to 2D medical imaging
- Learn how to statistically assess an algorithm’s performance
- Understand the key stakeholders in the 2D medical imaging
space.

###### LESSON THREE

```
2D Medical Imaging
Exploratory Data
Analysis
```
- Learn what the DICOM standard it is and why it exists
- Use Python tools to explore images extracted from DICOM files
- Apply Python tools to explore DICOM header data
- Prepare a DICOM dataset for machine learning
- Explore a dataset in preparation for machine learning

###### LESSON FOUR

```
Classification
Models of 2D
Medical Images
```
- Understand architectures of different machine learning and
deep learning models, and the differences between them
- Split a dataset for training and testing an algorithm
- Learn how to define a gold standard
- Apply common image pre-processing and augmentation
techniques to data
- Fine-tune an existing CNN architecture for transfer learning
with 2D medical imaging applications
- Evaluate a model’s performance and optimize its parameters

###### LESSON FIVE

```
Translating AI
Algorithms for
Clinical Settings
with the FDA
```
- Learn about the FDA’s risk categorization for medical devices
and how to define an Intended Use statement
- Identify and describe algorithmic limitations for the FDA
- Translate algorithm performance statistics into clinically
meaningful information that can trusted by professionals
- Learn how to create an FDA validation plan


## Course 2: Applying AI to 3D Medical Imaging

## Data

3D medical imaging exams such as CT and MRI serve as critical decision-making tools in the clinician’s
everyday diagnostic armamentarium. These modalities provide a detailed view of the patient’s anatomy and
potential diseases, and are a challenging though highly promising data type for AI applications. Learn the
fundamental skills needed to work with 3D medical imaging datasets and frame insights derived from the
data in a clinically relevant context. Understand how these images are acquired, stored in clinical archives, and
subsequently read and analyzed. Discover how clinicians use 3D medical images in practice and where AI holds
most potential in their work with these images. Design and apply machine learning algorithms to solve the
challenging problems in 3D medical imaging and how to integrate the algorithms into the clinical workflow.

###### LEARNING OUTCOMES

```
LESSON ONE Introduction to
AI for 3D Medical
Imaging
```
- Explain what AI for 3D medical imaging is and why it is
relevant

##### Course Project

##### Hippocampal Volume

##### Quantification in

##### Alzheimer’s Progression

```
Hippocampus is one of the major structures of the human brain
with functions that are primarily connected to learning and
memory. The volume of the hippocampus may change over time,
with age, or as a result of disease. In order to measure hippocampal
volume, a 3D imaging technique with good soft tissue contrast is
required. MRI provides such imaging characteristics, but manual
volume measurement still requires careful and time consuming
delineation of the hippocampal boundary. In this project, you will
go through the steps that will have you create an algorithm that will
help clinicians assess hippocampal volume in an automated way
and integrate this algorithm into a clinician’s working environment.
First, you’ll prepare a hippocampal image dataset to train the U-net
based segmentation model, and capture performance on the test
data. Then, you will connect the machine learning execution code
into a clinical network, create code that will generate reports based
on the algorithm output, and inspect results in a medical image
viewer. Lastly, you’ll write up a validation plan that would help
collect clinical evidence of the algorithm performance, similar to
that required by regulatory authorities.
```

###### LESSON TWO

```
3D Medical
Imaging - Clinical
Fundamentals
```
- Identify medical imaging modalities that generate 3D images
- List clinical specialties who use 3D images to influence clinical
decision making
- Describe use cases for 3D medical images
- Explain the principles of clinical decision making
- Articulate the basic principles of CT and MR scanner operation
- Perform some of the common 3D medical image analysis
tasks such as windowing, MPR and 3D reconstruction

###### LESSON THREE

```
3D Medical
Imaging
Exploratory Data
Analysis
```
- Describe and use DICOM and NIFTI representations of 3D
medical imaging data
- Explain specifics of spatial and dimensional encoding of 3D
medical images
- Use Python-based software packages to load and inspect 3D
medical imaging volumes
- Use Python-based software packages to explore datasets
of 3D medical images and prepare it for machine learning
pipelines
- Visualize 3D medical images using open software packages

###### LESSON FOUR

```
3D Medical
Imaging - Deep
Learning Methods
```
- Distinguish between classification and segmentation
problems as they apply to 3D imaging
- Apply 2D, 2.5D and 3D convolutions to a medical imaging
volume
- Apply U-net algorithm to train an automatic segmentation
model of a real-world CT dataset using PyTorch
- Interpret results of training, measure efficiency using Dice and
Jaccard performance metrics

###### LESSON FIVE

```
Deploying AI
Algorithms in the
Real World
```
- Identify the components of a clinical medical imaging network
and integration points as well as DICOM protocol for medical
image exchange
- Define the requirements for integration of AI algorithms
- Use tools for modeling of clinical environments so that
it is possible to emulate and troubleshoot real-world AI
deployments
- Describe regulatory requirements such as FDA medical device
framework and HIPAA required for operating AI for clinical
care
- Provide input into regulatory process, as a data scientist


## Course 3: Applying AI to EHR Data

```
With the transition to electronic health records (EHR) over the last decade, the amount of EHR data has increased
exponentially, providing an incredible opportunity to unlock this data with AI to benefit the healthcare system.
Learn the fundamental skills of working with EHR data in order to build and evaluate compliant, interpretable
machine learning models that account for bias and uncertainty using cutting-edge libraries and tools including
TensorFlow Probability, Aequitas, and Shapley. Understand the implications of key data privacy and security
standards in healthcare. Apply industry code sets (ICD10-CM, CPT, HCPCS, NDC), transform datasets at different
EHR data levels, and use TensorFlow to engineer features.
```
###### LEARNING OUTCOMES

###### LESSON ONE

```
EHR Data Security
and Analysis
```
- Understand U.S. healthcare data security and privacy best
practices (e.g. HIPAA, HITECH) and how they affect utilizing
protected health information (PHI) data and building
models
- Analyze EHR datasets to check for common issues
(data leakage, statistical properties, missing values, high
cardinality) by performing exploratory data analysis

```
LESSON TWO EHR Code Sets
```
- Understand the usage and structure of key industry code
sets (ICD, CPT, NDC).
- Group and categorize data within EHR datasets using code
sets.

##### Course Project

##### Patient Selection for

##### Diabetes Drug Testing

```
EHR data is becoming a key source of real-world evidence (RWE)
for the pharmaceutical industry and regulators to make decisions
on clinical trials. In this project, you will act as a data scientist
for an exciting unicorn healthcare startup that has created a
groundbreaking diabetes drug that is ready for clinical trial
testing. Your task will be to build a regression model to predict the
estimated hospitalization time for a patient in order to help select/
filter patients for your study. First, you will perform exploratory
data analysis in order to identify the dataset level and perform
feature selection. Next, you will build necessary categorical and
numerical feature transformations with TensorFlow. Lastly, you will
build a model and apply various analysis frameworks, including
TensorFlow Probability and Aequitas, to evaluate model bias and
uncertainty.
```

###### LESSON THREE

```
EHR Transformations
& Feature
Engineering
```
- Use the TensorFlow Dataset API to scalably extract,
transform, and load datasets
- Build datasets aggregated at the line, encounter, and
longitudinal(patient) data levels
- Create derived features (bucketing, cross-features,
embeddings) utilizing TensorFlow feature columns on both
continuous and categorical input features

###### LESSON FOUR

```
Building, Evaluating,
and Interpreting
Models
```
- Analyze and determine biases for a model for key
demographic groups by evaluating performance metrics
across groups by using the Aequitas framework.
- Train a model that provides an uncertainty range with the
TensorFlow Probability library
- Use Shapley values to select features for a model and
identify the marginal contribution for each selected feature


## Course 4: Applying AI to Wearable Device Data

Wearable devices are an emerging source of physical health data. With continuous, unobtrusive monitoring
they hold the promise to add richness to a patient’s health information in remarkable ways. Understand the
functional mechanisms of three sensors (IMU, PPG, and ECG) that are common to most wearable devices
and the foundational signal processing knowledge critical for success in this domain. Attribute physiology
and environmental context’s effect on the sensor signal. Build algorithms that process the data collected by
multiple sensor streams from wearable devices to surface insights about the wearer’s health.

###### LEARNING OUTCOMES

###### LESSON ONE

```
Intro to Digital
Sampling & Signal
Processing
```
- Describe how to digitally sample analog signals
- Apply signal processing techniques (eg. filtering,
resampling, interpolation) to time series signals.
- Apply frequency domain techniques (eg. FFT, STFT,
spectrogram) to time series signals
- Use matplotlib’s plotting functionality to visualize signals

###### LESSON TWO

```
Introduction to
Sensors
```
- Describe how sensors convert a physical phenomenon into
an electrical one.
- Understand the signal and noise characteristics of the IMU
and PPG signals

##### Course Project

##### Motion Compensated

##### Pulse Rate Estimation

```
Wearable devices have multiple sensors all collecting information
about the same person at the same time. Combining these
data streams allows us to accomplish many tasks that would be
impossible from a single sensor. In this project, you will build an
algorithm which combines information from two of the sensors
that are covered in this course -- the IMU and PPG sensors -- that
can estimate the wearer’s pulse rate in the presence of motion.
First, you’ll create and evaluate an activity classification algorithm
by building signal processing features and a random forest model.
Then, you will build a pulse rate algorithm that uses the activity
classifier and frequency domain techniques, and also produces
an associated confidence metric that estimates the accuracy
of the pulse rate estimate. Lastly, you will evaluate algorithm
performance and iterate on design until the desired accuracy is
achieved.
```

**LESSON THREE Activity Classification**

- Perform exploratory data analysis to understand class
imbalance and subject imbalance
- Gain an intuitive understanding signal characteristics and
potential feature performance
- Write code to implement features from literature
- Recognize the danger overfitting of technique (esp.
on small datasets), not simply of model parameters or
hyperparameters

**LESSON FOUR ECG Signal Processing**

- Understand the electrophysiology of the heart at a basic
level
- Understand the signal and noise characteristics of the ECG
- Understand how atrial fibrillation manifests in the ECG
- Build a QRS complex detection algorithm
- Build an arrhythmia detection algorithm from a wearable
ECG signal
- Understand how models can be cascaded together to
achieve higher-order functionality


## Our Classroom Experience

###### REAL-WORLD PROJECTS

```
Build your skills through industry-relevant projects. Get
personalized feedback from our network of 900+ project
reviewers. Our simple interface makes it easy to submit
your projects as often as you need and receive unlimited
feedback on your work.
```
###### KNOWLEDGE

```
Find answers to your questions with Knowledge, our
proprietary wiki. Search questions asked by other students,
connect with technical mentors, and discover in real-time
how to solve the challenges that you encounter.
```
###### STUDENT HUB

```
Leverage the power of community through a simple, yet
powerful chat interface built within the classroom. Use
Student Hub to connect with your fellow students in your
Executive Program.
```
###### WORKSPACES

```
See your code in action. Check the output and quality of
your code by running them on workspaces that are a part
of our classroom.
```
###### QUIZZES

```
Check your understanding of concepts learned in the
program by answering simple and auto-graded quizzes.
Easily go back to the lessons to brush up on concepts
anytime you get an answer wrong.
```
###### CUSTOM STUDY PLANS

```
Preschedule your study times and save them to your
personal calendar to create a custom study plan. Program
regular reminders to keep track of your progress toward
your goals and completion of your program.
```
###### PROGRESS TRACKER

```
Stay on track to complete your Nanodegree program with
useful milestone reminders.
```

## Learn with the Best

### Nikhil Bikhchandani

```
DATA SCIENTIST
AT VERILY LIFE SCIENCES
Nikhil spent five years working with
wearable devices at Google and Verily Life
Sciences. His work with wearables spans
many domains including cardiovascular
disease, neurodegenerative diseases, and
diabetes. Before Alphabet, he earned a
B.S. and M.S. in Electrical Engineering and
Computer Science at Carnegie Mellon.
```
### Mazen Zawaideh

```
RADIOLOGIST
AT UNIVERSITY OF WASHINGTON
Mazen Zawaideh is a Neuroradiology
Fellow at the University of Washington,
where he focuses on advanced diagnostic
imaging and minimally invasive
therapeutics. He also served as a Radiology
Consultant for Microsoft Research for AI
applications in oncologic imaging.
```
### Emily Lindemer

```
DIRECTOR OF DATA SCIENCE &
ANALYTICS AT WELLFRAME
Emily is an expert in AI for both medical
imaging and digital healthcare. She holds
a PhD from Harvard-MIT’s Health Sciences
& Technology division and founded her
own digital health company in the opioid
space. She now runs the data science
division of a digital healthcare company in
Boston called Wellframe.
```
### Ivan Tarapov

```
SR. PROGRAM MANAGER
AT MICROSOFT RESEARCH
At Microsoft Research, Ivan works on robust
auto-segmentation algorithms for MRI and CT
images. He has worked with Physio-Control,
Stryker, Medtronic, and Abbott, where he
helped develop external and internal cardiac
defibrillators, insulin pumps, telemedicine,
and medical imaging systems.
```

## Learn with the Best

### Michael Dandrea

```
PRINCIPAL DATA SCIENTIST
AT GENENTECH
```
```
Michael is on the Pharma Development
Informatics team at Genentech (part of
the Roche Group), where he works on
improving clinical trials and developing
safer, personalized treatments with
clinical and EHR data. Previously, he was
a Lead Data Scientist on the AI team at
McKesson’s Change Healthcare.
```

## All Our Nanodegree Programs Include:

###### EXPERIENCED PROJECT REVIEWERS

```
REVIEWER SERVICES
```
- Personalized feedback & line by line code reviews
- 1600+ Reviewers with a 4.85/5 average rating
- 3 hour average project review turnaround time
- Unlimited submissions and feedback loops
- Practical tips and industry best practices
- Additional suggested resources to improve

###### TECHNICAL MENTOR SUPPORT

```
MENTORSHIP SERVICES
```
- Questions answered quickly by our team of
technical mentors
- 1000+ Mentors with a 4.7/5 average rating
- Support for all your technical questions

###### PERSONAL CAREER SERVICES

```
CAREER COACHING
```
- Personal assistance in your job search
- Monthly 1-on-1 calls
- Personalized feedback and career guidance
- Interview preparation
- Resume services
- Github portfolio review
- LinkedIn profile optimization


## Frequently Asked Questions

PROGRAM OVERVIEW

**WHY SHOULD I ENROLL?**
Artificial Intelligence has revolutionized many industries in the past decade,
and healthcare is no exception. In fact, the amount of data in **healthcare has
grown 20x in the past 7 years** , causing an expected surge in the Healthcare AI
market from **$2.1 to $36.1 billion by 2025** at an annual growth rate of 50.4%. AI
in Healthcare is transforming the way patient care is delivered, and is impacting
all aspects of the medical industry, including early detection, more accurate
diagnosis, advanced treatment, health monitoring, robotics, training, research and
much more.

By leveraging the power of AI, providers can deploy more precise, efficient,
and impactful interventions at exactly the right moment in a patient’s care. In
light of the worldwide COVID-19 pandemic, there has never been a better time
to understand the possibilities of artificial intelligence within the healthcare
industry and learn how you can make an impact to better the world’s healthcare
infrastructure.

###### WHAT JOBS WILL THIS PROGRAM PREPARE ME FOR?

This program will help you apply your Data Science and Machine Learning
expertise in roles including Physician Data Scientist; Healthcare Data Scientist;
Healthcare Data Scientist, Machine Learning; Healthcare Machine Learning
Engineer, Research Scientist, Machine Learning, and more roles in the healthcare
and health tech industries that necessitate knowledge of AI and machine learning
techniques.

###### HOW DO I KNOW IF THIS PROGRAM IS RIGHT FOR ME?

If you are interested in applying your data science and machine learning
experience in the healthcare industry, then this program is right for you.

Additional job titles and backgrounds that could be helpful include Data Scientist,
Machine Learning Engineer, AI Specialist, Deep Learning Research Engineer, and AI
Scientist. This program is also a good fit for Researchers, Scientists, and Engineers
who want to make an impact in the medical field.

ENROLLMENT AND ADMISSION

###### DO I NEED TO APPLY? WHAT ARE THE ADMISSION CRITERIA?

There is no application. This Nanodegree program accepts everyone, regardless of
experience and specific background.


## FAQs Continued

###### WHAT ARE THE PREREQUISITES FOR ENROLLMENT?

To be best prepared to succeed in this program, students should be able to:

Intermediate Python:

- Read, understand, and write code in Python, including language constructs
such as functions and classes.
- Read code using vectorized operations with the NumPy library.

Machine Learning:

- Build a machine learning model for a supervised learning problem and
understand basic methods to represent categorical and numerical features
as inputs for this model
- Perform simple machine learning tasks, such as classification and
regression, from a set of features
- Apply basic knowledge of Python data and machine learning frameworks
(Pandas, NumPy, TensorFlow, PyTorch) to manipulate and clean data for
consumption by different estimators/algorithms (e.g. CNNs, RNNs, tree-
based models).

**IF I DO NOT MEET THE REQUIREMENTS TO ENROLL, WHAT SHOULD I DO?**
To best prepare for this program, we recommend the **AI Programming with
Python Nanodegree program** and the **Deep Learning Nanodegree program** or
the **Intro to Machine Learning with PyTorch Nanodegree program** or the **Intro
to Machine Learning with TensorFlow Nanodegree program**.

TUITION AND TERM OF PROGRAM

**HOW IS THIS NANODEGREE PROGRAM STRUCTURED?**
The AI for Healthcare Nanodegree program is comprised of content and
curriculum to support four projects. Once you subscribe to a Nanodegree
program, you will have access to the content and services for the length of time
specified by your subscription. We estimate that students can complete the
program in four months, working 15 hours per week.

Each project will be reviewed by the Udacity reviewer network. Feedback will be
provided and if you do not pass the project, you will be asked to resubmit the
project until it passes.

**HOW LONG IS THIS NANODEGREE PROGRAM?**
Access to this Nanodegree program runs for the length of time specified in
the payment card on the Nanodegree program overview page. If you do not
graduate within that time period, you will continue learning with month to
month payments. See the **Terms of Use** for other policies around the terms of
access to our Nanodegree programs.


## FAQs Continued

###### CAN I SWITCH MY START DATE? CAN I GET A REFUND?

Please see the Udacity Program **Terms of Use** and **FAQs** for policies on
enrollment in our programs.

SOFTWARE AND HARDWARE

**WHAT SOFTWARE AND VERSIONS WILL I NEED IN THIS PROGRAM?**
For this Nanodegree program, you will need a desktop or laptop computer
running recent versions of Windows, Mac OS X, or Linux and an unmetered
broadband Internet connection. For an ideal learning experience, a computer
with Mac or Linux OS is recommended.

You will use Python, PyTorch, TensorFlow, and Aequitas in this Nanodegree
program.


"
12,rahulremanan/HIMA,HTML,"﻿# HIMA
(Healthcare Image Analysis)

HIMA is phonetic equivalent of Sanskrit root: \हिम\ meaning snow.

An open-source cloud powered image analytics platform for healthcare imaging data.

Built with Jomiraki, an open source development environment for artificial intelligence applications using Python, Tensorflow and Keras, all residing inside a secure linux VM.
"
13,GoogleCloudPlatform/healthcare-data-harmonization-dataflow,Java,"# HL7v2 to FHIR Pipeline

This directory contains a reference Cloud Dataflow pipeline to convert HL7v2 messages to FHIR resources. Please note that additional configurations and hardening are required before processing PHI data with this pipeline.

## Prerequisites

* Have a Linux (Ubuntu & Debian preferred) machine ready.
  * Install [GCC compiler](https://gcc.gnu.org/install/).
  * Install [Go tools](https://golang.org/doc/install), versions >= [1.14](https://golang.org/dl/) are recommended.
  * Install [Gradle](https://gradle.org/install/), version [6.3.0](https://gradle.org/next-steps/?version=6.3&format=bin) is recommended.
  * Install [Protoc](https://github.com/protocolbuffers/protobuf/releases), version [3.14.0](https://github.com/protocolbuffers/protobuf/releases) is recommended.
* Add your public key to [GitHub](https://help.github.com/en/github/authenticating-to-github/adding-a-new-ssh-key-to-your-github-account).
* Install the latest [GCloud SDK](https://cloud.google.com/sdk/install).
* Create a [project](https://cloud.google.com/resource-manager/docs/creating-managing-projects).
* Create an [HL7v2 Store](https://cloud.google.com/healthcare/docs/how-tos/hl7v2).
  * Make sure to use beta endpoints and provide `NotificationConfig`s and a schematized `ParserConfig`.
* Create a [FHIR Store](https://cloud.google.com/healthcare/docs/how-tos/fhir).
  * Set [enableUpdateCreate](https://cloud.google.com/healthcare/docs/reference/rest/v1/projects.locations.datasets.fhirStores#FhirStore.FIELDS.enable_update_create) and [disableReferentialIntegrity](https://cloud.google.com/healthcare-api/docs/reference/rest/v1/projects.locations.datasets.fhirStores#FhirStore.FIELDS.disable_referential_integrity) for the FHIR store.
* Enable [Cloud Dataflow API](https://cloud.google.com/endpoints/docs/openapi/enable-api).
* (Highly recommended) Enable [audit logging](https://cloud.google.com/logging/docs/audit).

### Permissions

Make sure you have [enough permissions](https://cloud.google.com/dataflow/docs/concepts/access-control#creating_jobs) to run Cloud Dataflow jobs.

The [Cloud Dataflow Controller Service Account](https://cloud.google.com/dataflow/docs/concepts/security-and-permissions#controller_service_account) needs the following permissions.

* `roles/pubsub.subscriber`.
  * To listen for PubSub notifications from new messages. The service account only needs the role on the specific PubSub subscription.
* `roles/healthcare.hl7V2Consumer`.
  * To access messages in your HL7v2 store. The service account only needs the role on the source HL7v2 Store.
* `roles/healthcare.fhirResourceEditor`.
  * To write transformed resources to your FHIR store. The service account only needs this role on the target FHIR Store.
* `roles/storage.objectAdmin`.
  * To access mapping and harmonization configurations on GCS. The service account needs this role on all GCS buckets that the mappings reside in.

## How to Run

Build a fat JAR of the pipeline by running the following from the project directory.

* Please make sure gradle is added to PATH before running the following commands.

```bash
# Generate wrapper classes.
gradle wrapper --gradle-version 6.7.1
./gradlew shadowJar
```

A JAR file should be generated in `build/libs` folder.

Now run the pipeline with the following command:

```bash
# Please set the environment variables in the following command.

java -jar build/libs/converter-0.1.0-all.jar --pubSubSubscription=""projects/${PROJECT?}/subscriptions/${SUBSCRIPTION?}"" \
                                             --readErrorPath=""gs://${ERROR_BUCKET?}/read/"" \
                                             --writeErrorPath=""gs://${ERROR_BUCKET?}/write/"" \
                                             --mappingErrorPath=""gs://${ERROR_BUCKET?}/mapping/"" \
                                             --mappingPath=""gs://${MAPPING_BUCKET?}/mapping.textproto"" \
                                             --fhirStore=""projects/${PROJECT?}/locations/${LOCATION?}/datasets/${DATASET?}/fhirStores/${FHIRSTORE?}"" \
                                             --runner=DataflowRunner \
                                             --region=${REGION?} \
                                             --project=${PROJECT?}
```

A few notes:

- By default, streaming pipelines do not have autoscaling enabled, please use
either `--enableStreamingEngine` (recommended) or a combination of `--autoscalingAlgorithm=THROUGHPUT_BASED` and
`--maxNumWorkers=N` to manually enable it. See [this page](https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#autotuning-features) for more details.
- For production use, we recommend enabling agent metrics by appending `--experiments=enable_stackdriver_agent_metrics` as an option (you will need to grant `roles/monitoring.metricWriter` to Dataflow controller service account as well), see [this page](https://cloud.google.com/dataflow/docs/guides/using-cloud-monitoring#receive_worker_vm_metrics_from_monitoring_agent) for more details. Additionally, we **highly** recommend limiting the number of threads on each worker, e.g. `--numberOfWorkerHarnessThreads=10`. You can tune the limit based on your workload.
- To generate a template instead of running the pipeline, add `--stagingLocation=gs://${STAGING_LOCATION} --templateLocation=gs://${TEMPLATE_LOCATION}` to the above command. See [here](https://cloud.google.com/dataflow/docs/guides/templates/creating-templates)

Please take a look at the `PipelineRunner` class to see the concrete meaning of
each argument.

You should be able to verify that a Dataflow pipeline is running from the cloud
console UI. Data should start flowing through the pipeline and arrive at the
FHIR Store, use the SearchResources API to verify that FHIR Resources are
written correctly.

# DICOM to FHIR Pipeline

This directory contains a reference Cloud Dataflow pipeline to convert a DICOM Study to a FHIR ImagingStudy resource.

## Prerequisites

* Have a Linux (Ubuntu & Debian preferred) machine ready.
  * Install [GCC compiler](https://gcc.gnu.org/install/).
  * Install [Go tools](https://golang.org/doc/install), versions >= [1.14](https://golang.org/dl/) are recommended.
  * Install [Gradle](https://gradle.org/install/), version [6.3.0](https://gradle.org/next-steps/?version=6.3&format=bin) is recommended.
  * Install [Protoc](https://github.com/protocolbuffers/protobuf/releases), version [3.14.0](https://github.com/protocolbuffers/protobuf/releases) is recommended.
* Add your public key to [GitHub](https://help.github.com/en/github/authenticating-to-github/adding-a-new-ssh-key-to-your-github-account).
* Install the latest [GCloud SDK](https://cloud.google.com/sdk/install).
* Create a [project](https://cloud.google.com/resource-manager/docs/creating-managing-projects).
* Create a [DICOM Store](https://cloud.google.com/healthcare/docs/how-tos/dicom).
* Create an R4 [FHIR Store](https://cloud.google.com/healthcare/docs/how-tos/fhir).
  * Set [disableReferentialIntegrity](https://cloud.google.com/healthcare-api/docs/reference/rest/v1/projects.locations.datasets.fhirStores#FhirStore.FIELDS.disable_referential_integrity) for the FHIR store.
* Enable [Cloud Dataflow API](https://cloud.google.com/endpoints/docs/openapi/enable-api).

### Permissions

Make sure you have [enough permissions](https://cloud.google.com/dataflow/docs/concepts/access-control#creating_jobs) to run Cloud Dataflow jobs.

The [Cloud Dataflow Controller Service Account](https://cloud.google.com/dataflow/docs/concepts/security-and-permissions#controller_service_account) needs the following permissions.

* `roles/pubsub.subscriber`.
  * To listen for PubSub notifications from new messages. The service account only needs the role on the specific PubSub subscription.
* `roles/healthcare.dicomEditor`.
  * To access metadata of DICOM stores.
* `roles/healthcare.fhirResourceEditor`.
  * To write transformed resources to your FHIR store. The service account only needs this role on the target FHIR Store.
* `roles/storage.objectAdmin`.
  * To access mapping and harmonization configurations on GCS. The service account needs this role on all GCS buckets that the mappings reside in.

## How to Run

Build a fat JAR of the pipeline by running the following from the project directory.

* Please make sure gradle is added to PATH before running the following commands.

```bash
# Generate wrapper classes.
gradle wrapper
./gradlew shadowJar -PmainClass=com.google.cloud.healthcare.etl.runner.dicomtofhir.DicomToFhirStreamingRunner
```

A JAR file should be generated in `build/libs` folder.

Now run the pipeline with the following command:

```bash
# Please set the environment variables in the following command.

java -jar build/libs/converter-0.1.0-all.jar --pubSubSubscription=""projects/${PROJECT?}/subscriptions/${SUBSCRIPTION?}"" \
                                             --readErrorPath=""gs://${ERROR_BUCKET?}/read/"" \
                                             --writeErrorPath=""gs://${ERROR_BUCKET?}/write/"" \
                                             --mappingErrorPath=""gs://${ERROR_BUCKET?}/mapping/"" \
                                             --mappingPath=""gs://${MAPPING_BUCKET?}/main.textproto"" \
                                             --fhirStore=""projects/${PROJECT?}/locations/${LOCATION}/datasets/${DATASET?}/fhirStores/${FHIRSTORE?}"" \
                                             --runner=DataflowRunner \
                                             --region=${REGION?} \
                                             --project=${PROJECT?}
```

A few notes:

- By default, streaming pipelines do not have autoscaling enabled, please use
either `--enableStreamingEngine` (recommended) or a combination of `--autoscalingAlgorithm=THROUGHPUT_BASED` and
`--maxNumWorkers=N` to manually enable it. See [this page](https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#autotuning-features) for more details.
- For production use, we recommend enabling agent metrics by appending `--experiments=enable_stackdriver_agent_metrics` as an option (you will need to grant `roles/monitoring.metricWriter` to Dataflow controller service account as well), see [this page](https://cloud.google.com/dataflow/docs/guides/using-cloud-monitoring#receive_worker_vm_metrics_from_monitoring_agent) for more details. Additionally, we **highly** recommend limiting the number of threads on each worker, e.g. `--numberOfWorkerHarnessThreads=10`. You can tune the limit based on your workload.
- To generate a template instead of running the pipeline, add `--stagingLocation=gs://${STAGING_LOCATION} --templateLocation=gs://${TEMPLATE_LOCATION}` to the above command. See [here](https://cloud.google.com/dataflow/docs/guides/templates/creating-templates)
- The mappingPath file (main.textproto) configures the mapping library. Ensure that the paths inside the file exist (References the following repository: https://github.com/GoogleCloudPlatform/healthcare-data-harmonization/). The required binaries should be installed by the build JAR command. There is a sample main.textproto at src/main/java/com/google/cloud/healthcare/etl/runner/dicomtofhir/main.textproto, if specifying GCS (non-local) paths use `gcs_location:` instead of `local_path:`.
- As the mappings do not assign an ID to the mapped FHIR resource, each input creates a new output in the FHIR store. TODO: evaluate maintaining an ID for DICOM Instances.

Please take a look at the `PipelineRunner` class to see the concrete meaning of
each argument.

You should be able to verify that a Dataflow pipeline is running from the cloud
console UI. Data should start flowing through the pipeline and arrive at the
FHIR Store, use the SearchResources API to verify that FHIR Resources are
written correctly.

# Custom to FHIR Pipeline

This directory contains a reference Cloud Dataflow pipeline to convert custom/non standard messages to FHIR resources. Please note that additional configurations and hardening are required before processing PHI data with this pipeline.

## Prerequisites

* Have a Linux (Ubuntu & Debian preferred) machine ready.
  * Install [GCC compiler](https://gcc.gnu.org/install/).
  * Install [Go tools](https://golang.org/doc/install), versions >= [1.14](https://golang.org/dl/) are recommended.
  * Install [Gradle](https://gradle.org/install/), version [6.3.0](https://gradle.org/next-steps/?version=6.3&format=bin) is recommended.
  * Install [Protoc](https://github.com/protocolbuffers/protobuf/releases), version [3.14.0](https://github.com/protocolbuffers/protobuf/releases) is recommended.
* Add your public key to [GitHub](https://help.github.com/en/github/authenticating-to-github/adding-a-new-ssh-key-to-your-github-account).
* Install the latest [GCloud SDK](https://cloud.google.com/sdk/install).
* Create a [project](https://cloud.google.com/resource-manager/docs/creating-managing-projects).
* Create a [FHIR Store](https://cloud.google.com/healthcare/docs/how-tos/fhir).
  * Set [enableUpdateCreate](https://cloud.google.com/healthcare/docs/reference/rest/v1/projects.locations.datasets.fhirStores#FhirStore.FIELDS.enable_update_create) and [disableReferentialIntegrity](https://cloud.google.com/healthcare-api/docs/reference/rest/v1/projects.locations.datasets.fhirStores#FhirStore.FIELDS.disable_referential_integrity) for the FHIR store.
* Enable [Cloud Dataflow API](https://cloud.google.com/endpoints/docs/openapi/enable-api).
* (Highly recommended) Enable [audit logging](https://cloud.google.com/logging/docs/audit).

### Permissions

Make sure you have [enough permissions](https://cloud.google.com/dataflow/docs/concepts/access-control#creating_jobs) to run Cloud Dataflow jobs.

The [Cloud Dataflow Controller Service Account](https://cloud.google.com/dataflow/docs/concepts/security-and-permissions#controller_service_account) needs the following permissions.

* `roles/pubsub.subscriber`.
  * To listen for PubSub notifications from new messages. The service account only needs the role on the specific PubSub subscription.
* `roles/healthcare.fhirResourceEditor`.
  * To write transformed resources to your FHIR store. The service account only needs this role on the target FHIR Store.
* `roles/storage.objectAdmin`.
  * To access mapping and harmonization configurations on GCS. The service account needs this role on all GCS buckets that the mappings reside in.
* `roles/pubsub.viewer`.
  * To access the PubSub subscription.
* `roles/dataflow.worker`.
  * To execute the Dataflow job.

## How to Run

Build a fat JAR of the pipeline by running the following from the project directory.

* Please make sure gradle is added to PATH before running the following commands.

```bash
# Generate wrapper classes.
gradle wrapper --gradle-version 6.7.1
./gradlew shadowJar
```

A JAR file should be generated in `build/libs` folder.

Now run the pipeline with the following command:

* Edit build.gradle and make the change to ensure the mainClassName is set as thus

shadowJar {
    mainClassName = project.findProperty('mainClass') ?: 'com.google.cloud.healthcare.etl.runner.customtofhir.CustomToFhirStreamingRunner'
    dependsOn('buildDeps')
}

* (Optional) Edit the build.gradle
 Depending on the java environment you might need the change as well for the code to build.

// sourceCompatibility = 11
sourceCompatibility = 1.8

```bash
# Please set the environment variables in the following command.

java -jar build/libs/converter-0.1.0-all.jar --pubSubSubscription=""projects/${PROJECT?}/subscriptions/${SUBSCRIPTION?}"" \
                                             --readErrorPath=""gs://${ERROR_BUCKET?}/read/"" \
                                             --writeErrorPath=""gs://${ERROR_BUCKET?}/write/"" \
                                             --mappingErrorPath=""gs://${ERROR_BUCKET?}/mapping/"" \
                                             --mappingPath=""gs://${MAPPING_BUCKET?}/mapping.textproto"" \
                                             --fhirStore=""projects/${PROJECT?}/locations/${LOCATION?}/datasets/${DATASET?}/fhirStores/${FHIRSTORE?}"" \
                                             --runner=DataflowRunner \
                                             --region=${REGION?} \
                                             --project=${PROJECT?} \
                                             --serviceAccount=dataflow-0222@smede-276406.iam.gserviceaccount.com
```

A few notes:

- By default, streaming pipelines do not have autoscaling enabled, please use
either `--enableStreamingEngine` (recommended) or a combination of `--autoscalingAlgorithm=THROUGHPUT_BASED` and
`--maxNumWorkers=N` to manually enable it. See [this page](https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#autotuning-features) for more details.
- For production use, we recommend enabling agent metrics by appending `--experiments=enable_stackdriver_agent_metrics` as an option (you will need to grant `roles/monitoring.metricWriter` to Dataflow controller service account as well), see [this page](https://cloud.google.com/dataflow/docs/guides/using-cloud-monitoring#receive_worker_vm_metrics_from_monitoring_agent) for more details. Additionally, we **highly** recommend limiting the number of threads on each worker, e.g. `--numberOfWorkerHarnessThreads=10`. You can tune the limit based on your workload.
- To generate a template instead of running the pipeline, add `--stagingLocation=gs://${STAGING_LOCATION} --templateLocation=gs://${TEMPLATE_LOCATION}` to the above command. See [here](https://cloud.google.com/dataflow/docs/guides/templates/creating-templates)

Please take a look at the `PipelineRunner` class to see the concrete meaning of
each argument.

You should be able to verify that a Dataflow pipeline is running from the cloud
console UI. Data should start flowing through the pipeline and arrive at the
FHIR Store, use the SearchResources API to verify that FHIR Resources are
written correctly.

## Support

Please file GitHub issues if you encounter any problems.
"
14,IMA-WorldHealth/bhima,JavaScript,"BHIMA
=================

BHIMA is a free, open source accounting and hospital information management system
(HIMS) tailored for rural hospitals in Africa.  We are an international team
based in the Democratic Republic of the Congo.

BHIMA is an acronym for _basic hospital information management application_.

Project Goals
--------------------

BHIMA aims to provide a flexible and robust accounting and managerial solution
for rural hospitals.  This includes, but is not limited to, basic income/expense
reporting, budgeting, patient and organisational billing, depreciation,
inventory and pricing, and purchasing.

Additionally, BHIMA bundles reports and optional reporting plugins to aid
hospital administrators, aid organisations, and governmental/non-governmental
agencies access up to date utilization data.  It targets insitutions that must conform
to the [OHADA](https://en.wikipedia.org/wiki/OHADA) reporting standards in western
and central Africa.

Finally, the entire project is designed to scale from a single, low cost device
in a clinic, to a large multi-hundred bed institution with tens of users
accessing the server simultaneously.

Technology
---------------

The client-side is written in AngularJS and the server in NodeJS.  Session management
is enabled by Redis, and the backend is a MySQL database.

Contributing
---------------
All contributions are welcome!  If you want to get started hacking on BHIMA, the
[developer wiki](https://github.com/IMA-WorldHealth/bhima/wiki) contains notes
on our designs and testing infrastructure.  We also have a dedicated documentation
website https://docs.bhi.ma.  If you have any questions or need help getting started,
please [open an issue](https://github.com/IMA-WorldHealth/bhima/issues/new) - chances
are you are not the only one!

If you just want to jump into to messing with the software, check out [Getting Up And Running](https://github.com/IMA-WorldHealth/bhima/wiki/Getting-Up-and-Running).

If you are new to Github, they have an [excellent guide](https://docs.github.com/en/github/getting-started-with-github).

Installation
-------------------
See the [installation guide](https://docs.bhi.ma/en/for-developers/installing-bhima.html).

License
---------------
BHIMA is licensed under GPL-2.0.  [Read the License](./LICENSE).
"
15,CodeForBaltimore/Healthcare-Rollcall,Vue,"[![Build Status](https://travis-ci.org/CodeForBaltimore/Healthcare-Rollcall.svg?branch=master)](https://travis-ci.org/CodeForBaltimore/Healthcare-Rollcall) [![Netlify Status](https://api.netlify.com/api/v1/badges/83fb49cb-61e1-4c21-8893-03e17e75d972/deploy-status)](https://app.netlify.com/sites/healthcare-rollcall/deploys) [![Language grade: JavaScript](https://img.shields.io/lgtm/grade/javascript/g/CodeForBaltimore/Healthcare-Rollcall.svg?logo=lgtm&logoWidth=18)](https://lgtm.com/projects/g/CodeForBaltimore/Healthcare-Rollcall/context:javascript)

# Healthcare Rollcall

In the event of a disaster, Baltimore City and the Baltimore City Health Department (BCHD) needs to be able to verify the status of all healthcare providers in the city.

<!-- TOC -->

- [Healthcare Rollcall](#healthcare-rollcall)
  - [What is this?](#what-is-this)
  - [Documentation](#documentation)
- [Project setup](#project-setup)
  - [Keeping your API up to date](#keeping-your-api-up-to-date)
  - [Compiles and hot-reloads for development](#compiles-and-hot-reloads-for-development)
  - [Compiles and minifies for production](#compiles-and-minifies-for-production)
  - [Lints and fixes files](#lints-and-fixes-files)
  - [Customize configuration](#customize-configuration)
- [Using this product](#using-this-product)
  - [Testing](#testing)
    - [Using Jest for unit testing](#using-jest-for-unit-testing)
    - [Using Snyk to check for security vulnerabilities](#using-snyk-to-check-for-security-vulnerabilities)
- [Sources and Links](#sources-and-links)
  - [Contributors ✨](#contributors-)

<!-- /TOC -->

## What is this?

This system will provide methods for healthcare providers to check-in during disasters, and update their information during non-emergency periods. During an emergency this system will track providers responses to a questionnaire. This questionnaire can be specific to a single disaster, or can be more general. Examples:

- Widespread power blackout
- Epidemic or Pandemic response (COVID-19)
- Natural disaster

This system will make use of digital services and modern methodologies to automate parts of the check-in process to help the city prioritize its call list and response plan. Additionally, the system will validate contact information regularly during non-emergency times to ensure the city has the most up-to-date information for each provider.

## Documentation

More documentation can be found in the [Docs](/docs) folder.

# Project setup

The quickest way to get started is using the included `docker-compose` to build a complete local stack (web, api, and database) of the project.

Add the following to a file named `.env` in your project directory:

```conf
PORT=3000
VUE_APP_BASE_API_URL=http://localhost:3001
VUE_APP_API_VERSION=1
DATABASE_PASSWORD= # Custom value
JWT_KEY= # Custom value
```

- `PORT`: The port the web service will be exposed on the host machine. Default: `3000`
- `VUE_APP_BASE_API_URL`: The URL to the api service, includes hostname and port. Default: `http://localhost:3001`.
- `DATABASE_PASSWORD`: The password used to authenticate to the postgres database. For security, use a custom value.
- `JWT_KEY`: A secret value to generate JSON Web Tokens (JWTs) locally. For security, use a custom value.

You would then run the docker-compose setup with `docker-compose up -d --build` to run the DB & API, build the front end and stand up all containers.  Once this command completes, wait 5-30 seconds for the db scripts to finish and you'll be able to access your own Healthcare Rollcall app at `https://localhost:3000`.

## Keeping your API up to date

By default the backend solution will pull the `master` branch of [Bmore-Responsive](https://github.com/CodeForBaltimore/Bmore-Responsive). If you wish to keep this up to date you should run:

```shell
docker-compose build
```

You can also specify a tagged release by setting the `API_TAG` value in your `.env` file:

```shell
API_TAG=1.3.2
```

For more information on valid `API_TAG` values, see: [docker build - Git repositories](https://docs.docker.com/engine/reference/commandline/build/#git-repositories)

## Compiles and hot-reloads for development

Using `docker-compose` will mount your local `./src` directory into the application, which allows you to continue to make changes and view them within the application.

The application will be available at [http://localhost:3000/](http://localhost:3000/).

**User Credentials:** To find example user credentials, look to the user.json file in the [Bmore-Responsive repository](https://github.com/CodeForBaltimore/Bmore-Responsive).

**Note:** Depending on the OS you are running `Docker` on your localhost may be mapped to a different IP address. The standard IP address `Docker` is mapped to on Windows is `192.168.99.100` so you would access the application at `192.168.99.100:8080`.

## Compiles and minifies for production

```shell
npm run build
```

## Lints and fixes files

```shell
npm run lint
```

## Customize configuration

See [Configuration Reference](https://cli.vuejs.org/config/).

# Using this product

How would someone use this product? Give a few examples here.

## Testing

### Using Jest for unit testing

```shell
`npm test`
`yarn test`
```

### Using Snyk to check for security vulnerabilities

```shell
`npm install snyk -g`
`snyk test`
```

# Sources and Links

We are also building a back-end API to feed and manage data for this project. To view that project, or to contribute to it, please visit the repo here: https://github.com/CodeForBaltimore/Bmore-Responsive

<p align=""center"">
    <img src=""docs/img/CfB.png"" width=""400"">
</p>

## Contributors ✨

Thanks goes to these wonderful people ([emoji key](https://allcontributors.org/docs/en/emoji-key)):

<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->
<!-- prettier-ignore-start -->
<!-- markdownlint-disable -->
<table>
  <tr>
    <td align=""center""><a href=""http://www.jasonanton.com""><img src=""https://avatars0.githubusercontent.com/u/6391564?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Jason Anton</b></sub></a><br /><a href=""https://github.com/CodeForBaltimore/Healthcare-Rollcall/commits?author=revjtanton"" title=""Code"">💻</a> <a href=""https://github.com/CodeForBaltimore/Healthcare-Rollcall/commits?author=revjtanton"" title=""Documentation"">📖</a> <a href=""#security-revjtanton"" title=""Security"">🛡️</a></td>
    <td align=""center""><a href=""https://ao10.github.io""><img src=""https://avatars3.githubusercontent.com/u/14120224?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Ati Ok</b></sub></a><br /><a href=""https://github.com/CodeForBaltimore/Healthcare-Rollcall/commits?author=ao10"" title=""Code"">💻</a> <a href=""https://github.com/CodeForBaltimore/Healthcare-Rollcall/pulls?q=is%3Apr+reviewed-by%3Aao10"" title=""Reviewed Pull Requests"">👀</a></td>
    <td align=""center""><a href=""http://www.restechsys.com""><img src=""https://avatars2.githubusercontent.com/u/5619637?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Harry Respass</b></sub></a><br /><a href=""https://github.com/CodeForBaltimore/Healthcare-Rollcall/commits?author=helro154"" title=""Code"">💻</a> <a href=""https://github.com/CodeForBaltimore/Healthcare-Rollcall/pulls?q=is%3Apr+reviewed-by%3Ahelro154"" title=""Reviewed Pull Requests"">👀</a></td>
    <td align=""center""><a href=""https://github.com/cmavelis""><img src=""https://avatars3.githubusercontent.com/u/16199008?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Cameron Avelis</b></sub></a><br /><a href=""https://github.com/CodeForBaltimore/Healthcare-Rollcall/commits?author=cmavelis"" title=""Code"">💻</a> <a href=""https://github.com/CodeForBaltimore/Healthcare-Rollcall/pulls?q=is%3Apr+reviewed-by%3Acmavelis"" title=""Reviewed Pull Requests"">👀</a></td>
    <td align=""center""><a href=""https://github.com/joffutt4""><img src=""https://avatars0.githubusercontent.com/u/10181869?v=4"" width=""100px;"" alt=""""/><br /><sub><b>joffutt4</b></sub></a><br /><a href=""https://github.com/CodeForBaltimore/Healthcare-Rollcall/commits?author=joffutt4"" title=""Code"">💻</a> <a href=""https://github.com/CodeForBaltimore/Healthcare-Rollcall/pulls?q=is%3Apr+reviewed-by%3Ajoffutt4"" title=""Reviewed Pull Requests"">👀</a></td>
    <td align=""center""><a href=""https://github.com/MGardner02""><img src=""https://avatars0.githubusercontent.com/u/35646560?v=4"" width=""100px;"" alt=""""/><br /><sub><b>MGardner02</b></sub></a><br /><a href=""https://github.com/CodeForBaltimore/Healthcare-Rollcall/commits?author=MGardner02"" title=""Code"">💻</a> <a href=""https://github.com/CodeForBaltimore/Healthcare-Rollcall/pulls?q=is%3Apr+reviewed-by%3AMGardner02"" title=""Reviewed Pull Requests"">👀</a></td>
    <td align=""center""><a href=""https://markadk.in/s""><img src=""https://avatars0.githubusercontent.com/u/6365836?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Mark Adkins</b></sub></a><br /><a href=""https://github.com/CodeForBaltimore/Healthcare-Rollcall/commits?author=funkybunch"" title=""Code"">💻</a> <a href=""https://github.com/CodeForBaltimore/Healthcare-Rollcall/commits?author=funkybunch"" title=""Documentation"">📖</a> <a href=""#design-funkybunch"" title=""Design"">🎨</a></td>
  </tr>
  <tr>
    <td align=""center""><a href=""https://github.com/charlesw2004""><img src=""https://avatars0.githubusercontent.com/u/30778546?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Wilner Charles</b></sub></a><br /><a href=""https://github.com/CodeForBaltimore/Healthcare-Rollcall/commits?author=charlesw2004"" title=""Code"">💻</a></td>
    <td align=""center""><a href=""http://jasonbixon.netlify.com""><img src=""https://avatars3.githubusercontent.com/u/32110237?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Jason Bixon</b></sub></a><br /><a href=""https://github.com/CodeForBaltimore/Healthcare-Rollcall/commits?author=jbixon13"" title=""Code"">💻</a> <a href=""#design-jbixon13"" title=""Design"">🎨</a> <a href=""#infra-jbixon13"" title=""Infrastructure (Hosting, Build-Tools, etc)"">🚇</a></td>
    <td align=""center""><a href=""https://snyk.io""><img src=""https://avatars2.githubusercontent.com/u/19733683?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Snyk bot</b></sub></a><br /><a href=""#security-snyk-bot"" title=""Security"">🛡️</a></td>
    <td align=""center""><a href=""https://dependabot.com""><img src=""https://avatars1.githubusercontent.com/u/27347476?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Dependabot</b></sub></a><br /><a href=""#security-dependabot[bot]"" title=""Security"">🛡️</a></td>
    <td align=""center""><a href=""http://stephanie.marketing""><img src=""https://avatars2.githubusercontent.com/u/47190328?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Stephanie</b></sub></a><br /><a href=""#content-uxstephanie"" title=""Content"">🖋</a></td>
    <td align=""center""><a href=""https://github.com/c-w-allen""><img src=""https://avatars0.githubusercontent.com/u/64177457?v=4"" width=""100px;"" alt=""""/><br /><sub><b>c-w-allen</b></sub></a><br /><a href=""https://github.com/CodeForBaltimore/Healthcare-Rollcall/commits?author=c-w-allen"" title=""Code"">💻</a></td>
    <td align=""center""><a href=""https://github.com/blakenan-bellese""><img src=""https://avatars1.githubusercontent.com/u/61432973?v=4"" width=""100px;"" alt=""""/><br /><sub><b>blakenan-bellese</b></sub></a><br /><a href=""https://github.com/CodeForBaltimore/Healthcare-Rollcall/commits?author=blakenan-bellese"" title=""Documentation"">📖</a></td>
  </tr>
  <tr>
    <td align=""center""><a href=""http://ianjadams.com""><img src=""https://avatars1.githubusercontent.com/u/7966226?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Ian Adams</b></sub></a><br /><a href=""https://github.com/CodeForBaltimore/Healthcare-Rollcall/commits?author=ijadams"" title=""Code"">💻</a></td>
    <td align=""center""><a href=""https://www.joshglazer.com""><img src=""https://avatars1.githubusercontent.com/u/5789311?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Josh Glazer</b></sub></a><br /><a href=""https://github.com/CodeForBaltimore/Healthcare-Rollcall/commits?author=joshglazer"" title=""Code"">💻</a></td>
  </tr>
</table>

<!-- markdownlint-enable -->
<!-- prettier-ignore-end -->

<!-- ALL-CONTRIBUTORS-LIST:END -->

This project follows the [all-contributors](https://github.com/all-contributors/all-contributors) specification. Contributions of any kind welcome!
"
16,sample2025nit/HealthCareEx,HTML,"[{""name"":"".gitignore"",""path"":"".gitignore"",""sha"":""e43b0f988953ae3a84b00331d0ccf5f7d51cb3cf"",""size"":10,""url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/.gitignore?ref=master"",""html_url"":""https://github.com/wanghaisheng/healthcaredatastandard/blob/master/.gitignore"",""git_url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/e43b0f988953ae3a84b00331d0ccf5f7d51cb3cf"",""download_url"":""https://raw.githubusercontent.com/wanghaisheng/healthcaredatastandard/master/.gitignore"",""type"":""file"",""_links"":{""self"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/.gitignore?ref=master"",""git"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/e43b0f988953ae3a84b00331d0ccf5f7d51cb3cf"",""html"":""https://github.com/wanghaisheng/healthcaredatastandard/blob/master/.gitignore""}},{""name"":""README.md"",""path"":""README.md"",""sha"":""fc6bd9a7b0a339af5ee38d7481d24302a18d395c"",""size"":29010,""url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/README.md?ref=master"",""html_url"":""https://github.com/wanghaisheng/healthcaredatastandard/blob/master/README.md"",""git_url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/fc6bd9a7b0a339af5ee38d7481d24302a18d395c"",""download_url"":""https://raw.githubusercontent.com/wanghaisheng/healthcaredatastandard/master/README.md"",""type"":""file"",""_links"":{""self"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/README.md?ref=master"",""git"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/fc6bd9a7b0a339af5ee38d7481d24302a18d395c"",""html"":""https://github.com/wanghaisheng/healthcaredatastandard/blob/master/README.md""}},{""name"":""overview.png"",""path"":""overview.png"",""sha"":""5e49110c0ac25125bf0f277548f85389bd9178da"",""size"":559586,""url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/overview.png?ref=master"",""html_url"":""https://github.com/wanghaisheng/healthcaredatastandard/blob/master/overview.png"",""git_url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/5e49110c0ac25125bf0f277548f85389bd9178da"",""download_url"":""https://raw.githubusercontent.com/wanghaisheng/healthcaredatastandard/master/overview.png"",""type"":""file"",""_links"":{""self"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/overview.png?ref=master"",""git"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/5e49110c0ac25125bf0f277548f85389bd9178da"",""html"":""https://github.com/wanghaisheng/healthcaredatastandard/blob/master/overview.png""}},{""name"":""standard number -201506.png"",""path"":""standard number -201506.png"",""sha"":""10d20f19dadd0de6c6740685c16ad3d98bceb4eb"",""size"":552959,""url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/standard%20number%20-201506.png?ref=master"",""html_url"":""https://github.com/wanghaisheng/healthcaredatastandard/blob/master/standard%20number%20-201506.png"",""git_url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/10d20f19dadd0de6c6740685c16ad3d98bceb4eb"",""download_url"":""https://raw.githubusercontent.com/wanghaisheng/healthcaredatastandard/master/standard%20number%20-201506.png"",""type"":""file"",""_links"":{""self"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/standard%20number%20-201506.png?ref=master"",""git"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/10d20f19dadd0de6c6740685c16ad3d98bceb4eb"",""html"":""https://github.com/wanghaisheng/healthcaredatastandard/blob/master/standard%20number%20-201506.png""}},{""name"":""基础类标准"",""path"":""基础类标准"",""sha"":""945a3b3a1831fbad09264b9dea530af3f0fb737a"",""size"":0,""url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E5%9F%BA%E7%A1%80%E7%B1%BB%E6%A0%87%E5%87%86?ref=master"",""html_url"":""https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E5%9F%BA%E7%A1%80%E7%B1%BB%E6%A0%87%E5%87%86"",""git_url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/945a3b3a1831fbad09264b9dea530af3f0fb737a"",""download_url"":null,""type"":""dir"",""_links"":{""self"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E5%9F%BA%E7%A1%80%E7%B1%BB%E6%A0%87%E5%87%86?ref=master"",""git"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/945a3b3a1831fbad09264b9dea530af3f0fb737a"",""html"":""https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E5%9F%BA%E7%A1%80%E7%B1%BB%E6%A0%87%E5%87%86""}},{""name"":""已整理材料"",""path"":""已整理材料"",""sha"":""e9f14bd3afda272e5e3f310b779e115d0c125d29"",""size"":0,""url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E5%B7%B2%E6%95%B4%E7%90%86%E6%9D%90%E6%96%99?ref=master"",""html_url"":""https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E5%B7%B2%E6%95%B4%E7%90%86%E6%9D%90%E6%96%99"",""git_url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/e9f14bd3afda272e5e3f310b779e115d0c125d29"",""download_url"":null,""type"":""dir"",""_links"":{""self"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E5%B7%B2%E6%95%B4%E7%90%86%E6%9D%90%E6%96%99?ref=master"",""git"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/e9f14bd3afda272e5e3f310b779e115d0c125d29"",""html"":""https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E5%B7%B2%E6%95%B4%E7%90%86%E6%9D%90%E6%96%99""}},{""name"":""技术类标准"",""path"":""技术类标准"",""sha"":""de30b9a40cd054b6d7fb7fcebbe6f7e01b5e5770"",""size"":0,""url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E6%8A%80%E6%9C%AF%E7%B1%BB%E6%A0%87%E5%87%86?ref=master"",""html_url"":""https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E6%8A%80%E6%9C%AF%E7%B1%BB%E6%A0%87%E5%87%86"",""git_url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/de30b9a40cd054b6d7fb7fcebbe6f7e01b5e5770"",""download_url"":null,""type"":""dir"",""_links"":{""self"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E6%8A%80%E6%9C%AF%E7%B1%BB%E6%A0%87%E5%87%86?ref=master"",""git"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/de30b9a40cd054b6d7fb7fcebbe6f7e01b5e5770"",""html"":""https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E6%8A%80%E6%9C%AF%E7%B1%BB%E6%A0%87%E5%87%86""}},{""name"":""数据类标准"",""path"":""数据类标准"",""sha"":""b07085f5d932d491dc4776309fc799305e1b4838"",""size"":0,""url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E6%95%B0%E6%8D%AE%E7%B1%BB%E6%A0%87%E5%87%86?ref=master"",""html_url"":""https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E6%95%B0%E6%8D%AE%E7%B1%BB%E6%A0%87%E5%87%86"",""git_url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/b07085f5d932d491dc4776309fc799305e1b4838"",""download_url"":null,""type"":""dir"",""_links"":{""self"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E6%95%B0%E6%8D%AE%E7%B1%BB%E6%A0%87%E5%87%86?ref=master"",""git"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/b07085f5d932d491dc4776309fc799305e1b4838"",""html"":""https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E6%95%B0%E6%8D%AE%E7%B1%BB%E6%A0%87%E5%87%86""}},{""name"":""标准化测评相关规范"",""path"":""标准化测评相关规范"",""sha"":""5bf75d1217960dfa55654ed55bb07f644330a763"",""size"":0,""url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E6%A0%87%E5%87%86%E5%8C%96%E6%B5%8B%E8%AF%84%E7%9B%B8%E5%85%B3%E8%A7%84%E8%8C%83?ref=master"",""html_url"":""https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E6%A0%87%E5%87%86%E5%8C%96%E6%B5%8B%E8%AF%84%E7%9B%B8%E5%85%B3%E8%A7%84%E8%8C%83"",""git_url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/5bf75d1217960dfa55654ed55bb07f644330a763"",""download_url"":null,""type"":""dir"",""_links"":{""self"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E6%A0%87%E5%87%86%E5%8C%96%E6%B5%8B%E8%AF%84%E7%9B%B8%E5%85%B3%E8%A7%84%E8%8C%83?ref=master"",""git"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/5bf75d1217960dfa55654ed55bb07f644330a763"",""html"":""https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E6%A0%87%E5%87%86%E5%8C%96%E6%B5%8B%E8%AF%84%E7%9B%B8%E5%85%B3%E8%A7%84%E8%8C%83""}},{""name"":""管理类标准"",""path"":""管理类标准"",""sha"":""697c02441646c251192f32f1bdf86ea52042e7e4"",""size"":0,""url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E7%AE%A1%E7%90%86%E7%B1%BB%E6%A0%87%E5%87%86?ref=master"",""html_url"":""https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E7%AE%A1%E7%90%86%E7%B1%BB%E6%A0%87%E5%87%86"",""git_url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/697c02441646c251192f32f1bdf86ea52042e7e4"",""download_url"":null,""type"":""dir"",""_links"":{""self"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E7%AE%A1%E7%90%86%E7%B1%BB%E6%A0%87%E5%87%86?ref=master"",""git"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/697c02441646c251192f32f1bdf86ea52042e7e4"",""html"":""https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E7%AE%A1%E7%90%86%E7%B1%BB%E6%A0%87%E5%87%86""}}]"
17,aws-samples/aws-healthcare-lifescience-ai-ml-sample-notebooks,Jupyter Notebook,"# Healthcare and Life Sciences Amazon SageMaker and AI/ML Immersion Day Workshops

## Introduction

[AWS Healthcare Life Sciences (HCLS) Artificial Intelligence/Machine Learning (AI/ML) Immersion Days](https://catalog.workshops.aws/hcls-aiml/en-US) offer an opportunity for AWS customers and those who wish to learn about AWS AI/ML services via a deep, hands on workshop experience. Customers can use Immersion Days to:

* **Engage in hands on workshops to learn about AI/ML services.** We will work in a hands-on fashion with data scientists, machine learning engineers, developers, analysts and anyone else to familiarize the customer with our services. These workshops are hands on -- workshop participants will be provided with temporary AWS account(s) from which they will execute AI/ML workloads in a step-by-step fashion with our HCLS AI/ML Solutions Architects. Please see the Workshops section for available workshops.

* **Gain a deep understanding of AWS AI/ML Services.** We will discuss what our AI/ML services are, how they can be easily brought to bear on numerous workloads, and help enable the customer to approach their own business problems in the context of AI/ML. These conversations can be overviews of AWS services, or technical deep dives into specific components that to enable well-architected AI/ML applications for HCLS business.

* **Understand best practices with AI/ML in the context of HCLS.** We will discuss what are the best practices and procedures for using AI/ML intelligently in HCLS applications. This includes basics of training and testing, MLOps and deployment practices, software development life cycle in the context of AI/ML and many other components.

The Immersion Day workshops may be used by in the context of [AWS Instructure-Led Labs](https://sagemaker-immersionday.workshop.aws/en/prerequisites/option1.html) or [self-paced labs](https://sagemaker-immersionday.workshop.aws/en/prerequisites/option2.html). Please see [here](https://sagemaker-immersionday.workshop.aws/en/prerequisites.html) for more information.


## Related Resources

* The [AWS Healthcare Life Sciences (HCLS) Artificial Intelligence/Machine Learning (AI/ML) Immersion Days](https://catalog.workshops.aws/hcls-aiml/en-US) has overviews of a number of the workshops in this repository and instructions for running them.
* The [SageMaker Immersion Day](https://github.com/aws-samples/amazon-sagemaker-immersion-day) provides many other useful workshops.
* The [SageMaker sample code repository](https://github.com/aws/amazon-sagemaker-examples) provides more than 300 code samples for using SageMaker


## FAQ

**Do I have to be a machine learning expert to benefit from a workshop?**

Absolutely not! These workshops can benefit people at all levels, whether they are machine learning experts, developers, managers, or anyone in your organization. [Amazon SageMaker](https://aws.amazon.com/sagemaker/) and Amazon's [many other machine learning services](https://aws.amazon.com/machine-learning/) are designed to remove the heavy lifting from development to quickly enable you to integrate AI/ML into your applications.

**How can I get started?**

You can peruse this repository for notebooks that are relevant to you. 

**What workshops makes the most sense for me and my group?**

This depends on your teams familiarity with SageMaker. If the team is deeply familiar with ML and SageMaker we recommend picking workshops that best match the business problem(s) you are trying to solve. If your team is not yet deeply familiar with AWS infrastructure and SageMaker, we recommend  at least 1 more basic workshop that focuses on tabular analysis so that the team can get hands-on practice with AWS AI/ML steps (e.g. loading data into S3 for training with AI/ML, deploying models etc.)

**Who should come to the AWS Instructure-led workshops?**

Anyone is welcome to the workshop. We recommend that the customer have at least one developer present who will be actively working on business problems and can take away technical learnings that can be applied for their future work.


**How can I get started?**

Whether you are doing an [AWS Instructure-Led Labs](https://sagemaker-immersionday.workshop.aws/en/prerequisites/option1.html) or [self-paced labs](https://sagemaker-immersionday.workshop.aws/en/prerequisites/option2.html), we recommend that you begin by looking at the workshops and executing them to get an understanding of SageMaker and the AI/ML services work in the context of healthcare and life sciences.

**How do I use these workshops?**

The notebooks provided within these workshops are independent units and may be run on their own. Further instructions are provided within each specific directory. 


**What is the source of these workshops?**

Some of these workshops have been created by HCLS AI/ML team has written specific workshops that demonstrate key components of using SageMaker. We have also curated resources from the [AWS machine learning blog](https://aws.amazon.com/blogs/machine-learning/) and the Amazon SageMaker [respository](https://github.com/aws/amazon-sagemaker-examples) of sample code for these workshops.

**I am interested in workshops not listed on this repository.**

The workshops for the HCLS AI/ML listed are generally focused on applications related to Health and Life Sciences. However, there is a wealth of more general information and public facing AWS provided notebooks that use non-HCLS data [here](https://github.com/awslabs/amazon-sagemaker-examples) and [here](https://sagemaker-immersionday.workshop.aws/). 

**I think I see a mistake or something I want changed in the repository**.

Feel free to to submit a pull request detailing the issue. Please bear with us in if pull requests take longer than expected or are closed. 

**How can I arrange an AWS Instructor-Led Immersion Day?**

If you are interested in having an Immersion Day for your team, please reach out to your AWS Account Manager.

## Security

See [CONTRIBUTING](CONTRIBUTING.md#security-issue-notifications) for more information.

## License

This library is licensed under the MIT-0 License. See the LICENSE file.

"
18,PacktPublishing/Healthcare-Analytics-Made-Simple,Jupyter Notebook,"


# Healthcare Analytics Made Simple

<a href=""https://www.packtpub.com/big-data-and-business-intelligence/healthcare-analytics-made-simple?utm_source=github&utm_medium=repository&utm_campaign=9781787286702""><img src=""https://www.packtpub.com/sites/default/files/B06444.png"" alt=""Healthcare Analytics Made Simple"" height=""256px"" align=""right""></a>

This is the code repository for [Healthcare Analytics Made Simple](https://www.packtpub.com/big-data-and-business-intelligence/healthcare-analytics-made-simple?utm_source=github&utm_medium=repository&utm_campaign=9781787286702), published by Packt.

**Techniques in healthcare computing using machine learning and Python**

## What is this book about?
In recent years, machine learning technologies and analytics have been widely utilized across the healthcare sector. Healthcare Analytics Made Simple bridges the gap between practising doctors and data scientists. It equips the data scientists’ work with healthcare data and allows them to gain better insight from this data in order to improve healthcare outcomes.

This book covers the following exciting features:
* Gain valuable insight into healthcare incentives, finances, and legislation 
* Discover the connection between machine learning and healthcare processes
* Use SQL and Python to analyze data
* Measure healthcare quality and provider performance
* Identify features and attributes to build successful healthcare models 

If you feel this book is for you, get your [copy](https://www.amazon.com/dp/1787286703) today!

<a href=""https://www.packtpub.com/?utm_source=github&utm_medium=banner&utm_campaign=GitHubBanner""><img src=""https://raw.githubusercontent.com/PacktPublishing/GitHub/master/GitHub.png"" 
alt=""https://www.packtpub.com/"" border=""5"" /></a>


## Instructions and Navigations
All of the code is organized into folders. For example, Chapter02.

The code will look like the following:
```
string_1 = '1'
string_2 = '2'
string_sum = string_1 + string_2
print(string_sum)
```

**Following is what you need for this book:**
Healthcare Analytics Made Simple is for you if you are a developer who has a working knowledge of Python or a related programming language, although you are new to healthcare or predictive modeling with healthcare data. Clinicians interested in analytics and healthcare computing will also benefit from this book. This book can also serve as a textbook for students enrolled in an introductory course on machine learning for healthcare.

With the following software and hardware list you can run all code files present in the book (Chapter 1-9).

### Software and Hardware List

| Chapter  | Software required                      | OS required                          |
| -------- | ------------------------------------   | ------------------------------------ |
| 1        | Anaconda: 4.4.0                        |6GB of RAM, i5 Pentium, Windows 10 OS |
| 4        | Python: 3.6.1                          |6GB of RAM, i5 Pentium, Windows 10 OS |
| 5        | NumPy: 1.12.1                          |6GB of RAM, i5 Pentium, Windows 10 OS |
| 6        | pandas: 0.20.1                         |6GB of RAM, i5 Pentium, Windows 10 OS |
| 7        | scikit-learn: 0.18.1,matplotlib: 2.0.2 |6GB of RAM, i5 Pentium, Windows 10 OS |



We also provide a PDF file that has color images of the screenshots/diagrams used in this book. [Click here to download it](http://www.packtpub.com/sites/default/files/downloads/HealthcareAnalyticsMadeSimple_ColorImages.pdf).

### Related products 
* Learning Social Media Analytics with R [[Packt]](https://www.packtpub.com/big-data-and-business-intelligence/learning-social-media-analytics-r?utm_source=github&utm_medium=repository&utm_campaign=9781787127524) [[Amazon]](https://www.amazon.com/dp/1787127524)

* Predictive Analytics with Tensorflow [[Packt]](https://www.packtpub.com/big-data-and-business-intelligence/predictive-analytics-tensorflow?utm_source=github&utm_medium=repository&utm_campaign=9781788398923) [[Amazon]](https://www.amazon.com/dp/1788398920)

## Get to Know the Author
**Dr. Vikas (Vik) Kumar**
 grew up in the United States in Niskayuna, New York. He earned
his MD from the University of Pittsburgh, but shortly afterwards he discovered his true
calling of computers and data science. He then earned his MS in the College of Computing
at Georgia Institute of Technology and has subsequently worked as a data scientist for both
healthcare and non-healthcare companies. He currently lives in Atlanta, Georgia.




### Suggestions and Feedback
[Click here](https://docs.google.com/forms/d/e/1FAIpQLSdy7dATC6QmEL81FIUuymZ0Wy9vH1jHkvpY57OiMeKGqib_Ow/viewform) if you have any feedback or suggestions.

### Download a free PDF

 <i>If you have already purchased a print or Kindle version of this book, you can get a DRM-free PDF version at no cost.<br>Simply click on the link to claim your free PDF.</i>
<p align=""center""> <a href=""https://packt.link/free-ebook/9781787286702"">https://packt.link/free-ebook/9781787286702 </a> </p>"
19,simpledotorg/simple-android,Kotlin,"![Build Status](https://github.com/simpledotorg/simple-android/workflows/CI/badge.svg)

# Simple

An Android app for recording blood pressure measurements.

## Pre-requisites

The application currently requires JDK 17 to build. If you already have JDK 17 installed, skip this step.

**Check if the right JDK is already available**

Run the command `java -version`. If you have the right version of the JDK installed, you should see something like:

```sh
openjdk 17.0.7 2023-04-18 LTS
OpenJDK Runtime Environment Zulu17.42+19-CA (build 17.0.7+7-LTS)
OpenJDK 64-Bit Server VM Zulu17.42+19-CA (build 17.0.7+7-LTS, mixed mode, sharing)
```

If this command has an error, or shows a different version, you can follow the instructions below to install the JDK.

**Install the JDK**

We recommend using [jEnv](https://www.jenv.be/) to manage your JDK installations. Here are instructions to setup a working JDK 17 installation (macOS
only):

1. Setup up [Homebrew](https://brew.sh/).

2. Install `jEnv` using Homebrew.

```sh
brew install jenv
```

3. Add the following lines to your shell configuration file (`~/.bash_profile` if you're using bash, or `~/.zshrc` if you're using zsh).

```sh
export PATH=""$HOME/.jenv/bin:$PATH""
eval ""$(jenv init -)""
```

4. Once this is done, you'll need to restart the terminal or reload the configuration file in order for the `jenv` command to be recognised.

```sh
source <path to shell configuration file>
```

5. Install the JDK using Homebrew.

```sh
brew tap mdogan/zulu
brew install zulu-jdk17
```

6. Add the installed JDK to `jEnv`

```sh
jenv add /Library/Java/JavaVirtualMachines/zulu-17.jdk/Contents/Home/
```

7. Run the command `jenv versions`. You should see something like:

```sh
  system
* 17.0
  17.0.7
  zulu64-17.0.7
```

## How to build

**Clone the project using git.**

Run the following command in a terminal.

 ```
 $ git clone git@github.com:simpledotorg/simple-android.git
 ```

**Install Android Studio**

Download and install Android Studio from [their website](https://developer.android.com/studio/).

**Import the project into Android Studio.**

When Android Studio starts up, it will prompt you to create a new project or import an existing project. Select the option to import an existing
project, navigate to the `simple-android` directory you cloned earlier, and select it.

When building for the first time, gradle will download all dependencies so it'll take a few minutes to complete. Subsequent builds will be faster.

If during the build process you see the message:
""Warning: License for package Android SDK Build-Tools 30.0.2 not accepted.""
Then you may need to install the Google Play Licensing Library:

* Open the SDK Manager through Tools -> SDK Manager
* Select Appearance & Behavior -> System Settings -> Android SDK in the left sidebar
* Select the SDK Tools tab in the main window
* Activate Google Play Licensing Library and click Apply

## Running locally

The Simple App can be run locally on an Android emulator using Android Studio. To do this,

**Install the NDK library**

The NDK library is currently required by the project to enable an SQLite extension. To install it:

* Open the SDK Manager through Tools -> SDK Manager
* Select Appearance & Behavior -> System Settings -> Android SDK in the left sidebar
* Select the SDK Tools tab in the main window
* Activate NDK (Side by Side) and click Apply

NDK will now be installed.

**Create a Run/Debug configuration**

* Open the Run/Debug configurations window through Run -> Edit Configurations ([ref](https://developer.android.com/studio/run/rundebugconfig))
* Create a new configuration using the `Android App` template
* Set the module to `app`, and finish creating the configuration

**Create a virtual device**

* Create an Android Virtual Device (AVD) using the AVD Manager, usually found in Tools -> AVD
  Manager. ([ref](https://developer.android.com/studio/run/managing-avds))
* Select a device and operating system
* Note: You will have to download one of the available OS options the first time you create an AVD

**Set the right build variant**

* Open the Build Variants window through View -> Tool Windows -> Build Variants, or clicking the item in the lower left corner of the main window
* Set the Build Variant of the app module to `qaDebug`

**Run the app**

* Click ""Run"", either through Run -> Run, or the green play button in the top toolbar.

## Code styles

The code styles which the project uses have been exported as an IntelliJ code style XML file and are saved as
`quality/code-style.xml`. To import them into Android Studio,

1. Open the Android Studio preferences page, and navigate to Editor -> Code Style.
1. Click on the gear/settings button next to the ""Scheme"" label.
1. In the drop-down menu, select ""Import scheme"".
1. In the file picker, navigate to  `<project>/quality/code-style.xml`.
1. Import the `Simple` scheme into the IDE and set it as the project code style.

## Tooling

An Android Studio plugin that provides some quality of life improvements like live templates can be
found [HERE](https://github.com/simpledotorg/simple-android-idea-plugin).

## Building an APK with a different build variant

There are currently 2 ways to build an app pointing to different environments:

1. Changing the `qa` API URL in `gradle.properties` file to point to the environment you want. These builds will be debuggable and require us to clone
   the project and build it using [Android Studio](https://developer.android.com/studio). [*
   Warning*: These changes should not be commited back to `master` branch]
2. Use Bitrise workflows to build APKs of different build variants. These builds will not be debuggable, unless for `build-debuggable-sandbox-apk`.

## Build and deploy Simple Server

Simple Server is in a separate repository, and you should follow
the [instructions there](https://github.com/simpledotorg/simple-server/blob/master/README.md).

## Execute SQL Queries

You can use [Flipper](https://fbflipper.com/) to run SQL queries on Simple:

1. Install Flipper using brew or download from their [website](https://fbflipper.com/).

```sh 
brew install Flipper
```

2. Launch Flipper (you might have to allow Flipper to launch from System Preferences > Security > General as it’s from an unknown developer to Apple).
3. Run the Simple app in an emulator or your physical device(as Flipper loads the data from your device's local database).
4. In the Plugins section in the sidebar menu click on Disabled and enable the Database plugin.
5. Click on Databases, select `red-db` and choose whichever table’s data you want to inspect.
6. Click on SQL at the top to execute SQL queries.

## Resources

Check out the following documents for more information.

* [Quirks That You Should Probably Be Aware Of](doc/QUIRKS.md)
* [More Documentation](doc)
* [Recipes](doc/recipes.md)
* [Integration Test Heroku Setup](doc/integration-test-suite-setup.md)
"
20,katalon-studio-samples/healthcare-tests,Groovy,"# healthcare-tests

Navigate to https://docs.katalon.com/katalon-studio/docs/health-care-prj.html for further details.

## Companion products

### Katalon TestOps

[Katalon TestOps](https://analytics.katalon.com) is a web-based application that provides dynamic perspectives and an insightful look at your automation testing data. You can leverage your automation testing data by transforming and visualizing your data; analyzing test results; seamlessly integrating with such tools as Katalon Studio and Jira; maximizing the testing capacity with remote execution.

* Read our [documentation](https://docs.katalon.com/katalon-analytics/docs/overview.html).
* Ask a question on [Forum](https://forum.katalon.com/categories/katalon-analytics).
* Request a new feature on [GitHub](CONTRIBUTING.md).
* Vote for [Popular Feature Requests](https://github.com/katalon-analytics/katalon-analytics/issues?q=is%3Aopen+is%3Aissue+label%3Afeature-request+sort%3Areactions-%2B1-desc).
* File a bug in [GitHub Issues](https://github.com/katalon-analytics/katalon-analytics/issues).

### Katalon Studio
[Katalon Studio](https://www.katalon.com) is a free and complete automation testing solution for Web, Mobile, and API testing with modern methodologies (Data-Driven Testing, TDD/BDD, Page Object Model, etc.) as well as advanced integration (JIRA, qTest, Slack, CI, Katalon TestOps, etc.). Learn more about [Katalon Studio features](https://www.katalon.com/features/).
"
21,pras75299/Healthcare-Website,HTML,"# Healthcare-Website
- Informational Website related to Healthcare, Details and Services provided by different hospitals, Details about them and Inquiry form for foreigners who want to use the facility in India.

## Table of contents
- [About Healthcare](#about-healthcare)
- [Responsibility](#responsibility)
- [Screenshots](#screenshots)
- [Dependencies](#dependencies)


#### About Healthcare
- Informational Website related to Healthcare, Details and Services provided by different hospitals, Details about them and Inquiry form for foreigners who want to use the facility in India.

##### Responsibility
- Template Design
- Bug Fixing
- Responsive Design Check
- Cross Browser Compatibility Checking
- UI Design
- Front End Development
- Photoshop Designs
- Logo Design


###### Screenshots

- **Home Page Image** 
<img src=""https://github.com/pras75299/Healthcare-Website/blob/master/images/home-healthcare.png?raw=true"" width=""50%"" height=""50%""/>


###### Dependencies
- Basically it’s the website for  Information about all major hospital in Delhi/NCR, and anyone can read the information, and see what services provided by each hospital and By submitting an enquiry for availability in hospital.


- [Jquery](https://code.jquery.com/jquery-3.2.1.min.js) <br/>
- [Bootstrap 3.3](https://getbootstrap.com/docs/3.3/) <br/>
- [Mean Menu For Mobile Devices](https://github.com/meanthemes/meanMenu) <br/>
- HTML5 <br/>
- CSS3 <br/>
- Smooth Scroll <br/> 
- Parallax <br/>
- Animation <br/>
"
22,rajagopal28/healthcare-server,Ruby,"# healthcare-server
A rubyOnRails based web application with a small concept behind healthcare full proposal here [Proposal](https://github.com/rajagopal28/healthcare-server/blob/master/proposal.md)
The related mobile repository can be viewed ==> [Mobile](https://github.com/rajagopal28/Jackie)
## Problem at hand
Our major objective is to create an environment that helps us be independent and be healthy. Being independent makes us feel empowered all the time. People tend to forget things more often. But when it comes to health we got to be vigilant. Diabetic people need constant attention and care when it comes to health checks and medications. Level-2 Diabetes often required periodic insulin intake to keep glucose level balanced. They should also maintain a timely and proper diet that goes hand in hand with their medication schedules. We live in a busy world where we cannot be around all the time. With that being said we can deep dive into our proposed solution.

## The proposed solution
The proposed solution is to have a multi-platform environment that helps you take care of yourself. We intend to build a personal assistant based ecosystem that helps you keep track of your health by monitoring your body vitals viz., glucose, pressure, pulse and temperature, perform tasks like book appointments, view or remind you about your booked appointments, keep track of you medicine prescriptions, intake and personal medicine inventory management in a more nurturing and enjoyable way.


## Proposed architecture
![Architecture](./images/image00.png)
This entire application has 3 essential components
- The centralized healthcare server which holds patient data such as vital information, medicine intake logs, appointments, prescriptions etc.
- The mobile app + wearable component - with this combo we can collect user information such as vitals, medicine intake activities, reminders on appointments and medicine intakes etc.
- The Alexa skill - which is essentially coupled with the data back-end to personally serve people in managing their vitals, appointments and medicine intake.


## Backend Schema
![Schema](./images/image02.png)


## Major User cases
Centralized web applications with ability too
- view & create doctor appointments
- view & create vitals
- monitor and visualize vitals
- view & create medicines
- view & create prescriptions and medicines
- view & create doctor appointments, schedules and reschedules
- view & create notifications for doctors
- monitor and visualize medicine availability

## Technical Nuances
As we wanted to have to quick backend setup so that we can have some time available to spent on the new technologies that are involved in the component(viz., react native, android, alexa and Aurdino devlopment) we chose Ruby On Rails and it was totally worth it.
* **Ruby on Rails** is one of the beautiful script based web frameworks, it did all the data management work setup for us with it's scaffolding generation, what a beauty. Just defining the attributes in `` rails generate scaffolding `` command generates everything to manage that particular model, it even gives rest end points in an instant. We were totally carried away by it capability to create a robust and flexible back-end in a short span.
* **Postgres** is one of the most advanced open source database management system that is as is. We chose rails as we structured the data in a most relational way. Postgres supported quick setup and easy to manage data and their relationship. Of course, rails and it's migrations have a great part as the out of the box postgres support elevated everything to a different level.
* **Pure CSS** is the best light weight css framework that helped us create a pretty decent looking UI views. Their approach was so simplistic that they provide on demand inclusions of styles that can be included only when needed say forms, grids and layouts , such that the site does not become heavy with elements that will not be used.
* **Chartkick + highcharts** made us drop our jaws because it is the first ever server side chart rendering framework. It was really smooth as if we are using server side tag libraries to loop through list of data. Credits to rails of cource, gems for everything that we need, really helped us save time. We used some server side capabilities to conditionally choose charts and render data in a synchronous way, really first time we have used a chart library that did not use ajax and rest call.
* **Heroku** was our first choice as it is well known for its intensive support for rails applications. Its of the box support to postgres as an out of the box add-on made us feel re-assured with our choice on postgres as our database.
* **GCM server side support** was required as part of the mobile application concept. With an additional inclusion of server side capabilities in capabilities to call external APIs such as RestClient gem helped us big time to integrate this feature in a seamless way.


## Major User Flows:
### Home:
This is the simplistic Home UI in PureCSS with nav and everything. I know it looks kind of childish with the images we have chosen but our features are realtime and helpful.
![Home](./images/image000.png)
### Users:
![Users](./images/image001.png)
### Doctors:
![Doctors](./images/image002.png)
### Doctor Appointments:
![Doctor Appointments](./images/image003.png)
### Doctors Notifications:
![Doctors Notifications](./images/image004.png)
##New doctor appointments
![Doctor appointments](./images/image009.png)
### Medicines:
![Medicines](./images/image006.png)
### Prescribed Medicines:
Prescribed Medicines for user
![Prescribed Medicines](./images/image010.png)
Prescribed medicines edit view
![Prescribed Medicines](./images/image017.png)
### In Patients:
![In Patients](./images/image005.png)
### Medicine intake logs:
![User Vital logs](./images/image013.png)
Medicine intake logs deletion view
![Medicine intake logs](./images/image018.png)
![Medicine intake logs](./images/image019.png)
### Prescriptions:
![Prescriptions](./images/image007.png)
### User Vital logs:
![User Vital logs](./images/image011.png)
User Vital logs with user wise grouping
![User Vital logs](./images/image012.png)
### User vitals summary:
![User vitals summary](./images/image016.png)



## Key Learnings
- How to create and publish an alexa skill by leveraging the voice activated technlogies in a smooth and effective way.
- React native is adaptive, flexible enough to let both native as well as hybrid code and features by binding them together with their coherant data flows and models.
- Ruby on rails is the quickest script based web application framework that can be developer friendly as well as feature friendly with their ability to scale and balance.

## References
- http://guides.rubyonrails.org/association_basics.html
- https://stackoverflow.com/questions/36946498/for-loop-with-select-helper
- https://www.tutorialspoint.com/ruby-on-rails/rails-scaffolding.htm
- https://www.digitalocean.com/community/tutorials/how-to-use-postgresql-with-your-ruby-on-rails-application-on-ubuntu-14-04
- http://mentalized.net/journal/2017/04/22/run-rails-migrations-on-heroku-deploy/
- https://www.chartkick.com/
- http://guides.rubyonrails.org/active_record_querying.html
- https://www.theodinproject.com/courses/ruby-on-rails/lessons/sessions-cookies-and-authentication
- version/arguments mismatch issue: https://stackoverflow.com/a/69274921
- Issue `uninitialized class variable @@schemes in URI` : https://stackoverflow.com/a/73583358
- Release issue with db-migrate: https://stackoverflow.com/a/71192990
"
23,blencorp/HealthCare.gov-Open-Source-Release,JavaScript,"HealthCare.gov-Open-Source-Release
==================================
This project includes the source code and content for the healthcare.gov website. For more information, please visit https://www.healthcare.gov/developers


==============================================
Local Installation Requirements
==============================================

Installing the code in this repository should be fairly straight-forward, but there are a few requirements you’ll need to make sure your system has before you start:

- RedHat Enterprise Linux (RHEL) 6.1 or similar
- Ruby on Rails
- RubyGems
- Jekyll


==============================================
Linux Environment
==============================================

Healthcare.Gov is currently hosted on a RedHat Enterprise Linux (RHEL) environment. Current version is RHEL 6.1 It is advised that local environments try to match this as closely as possible. If RHEL is not available, CentOS linux distribution may be used. 

Once you have setup your local environment, run 'yum update' to ensure that the system has all of the latest updates and is current. 


==============================================
Ruby on Rails
==============================================

Ruby and Rails will need to be installed after configuration of your local/development environment. Follow the steps below to install Ruby on Rails:

Install the Ruby Package:

 - yum install ruby
 - yum install ruby-devel ruby-irb ruby-rdoc ruby-ri
 - mkdir ~/src
 - cd ~/src

 
==============================================
Install rubygems: 
==============================================

 - wget http://production.cf.rubygems.org/rubygems/rubygems-1.8.24.tgz
 - Copy the tar file to  the /opt directory
 - Run the following command to untar the file: tar xzvf rubygems-1.8.24.tgz

Remove the rubygem tar file and install RubyGems:

 - rm rubygems-1.8.24.tgz –f
 - cd rubygems-1.8.24 and issue the following command to install ruby gems
 - ruby setup.rb

Issue the following command to update the gems:

 - gem update
 - gem update --system

Install gcc compiler: 

 - yum install gcc gcc-c++ make –y
 - gem install rails –V
 
Issue the following command to install rails:
 
 - gem install rails

Check the version of rails:
 - rails --version

To check the list of gems installed issue the following command:
- gem list

Install sqlite

 - yum install sqlite-devel
 
Install bundle:

 - bundle install
 - gem install therubyracer
 - vi Gemfile and uncomment ""gem therubyracer""

Start the rails server

 - rails server
 - Browse to http://localhost:3000 to view the site

 
============================================== 
Install Jekyll
==============================================

Runtime Dependencies

The following Ruby gems are required in order to run Jekyll. These can be installed via the 'gem install <gem name>' command.

 - Classifier: Generating related posts (Ruby)
 - Directory Watcher: Auto-regeneration of sites (Ruby)
 - Kramdown: Markdown-superset converter (Ruby)
 - Liquid: Templating system (Ruby)
 - Maruku: Default markdown engine (Ruby)

Developer Dependencies

The following Ruby gems should also be installed to develop for Jekyll. These can be installed via the 'gem install <gem name>' command.

 - RDiscount: Discount Markdown Processor (Ruby)
 - RedCloth: Textile support (Ruby)
 - RedGreen: Nicer test output (Ruby)
 - RR: Mocking (Ruby)
 - Shoulda: Test framework (Ruby)


Install Jekyll by issuing the following command:

 - gem install Jekyll

Change directory to the following:
 
 - cd /var/www/html

Create a directory to store the project files
 - mkdir /healthcare.gov
 - cd /healthcare.gov

After downloading and unzipping the project files, start the Jekyll Server:

 - jekyll serve
 - Browse to http://localhost:4000 to view the site
 
 
 




 
 
 



"
24,Jianing-Qiu/Awesome-Healthcare-Foundation-Models,,"# Awesome-Healthcare-Foundation-Models 

[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

Curated list of awesome large AI models (LAMs), or foundation models, in healthcare. We organize the current LAMs into four categories: large language models (LLMs), large vision models (LVMs), large audio models (LAudiMs), and large multi-modal models (LMMs). The areas that these LAMs are applied to include but not limited to bioinformatics, medical diagnosis and decision making, medical imaging and vision, medical informatics, medical education, public health, and medical robotics.

We welcome contributions to this repository to add more resources. Please submit a pull request if you want to contribute!

## News

We are excited to annouce a *IEEE J-BHI* special issue on **Biomedical and Health Foundation Models**. Please refer to the [call-for-papers](https://www.embs.org/jbhi/wp-content/uploads/sites/18/2023/06/JBHI_Foundation_Models_Call-for-Papers.pdf) for more details. 

Topics of interest include but not limited to:
1) Basic research on new theories, principles, and structures of biomedical and health foundation models
2) Basic research on the interpretability and explainability of biomedical and health foundation models
3) Prompt engineering in biomedical and health foundation models
4) Data engineering in biomedical and health foundation models
5) Large-scale biomedical and health dataset
6) Multi-modal learning and alignment for biomedical and health foundation models
7) Efficient computing for biomedical and health foundation models
8) Adversarial robustness of biomedical and health foundation models
9) Applications of foundation models in biomedical and health informatics
10) New evaluation paradigms for biomedical and health foundation models
11) New computer systems for biomedical and health foundation models
12) Decentralised methods for developing and deploying biomedical and health foundation models
13) Foundation model ethics, safety, privacy, and regulations in biomedicine and healthcare

Please help spread the word and contribute if you are interested or already working on these topics!


## Table of Contents
* [Survey](#survey)
* [Large Language Models](#large-language-models)
* [Large Vision Models](#large-vision-models)
* [Large Audio Models](#large-audio-models)
* [Large Multi-modal models](#large-multi-modal-models)
* [Applications of Large AI Models in Healthcare](#applications-of-large-ai-models-in-healthcare)


## Survey

This repository is largely based on the following paper:

**[Large AI Models in Health Informatics:
Applications, Challenges, and the Future](https://arxiv.org/pdf/2303.11568v1.pdf)**
<br /> 
Jianing Qiu,
Lin Li, 
Jiankai Sun,
Jiachuan Peng,
Peilun Shi,
Ruiyang Zhang,
Yinzhao Dong,
Kyle Lam,
Frank P.-W. Lo,
Bo Xiao,
Wu Yuan,
Dong Xu, and
Benny Lo
<br />


If you find this repository helpful, please consider citing:

```bibtex
@article{qiu2023large,
  title={Large AI Models in Health Informatics: Applications, Challenges, and the Future},
  author={Qiu, Jianing and Li, Lin and Sun, Jiankai and Peng, Jiachuan and Shi, Peilun and Zhang, Ruiyang and Dong, Yinzhao and Lam, Kyle and Lo, Frank P-W and Xiao, Bo and others},
  journal={arXiv preprint arXiv:2303.11568},
  year={2023}
}
```






## Large Language Models

### Healthcare Domain

* KeBioLM: Improving Biomedical Pretrained Language Models with Knowledge [[Paper]](https://arxiv.org/abs/2104.10344)
* BioELMo: Probing Biomedical Embeddings from Language Models [[Paper]](https://arxiv.org/abs/1904.02181)
* BioBART: Pretraining and Evaluation of A Biomedical Generative Language Model [[Paper]](https://aclanthology.org/2022.bionlp-1.9.pdf)
* ClinicalT5: A Generative Language Model for Clinical Text [[Paper]](https://aclanthology.org/2022.findings-emnlp.398.pdf)
* GatorTron: A Large Clinical Language Model to Unlock Patient Information from Unstructured Electronic Health Records [[Paper]](https://arxiv.org/pdf/2203.03540v2.pdf)
* ChatCAD: Interactive Computer-Aided Diagnosis on Medical Image using Large Language Models [[Paper]](https://arxiv.org/pdf/2302.07257.pdf)
* DeID-GPT: Zero-shot Medical Text De-Identification by GPT-4 [[Paper]](https://arxiv.org/pdf/2303.11032.pdf)
* Capabilities of GPT-4 on Medical Challenge Problems [[Paper]](https://arxiv.org/pdf/2303.13375.pdf)
* BioBERT: a pre-trained biomedical language representation model for biomedical text mining [[Paper]](https://arxiv.org/pdf/1901.08746.pdf)
* Publicly Available Clinical BERT Embeddings [[Paper]](https://arxiv.org/pdf/1904.03323.pdf)
* BioMegatron: Larger Biomedical Domain Language Model [[Paper]](https://arxiv.org/pdf/2010.06060.pdf)
* Don’t Stop Pretraining: Adapt Language Models to Domains and Tasks [[Paper]](https://aclanthology.org/2020.acl-main.740.pdf)
* Med-BERT: pretrained contextualized embeddings on large-scale structured electronic health records for disease prediction [[Paper]](https://www.nature.com/articles/s41746-021-00455-y)
* BioELECTRA:Pretrained Biomedical text Encoder using Discriminators [[Paper]](https://aclanthology.org/2021.bionlp-1.16.pdf)
* LinkBERT: Pretraining Language Models with Document Links [[Paper]](https://arxiv.org/pdf/2203.15827.pdf)
* BioGPT: Generative Pre-trained Transformer for Biomedical Text Generation and Mining [[Paper]](https://arxiv.org/pdf/2210.10341.pdf)
* Large Language Models Encode Clinical Knowledge [[Paper]](https://arxiv.org/pdf/2212.13138.pdf)
* A large language model for electronic health records [[Paper]](https://www.nature.com/articles/s41746-022-00742-2)
* Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing [[Paper]](https://arxiv.org/pdf/2007.15779.pdf)
* BEHRT: Transformer for Electronic Health Records [[Paper]](https://www.nature.com/articles/s41598-020-62922-y)
* Federated Learning of Medical Concepts Embedding using BEHRT [[Paper]](https://arxiv.org/abs/2305.13052) [[Code]](https://github.com/nadavlab/FederatedBEHRT)
* RadBERT: Adapting Transformer-based Language Models to Radiology [[paper]](https://pubs.rsna.org/doi/epdf/10.1148/ryai.210258) [[HuggingFace]](https://huggingface.co/UCSD-VA-health/RadBERT-RoBERTa-4m)
* Highly accurate protein structure prediction with AlphaFold [[Paper]](https://www.nature.com/articles/s41586-021-03819-2) [[Code]](https://github.com/deepmind/alphafold)
* Accurate prediction of protein structures and interactions using a three-track neural network [[Paper]](https://www.science.org/doi/full/10.1126/science.abj8754?casa_token=tleEHPOOSr8AAAAA%3AT0eToIMPW0oN1jjIGLs8aPyQK8qbcFIByjT1x4k90tvBAj03SZUzpEinCPe_t-g4ECmjJ9wlj8OwQBs)
* Protein complex prediction with AlphaFold-Multimer [[Paper]](https://www.biorxiv.org/content/10.1101/2021.10.04.463034v2.abstract)
* FastFold: Reducing AlphaFold Training Time from 11 Days to 67 Hours [[Paper]](https://arxiv.org/abs/2203.00854) [[Code]](https://github.com/hpcaitech/fastfold)
* HelixFold: An Efficient Implementation of AlphaFold2 using PaddlePaddle [[Paper]](https://arxiv.org/abs/2207.05477) [[Code]](https://github.com/PaddlePaddle/PaddleHelix)
* Uni-Fold: An Open-Source Platform for Developing Protein Folding Models beyond AlphaFold [[Paper]](https://www.biorxiv.org/content/10.1101/2022.08.04.502811v3.abstract) [[Code]](https://github.com/dptech-corp/Uni-Fold)
* OpenFold: Retraining AlphaFold2 yields new insights into its learning mechanisms and capacity for generalization [[Paper]](https://www.biorxiv.org/content/10.1101/2022.11.20.517210v2.abstract) [[Code]](https://github.com/aqlaboratory/openfold)
* ManyFold: an efficient and flexible library for training and validating protein folding models [[Paper]](https://academic.oup.com/bioinformatics/article/39/1/btac773/6887136) [[Code]](https://github.com/instadeepai/manyfold)
* ColabFold: making protein folding accessible to all [[Paper]](https://www.nature.com/articles/s41592-022-01488-1) [[Code]](https://github.com/sokrypton/ColabFold)
* Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences [[Paper]](https://www.pnas.org/doi/abs/10.1073/pnas.2016239118) [[Code]](https://github.com/facebookresearch/esm)
* ProGen: Language Modeling for Protein Generation [[Paper]](https://arxiv.org/abs/2004.03497) [[Code]](https://github.com/lucidrains/progen)
* ProtTrans: Towards Cracking the Language of Life's Code Through Self-Supervised Deep Learning and High Performance Computing [[Paper]](https://arxiv.org/abs/2007.06225) [[Code]](https://github.com/agemagician/ProtTrans)
* Evolutionary-scale prediction of atomic level protein structure with a language model [[Paper]](https://www.science.org/doi/full/10.1126/science.ade2574) 
* High-resolution de novo structure prediction from primary sequence [[Paper]](https://www.biorxiv.org/content/10.1101/2022.07.21.500999v1.abstract) [[Code]](https://github.com/HeliXonProtein/OmegaFold)
* Single-sequence protein structure prediction using a language model and deep learning [[Paper]](https://www.nature.com/articles/s41587-022-01432-w)
* Improved the Protein Complex Prediction with Protein Language Models [[Paper]](https://www.biorxiv.org/content/10.1101/2022.09.15.508065v2.abstract)
* MSA Transformer [[Paper]](http://proceedings.mlr.press/v139/rao21a.html) [[Code]](https://github.com/The-AI-Summer/self-attention-cv)
* Deciphering antibody affinity maturation with language models and weakly supervised learning [[Paper]](https://arxiv.org/abs/2112.07782)
* xTrimoABFold: De novo Antibody Structure Prediction without MSA [[Paper]](https://arxiv.org/abs/2212.00735)
* scBERT as a large-scale pretrained deep language model for cell type annotation of single-cell RNA-seq data [[Paper]](https://arxiv.org/abs/2212.00735) [[Code]](https://github.com/TencentAILabHealthcare/scBERT)
* Interpretable RNA Foundation Model from Unannotated Data for Highly Accurate RNA Structure and Function Predictions [[Paper]](https://www.biorxiv.org/content/10.1101/2022.08.06.503062v2.abstract) [[Code]](https://github.com/ml4bio/rna-fm)
* E2Efold-3D: End-to-End Deep Learning Method for accurate de novo RNA 3D Structure Prediction [[Paper]](https://www.biorxiv.org/content/10.1101/2022.08.06.503062v2.abstract) [[Code]](https://github.com/ml4bio/rna-fm)

### General Domain

* Chatgpt: Optimizing language models for dialogue [[Blog]](https://openai.com/blog/chatgpt/) 
* LLaMA: Open and Efficient Foundation Language Models [[Paper]](https://arxiv.org/pdf/2302.13971.pdf)
* Scaling Instruction-Finetuned Language Models [[Paper]](https://arxiv.org/pdf/2210.11416.pdf)
* PaLM: Scaling Language Modeling with Pathways [[Paper]](https://arxiv.org/pdf/2204.02311.pdf)
* Training Compute-Optimal Large Language Models [[Paper]](https://arxiv.org/pdf/2203.15556.pdf)
* Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model [[Paper]](https://arxiv.org/pdf/2201.11990.pdf)
* BLOOM: A 176B-Parameter Open-Access Multilingual Language Model [[Paper]](https://arxiv.org/pdf/2211.05100.pdf)
* LaMDA: Language Models for Dialog Applications [[Paper]](https://arxiv.org/pdf/2201.08239.pdf)
* OPT: Open Pre-trained Transformer Language Models [[Paper]](https://arxiv.org/pdf/2205.01068.pdf)
* Training language models to follow instructions with human feedback [[Paper]](https://arxiv.org/pdf/2203.02155.pdf)
* Scaling Language Models: Methods, Analysis & Insights from Training Gopher [[Paper]](https://arxiv.org/pdf/2112.11446.pdf)
* Multitask prompted training enables zero-shot task generalization [[Paper]](https://arxiv.org/pdf/2110.08207.pdf)
* Language Models are Few-Shot Learners [[Paper]](https://arxiv.org/pdf/2005.14165.pdf)
* Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer [[Paper]](https://arxiv.org/pdf/1910.10683.pdf)
* RoBERTa: A Robustly Optimized BERT Pretraining Approach [[Paper]](https://arxiv.org/pdf/1907.11692.pdf)
* Language Models are Unsupervised Multitask Learners [[Paper]](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)
* Improving language models by retrieving from trillions of tokens [[Paper]](https://arxiv.org/pdf/2112.04426.pdf)
* WebGPT: Browser-assisted question-answering with human feedback [[Paper]](https://arxiv.org/pdf/2112.09332.pdf)
* Improving alignment of dialogue agents via targeted human judgements [[Paper]](https://arxiv.org/pdf/2209.14375.pdf)
* Improving Language Understanding by Generative Pre-Training [[Paper]](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf)
* BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding [[Paper]](https://arxiv.org/pdf/1810.04805.pdf)






## Large Vision Models

### Healthcare Domain


* Med3d: Transfer learning for 3d medical image analysis [[Paper]](https://arxiv.org/abs/1904.00625) [[Code]](https://github.com/Tencent/MedicalNet)
* Models genesis: Generic autodidactic models for 3d medical image analysis [[Paper]](https://arxiv.org/abs/1908.06912) [[Code]](https://github.com/MrGiovanni/ModelsGenesis)
* MICLe: Big self-supervised models advance medical image classifications [[Paper]](https://arxiv.org/abs/2101.05224) [[Code]](https://github.com/rjrobben/MICLe_pytorch)
* C2l: Comparing to Learn: Surpassing ImageNet Pretraining on Radiographs By Comparing Image Representations [[Paper]](https://arxiv.org/abs/2007.07423) [[Code]](https://github.com/funnyzhou/C2L_MICCAI2020)
* MoCo-CXR: MoCo Pretraining Improves Representation and Transferability of Chest X-ray Models [[Paper]](https://arxiv.org/abs/2010.05352) [[Code]](https://github.com/stanfordmlgroup/MoCo-CXR)
* Transunet: Transformers make strong encoders for medical image segmentation [[Paper]](https://arxiv.org/abs/2102.04306) [[Code]](https://github.com/Beckschen/TransUNet)
* Transfuse: Fusing transformers and cnns for medical image segmentation [[Paper]](https://arxiv.org/abs/2102.08005) [[Code]](https://github.com/Rayicer/TransFuse)
* Medical transformer: Gated axial-attention for medical image segmentation [[Paper]](https://arxiv.org/abs/2102.10662) [[Code]](https://github.com/jeya-maria-jose/Medical-Transformer)
* UNETR: Transformers for 3D Medical Image Segmentation [[Paper]](https://arxiv.org/abs/2103.10504) [[Code]](https://github.com/Project-MONAI/research-contributions/tree/main/UNETR/BTCV)
* Cotr: Efficiently bridging cnn and transformer for 3d medical image segmentation [[Paper]](https://arxiv.org/abs/2103.03024) [[Code]](https://github.com/YtongXie/CoTr)
* Swin-unet: Unet-like pure transformer for medical image segmentation [[Paper]](https://arxiv.org/abs/2105.05537) [[Code]](https://github.com/HuCaoFighting/Swin-Unet)
* SAM4Med: Generalist Vision Foundation Models for Medical Imaging: A Case Study of Segment Anything Model on Zero-Shot Medical Segmentation [[Paper]](https://arxiv.org/pdf/2304.12637.pdf)

### General Domain

**CNNs**:

* GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism [[paper]](https://proceedings.neurips.cc/paper/2019/hash/093f65e080a295f8076b1c5722a46aa2-Abstract.html)
* Big Transfer (BiT): General Visual Representation Learning [[paper]](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123500477.pdf)
* Designing Network Design Spaces [[paper]](https://openaccess.thecvf.com/content_CVPR_2020/html/Radosavovic_Designing_Network_Design_Spaces_CVPR_2020_paper.html)
* Self-supervised Pretraining of Visual Features in the Wild [[paper]](http://arxiv.org/abs/2103.01988)
* EfficientNetV2: Smaller Models and Faster Training [[paper]](https://proceedings.mlr.press/v139/tan21a.html)
* A ConvNet for the 2020s [[paper]](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_A_ConvNet_for_the_2020s_CVPR_2022_paper.pdf)
* InternImage: Exploring Large-Scale Vision Foundation Models with Deformable Convolutions [[paper]](http://arxiv.org/abs/2211.05778)

**Vision Transformers**:

* Generative Pretraining From Pixels [[paper]](https://proceedings.mlr.press/v119/chen20s.html)
* An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale [[paper]](https://openreview.net/forum?id=YicbFdNTTy&utm_campaign=f86497ed3a-EMAIL_CAMPAIGN_2019_04_24_03_18_COPY_01&utm_medium=email&utm_source=Deep%20Learning%20Weekly&utm_term=0_384567b42d-f86497ed3a-72965345)
* Transformer in Transformer [[paper]](https://proceedings.neurips.cc/paper/2021/hash/854d9fca60b4bd07f9bb215d59ef5561-Abstract.html)
* Swin Transformer: Hierarchical Vision Transformer Using Shifted Windows [[paper]](https://openaccess.thecvf.com/content/ICCV2021/html/Liu_Swin_Transformer_Hierarchical_Vision_Transformer_Using_Shifted_Windows_ICCV_2021_paper.html)
* Training data-efficient image transformers & distillation through attention [[paper]](https://proceedings.mlr.press/v139/touvron21a.html)
* Self-supervised Models are Good Teaching Assistants for Vision Transformers [[paper]](https://proceedings.mlr.press/v162/wu22c.html)
* Scaling Vision with Sparse Mixture of Experts [[paper]](https://proceedings.neurips.cc/paper/2021/hash/48237d9f2dea8c74c2a72126cf63d933-Abstract.html)
* Going Deeper With Image Transformers [[paper]](https://openaccess.thecvf.com/content/ICCV2021/html/Touvron_Going_Deeper_With_Image_Transformers_ICCV_2021_paper.html)
* Masked Autoencoders Are Scalable Vision Learners [[paper]](https://openaccess.thecvf.com/content/CVPR2022/html/He_Masked_Autoencoders_Are_Scalable_Vision_Learners_CVPR_2022_paper.html)
* Swin Transformer V2: Scaling Up Capacity and Resolution [[paper]](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Swin_Transformer_V2_Scaling_Up_Capacity_and_Resolution_CVPR_2022_paper.html)
* Scaling Vision Transformers [[paper]](https://openaccess.thecvf.com/content/CVPR2022/html/Zhai_Scaling_Vision_Transformers_CVPR_2022_paper.html)
* Efficient Self-supervised Vision Transformers for Representation Learning [[paper]](https://openreview.net/forum?id=fVu3o-YUGQK)
* Scaling Vision Transformers to 22 Billion Parameters [[paper]](http://arxiv.org/abs/2302.05442)

**CNNs + ViTs**:

* CoAtNet: Marrying Convolution and Attention for All Data Sizes [[paper]](https://proceedings.neurips.cc/paper/2021/hash/20568692db622456cc42a2e853ca21f8-Abstract.html)
* LeViT: A Vision Transformer in ConvNet's Clothing for Faster Inference [[paper]](https://openaccess.thecvf.com/content/ICCV2021/html/Graham_LeViT_A_Vision_Transformer_in_ConvNets_Clothing_for_Faster_Inference_ICCV_2021_paper.html)
* ConViT: Improving Vision Transformers with Soft Convolutional Inductive Biases [[paper]](https://proceedings.mlr.press/v139/d-ascoli21a.html)



## Large Audio Models

### Healthcare Domain


### General Domain

* wav2vec: Unsupervised Pre-training for Speech Recognition [[Paper]](https://arxiv.org/abs/1904.05862) [[Blog]](https://ai.facebook.com/blog/wav2vec-20-learning-the-structure-of-speech-from-raw-audio/)
* W2v-BERT: Combining Contrastive Learning and Masked Language Modeling for Self-Supervised Speech Pre-Training [[Paper]](https://arxiv.org/abs/2108.06209)
* AudioLM: a Language Modeling Approach to Audio Generation [[Paper]](https://arxiv.org/abs/2209.03143) [[Project]](https://google-research.github.io/seanet/audiolm/examples/) [[Blog]](https://ai.googleblog.com/2022/10/audiolm-language-modeling-approach-to.html)
* HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units [[Paper]](https://arxiv.org/abs/2106.07447) [[HuggingFace]](https://huggingface.co/docs/transformers/model_doc/hubert)
* XLS-R: Self-supervised Cross-lingual Speech Representation Learning at Scale [[Paper]](https://arxiv.org/abs/2111.09296) [[Blog]](https://ai.facebook.com/blog/xls-r-self-supervised-speech-processing-for-128-languages/) [[HuggingFace]](https://huggingface.co/facebook/wav2vec2-xls-r-300m)
* MusicLM: Generating Music From Text [[Paper]](https://arxiv.org/abs/2301.11325) [[Project]](https://google-research.github.io/seanet/musiclm/examples/) [[Code]](https://github.com/lucidrains/musiclm-pytorch)
* Diffsound: Discrete Diffusion Model for Text-to-sound Generation [[Paper]](https://arxiv.org/abs/2207.09983) [[Project]](http://dongchaoyang.top/text-to-sound-synthesis-demo/) [[Code]](https://github.com/yangdongchao/Text-to-sound-Synthesis)
* AudioGen: Textually Guided Audio Generation [[Paper]](https://arxiv.org/abs/2209.15352) [[Project]](https://felixkreuk.github.io/audiogen/)
* Whisper: Robust Speech Recognition via Large-Scale Weak Supervision [[Paper]](https://arxiv.org/abs/2212.04356) [[Code]](https://github.com/openai/whisper) [[HuggingFace]](https://huggingface.co/openai/whisper-tiny.en)
* Google USM: Scaling Automatic Speech Recognition Beyond 100 Languages [[Paper]](https://arxiv.org/abs/2303.01037) [[Blog]](https://ai.googleblog.com/2023/03/universal-speech-model-usm-state-of-art.html)


## Large Multi-modal Models

### Healthcare Domain

* GPT-4 Technical Report [[Paper]](https://arxiv.org/pdf/2303.08774.pdf)
* Expert-level detection of pathologies from unannotated chest X-ray images via self-supervised learning [[Paper]](https://www.nature.com/articles/s41551-022-00936-9)
* Contrastive Learning of Medical Visual Representations from Paired Images and Text [[Paper]](https://arxiv.org/pdf/2010.00747.pdf) [[Code]](https://github.com/edreisMD/ConVIRT-pytorch)
* Gloria: A multimodal global-local representation learning framework for labelefficient medical image recognition [[Paper]](https://ieeexplore.ieee.org/document/9710099) [[Code]](https://github.com/marshuang80/gloria)
* RAMM: Retrieval-augmented Biomedical Visual Question Answering with Multi-modal Pre-training [[Paper]](https://arxiv.org/abs/2303.00534)

### General Domain

**Representation learning**:

* Learning Transferable Visual Models From Natural Language Supervision [[paper]](https://proceedings.mlr.press/v139/radford21a.html)
* Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision [[paper]](https://proceedings.mlr.press/v139/jia21b.html)
* Florence: A New Foundation Model for Computer Vision [[paper]](http://arxiv.org/abs/2111.11432)
* Grounded Language-Image Pre-Training [[paper]](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Grounded_Language-Image_Pre-Training_CVPR_2022_paper.html)
* WenLan: Bridging Vision and Language by Large-Scale Multi-Modal Pre-Training [[paper]](http://arxiv.org/abs/2103.06561)
* FLAVA: A Foundational Language and Vision Alignment Model [[paper]](https://openaccess.thecvf.com/content/CVPR2022/html/Singh_FLAVA_A_Foundational_Language_and_Vision_Alignment_Model_CVPR_2022_paper.html)
* SimVLM: Simple Visual Language Model Pretraining with Weak Supervision [[paper]](https://openreview.net/forum?id=GUrhfTuf_3)
* FILIP: Fine-grained Interactive Language-Image Pre-Training [[paper]](https://openreview.net/forum?id=cpDhcsEDC2)
* Combined Scaling for Open-Vocabulary Image Classification [[paper]](http://arxiv.org/abs/2111.10050)
* BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation [[paper]](https://proceedings.mlr.press/v162/li22n.html)
* PaLI: A Jointly-Scaled Multilingual Language-Image Model [[paper]](http://arxiv.org/abs/2209.06794)
* Towards All-in-one Pre-training via Maximizing Multi-modal Mutual Information [[paper]](http://arxiv.org/abs/2211.09807)
* BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models [[paper]](http://arxiv.org/abs/2301.12597)
* Supervision Exists Everywhere: A Data Efficient Contrastive Language-Image Pre-training Paradigm [[paper]](https://openreview.net/forum?id=zq1iJkNk3uN)
* Language Is Not All You Need: Aligning Perception with Language Models [[paper]](http://arxiv.org/abs/2302.14045)
* PaLM-E: An Embodied Multimodal Language Model [[paper]](http://arxiv.org/abs/2303.03378)
* Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models [[paper]](http://arxiv.org/abs/2303.04671)

**Text-to-image generation**:

* Zero-Shot Text-to-Image Generation [[paper]](https://proceedings.mlr.press/v139/ramesh21a.html)
* High-Resolution Image Synthesis With Latent Diffusion Models [[paper]](https://openaccess.thecvf.com/content/CVPR2022/html/Rombach_High-Resolution_Image_Synthesis_With_Latent_Diffusion_Models_CVPR_2022_paper.html)
* Hierarchical Text-Conditional Image Generation with CLIP Latents [[paper]](http://arxiv.org/abs/2204.06125)
* GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models [[paper]](https://proceedings.mlr.press/v162/nichol22a.html)
* Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding [[paper]](https://openreview.net/forum?id=08Yk-n5l2Al)
* Scaling Autoregressive Models for Content-Rich Text-to-Image Generation [[paper]](https://openreview.net/forum?id=AFDcYJKhND)



## Applications of Large AI Models in Healthcare

Note that some of the following models were not targeted at healthcare applications initially but may have the potential to be transferred to the healthcare domain or inspire future development.


### Bioinformatics

* GeneGPT: Augmenting Large Language Models with Domain Tools for Improved Access to Biomedical Information [[Paper]](https://arxiv.org/abs/2304.09667)
* Highly accurate protein structure prediction with AlphaFold [[Paper]](https://www.nature.com/articles/s41586-021-03819-2) [[Code]](https://github.com/deepmind/alphafold)
* Accurate prediction of protein structures and interactions using a three-track neural network [[Paper]](https://www.science.org/doi/full/10.1126/science.abj8754?casa_token=tleEHPOOSr8AAAAA%3AT0eToIMPW0oN1jjIGLs8aPyQK8qbcFIByjT1x4k90tvBAj03SZUzpEinCPe_t-g4ECmjJ9wlj8OwQBs)
* Protein complex prediction with AlphaFold-Multimer [[Paper]](https://www.biorxiv.org/content/10.1101/2021.10.04.463034v2.abstract)
* FastFold: Reducing AlphaFold Training Time from 11 Days to 67 Hours [[Paper]](https://arxiv.org/abs/2203.00854) [[Code]](https://github.com/hpcaitech/fastfold)
* HelixFold: An Efficient Implementation of AlphaFold2 using PaddlePaddle [[Paper]](https://arxiv.org/abs/2207.05477) [[Code]](https://github.com/PaddlePaddle/PaddleHelix)
* Uni-Fold: An Open-Source Platform for Developing Protein Folding Models beyond AlphaFold [[Paper]](https://www.biorxiv.org/content/10.1101/2022.08.04.502811v3.abstract) [[Code]](https://github.com/dptech-corp/Uni-Fold)
* OpenFold: Retraining AlphaFold2 yields new insights into its learning mechanisms and capacity for generalization [[Paper]](https://www.biorxiv.org/content/10.1101/2022.11.20.517210v2.abstract) [[Code]](https://github.com/aqlaboratory/openfold)
* ManyFold: an efficient and flexible library for training and validating protein folding models [[Paper]](https://academic.oup.com/bioinformatics/article/39/1/btac773/6887136) [[Code]](https://github.com/instadeepai/manyfold)
* ColabFold: making protein folding accessible to all [[Paper]](https://www.nature.com/articles/s41592-022-01488-1) [[Code]](https://github.com/sokrypton/ColabFold)
* Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences [[Paper]](https://www.pnas.org/doi/abs/10.1073/pnas.2016239118) [[Code]](https://github.com/facebookresearch/esm)
* ProGen: Language Modeling for Protein Generation [[Paper]](https://arxiv.org/abs/2004.03497) [[Code]](https://github.com/lucidrains/progen)
* ProtTrans: Towards Cracking the Language of Life's Code Through Self-Supervised Deep Learning and High Performance Computing [[Paper]](https://arxiv.org/abs/2007.06225) [[Code]](https://github.com/agemagician/ProtTrans)
* Evolutionary-scale prediction of atomic level protein structure with a language model [[Paper]](https://www.science.org/doi/full/10.1126/science.ade2574) 
* High-resolution de novo structure prediction from primary sequence [[Paper]](https://www.biorxiv.org/content/10.1101/2022.07.21.500999v1.abstract) [[Code]](https://github.com/HeliXonProtein/OmegaFold)
* Single-sequence protein structure prediction using a language model and deep learning [[Paper]](https://www.nature.com/articles/s41587-022-01432-w)
* Improved the Protein Complex Prediction with Protein Language Models [[Paper]](https://www.biorxiv.org/content/10.1101/2022.09.15.508065v2.abstract)
* MSA Transformer [[Paper]](http://proceedings.mlr.press/v139/rao21a.html) [[Code]](https://github.com/The-AI-Summer/self-attention-cv)
* Deciphering antibody affinity maturation with language models and weakly supervised learning [[Paper]](https://arxiv.org/abs/2112.07782)
* xTrimoABFold: De novo Antibody Structure Prediction without MSA [[Paper]](https://arxiv.org/abs/2212.00735)
* scBERT as a large-scale pretrained deep language model for cell type annotation of single-cell RNA-seq data [[Paper]](https://arxiv.org/abs/2212.00735) [[Code]](https://github.com/TencentAILabHealthcare/scBERT)
* Interpretable RNA Foundation Model from Unannotated Data for Highly Accurate RNA Structure and Function Predictions [[Paper]](https://www.biorxiv.org/content/10.1101/2022.08.06.503062v2.abstract) [[Code]](https://github.com/ml4bio/rna-fm)
* E2Efold-3D: End-to-End Deep Learning Method for accurate de novo RNA 3D Structure Prediction [[Paper]](https://www.biorxiv.org/content/10.1101/2022.08.06.503062v2.abstract) [[Code]](https://github.com/ml4bio/rna-fm)
* SMILES-BERT: large scale unsupervised pre-training for molecular property prediction [[Paper]](https://par.nsf.gov/servlets/purl/10168888) [[Code]](https://github.com/uta-smile/SMILES-BERT)
* SMILES Transformer: Pre-trained molecular fingerprint for low data drug discovery [[Paper]](https://arxiv.org/abs/1911.04738) [[Code]](https://github.com/DSPsleeporg/smiles-transformer)
* MolBert: Molecular representation learning with language models and domain-relevant auxiliary tasks [[Paper]](https://arxiv.org/abs/2011.13230) [[Code]](https://github.com/BenevolentAI/MolBERT)
* AGBT: Algebraic graph-assisted bidirectional transformers for molecular property prediction [[Paper]](https://www.nature.com/articles/s41467-021-23720-w) [[Code]](https://github.com/ChenDdon/AGBTcode)
* GROVER: Self-supervised graph transformer on large-scale molecular data [[Paper]](https://arxiv.org/abs/2007.02835) [[Code]](https://github.com/tencent-ailab/grover)
* Molgpt: molecular generation using a transformer-decoder model [[Paper]](https://pubs.acs.org/doi/10.1021/acs.jcim.1c00600) [[Code]](https://github.com/devalab/molgpt)
* A Model to Search for Synthesizable Molecules [[Paper]](https://arxiv.org/abs/1906.05221) [[Code]](https://github.com/john-bradshaw/molecule-chef)
* Transformer neural network for protein-specific de novo drug generation as a machine translation problem [[Paper]](https://www.nature.com/articles/s41598-020-79682-4)
* Deepconv-dti: Prediction of drug-target interactions via deep learning with convolution on protein sequences [[Paper]](https://arxiv.org/abs/1811.02114) [[Code]](https://github.com/GIST-CSBL/DeepConv-DTI)
* Graphdta: predicting drug–target binding affinity with graph neural networks [[Paper]](https://pubmed.ncbi.nlm.nih.gov/33119053/) [[Code]](https://github.com/thinng/GraphDTA)
* Moltrans: molecular interaction transformer for drug–target interaction prediction [[Paper]](https://arxiv.org/abs/2004.11424) [[Code]](https://github.com/kexinhuang12345/moltrans)
* Extracting Predictive Representations from Hundreds of Millions of Molecules [[Paper]](https://pubs.acs.org/doi/10.1021/acs.jpclett.1c03058) [[Code]](https://github.com/WeilabMSU/PretrainModels)
* ADMETlab 2.0: an integrated online platform for accurate and comprehensive predictions of ADMET properties [[Project]](https://admetmesh.scbdd.com/) [[Paper]](https://pubmed.ncbi.nlm.nih.gov/33893803/)
* MPG: Learn molecular representations from large-scale unlabeled molecules for drug discovery [[Paper]](https://arxiv.org/abs/2012.11175)
* MG-BERT: leveraging unsupervised atomic representation learning for molecular property prediction [[Paper]](https://academic.oup.com/bib/article-abstract/22/6/bbab152/6265201?redirectedFrom=fulltext) [[Code]](https://github.com/ParishadBehnam/MG-BERT)
* PanGu Drug Model: Learn a Molecule Like a Human [[Project]](http://www.pangu-drug.com/) [[Paper]](https://www.biorxiv.org/content/10.1101/2022.03.31.485886v1.full)
* DrugBAN: Interpretable bilinear attention network with domain adaptation improves drug–target prediction [[Paper]](https://www.nature.com/articles/s42256-022-00605-1) [[Code]](https://github.com/peizhenbai/DrugBAN)
* DrugOOD: Out-of-Distribution (OOD) Dataset Curator and Benchmark for AI-aided Drug Discovery [[Paper]](https://arxiv.org/abs/2201.09637) [[Code]](https://github.com/tencent-ailab/DrugOOD)

### Medical Diagnosis and Decision-making

* Expert-level detection of pathologies from unannotated chest X-ray images via self-supervised learning [[Paper]](https://www.nature.com/articles/s41551-022-00936-9)
* ChatCAD: Interactive Computer-Aided Diagnosis on Medical Image using Large Language Models [[Paper]](https://arxiv.org/pdf/2302.07257.pdf)
* BEHRT: Transformer for Electronic Health Records [[Paper]](https://www.nature.com/articles/s41598-020-62922-y)
* Federated Learning of Medical Concepts Embedding using BEHRT [[Paper]](https://arxiv.org/abs/2305.13052) [[Code]](https://github.com/nadavlab/FederatedBEHRT)
* Med-BERT: pretrained contextualized embeddings on large-scale structured electronic health records for disease prediction [[Paper]](https://www.nature.com/articles/s41746-021-00455-y)
* RadBERT: Adapting Transformer-based Language Models to Radiology [[paper]](https://pubs.rsna.org/doi/epdf/10.1148/ryai.210258) [[HuggingFace]](https://huggingface.co/UCSD-VA-health/RadBERT-RoBERTa-4m)

### Medical Imaging and Vision

* Expert-level detection of pathologies from unannotated chest X-ray images via self-supervised learning [[Paper]](https://www.nature.com/articles/s41551-022-00936-9)
* Med3d: Transfer learning for 3d medical image analysis [[Paper]](https://arxiv.org/abs/1904.00625) [[Code]](https://github.com/Tencent/MedicalNet)
* Models genesis: Generic autodidactic models for 3d medical image analysis [[Paper]](https://arxiv.org/abs/1908.06912) [[Code]](https://github.com/MrGiovanni/ModelsGenesis)
* MICLe: Big self-supervised models advance medical image classifications [[Paper]](https://arxiv.org/abs/2101.05224) [[Code]](https://github.com/rjrobben/MICLe_pytorch)
* C2l: Comparing to Learn: Surpassing ImageNet Pretraining on Radiographs By Comparing Image Representations [[Paper]](https://arxiv.org/abs/2007.07423) [[Code]](https://github.com/funnyzhou/C2L_MICCAI2020)
* ConVIRT: Contrastive learning of medical visual representations from paired images and text [[Paper]](https://arxiv.org/pdf/2303.11032.pdf) [[Code]](https://github.com/edreisMD/ConVIRT-pytorch)
* Gloria: A multimodal global-local representation learning framework for labelefficient medical image recognition [[Paper]](https://ieeexplore.ieee.org/document/9710099) [[Code]](https://github.com/marshuang80/gloria)
* MoCo-CXR: MoCo Pretraining Improves Representation and Transferability of Chest X-ray Models [[Paper]](https://arxiv.org/abs/2010.05352) [[Code]](https://github.com/stanfordmlgroup/MoCo-CXR)
* Transunet: Transformers make strong encoders for medical image segmentation [[Paper]](https://arxiv.org/abs/2102.04306) [[Code]](https://github.com/Beckschen/TransUNet)
* Transfuse: Fusing transformers and cnns for medical image segmentation [[Paper]](https://arxiv.org/abs/2102.08005) [[Code]](https://github.com/Rayicer/TransFuse)
* Medical transformer: Gated axial-attention for medical image segmentation [[Paper]](https://arxiv.org/abs/2102.10662) [[Code]](https://github.com/jeya-maria-jose/Medical-Transformer)
* UNETR: Transformers for 3D Medical Image Segmentation [[Paper]](https://arxiv.org/abs/2103.10504) [[Code]](https://github.com/Project-MONAI/research-contributions/tree/main/UNETR/BTCV)
* Cotr: Efficiently bridging cnn and transformer for 3d medical image segmentation [[Paper]](https://arxiv.org/abs/2103.03024) [[Code]](https://github.com/YtongXie/CoTr)
* Swin-unet: Unet-like pure transformer for medical image segmentation [[Paper]](https://arxiv.org/abs/2105.05537) [[Code]](https://github.com/HuCaoFighting/Swin-Unet)
* SAM4Med: Generalist Vision Foundation Models for Medical Imaging: A Case Study of Segment Anything Model on Zero-Shot Medical Segmentation [[Paper]](https://arxiv.org/pdf/2304.12637.pdf)





### Medical Informatics

* DeID-GPT: Zero-shot Medical Text De-Identification by GPT-4 [[Paper]](https://arxiv.org/pdf/2303.11032.pdf)
* Capabilities of GPT-4 on Medical Challenge Problems [[Paper]](https://arxiv.org/pdf/2303.13375.pdf)
* BioBERT: a pre-trained biomedical language representation model for biomedical text mining [[Paper]](https://arxiv.org/pdf/1901.08746.pdf)
* Publicly Available Clinical BERT Embeddings [[Paper]](https://arxiv.org/pdf/1904.03323.pdf)
* BioMegatron: Larger Biomedical Domain Language Model [[Paper]](https://arxiv.org/pdf/2010.06060.pdf)
* Don’t Stop Pretraining: Adapt Language Models to Domains and Tasks [[Paper]](https://aclanthology.org/2020.acl-main.740.pdf)
* Med-BERT: pretrained contextualized embeddings on large-scale structured electronic health records for disease prediction [[Paper]](https://www.nature.com/articles/s41746-021-00455-y)
* BioELECTRA:Pretrained Biomedical text Encoder using Discriminators [[Paper]](https://aclanthology.org/2021.bionlp-1.16.pdf)
* LinkBERT: Pretraining Language Models with Document Links [[Paper]](https://arxiv.org/pdf/2203.15827.pdf)
* BioGPT: Generative Pre-trained Transformer for Biomedical Text Generation and Mining [[Paper]](https://arxiv.org/pdf/2210.10341.pdf)
* Large Language Models Encode Clinical Knowledge [[Paper]](https://arxiv.org/pdf/2212.13138.pdf)
* A large language model for electronic health records [[Paper]](https://www.nature.com/articles/s41746-022-00742-2)
* Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing [[Paper]](https://arxiv.org/pdf/2007.15779.pdf)
* BEHRT: Transformer for Electronic Health Records [[Paper]](https://www.nature.com/articles/s41598-020-62922-y)
* Federated Learning of Medical Concepts Embedding using BEHRT [[Paper]](https://arxiv.org/abs/2305.13052) [[Code]](https://github.com/nadavlab/FederatedBEHRT)


### Medical Education

* GPT-4 Technical Report [[Paper]](https://arxiv.org/pdf/2303.08774.pdf)
* Empowering Beginners in Bioinformatics with ChatGPT [[Paper]](https://www.biorxiv.org/content/10.1101/2023.03.07.531414v1)


### Public Health

* Expert-level detection of pathologies from unannotated chest X-ray images via self-supervised learning [[Paper]](https://www.nature.com/articles/s41551-022-00936-9)
* Clustering Egocentric Images in Passive Dietary Monitoring with Self-Supervised Learning [[Paper]](https://arxiv.org/pdf/2208.12160.pdf)
* ClimaX: A foundation model for weather and climate [[Paper]](https://arxiv.org/pdf/2301.10343.pdf)



###  Medical Robotics

* Decision Transformer: Reinforcement Learning via Sequence Modeling [[Paper]](https://arxiv.org/abs/2106.01345) [[Code]](https://github.com/kzl/decision-transformer)
* R3M: A Universal Visual Representation for Robot Manipulation [[Paper]](https://arxiv.org/abs/2203.12601) [[Project]](https://sites.google.com/view/robot-r3m/) [[Code]](https://github.com/facebookresearch/r3m)
* MimicPlay: Long-Horizon Imitation Learning by Watching Human Play [[Paper]](https://arxiv.org/abs/2302.12422) [[Project]](https://mimic-play.github.io/)
* PaLM-E: An Embodied Multimodal Language Model [[Paper]](https://arxiv.org/abs/2303.03378) [[Project]](https://palm-e.github.io/) [[Blog]](https://ai.googleblog.com/2023/03/palm-e-embodied-multimodal-language.html)
* A Generalist Agent [[Paper]](https://arxiv.org/abs/2205.06175) [[Blog]](https://www.deepmind.com/blog/a-generalist-agent)
* CLIPort: What and Where Pathways for Robotic Manipulation [[Paper]](https://arxiv.org/abs/2109.12098) [[Project]](https://cliport.github.io/) [[Code]](https://github.com/cliport/cliport)
* Perceiver-Actor: A Multi-Task Transformer for Robotic Manipulation [[Paper]](https://arxiv.org/abs/2209.05451) [[Project]](https://peract.github.io/) [[Code]](https://github.com/peract/peract)
* Do As I Can, Not As I Say: Grounding Language in Robotic Affordances [[Paper]](https://arxiv.org/abs/2204.01691) [[Project]](https://say-can.github.io/) [[Code]](https://github.com/google-research/google-research/tree/master/saycan)
* VIMA: General Robot Manipulation with Multimodal Prompts [[Paper]](https://arxiv.org/abs/2210.03094) [[Project]](https://vimalabs.github.io/) [[Code]](https://github.com/vimalabs/VIMA)
* RT-1: Robotics Transformer for Real-World Control at Scale [[Paper]](https://arxiv.org/abs/2212.06817) [[Project]](https://robotics-transformer.github.io/) [[Code]](https://github.com/google-research/robotics_transformer)
* ChatGPT for Robotics: Design Principles and Model Abilities [[Paper]](https://www.microsoft.com/en-us/research/uploads/prod/2023/02/ChatGPT___Robotics.pdf) [[Blog]](https://www.microsoft.com/en-us/research/group/autonomous-systems-group-robotics/articles/chatgpt-for-robotics/) [[Code]](https://github.com/microsoft/PromptCraft-Robotics)
"
25,metriport/metriport,JavaScript,"<p align=""center"">
  <a href=""https://github.com/metriport/metriport"">
    <img src=""./assets/logo.png"" alt=""Logo"">
  </a>

  <p align=""center"">
    Metriport helps digital health companies access and manage health and medical data, through a single open source API.
    <br />
    <a href=""https://metriport.com"" target=""_blank""><strong>Learn more »</strong></a>
    <br />
    <br />
    <a href=""https://docs.metriport.com/"" target=""_blank"">Docs</a>
    ·
    <a href=""https://www.npmjs.com/package/@metriport/api"" target=""_blank"">NPM</a>
    ·
    <a href=""https://dash.metriport.com"" target=""_blank"">Developer Dashboard</a>
    ·
    <a href=""https://metriport.com"" target=""_blank"">Website</a>

  </p>
</p>

<p align=""center"">
   <a href=""https://status.metriport.com/""><img src=""https://api.checklyhq.com/v1/badges/checks/38e13035-5922-4b4c-8d94-6fe766a3c4da?style=flat&theme=default"" alt=""API Status Check""></a>
   <a href=""https://github.com/metriport/metriport/stargazers""><img src=""https://img.shields.io/github/stars/metriport/metriport"" alt=""Github Stars""></a>
   <a href=""https://github.com/metriport/metriport/blob/master/LICENSE""><img src=""https://img.shields.io/badge/license-AGPLv3-purple"" alt=""License""></a>
   <a href=""https://github.com/metriport/metriport/pulse""><img src=""https://img.shields.io/github/commit-activity/m/metriport/metriport"" alt=""Commits-per-month""></a>
   <a href=""https://twitter.com/metriport""><img src=""https://img.shields.io/twitter/follow/metriport?style=social""></a>
   <a href=""https://www.linkedin.com/company/metriport""><img src=""https://img.shields.io/static/v1?label=LinkedIn&message=Metriport (YC S22)&color=blue"" alt=""LinkedIn""></a>
   <a href=""https://www.ycombinator.com/companies/metriport""><img src=""https://img.shields.io/static/v1?label=Y Combinator&message=Metriport&color=orange"" alt=""YC""></a>
</p>

<div align=""center"">

#### Support us on [Product Hunt](https://www.producthunt.com/products/metriport-api) and [Launch YC](https://www.ycombinator.com/launches/Ghx-metriport-universal-api-for-healthcare-data)

<a href=""https://www.producthunt.com/posts/metriport-health-devices-api?utm_source=badge-featured&utm_medium=badge&utm_souce=badge-metriport&#0045;health&#0045;devices&#0045;api"" target=""_blank""><img src=""https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=371762&theme=light"" alt=""Metriport&#0032;&#0045;&#0032;Health&#0032;Devices&#0032;API - Open&#0045;source&#0032;Plaid&#0032;for&#0032;healthcare&#0032;data | Product Hunt"" style=""width: 250px; height: 54px;"" width=""250"" height=""54"" /></a> <a href='https://www.ycombinator.com/launches/Ghx-metriport-universal-api-for-healthcare-data' target=""_blank""><img src='https://www.ycombinator.com/launches/Ghx-metriport-universal-api-for-healthcare-data/upvote_embed.svg' alt='Launch YC: Metriport - Universal API for Healthcare Data'></a>

</div>

## **Overview**

<div align=""center"">
   <img width=""50%"" alt=""wearables"" src=""./assets/wearables.svg"">
</div>

## **Security and Privacy**

Metriport is SOC 2 and HIPAA compliant. [Click here](https://metriport.com/security/) to learn more about our security practices.

<p float=""left"">
  <img src=""./assets/soc2.png"" width=""20%"" />
  <img src=""./assets/hipaa.png"" width=""30%"" />
  <img src=""./assets/soc2-vanta.png"" width=""20%"" />
  <img src=""./assets/hipaa-vanta.png"" width=""20%"" />
</p>

### **Health Devices API**

Our [Health Devices API](https://metriport.com/devices), allows you to gain access to your users’ health data from various wearables, RPM devices, and mHealth sources through a single standardized API.

Out of the box, our Health Devices API supports the following integrations:

- Dexcom
- Fitbit
- Garmin
- Oura
- Whoop
- Withings
- Cronometer
- Apple Health
- Google Fit

...with many more integrations on the way! If there’s an integration you need that’s not currently on here, feel free to shoot us an [email](mailto:contact@metriport.com) and let us know so we can build it, or feel free to fork our code and add the integration yourself.

<div align=""center"">
   <img width=""50%"" alt=""wearables"" src=""./assets/graphic.svg"">
</div>

### **Medical API (Coming Soon)**

Open-source with native FHIR support. More info on our Medical API here: https://metriport.com/medical/

## **Getting Started**

Check out the links below to get started with Metriport in minutes!

### **[Quickstart Guide](https://docs.metriport.com/getting-started/introduction) 🚀**

### **[Developer Dashboard](https://dash.metriport.com/) 💻**

### **[npm package](https://www.npmjs.com/package/@metriport/api)**

## **Repo Rundown**

### **API Server**

Backend for the Metriport API.

- Dir: [`/api`](/api)
- URL: [https://api.metriport.com/](https://api.metriport.com/)
- Sandbox URL: [https://api.sandbox.metriport.com/](https://api.sandbox.metriport.com/)

### **Connect Widget**

Pre-built app that you can embed your own app! Use it to allow your users to authenticate with various data sources, allowing you to pull their health data from those sources.

<div align=""left"">
   <img width=""50%"" alt=""connect widget"" src=""https://i.ibb.co/mNgMwyd/Screenshot-2022-12-20-at-3-51-47-PM.png"">
</div>

- Dir: [`/connect-widget`](/connect-widget)
- URL: [https://connect.metriport.com/](https://connect.metriport.com/?token=demo)

### **Infrastructure as Code**

We use AWS CDK as IaC.

- Dir: [`/infra`](/infra)

### **Docs**

Our beautiful developer documentation, powered by [mintlify](https://mintlify.com/) ❤️.

- Dir: [`/docs`](/docs)
- URL: [https://docs.metriport.com/](https://docs.metriport.com/getting-started/introduction)

### **Packages**

Checkout our packages in [`/pkgs`](/pkgs) to help you turbocharge your development:

#### **npm**

Our npm packages are available in [`/packages`](/packages):

- [Metriport API](/packages/packages/api/): contains the Metriport data models, and a convenient API client wrapper.
- [CommonWell JWT Maker](/packages/packages/commonwell-jwt-maker/): CLI to create a JWT for use in [CommonWell](https://www.commonwellalliance.org/) queries.
- [CommonWell SDK](/packages/packages/commonwell-sdk/): SDK to simplify CommonWell API integration.

#### **iOS**

Our iOS packages are available in our [`iOS repo`](https://github.com/metriport/metriport-ios-sdk):

- [Metriport iOS](https://github.com/metriport/metriport-ios-sdk): SDK to integrate with the Metriport Connect Widget and Apple Health on iOS.

### **Code Examples**

Some example projects that serve as examples for how to integrate with Metriport on various platforms - such as iOS and Android.

- Dir: [`/examples`](/examples)

---

## **Prerequisites**

Before getting started with the deployment or any development, ensure you have done the following:

1. Install the prerequisite programs:
   - [The latest LTS Node.js version](https://nodejs.org/en/download/).
   - [Docker Desktop](https://www.docker.com/products/docker-desktop/).
   - (Optional) [VS Code](https://code.visualstudio.com/) - recommended IDE.
   - (Optional) [DBeaver](https://dbeaver.io/) - recommended universal DB tool.
2. Create an AWS account.
3. Create an [AWS IAM admin user](https://docs.aws.amazon.com/IAM/latest/UserGuide/getting-started_create-admin-group.html).
4. Setup AWS `Route 53` to [handle the DNS for your domain, and create a hosted zone](https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/migrate-dns-domain-inactive.html).
5. Follow modules 1 & 2 of [this guide](https://aws.amazon.com/getting-started/guides/setup-cdk/) for `Typescript` to bootstrap the `AWS CDK` on your local machine.
6. 🥳 🎉 🥳 🎉 🥳 🎉

## **Local Development**

### Monorepo

This monorepo uses [npm workspaces](https://docs.npmjs.com/cli/v9/using-npm/workspaces) to manage the packages and execute commands globally.

To setup this repository for local development, issue this command on the root folder:

```shell
$ npm install # only needs to be run once
```

Useful commands:

- `npm run typecheck`: it will run `typecheck` on all workspaces, which checks for typescript compilation/syntax issues;
- `npm run lint-fix`: it will run `lint-fix` on all workspaces, which checks for linting issues and automatically fixes the issues it can;
- `npm run prettier-fix`: it will run `prettier-fix` on all workspaces, which checks for formatting issues and automatically fixes the issues it can;

### Semantic version

This repo uses [Semantic Version](https://semver.org/), and we automate the versioning by using [Conventional Commits](https://www.conventionalcommits.org/en/v1.0.0/).

This means all commit messages must be created following a certain standard:

```
<type>[optional scope]: <description>
[optional body]
[optional footer(s)]
```

To enforce commits follow this pattern, we have a Git hook (using [Husky](https://github.com/typicode/husky)) that verifies commit messages according to the Conventional Commits -
it uses [commitlint](https://github.com/conventional-changelog/commitlint) under the hood ([config](https://github.com/conventional-changelog/commitlint/tree/master/@commitlint/config-conventional)).

Accepted types:

- build
- chore
- ci
- docs
- feat
- fix
- perf
- refactor
- revert
- style
- test

Scope is optional, and we can use one of these, or empty (no scope):

- api
- widget
- infra

The footer should have the ticket number supporting the commit:

```
...
Ref: #<ticket-number>
```

#### Commitizen

One can enter the commit message manually and have `commitlint` check its content, or use [Commitizen](https://github.com/commitizen/cz-cli)'s
CLI to guide through building the commit message:

```shell
$ npm run commit
```

In case something goes wrong after you prepare the commit message and you want to retry it after fixing the issue, you can issue this command:

```shell
$ npm run commit -- --retry
```

Commitizen will retry the last commit message you prepared previously. More about this [here](https://github.com/commitizen/cz-cli#retrying-failed-commits).

### **API Server**

First, create a local environment file to define your developer keys, and local dev URLs:

```shell
$ touch api/app/.env
$ echo ""LOCAL_ACCOUNT_CXID=<YOUR-TESTING-ACCOUNT-ID>"" >> api/app/.env
$ echo ""API_URL=http://localhost:8080"" >> api/app/.env
$ echo ""CONNECT_WIDGET_URL=http://localhost:3001/"" >> api/app/.env
$ echo ""CRONOMETER_CLIENT_ID=<YOUR-ID>"" >> api/app/.env
$ echo ""CRONOMETER_CLIENT_SECRET=<YOUR-SECRET>"" >> api/app/.env
$ echo ""DEXCOM_CLIENT_ID=<YOUR-KEY>"" >> api/app/.env
$ echo ""DEXCOM_CLIENT_SECRET=<YOUR-SECRET>"" >> api/app/.env
$ echo ""FITBIT_CLIENT_ID=<YOUR-KEY>"" >> api/app/.env
$ echo ""FITBIT_CLIENT_SECRET=<YOUR-SECRET>"" >> api/app/.env
$ echo ""GARMIN_CONSUMER_KEY=<YOUR-KEY>"" >> api/app/.env
$ echo ""GARMIN_CONSUMER_SECRET=<YOUR-SECRET>"" >> api/app/.env
$ echo ""GOOGLE_CLIENT_ID=<YOUR-KEY>"" >> api/app/.env
$ echo ""GOOGLE_CLIENT_SECRET=<YOUR-SECRET>"" >> api/app/.env
$ echo ""OURA_CLIENT_ID=<YOUR-KEY>"" >> api/app/.env
$ echo ""OURA_CLIENT_SECRET=<YOUR-SECRET>"" >> api/app/.env
$ echo ""WHOOP_CLIENT_ID=<YOUR-KEY>"" >> api/app/.env
$ echo ""WHOOP_CLIENT_SECRET=<YOUR-KEY>"" >> api/app/.env
$ echo ""WITHINGS_CLIENT_ID=<YOUR-SECRET>"" >> api/app/.env
$ echo ""WITHINGS_CLIENT_SECRET=<YOUR-SECRET>"" >> api/app/.env
$ echo ""FHIR_SERVER_URL=<FHIR-SERVER-URL>"" >> api/app/.env # optional
```

Additionally, define your System Root [OID](https://en.wikipedia.org/wiki/Object_identifier). This will be the base identifier to represent your system in any medical data you create - such as organizations, facilities, patients, and etc.

Your OID must be registered and assigned by HL7. You can do this [here](http://www.hl7.org/oid/index.cfm).

By default, OIDs in Metriport are managed according to the [recommended standards outlined by HL7](http://www.hl7.org/documentcenter/private/standards/v3/V3_OIDS_R1_INFORM_2011NOV.pdf).

```shell
$ echo ""SYSTEM_ROOT_OID=<YOUR-OID>"" >> api/app/.env
```

These envs are specific to Commonwell and are necessary in sending requests to their platform.

```shell
$ echo ""CW_TECHNICAL_CONTACT_NAME=<YOUR-SECRET>"" >> api/app/.env
$ echo ""CW_TECHNICAL_CONTACT_TITLE=<YOUR-SECRET>"" >> api/app/.env
$ echo ""CW_TECHNICAL_CONTACT_EMAIL=<YOUR-SECRET>"" >> api/app/.env
$ echo ""CW_TECHNICAL_CONTACT_PHONE=<YOUR-SECRET>"" >> api/app/.env
$ echo ""CW_GATEWAY_ENDPOINT=<YOUR-SECRET>"" >> api/app/.env
$ echo ""CW_GATEWAY_AUTHORIZATION_SERVER_ENDPOINT=<YOUR-SECRET>"" >> api/app/.env
$ echo ""CW_GATEWAY_AUTHORIZATION_CLIENT_ID=<YOUR-SECRET>"" >> api/app/.env
$ echo ""CW_GATEWAY_AUTHORIZATION_CLIENT_SECRET=<YOUR-SECRET>"" >> api/app/.env
$ echo ""CW_MEMBER_NAME=<YOUR-SECRET>"" >> api/app/.env
$ echo ""CW_MEMBER_OID=<YOUR-SECRET>"" >> api/app/.env
$ echo ""CW_ORG_MANAGEMENT_PRIVATE_KEY=<YOUR-SECRET>"" >> api/app/.env
$ echo ""CW_ORG_MANAGEMENT_CERTIFICATE=<YOUR-SECRET>"" >> api/app/.env
$ echo ""CW_MEMBER_PRIVATE_KEY=<YOUR-SECRET>"" >> api/app/.env
$ echo ""CW_MEMBER_CERTIFICATE=<YOUR-SECRET>"" >> api/app/.env
```

#### **Optional analytics reporting**

The API server reports analytics to [PostHog](https://posthog.com/). This is optional.

If you want to set it up, add this to the `.env` file:

```shell
$ echo ""POST_HOG_API_KEY=<YOUR-API-KEY>"" >> api/app/.env
```

#### **Optional usage report**

The API server reports endpoint usage to an external service. This is optional.

A reachable service that accepts a `POST` request to the informed URL with the payload below is required:

```json
{
  ""cxId"": ""<the account ID>"",
  ""cxUserId"": ""<the ID of the user who's data is being requested>""
}
```

If you want to set it up, add this to the `.env` file:

```shell
$ echo ""USAGE_URL=<YOUR-URL>"" > api/app/.env
```

#### **Finalizing setting up the API Server**

Then to run the full back-end stack, use docker-compose to lauch a Postgres container, local instance of DynamoDB, and the Node server itself:

```shell
$ cd api/app
$ npm run start-docker-compose
```

...or, from the root folder...

```shell
$ npm run start-docker-compose -w api
```

Now, the backend services will be available at:

- API Server: `0.0.0/0:8080`
- Postgres: `localhost:5432`
- DynamoDB: `localhost:8000`

Another option is to have the dependency services running with docker compose and the back-end API running as regular NodeJS process (faster
to run and restart); this has the benefit of Docker Desktop managing the services and you likely only need to start the dependencies once.

```shell
$ cd api/app
$ npm run start-dependencies # might be able run it once
$ npm run dev
```

#### **Database Migrations**

The API Server uses Sequelize as an ORM, and its migration component to update the DB with changes as the application
evolves. It also uses Umzug for programatic migration execution and typing.

When the application runs it automatically executes all migrations located under `src/sequelize/migrations` (in ascending order)
before the code is atually executed.

If you need to undo/revert a migration manually, you can use the CLI, which is a wrapper to Umzug's CLI (still under heavy
development at the time of this writing).

It requires DB credentials on the environment variable `DB_CREDS` (values from `docker-compose.dev.yml`, update as needed):

```shell
$ export DB_CREDS='{""username"":""admin"",""password"":""admin"",""dbname"":""db"",""engine"":""postgres"",""host"":""localhost"",""port"":5432}'
```

Run the CLI with:

```shell
$ npm i -g ts-node # only needs to be run once
$ cd api/app
$ ts-node src/sequelize/cli
```

Alternatively, you can use a shortcut for migrations on local environment:

```shell
$ npm run db-local -- <cmd>
```

> Note: the double dash `--` is required so parameters after it go to sequelize cli; without it, parameters go to `npm`

Umzug's CLI is still in development at the time of this writing, so that's how one uses it:

- it will print the commands being sent to the DB
- followed by the result of the command
- it won't exit by default, you need to `ctrl+c`
- the command `up` executes all outstanding migrations
- the command `down` reverts one migration at a time

To create new migrations:

1. Duplicate a migration file on `./api/app/src/sequelize/migrations`
2. Rename the new file so the timestamp is close to the current time - it must be unique, migrations are executed in sorting order
3. Edit the migration file to perform the changes you want
   - `up` add changes to the DB (takes it to the new version)
   - `down` rolls back changes from the DB (goes back to the previous version)

#### **Additional stuff**

To do basic UI admin operations on the DynamoDB instance, you can do the following:

```shell
$ npm install -g dynamodb-admin # only needs to be run once
$ npm run ddb-admin # admin console will be available at http://localhost:8001/
```

To kill and clean-up the back-end, hit `CTRL + C` a few times, and run the following from the `api/app` directory:

```shell
$ docker-compose -f docker-compose.dev.yml down
```

To debug the backend, you can attach a debugger to the running Docker container by launching the `Docker: Attach to Node` configuration in VS Code. Note that this will support hot reloads 🔥🔥!

### **Connect Widget**

To run the Connect Widget:

```shell
$ cd connect-widget/app
$ npm run start # available on port 3001 by default
```

...or, from the root folder...

```shell
$ npm run start -w connect-widget
```

To debug the Connect Widget, you can run a Chrome window by launching the `Run Chrome` configuration in VS Code.

### Utils

The `./utils` folder contains utilities that help with the development of this and other opensource Metriport projects:

- [mock-webhook](https://github.com/metriport/metriport/blob/develop/utils/src/mock-webhook.ts): implements the Metriport webhook protocol, can be used by applications integrating with Metriport API as a reference to the behavior expected from these applications when using the webhook feature.
- [fhir-uploader](https://github.com/metriport/metriport/blob/develop/utils/src/fhir-uploader.ts): useful to insert synthetic/mock data from [Synthea](https://github.com/synthetichealth/synthea) into [FHIR](https://www.hl7.org/fhir) servers (see https://github.com/metriport/hapi-fhir-jpaserver).

Check the scripts on the folder's [package.json](https://github.com/metriport/metriport/blob/develop/utils/package.json) to see how to run these.

---

### Tests

Unit tests can be executed with:

```shell
$ npm run test
```

To run integration tests, make sure to check each package/folder README for requirements, but in general they can be
executed with:

```shell
$ npm run test:e2e
```

## **Self-Hosted Deployments**

### **API Key Setup**

Most endpoints require an API Gateway [API Key](https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-api-usage-plans.html). You can do it manually on AWS console or programaticaly through AWS CLI or SDK.

To do it manually:

1. Login to the AWS console;
1. Go to API Gateway;
1. Create a Usage Plan if you don't already have one;
1. Create an API Key;
   - the `value` field must follow this pattern: base 64 of ""`<KEY>:<UUID>`"", where:
   - `KEY` is a random key (e.g., generated with `nanoid`); and
   - `UUID` is the customer ID (more about this on [Initialization](#initialization))
1. Add the newly created API Key to a Usage Plan.

Now you can make requests to endpoints that require the an API Key by setting the `x-api-key` header.

### **Environment Setup**

1. You'll need to create and configure a deployment config file: `/infra/config/production.ts`. You can see `example.ts` in the same directory for a sample of what the end result should look like. Optionally, you can setup config files for `staging` and `sandbox` deployments, based on your environment needs. Then, proceed with the deployment steps below.

2. Configure the Connect Widget environment variables to the subdomain and domain you'll be hosting the API at in the config file: `connect-widget/app/.env.production`.

### **Deployment Steps**

1. First, deploy the secrets stack. This will setup the secret keys required to run the server using AWS Secrets Manager and create other infra pre-requisites. To deploy it, run the following commands (with `<config.stackName>` replaced with what you've set in your config file):

```shell
$ ./deploy.sh -e ""production"" -s ""<config.secretsStackName>""
```

2. After the previous steps are done, define all of the required keys in the AWS console by navigating to the Secrets Manager.

3. Then, to deploy the back-end execute the following command:

```shell
$ ./deploy.sh -e ""production"" -s ""<config.stackName>""
```

After deployment, the API will be available at the configured subdomain + domain.

4. Finally, to self-host the Connect widget, run the following:

```shell
$ ./deploy.sh -e ""production"" -s ""<config.connectWidget.stackName>""
```

Note: if you need help with the `deploy.sh` script at any time, you can run:

```shell
$ ./deploy.sh -h
```

### **Initialization**

The API Server works with the concept of ""Customer"", which is basically a tenant on the API Server DB.
There must be at least one customer on the API Server DB - you can think of it as your account in case you're
planning to have only one.

Each new Customer on the API Server should be initialized by calling the ""init"" endpoint with said customer ID:

```
POST /internal/init?cxId=<customer-id>
```

The customer ID must be a UUID.

## License

Distributed under the AGPLv3 License. See `LICENSE` for more information.

Copyright © Metriport 2022-present
"
26,IBM/Medical-Blockchain,Vue,"# Store private healthcare data off-chain and manage medical data using blockchain

Electronic medical records and data craves the need for innovation. The way patient health records are stored and secured today do not showcase our technological advancement in this area in the past decade, and hospitals continue to use age-old data management systems for patient data. This is partly due to strict regulations around privacy and security of medical data, which has stifled the use of latest technology to make medical data management more transparent and useful for both patients as well as doctors.

This code pattern showcases a medical data/access management platform built using blockchain. The application shows the platform from the point of view of 4 stakeholders -
* The solution admin is the admin of a conglomerate of hospitals, and has the highest of access levels in the hierarchy. They have the ability to onboard a new organization (hospital) to the conglomerate and assign/de-assign hospital admins on their dashboard.
* The organization (hospital) admin is the admin of a particular hospital which is part of the conglomerate/solution. They have the ability to onboard new users with the role of either patient or doctor, or remove a user.
* The doctor is a user in the organization with the appropriate role and has the ability to upload documents for their patients and download/view documents of their patients to which they have been granted access.
* The patient is a user in the organization with the appropriate role and has the ability to upload documents on their own, view them, view the document access logs and also manage access to their documents on their dashboard.

This code pattern is for developers who want to integrate with the Blockchain Solution Manager, Blockchain Document Store and the IBM Blockchain Platform. When you have completed it, you will understand how to:

* Connect the Blockchain Solution Manager and Blockchain Document Store with the IBM Blockchain Platform.
* Create a VueJS web app that has multiple dashboards on a single page application, which can communicate in realtime with each other.
* Create a NodeJS server that is deployed to Kubernetes on IBM Cloud, and connected with a Redis database deployed on the IBM Cloud.
* Store and retrieve data from a Redis datastore for persistent storage through a NodeJS server.
* Make REST calls to an external service.
* Use JWT (JSON web token) tokens for user management.

# Architecture flow

![Architecture flow](docs/doc-images/arch-flow.png?raw=true)

### Login flow
1. All the stakeholders of the application (solution admin, hospital admin, doctor and patient) begin the user flow by logging into their respective dashboards.
2. Clicking the login button leads to the login portal of the Blockchain Solution Manager, hosted on the IBM cloud.
3. The login portal uses OpenAPI Connect and allows the user the login through any onboarded identity provider (in our example, we have on-boarded IBMID ad GoogleID). Successful authentication leads to the JWT credentials for the user.

### Admin dashboard
4. The solution admin flow begins at the admin component, and requires the user to authenticate themselves through the login flow described above.
5. After successful authentication, the user can access the solution admin dashboard. They are able to view the solution, and add/remove hospitals from the solution using the Admin API's.
6. All the admin API's connect with the Blockchain Solution Manager through REST to process the user queries.
7. The Blockchain Solution Manager connects with the IBM Blockchain Platform and updates the ledger appropriately.

### Organization dashboard
8. The hospital admin flow begins at the organization component, and requires the user to authenticate themselves through the login flow described above.
9. After successful authentication, the user can access the hospital admin dashboard. They are able to add/remove any user in their respective hospital with the on-boarded roles (patient/doctor in our case) using the organization API's.
10. All the organization API's connect with the Blockchain Solution Manager through REST to process the user queries.
11. The Blockchain Solution Manager connects with the IBM Blockchain Platform and updates the ledger appropriately.

### Doctor dashboard
12. The doctor flow begins at the doctor component, and requires the user to authenticate themselves through the login flow described above.
13. After successful authentication, the user can access the doctor dashboard. They are able to upload a medical record for a patient who is part of their hospital and download any medical record associated with a patient to which they have access to, using the Doctor API's. The ACL's for all the patient documents is application level and is maintained through the Document ACL flow described below.
14. All the doctor API's connect with the Blockchain Document Store through REST to process the user queries.
15. The Blockchain Document Store connects with the IBM Blockchain Platform and updates the ledger appropriately.

### Patient dashboard
16. The patient flow begins at the patient component, and requires the user to authenticate themselves through the login flow described above.
17. After successful authentication, the user can access the patient dashboard. They are able to upload a medical record for themselves, download any of their medical records, view the access logs of their documents, and view/manage permissions to their documents, using the Patient API's. The ACL's for all the documents is application level and is maintained through the document ACL flow described below.
18. All the patient API's connect with the Blockchain Document Store through REST to process the user queries.
19. The Blockchain Document Store connects with the IBM Blockchain Platform and updates the ledger appropriately.

### Document access control list (ACL) flow
20. The doctor and patient component are connected with the Redis API's that invoke methods to manage the document level access control across hospitals.
21. The Redis API's talk to a NodeJS server deployed in a Docker container in a Kubernetes cluster on the IBM Cloud.
22. The server talks to two Redis databases which hold the access-per-document and access-per-user permissions. 

# Included components

+ [IBM Blockchain Platform](https://console.bluemix.net/docs/services/blockchain/howto/ibp-v2-deploy-iks.html#ibp-v2-deploy-iks) gives you total control of your blockchain network with a user interface that can simplify and accelerate your journey to deploy and manage blockchain components on the IBM Cloud Kubernetes Service.
+ [IBM Blockchain Solution Manager:](https://cloud.ibm.com/docs/services/blockchain-document-store?topic=blockchain-document-store-blockchain-solution-manager-api-acls) The Blockchain Document Store service includes the IBM Blockchain Solution Manager component, which enables organizations to easily manage blockchain networks, solutions, services, and users.
+ [IBM Blockchain Document Store](https://cloud.ibm.com/docs/services/blockchain-document-store?topic=blockchain-document-store-getting-started#getting-started) is a comprehensive document management service for IBM Blockchain Platform business networks.
+ [IBM Cloud Kubernetes Service](https://www.ibm.com/cloud/container-service) creates a cluster of compute hosts and deploys highly available containers. A Kubernetes cluster lets you securely manage the resources that you need to quickly deploy, update, and scale applications.
+ [IBM Cloud Databases for Redis Service:](https://console.bluemix.net/catalog/services/databases-for-redis) Redis is an open source, in-memory data structure store, used as a database, cache and message broker. It supports data structures such as strings, hashes, lists, sets, sorted sets with range queries, bitmaps, hyperloglogs and geospatial indexes with radius queries.

## Featured technologies

* [Nodejs](https://www.nodejs.org/) is an open-source, cross-platform JavaScript run-time environment that executes JavaScript code server-side.
* [Vuejs](https://vuejs.org/) is a progressive framework for building user interfaces.
* [Redis](https://redis.io/) is an open source (BSD licensed), in-memory data structure store, used as a database, cache and message broker.
* [Bootstrap](https://getbootstrap.com/) is a free and open-source front-end Web framework. It contains HTML and CSS-based design templates for typography, forms, buttons, navigation and other interface components, as well as optional JavaScript extensions.
* [Docker](https://www.docker.com/) is a computer program that performs operating-system-level virtualization, also known as Containerization.

## Prerequisites

We find that Blockchain can be finicky when it comes to installing Node. We want to share this [StackOverflow response](https://stackoverflow.com/questions/49744276/error-cannot-find-module-api-hyperledger-composer) - because many times the errors you see with Compose are derived in having installed either the wrong Node version or took an approach that is not supported by Compose:

* [IBM Cloud account](https://cloud.ibm.com/registration/?target=%2Fdashboard%2Fapps)
* [Docker](https://www.docker.com/products) - latest
* [Docker Compose](https://docs.docker.com/compose/overview/) - latest
* [NPM](https://www.npmjs.com/get-npm) - latest
* [nvm]() - latest
* [Node.js](https://nodejs.org/en/download/) - Node v8.9.x
* [Git client](https://git-scm.com/downloads) - latest


# Running the application

## Manually deploy to local machine
1. [Set up your machine](#1-set-up-your-machine)
2. [Create IBM cloud services](#2-create-ibm-cloud-services)
3. [Create a solution](#3-create-a-solution)
4. [Clone the repository](#4-clone-the-repository)
5. [Modify the configuration files](#5-modify-the-configuration-files)
6. [Run the application](#6-run-the-application)

### 1. Set up your machine

Install the following dependencies -

- [Docker](https://www.docker.com/): Go to the Docker website and download the installer. After installation, run Docker.
- [git](https://git-scm.com/): Install `git` which is a free and open source distributed version control system.

### 2. Create IBM cloud services

* Create the [IBM Cloud Kubernetes Service](https://cloud.ibm.com/catalog/infrastructure/containers-kubernetes).  You can find the service in the `Catalog`. For this code pattern, we can use the `Free` cluster, and give it a name.  Note, that the IBM Cloud allows one instance of a free cluster and expires after 30 days.

<br>
<p align=""center"">
  <img src=""docs/doc-gifs/1.gif"">
</p>
<br>

* Create two instances of [Databases for Redis Service](https://cloud.ibm.com/catalog/services/databases-for-redis).  You can find the service in the `Catalog`.

<br>
<p align=""center"">
  <img src=""docs/doc-gifs/2.gif"">
</p>
<br>

  > Note: You can use just one instance of Redis as well. Modify the code in the server repository to allow for this.

* Create the [IBM Blockchain Service](https://cloud.ibm.com/catalog/services/ibm-blockchain-5-prod). You can find the service in the `Catalog`.

<br>
<p align=""center"">
  <img src=""docs/doc-gifs/3.gif"">
</p>
<br>

* Create the `Blockchain document store` and `Blockchain solution manager` services. These services are not currently available publicly on the `IBM cloud catalog`. You can reach out to `Rak-Joon Choi (rak-joon.choi@us.ibm.com)` to provision these services for you. Follow the service [documentation](https://cloud.ibm.com/docs/services/blockchain-document-store?topic=blockchain-document-store-getting-started#getting-started) to connect the `Blockchain document store` to the `Blockchain service`.

<br>
<p align=""center"">
  <img src=""docs/doc-gifs/4.gif"">
</p>
<br>

### 3. Create a solution

* After configuring your services in the previous step, we now move on to creating a solution using our custom swagger url for the `blockchain solution manager` service. Go to the `Patch endpoint (/v1/solutions)` under `Solution` and authorize using the api by going to the `/v1/logins` url in a new tab, logging in as `Administrator`, and getting the JWT. Add the token prepended by `bearer` such that it looks like `bearer <JWT>`. After authorization, click on `try it out` to execute the api, and paste the following JSON in the `on-boarding` section. Give the name `medrec_demo` to the solution.

```
{
  ""onboardingdata"": {
    ""solution"": {
      ""id"": ""medrec_demo"",
      ""name"": ""demo for medrec pattern""
    },
    ""roles"": [
      {
        ""id"": ""role_patient"",
        ""name"": ""Patient"",
        ""solutionId"": ""medrec_demo"",
        ""isBlockchainRole"": true
      },
      {
        ""id"": ""role_doctor"",
        ""name"": ""Doctor"",
        ""solutionId"": ""medrec_demo"",
        ""isBlockchainRole"": true
      }
    ]
  }
}
```

<br>
<p align=""center"">
  <img src=""docs/doc-gifs/5.gif"">
</p>
<br>

* After creating the solution successfully, add yourself as the admin of the solution. Go to the `Post endpoint (/v1/solutions/{solutionId}/administrators)` under `Solution` and authorize using the api by going to the `/v1/logins` url in a new tab, logging in as `Administrator`, and getting the JWT. Add the token prepended by `bearer` such that it looks like `bearer <JWT>`. After authorization, click on `try it out` to execute the api, and type your email id under `solutionAdministrators` in the JSON object. Provide `medrec_demo` as the `solutionId`.

<br>
<p align=""center"">
  <img src=""docs/doc-gifs/6.gif"">
</p>
<br>

### 4. Clone the repository

```
git clone https://github.com/IBM/Medical-Blockchain.git
cd Medical-Blockchain
```

### 5. Modify the configuration files

* Modify the redis config file:
  - Go to the previously provisioned redis services on IBM Cloud.
  - Click on `Service credentials`.
  - Click on `New credential` button.
  - Once the new credentials are created, click on `view credentials`.
  - From the JSON object, extract the URI from `connection.rediss.composed[0]`.
  - From the JSON object, extract the certificate from `connection.rediss.certificate.certificate_base64`.
  - Navigate to the `server/config.json` file in the cloned repository.
  - Replace the URI and certificate values in the marked places.
  - Repeat the steps for the second provisioned service, and enter it in the second spot in the config file.

<br>
<p align=""center"">
  <img src=""docs/doc-gifs/7.gif"">
</p>
<br>

* Modify the blockchain config file:
  - Go to the `/v1/logins` url for your blockchain document store service.
  - Login as administrator.
  - Extract the `iss` field from the decoded JWT and remove `/onboarding` string from it.
  - Navigate to the `src/secrets/config.json` file in the cloned repository.
  - Replace the `iss` field with the extracted value above.
  - Replace the `blockchain_channel` field with the name of the channel provided during connecting the blockchain service to the document store.

<br>
<p align=""center"">
  <img src=""docs/doc-gifs/8.gif"">
</p>
<br>

### 6. Run the application

* Running the application locally:
  - To run the application on the local system, execute the `run-application.sh` file.
  - Go to `localhost:8080` to see the running application.

<br>
<p align=""center"">
  <img src=""docs/doc-gifs/9.gif"">
</p>
<br>

* Running the application on kubernetes:
  - Navigate to server directory - `cd server`.
  - Build the docker image for the server - `docker build -t <DOCKERHUB_USERNAME>/medrec-server .`
  - Replace the image name in `manifest.yml`, where indicated.
  - Apply the manifest to the previously provisioned kubernetes cluster.
  - Navigate to `/src/apis/RedisApi.js` and replace the `baseURL` value with the Kubernetes load balancer IP.
  - Build and run the Vue application by executing the below in the repository home.
  - Go to `localhost:8080` to see the running application.

```
docker build -t medrec-vue .
docker run -d --restart always --name medrec-vue -p 8080:8080 medrec-vue
```

> Note: You can also deploy the Vue App to Kubernetes, by modifying the manifest.yml to support two pods.

# License

This code pattern is licensed under the Apache Software License, Version 2.  Separate third-party code objects invoked within this code pattern are licensed by their respective providers pursuant to their own separate licenses. Contributions are subject to the [Developer Certificate of Origin, Version 1.1 (DCO)](https://developercertificate.org/) and the [Apache Software License, Version 2](http://www.apache.org/licenses/LICENSE-2.0.txt).

[Apache Software License (ASL) FAQ](http://www.apache.org/foundation/license-faq.html#WhatDoesItMEAN)
"
27,ESS-LLP/smarte,Python,"## This repo is no longer maintained
To try out the features setup a new bench and install erpnext from https://github.com/ESS-LLP/erpnext-medical

# smarteCare

Modules on frappe to suite General Practice, Hospital and Laboratory Management. It is designed to work seamlessly with ERPNext so that healthcare providers can administer their day today operations in a smarter way.

## Installation
You will need a frappe site with erpnext installed. Visit https://github.com/frappe/bench

	bench get-app smarte https://github.com/ESS-LLP/smarte.git
	bench new-site site.name
	bench --site site.name install-app erpnext
	bench --site site.name install-app smarte

## Demo and Website
Visit [smarteCare](https://smarteHIS.com) to see live demo

## Feature list
#### General Practice / Clinic Out Patient
* Appointments scheduling
* Consultation - Prescriptions, Investigations etc.

#### Laboratory Management
* Lab Procedures
* Lab Test Result Templates and Printing / Emailing
* Sample Collection
* Configurable workflow - Auto create sample collection task and lab procedure on Invoice submit

#### Hospital / In-patient Management(beta)
* In-patient admission, facility allotment
* Infrastructure management - Wards, Rooms, Beds
* Service Units - Nurses’ stations, Diagnostic test centres, Housekeeping units etc. and user assignment
* Service Tasks (Tasks for service units)
* Configurable workflow - Auto create service tasks

#### General
* Send SMS - automatic / manual
* Resource Scheduling (Physicians, Service Units etc.)

#### License
GNU / General Public License v3.
"
28,mp2893/retain,Python,"RETAIN
=========================================

RETAIN is an interpretable predictive model for healthcare applications. Given patient records, it can make predictions while explaining how each medical code (diagnosis codes, medication codes, or procedure codes) at each visit contributes to the prediction. The interpretation is possible due to the use of neural attention mechanism.

[![RETAIN Interpretation Demo](http://mp2893.com/images/thumbnail.png)](https://youtu.be/co3lTOSgFlA?t=1m46s ""RETAIN Interpretation Demo - Click to Watch!"")
Using RETAIN, you can calculate how positively/negatively each medical code (diagnosis, medication, or procedure code) at different visits contributes to the final score. In this case, we are predicting whether the given patient will be diagnosed with Heart Failure (HF). You can see that the codes that are highly related to HF makes positive contributions. RETAIN also learns to pay more attention to new information than old information. You can see that Cardiac Dysrythmia (CD) makes a bigger contribution as it occurs in the more recent visit.

#### Relevant Publications

RETAIN implements an algorithm introduced in the following [paper](http://papers.nips.cc/paper/6321-retain-an-interpretable-predictive-model-for-healthcare-using-reverse-time-attention-mechanism):

	RETAIN: An Interpretable Predictive Model for Healthcare using Reverse Time Attention Mechanism
	Edward Choi, Mohammad Taha Bahadori, Joshua A. Kulas, Andy Schuetz, Walter F. Stewart, Jimeng Sun,
	NIPS 2016, pp.3504-3512

#### Notice

The RETAIN paper formulates the model as being able to make prediction at each timestep (e.g. try to predict what diagnoses the patient will receive at each visit), and treats sequence classification (e.g. Given a patient record, will he be diagnosed with heart failure in the future?) as a special case, since sequence classification makes the prediction at the last timestep only.

This code, however, is implemented to perform the sequence classification task. For example, you can use this code to predict whether the given patient is a heart failure patient or not. Or you can predict whether this patient will be readmitted in the future. The more general version of RETAIN will be released in the future.
	
#### Running RETAIN

**STEP 1: Installation**  

1. Install [python](https://www.python.org/), [Theano](http://deeplearning.net/software/theano/index.html). We use Python 2.7, Theano 0.8. Theano can be easily installed in Ubuntu as suggested [here](http://deeplearning.net/software/theano/install_ubuntu.html#install-ubuntu)

2. If you plan to use GPU computation, install [CUDA](https://developer.nvidia.com/cuda-downloads)

3. Download/clone the RETAIN code  

**STEP 2: Fast way to test RETAIN with MIMIC-III**  
This step describes how to train RETAIN, with minimum number of steps using MIMIC-III, to predict patients' mortality using their visit records.

0. You will first need to request access for [MIMIC-III](https://mimic.physionet.org/gettingstarted/access/), a publicly avaiable electronic health records collected from ICU patients over 11 years. 

1. You can use ""process_mimic.py"" to process MIMIC-III dataset and generate a suitable training dataset for RETAIN. 
Place the script to the same location where the MIMIC-III CSV files are located, and run the script.
The execution command is `python process_mimic.py ADMISSIONS.csv DIAGNOSES_ICD.csv PATIENTS.csv <output file>`.

2. Run RETAIN using the "".seqs"" and "".morts"" file generated by process_mimic.py. 
The "".seqs"" file contains the sequence of visits for each patient. Each visit consists of multiple diagnosis codes.
However we recommend using "".3digitICD9.seqs"" file instead, as the results will be much more interpretable.
(Or you could use [Single-level Clical Classification Software for ICD9](https://www.hcup-us.ahrq.gov/toolssoftware/ccs/ccs.jsp#examples) to decrease the number of codes to a couple of hundreds, which will even more improve the performance)
The "".morts"" file contains the sequence of mortality labels for each patient. 
The command is `python retain.py <3digitICD9.seqs file> 942 <morts file> <output path> --simple_load --n_epochs 100 --keep_prob_context 0.8 --keep_prob_emb 0.5`.
`942` is the number of the entire 3-digit ICD9 codes used in the dataset.

3. To test the model for interpretation, please refer to Step 6. I personally found that _perinatal jaundice (ICD9 774)_ has high correlation with mortality.

4. The model reaches AUC above 0.8 with the above command, but the interpretations are not super clear. 
You could tune the hyper-parameters, but I doubt things will dramatically improve. 
After all, only 7,500 patients made more than a single hospital visit, and most of them have only two visits.

**STEP 3: How to prepare your own dataset**  

1. RETAIN's training dataset needs to be a Python cPickled list of list of list. The outermost list corresponds to patients, the intermediate to the visit sequence each patient made, and the innermost to the medical codes (e.g. diagnosis codes, medication codes, procedure codes, etc.) that occurred within each visit.
First, medical codes need to be converted to an integer. Then a single visit can be seen as a list of integers. Then a patient can be seen as a list of visits.
For example, [5,8,15] means the patient was assigned with code 5, 8, and 15 at a certain visit.
If a patient made two visits [1,2,3] and [4,5,6,7], it can be converted to a list of list [[1,2,3], [4,5,6,7]].
Multiple patients can be represented as [[[1,2,3], [4,5,6,7]], [[2,4], [8,3,1], [3]]], which means there are two patients where the first patient made two visits and the second patient made three visits.
This list of list of list needs to be pickled using cPickle. We will refer to this file as the ""visit file"".

2. The total number of unique medical codes is required to run RETAIN.
For example, if the dataset is using 14,000 diagnosis codes and 11,000 procedure codes, the total number is 25,000. 

3. The label dataset (let us call this ""label file"") needs to be a Python cPickled list. Each element corresponds to the true label of each patient. For example, 1 can be the case patient and 0 can be the control patient. If there are two patients where only the first patient is a case, then we should have [1,0].

4. The ""visit file"" and ""label file"" need to have 3 sets respectively: training set, validation set, and test set.
The file extension must be "".train"", "".valid"", and "".test"" respectivley.  
For example, if you want to use a file named ""my_visit_sequences"" as the ""visit file"", then RETAIN will try to load ""my_visit_sequences.train"", ""my_visit_sequences.valid"", and ""my_visit_sequences.test"".  
This is also true for the ""label file""

5. You can use the time information regarding the visits as an additional source of information. Let us call this ""time file"".
Note that the time information could be anything: duration between consecutive visits, cumulative number of days since the first visit, etc.
""time file"" needs to be prepared as a Python cPickled list of list. The outermost list corresponds to patients, and the innermost to the time information of each visit.
For example, given a ""visit file"" [[[1,2,3], [4,5,6,7]], [[2,4], [8,3,1], [3]]], its corresponding ""time file"" could look like [[0, 15], [0, 45, 23]], if we are using the duration between the consecutive visits. (of course the numbers are fake, and I've set the duration for the first visit to zero.)
Use `--time_file <path to time file>` option to use ""time file""
Remember that the "".train"", "".valid"", "".test"" rule also applies to the ""time file"" as well.

**Additional: Using your own medical code representations**  
RETAIN internally learns the vector representation of medical codes while training. These vectors are initialized with random values of course.  
You can, however, also use your own medical code representations, if you have one. (They can be trained by using Skip-gram like algorithms. Refer to [Med2Vec](http://www.kdd.org/kdd2016/subtopic/view/multi-layer-representation-learning-for-medical-concepts) or [this](http://arxiv.org/abs/1602.03686) for further details.)
If you want to provide the medical code representations, it has to be a list of list (basically a matrix) of N rows and M columns where N is the number of unique codes in your ""visit file"" and M is the size of the code representations.
Specify the path to your code representation file using `--embed_file <path to embedding file>`.
Additionally, even if you use your own medical code representations, you can re-train (a.k.a fine-tune) them as you train RETAIN.
Use `--embed_finetune` option to do this. If you are not providing your own medical code representations, RETAIN will use randomly initialized one, which obviously requires this fine-tuning process. Since the default is to use the fine-tuning, you do not need to worry about this.

**STEP 4: Running RETAIN**  

1. The minimum input you need to run RETAIN is the ""visit file"", the number of unique medical codes in the ""visit file"", 
the ""label file"", and the output path. The output path is where the learned weights and the log will be saved.  
`python retain.py <visit file> <# codes in the visit file> <label file> <output path>`  

2. Specifying `--verbose` option will print training process after each 10 mini-batches.

3. You can specify the size of the embedding W_emb, the size of the hidden layer of the GRU that generates alpha, and the size of the hidden layer of the GRU that generates beta.
The respective commands are `--embed_size <integer>`, `--alpha_hidden_dim_size <integer>`, and `--beta_hidden_dim_size <integer>`.
For example `--alpha_hidden_dim_size 128` will tell RETAIN to use a GRU with 128-dimensional hidden layer for generating alpha.

4. Dropouts are applied to two places: 1) to the input embedding, 2) to the context vector c_i. The respective dropout rates can be adjusted using `--keep_prob_embed {0.0, 1.0}` and `--keep_prob_context {0.0, 1.0}`. Dropout values affect the performance so it is recommended to tune them for your data.

5. L2 regularizations can be applied to W_emb, w_alpha, W_beta, and w_output.

6. Additional options can be specified such as the size of the batch size, the number of epochs, etc. Detailed information can be accessed by `python retain.py --help`

7. My personal recommendation: use mild regularization (0.0001 ~ 0.001) on all four weights, and use moderate dropout on the context vector only. But this entirely depends on your data, so you should always tune the hyperparameters for yourself.

**STEP 5: Getting your results**  

RETAIN checks the AUC of the validation set after each epoch, and if it is higher than all previous values, it will save the current model. The model file is generated by [numpy.savez_compressed](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.savez_compressed.html).

**Step 6: Testing your model**

1. Using the file ""test_retain.py"", you can calculate the contributions of each medical code at each visit. First you need to have a trained model that was saved by numpy.savez_compressed. Note that you need to know the configuration with which you trained RETAIN (e.g. use of `--time_file`, use of `--use_log_time`.)

2. Again, you need the ""visit file"" and ""label file"" prepared in the same way. This time, however, you do not need to follow the "".train"", "".valid"", "".test"" rule. The testing script will try to load the file name as given.

3. You also need the mapping information between the actual string medical codes and their integer codes. 
(e.g. ""Hypertension"" is mapped to 24) 
This file (let's call this ""mapping file"") need to be a Python cPickled dictionary where the keys are the string medical codes and the values are the corresponding intergers. 
(e.g. The mapping file generated by process_mimic.py is the "".types"" file)
This file is required to print the contributions of each medical code in a user-friendly format. 

4. For the additional options such as `--time_file` or `--use_log_time`, you should use exactly the same configuration with which you trained the model. For more detailed information, use ""--help"" option.

5. The minimum input to run the testing script is the ""model file"", ""visit file"", ""label file"", ""mapping file"", and ""output file"". ""output file"" is where the contributions will be stored.
`python test_retain.py <model file> <visit file> <label file> <mapping file> <output file>`
"
29,PacktPublishing/Applied-Machine-Learning-For-Healthcare,HTML,"# Applied-Machine-Learning-For-Healthcare
Applied Machine Learning For Healthcare, published by Packt
"
30,openmrs/openmrs-core,Java,"<img src=""https://talk.openmrs.org/uploads/default/original/2X/f/f1ec579b0398cb04c80a54c56da219b2440fe249.jpg"" alt=""OpenMRS""/>

[![Build Status](https://travis-ci.org/openmrs/openmrs-core.svg?branch=master)](https://travis-ci.org/openmrs/openmrs-core) [![Coverage Status](https://coveralls.io/repos/github/openmrs/openmrs-core/badge.svg?branch=master)](https://coveralls.io/github/openmrs/openmrs-core?branch=master) [![Codacy Badge](https://api.codacy.com/project/badge/Grade/a51303ee46c34775a7c31c8d6016da6b)](https://www.codacy.com/app/openmrs/openmrs-core?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=openmrs/openmrs-core&amp;utm_campaign=Badge_Grade)

api: [![API](https://snyk.io/test/github/openmrs/openmrs-core/badge.svg?targetFile=api%2Fpom.xml)](https://snyk.io/test/github/openmrs/openmrs-core?targetFile=api%2Fpom.xml)
test: [![test](https://snyk.io/test/github/openmrs/openmrs-core/badge.svg?targetFile=test%2Fpom.xml)](https://snyk.io/test/github/openmrs/openmrs-core?targetFile=test%2Fpom.xml)
tools: [![tools](https://snyk.io/test/github/openmrs/openmrs-core/badge.svg?targetFile=tools%2Fpom.xml)](https://snyk.io/test/github/openmrs/openmrs-core?targetFile=tools%2Fpom.xml)
web: [![web](https://snyk.io/test/github/openmrs/openmrs-core/badge.svg?targetFile=web%2Fpom.xml)](https://snyk.io/test/github/openmrs/openmrs-core?targetFile=web%2Fpom.xml)
webapp: [![webapp](https://snyk.io/test/github/openmrs/openmrs-core/badge.svg?targetFile=webapp%2Fpom.xml)](https://snyk.io/test/github/openmrs/openmrs-core?targetFile=webapp%2Fpom.xml)

OpenMRS is a patient-based medical record system focusing on giving providers a free customizable electronic medical record system (EMR).

The mission of OpenMRS is to improve health care delivery in resource-constrained environments by coordinating a global community that creates a robust, scalable, user-driven, open source medical record system platform.

#### Table of Contents

1. [Build](#build)
   1. [Prerequisites](#prerequisites)
   2. [Build Command](#build-command)
   3. [Deploy](#deploy)
2. [Docker build](#docker-build)
3. [Navigating the repository](#navigating-the-repository)
4. [Software Development Kit](#software-development-kit)
5. [Extending OpenMRS with Modules](#extending-openmrs-with-modules)
6. [Documentation](#documentation)
   1. [Developer guides](#developer-guides)
   2. [Wiki](#wiki)
   3. [Website](#website)
7. [Contributing](#contributing)
   1. [Code](#code)
   2. [Code Reviews](#code-reviews)
   3. [Translation](#translation)
8. [Issues](#issues)
9. [Community](#community)
10. [Support](#support)
11. [License](#license)

## Build

### Prerequisites

#### Java

OpenMRS is a Java application which is why you need to install a Java JDK.

If you want to build the master branch you will need a Java JDK of minimum version 8.

#### Maven

Install the build tool [Maven](https://maven.apache.org/).

You need to ensure that Maven uses the Java JDK needed for the branch you want to build.

To do so execute

```bash
mvn -version
```

which will tell you what version Maven is using. Refer to the [Maven docs](https://maven.apache.org/configure.html) if you need to configure Maven.

#### Git

Install the version control tool [git](https://git-scm.com/) and clone this repository with

```bash
git clone https://github.com/openmrs/openmrs-core.git
```

### Build Command

After you have taken care of the [Prerequisites](#prerequisites)

Execute the following

```bash
cd openmrs-core
mvn clean package
```

This will generate the OpenMRS application in `webapp/target/openmrs.war` which you will have to deploy into an application server like for example [tomcat](https://tomcat.apache.org/) or [jetty](http://www.eclipse.org/jetty/).

### Deploy

For development purposes you can simply deploy the `openmrs.war` into the application server jetty via

```bash
cd openmrs-core/webapp
mvn jetty:run
```

If all goes well (check the console output) you can access the OpenMRS application at `localhost:8080/openmrs`.

Refer to [Getting Started as a Developer - Maven](https://wiki.openmrs.org/display/docs/Maven) for some more information
on useful Maven commands and build options.

## Docker build

Docker builds are still work in progress. We appreciate any feedback and improvements to the process.

The only prerequisite needed is Docker. 

In order to build a development version run:
```bash 
docker-compose build
```
It calls `mvn install` by default. If you would like to customize mvn build arguments you can do so by running:
```bash
docker-compose build --build-arg MVN_ARGS='install -DskipTests'
```
It is also possible to use the built dev image to run jetty:
```bash
docker-compose up
```

In order to build a production version run:
```bash
docker-compose -f docker-compose.yml build
```
It first builds the dev image and then an image with Tomcat and openmrs.war. 
It has no dev dependencies.

The production version can be run with:
```bash
docker-compose -f docker-compose.yml up
```

## Navigating the repository

The project tree is set up as follows:

<table>
 <tr>
  <td>api/</td>
  <td>Java and resource files for building the java api jar file.</td>
 </tr>
 <tr>
  <td>tools/</td>
  <td>Meta code used during compiling and testing. Does not go into any released binary (like doclets).</td>
 </tr>
 <tr>
  <td>web/</td>
  <td>Java and resource files that are used in the webapp/war file.</td>
 </tr>
 <tr>
  <td>webapp/</td>
  <td>files used in building the war file (contains JSP files on older versions).</td>
 </tr>
 <tr>
  <td>pom.xml</td>
  <td>The main maven file used to build and package OpenMRS.</td>
 </tr>  
</table>

## Software Development Kit

For rapid development of modules and the OpenMRS Platform code check out the
awesome SDK at

https://wiki.openmrs.org/display/docs/OpenMRS+SDK

## Extending OpenMRS with Modules

OpenMRS has a modular architecture that allows developers to extend the OpenMRS core functionality by creating modules that can easily be added or removed to meet the needs of a specific implementation.

Before creating your own module go to the [OpenMRS Module Repository](https://addons.openmrs.org/) and see if there is already a module for your specific use case. If so deploy and try it and if a functionality is missing join the developers of the module to add a feature.

If you haven't found what you were looking for refer to the [Module - wiki](https://wiki.openmrs.org/display/docs/Modules) to learn how you can create a new module.

## Documentation

### Developer guides

If you want to contribute please refer to these resources

* [Getting Started as a Developer](https://wiki.openmrs.org/display/docs/Get+Started+as+a+Developer)
* [How To Configure Your IDE](https://wiki.openmrs.org/display/docs/How-To+Setup+And+Use+Your+IDE)
* [How To Make a Pull Request](https://wiki.openmrs.org/display/docs/Pull+Request+Tips)

### Wiki

If you are looking for detailed guides on how to install, configure, contribute and
extend OpenMRS visit

http://wiki.openmrs.org

### Website

If you are looking for more information regarding OpenMRS as an organization
check

http://openmrs.org

## Contributing

Contributions are very welcome, we can definitely use your help!

OpenMRS organizes the privileges of its contributors in developer stages which
are documented [here](https://wiki.openmrs.org/display/RES/OpenMRS+Developer+Stages).

Read the following sections to find out where you could help.

### Code

Check out our [contributing guidelines](CONTRIBUTING.md), read through the [Developer guides](#developer-guides).

After you've read up :eyeglasses: [grab an introductory issue](https://wiki.openmrs.org/display/docs/Contribute+as+a+Developer#ContributeasaDeveloper-Workonanissue) that is `Ready For Work`.

### Code Reviews

You might not have the time to develop yourself but enough experience with
OpenMRS and/or reviewing code, your help on code reviews will be much
appreciated!

Read

https://wiki.openmrs.org/display/docs/Code+Review

and get started with re-:eyes: pull requests!

### Translation

We use

https://www.transifex.com/openmrs/OpenMRS/

to manage our translations.

The `messages.properties` file in this repository is our single source of
truth. It contains key, value pairs for the English language which is the
default.

Transifex fetches updates to this file every night which can then be translated
by you and me on transifex website itself. At any time we can pull new translations from transifex
back into this repository. Other languages like for ex. Spanish will then be in
the `messages_es.properties` file.

If you would like to know how to help with translations see

http://openmrs.org/join-the-community/translate/

## Issues

If you want help fix existing issues or you found a bug and want to tell us please go to

https://issues.openmrs.org

## Community

[![OpenMRS Talk](https://omrs-shields.psbrandt.io/custom/openmrs/talk/F26522?logo=openmrs)](http://talk.openmrs.org)
[![OpenMRS IRC](https://img.shields.io/badge/openmrs-irc-EEA616.svg?logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI2MTIiIGhlaWdodD0iNjEyIiB2aWV3Qm94PSIwIDAgNjEyIDYxMiI%2BPHBhdGggZD0iTTE1MyAyMjkuNWMtMjEuMTMzIDAtMzguMjUgMTcuMTE3LTM4LjI1IDM4LjI1UzEzMS44NjcgMzA2IDE1MyAzMDZjMjEuMTE0IDAgMzguMjUtMTcuMTE3IDM4LjI1LTM4LjI1UzE3NC4xMzMgMjI5LjUgMTUzIDIyOS41em0xNTMgMGMtMjEuMTMzIDAtMzguMjUgMTcuMTE3LTM4LjI1IDM4LjI1UzI4NC44NjcgMzA2IDMwNiAzMDZjMjEuMTE0IDAgMzguMjUtMTcuMTE3IDM4LjI1LTM4LjI1UzMyNy4xMzMgMjI5LjUgMzA2IDIyOS41em0xNTMgMGMtMjEuMTMzIDAtMzguMjUgMTcuMTE3LTM4LjI1IDM4LjI1UzQzNy44NjcgMzA2IDQ1OSAzMDZzMzguMjUtMTcuMTE3IDM4LjI1LTM4LjI1UzQ4MC4xMzMgMjI5LjUgNDU5IDIyOS41ek0zMDYgMEMxMzcuMDEyIDAgMCAxMTkuODc1IDAgMjY3Ljc1YzAgODQuNTE0IDQ0Ljg0OCAxNTkuNzUgMTE0Ljc1IDIwOC44MjZWNjEybDEzNC4wNDctODEuMzRjMTguNTUyIDMuMDYyIDM3LjYzOCA0Ljg0IDU3LjIwMyA0Ljg0IDE2OS4wMDggMCAzMDYtMTE5Ljg3NSAzMDYtMjY3Ljc1UzQ3NS4wMDggMCAzMDYgMHptMCA0OTcuMjVjLTIyLjMzOCAwLTQzLjkxLTIuNi02NC42NDMtNy4wMmwtOTAuMDQgNTQuMTI0IDEuMjA0LTg4LjdDODMuNSA0MTQuMTMzIDM4LjI1IDM0NS41MTMgMzguMjUgMjY3Ljc1YzAtMTI2Ljc0IDExOS44NzUtMjI5LjUgMjY3Ljc1LTIyOS41czI2Ny43NSAxMDIuNzYgMjY3Ljc1IDIyOS41UzQ1My44NzUgNDk3LjI1IDMwNiA0OTcuMjV6IiBmaWxsPSIjZmZmIi8%2BPC9zdmc%2B)](http://irc.openmrs.org)
[![OpenMRS Telegram](https://img.shields.io/badge/openmrs-telegram-009384.svg?logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNDAgMjQwIj48ZGVmcz48bGluZWFyR3JhZGllbnQgaWQ9ImEiIHgxPSIuNjY3IiB5MT0iLjE2NyIgeDI9Ii40MTciIHkyPSIuNzUiPjxzdG9wIHN0b3AtY29sb3I9IiMzN2FlZTIiIG9mZnNldD0iMCIvPjxzdG9wIHN0b3AtY29sb3I9IiMxZTk2YzgiIG9mZnNldD0iMSIvPjwvbGluZWFyR3JhZGllbnQ%2BPGxpbmVhckdyYWRpZW50IGlkPSJiIiB4MT0iLjY2IiB5MT0iLjQzNyIgeDI9Ii44NTEiIHkyPSIuODAyIj48c3RvcCBzdG9wLWNvbG9yPSIjZWZmN2ZjIiBvZmZzZXQ9IjAiLz48c3RvcCBzdG9wLWNvbG9yPSIjZmZmIiBvZmZzZXQ9IjEiLz48L2xpbmVhckdyYWRpZW50PjwvZGVmcz48Y2lyY2xlIGN4PSIxMjAiIGN5PSIxMjAiIHI9IjEyMCIgZmlsbD0idXJsKCNhKSIvPjxwYXRoIGZpbGw9IiNjOGRhZWEiIGQ9Ik05OCAxNzVjLTMuODg4IDAtMy4yMjctMS40NjgtNC41NjgtNS4xN0w4MiAxMzIuMjA3IDE3MCA4MCIvPjxwYXRoIGZpbGw9IiNhOWM5ZGQiIGQ9Ik05OCAxNzVjMyAwIDQuMzI1LTEuMzcyIDYtM2wxNi0xNS41NTgtMTkuOTU4LTEyLjAzNSIvPjxwYXRoIGZpbGw9InVybCgjYikiIGQ9Ik0xMDAuMDQgMTQ0LjQxbDQ4LjM2IDM1LjczYzUuNTIgMy4wNDQgOS41IDEuNDY3IDEwLjg3Ni01LjEyNGwxOS42ODUtOTIuNzYzYzIuMDE2LTguMDgtMy4wOC0xMS43NDYtOC4zNTgtOS4zNWwtMTE1LjU5IDQ0LjU3MmMtNy44OSAzLjE2NS03Ljg0NCA3LjU2Ny0xLjQ0IDkuNTI4bDI5LjY2NCA5LjI2IDY4LjY3My00My4zMjZjMy4yNC0xLjk2NiA2LjIxNy0uOTEgMy43NzUgMS4yNTgiLz48L3N2Zz4%3D)](https://telegram.me/openmrs)
[![OpenMRS Wiki](https://img.shields.io/badge/openmrs-wiki-5B57A6.svg?logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNjAiIGhlaWdodD0iMTQyIiB2aWV3Qm94PSIwIDAgMTYwIDE0MiI%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%3D%3D)](https://wiki.openmrs.org)

## Support

Talk to us on [OpenMRS Talk](https://talk.openmrs.org/)

## License

[MPL 2.0 w/ HD](http://openmrs.org/license/) © [OpenMRS Inc.](http://www.openmrs.org/)

"
31,informatici/openhospital-core,Java,"# Open Hospital - Core
[![Java CI](https://github.com/informatici/openhospital-core/workflows/Java%20CI%20with%20Maven/badge.svg)](https://github.com/informatici/openhospital-core/actions?query=workflow%3A%22Java+CI+with+Maven%22)

This is the Core component of [Open Hospital][openhospital]: it contains the business logic and the data abstraction layer.  
The Core component is used by the [Java Swing desktop GUI][openhospital-gui], and by the [web UI][openhospital-ui] (through the [API component][openhospital-api]).

## How to build

After having installed Java JDK 8+ and Maven, to build this project issue:  

    mvn package

To use the Core component in the other projects, you'll need to install it locally with:

    mvn install
    
To run the tests simply issue:

    mvn test

Tests are run against an in-memory database (H2).  
To test the application against MySQL, you can change [`database.properties`][database.prop] and run the Docker container in the root folder with:

    # clean previous build
    docker compose rm --stop --volumes --force
    docker-compose up


## How to run Open Hospital

To run Open Hospital, you'll need a user interface, which is provided in the [GUI][openhospital-gui] and in the [UI][openhospital-ui] projects.  
Please follow the instructions in the documentation of those repositories.

## How to contribute

You can find the contribution guidelines in the [Open Hospital wiki][contribution-guide].  
A list of open issues is available on [Jira][jira].

## Community

You can reach out to the community of contributors by joining 
our [Slack workspace][slack] or by subscribing to our [mailing list][ml].

## Code style

This project uses a consistent code style and provides definitions for use in both IntelliJ and Eclipse IDEs.

<details><summary>IntelliJ IDEA instructions</summary>

For IntelliJ IDEA the process for importing the code style is:

* Select *Settings* in the *File* menu
* Select *Editor*
* Select *Code Style*
* Expand the menu item and select *Java*
* Go to *Scheme* at the top, click on the setting button by the side of the drop-down list
* Select *Import Scheme*
* Select *IntelliJ IDE code style XML*
* Navigate to the location of the file which relative to the project root is:  `.ide-settings/idea/OpenHospital-code-style-configuration.xml`
* Select *OK* 
* At this point the code style is stored as part of the IDE and is used for **all** projects opened in the editor.  To restrict the settings to just this project again select the setting button by the side of the *Scheme* list and select *Copy to Project...*. If successful a notice appears in the window that reads: *For current project*.

</details>

<details><summary>Eclipse instructions</summary>

For Eclipse the process requires loading the formatting style and the import order separately.

* Select *Preferences* in the *Window* menu
* Select *Java*
* Select *Code Style* and expand the menu
* Select *Formatter*
* Select the *Import...* button
* Navigate to the location of the file which relative to the project root is:  `.ide-settings/eclipse/OpenHospital-Java-CodeStyle-Formatter.xml`
* Select *Open*
* At this point the code style is stored and is applicable to all projects opened in the IDE.  To restrict the settings just to this project select *Configure Project Specific Settings...* in the upper right.  In the next dialog select the *openhospital* repository and select *OK*.  In the next dialog select the *Enable project specific settings* checkbox.  Finally select *Apply and Close*.
* Back in the *Code Style* menu area, select *Organize Imports*
* Select *Import...*
* Navigate to the location of the file which relative to the project root is:  `.ide-settings/eclipse/OpenHospital.importorder`
* Select *Open*
* As with the formatting styles the import order is applicable to all projects.  In order to change it just for this project repeat the same steps as above for *Configure Project Specific Settings...*
 
</details> 

 [openhospital]: https://www.open-hospital.org/
 [openhospital-gui]: https://github.com/informatici/openhospital-gui
 [openhospital-ui]: https://github.com/informatici/openhospital-ui
 [openhospital-api]: https://github.com/informatici/openhospital-api
 [contribution-guide]: https://openhospital.atlassian.net/wiki/display/OH/Contribution+Guidelines
 [jira]: https://openhospital.atlassian.net/jira/software/c/projects/OP/issues/
 [database.prop]: https://github.com/informatici/openhospital-core/blob/develop/src/test/resources/database.properties
 [slack]: https://join.slack.com/t/openhospitalworkspace/shared_invite/enQtOTc1Nzc0MzE2NjQ0LWIyMzRlZTU5NmNlMjE2MDcwM2FhMjRkNmM4YzI0MTAzYTA0YTI3NjZiOTVhMDZlNWUwNWEzMjE5ZDgzNWQ1YzE
 [ml]: https://sourceforge.net/projects/openhospital/lists/openhospital-devel
"
32,opensource-emr/hospital-management-emr,JavaScript,"
If you have any issues please send us mail at shiv_koirala@yahoo.com  more than happy to help you in understanding and installing. You can also <a href=""https://www.ehospitalmanagementsystem.com/"" target=""_new"">
 Chat with us here.
</a> 
 <br>
 If you wish to see demo <a href=""http://202.51.74.168:175/"" target=""_blank"">
 Click here
</a> Username  : admin / Password  : pass123 <br>
Also please do read down for more details of how to install and configure.

Introduction
==============
Danphe EMR is a enterprise web-based application which covers all day to day aspects of Hospital management end to end. Its currently live 50 plus hospitals in Asia(India,Nepal and Bangladesh). 

![danphelogin](https://user-images.githubusercontent.com/48054642/159859670-05cbe026-f0eb-43cf-811a-0404a36a76f7.jpg) ![danphepatientregistration](https://user-images.githubusercontent.com/48054642/159859505-84b59b71-d271-4e33-b504-1c15ecba3580.jpg)

Modules in Danphe EMR
==============
It has around 40 modules and below are important ones listed.

+ Registration/Patient 
+ Appointment 
+ Billing Module 
+ Accounting Module 
+ Inventory Management 
+ Pharmacy Module 
+ Laboratory Management 
+ User Module 
+ Admission Discharge and Transfer (ADT) 
+ Nursing Module 
+ Sub-store Module 
+ Radiology Management 
+ Medical Record 
+ Emergency 
+ Reporting and Dashboard 
+ Doctors 

`and more...`

Demo of Danphe EMR
==============
If you have any issues please sen us mail at shiv_koirala@yahoo.com 

Click on below demo link and check out live application

<a href=""http://202.51.74.168:175/"" target=""_blank"">
  Danphe EMR Live Application
</a>

Use below `credentials` for login

```
   Username  : admin
   Password  : pass123
```   

Need help?
==============
If you have any issues please send us mail at shiv_koirala@yahoo.com  more than happy to help you in understanding and installing.

Installation & Setup
======================
Getting start with **DanpheEMR** Please visit <a href=""https://opensource-emr.github.io/hospital-management-emr//#setup"" target=""_blank"">
    :point_right: Page
</a>  and read it carefully. 
Here you have details about requirements, configuration and setup.


#### Development Setup

+ This details for `developers` who wants to `clone DanpheEMR`, Use it and `help` us for improvements.
+ We have all details like software and tools `requirements`
+ Step by step guide for `build and run` project
+ Database creation 
`and more..`


<a href=""https://opensource-emr.github.io/hospital-management-emr/#setup"" target=""_blank"">
    :point_right: docs
</a>

Credits
========

## Sponsors
All sponsors are here. Thanks all sponsors for your contributions.

<a href=""https://www.imarkdigital.com/"" target=""_blank"">
  <img src=""https://user-images.githubusercontent.com/48054642/161473176-51fcb05f-e87f-4229-8673-887bf5060fe0.png"" />
</a>

## Contributors
Thanks all contributors. 

<a href=""https://github.com/opensource-emr/hospital-management-emr/graphs/contributors"" target=""_blank"">
  <img src=""https://contrib.rocks/image?repo=opensource-emr/hospital-management-emr"" />
</a> <br><br>


License
==============

See the [LICENSE](https://github.com/opensource-emr/hospital-management-emr/blob/master/LICENSE) file.

"
33,clinical-meteor/meteor-on-fhir,Objective-C,"# Meteor on FHIR
For my Masters of Science in Biomedical Informatics, we are required to create a Capstone Project.  So I decided to write a Health Information Exchange infrastructure.  The technical infrastructure uses MongoDB (a modern hierarchical database, similar to the MUMPS/Cache database what Epic uses), a full-stack isomorphic javascript framework called [Meteor](https://www.meteor.com/), and Facebook's user interface layer React.  The HIE uses a wordpress business model, and is intended to be a distributed and federated peer-to-peer network.  We use [HL7 Fast Healthcare Interoperability Resources (FHIR)](https://www.hl7.org/fhir/) for data exchange and interoperability.  

> NOTE: We have recently refactored the codebase.  We removed a ton of clutter, stale prototypes, dead code, and binary files that were tying Meteor on FHIR to Mac/Linux.  Meteor on FHIR should now run on Azure, and is configured as a community build by default.  You may notice some missing functionality, such as theming, geomapping, timelines, and other features.  Please contact demos@symptomatic.io if you need access to those features.  

[![CircleCI](https://circleci.com/gh/clinical-meteor/meteor-on-fhir/tree/master.svg?style=svg)](https://circleci.com/gh/clinical-meteor/meteor-on-fhir/tree/master)  


![https://github.com/clinical-meteor/meteor-on-fhir/blob/master/media/screenshot-1.png](https://github.com/clinical-meteor/meteor-on-fhir/blob/master/media/screenshot-1.png)

Yes, the above is a live screenshot of the app, which supports a theming engine and an augmented reality interface.

#### A. Installation  

```sh
# get the application
git clone http://github.com/clinical-meteor/meteor-on-fhir

# move into the webapp directory
cd meteor-on-fhir/webapp

# clone the example plugin
git clone http://github.com/clinical-meteor/example-plugin packages/example-plugin

# install the example plugin
meteor add clinical:example-plugin

# install the app
meteor npm install
```


#### B. Running Local

```sh
## general development
meteor --settings configs/settings.blank.canvas.json
```


#### C. Install Test Data

```sh
# install sample doctors and nurses
meteor add clinical:accounts-housemd

# run with initialization variables
INITIALIZE=true Patients=true Practitioners=true meteor
```


#### D. Theme and Remove Licensed Media Assets
Edit the `settings.dev.json` file, and update:
```
{
  ""public"": {
    ""title"": ""Rainbow's End Nursing Home Health Exchange"",
    ""theme"": {
      ""backgroundImagePath"": ""/backgrounds/medical/Gradient.jpg"",
      ""backgroundColor"": ""#34B6C2"",
      ""palette"": {
        ""colorA"": ""#34B6C2"",
        ""colorB"": ""#177AB9"",
        ""colorC"": ""#31323C"",
        ""colorD"": ""#710A4A"",
        ""colorE"": ""#FFFFFF""
      }
    },
    ""meshNetwork"": {
      ""upstreamSync"": ""http://meteor-on-fhir.meteorapp.com/fhir-3.0.0"", 
      ""autosync"": false
    }    
  },
  ""private"": {
    ""practitionerAccessCode"": ""practitionerAccessCode"",
    ""sysadminAccessCode"": ""sysadminAccessCode""
  },
  ""galaxy.meteor.com"": {
    ""env"": {
      ""MONGO_URL"": ""mongodb://username:password@mlab.com:25389/my-org-exchange-db"",
      ""NODE_ENV"": ""production""
    }
  }  
}
```

Run the script to remove restricted media assets:
```
scripts/remove_restricted_media_assets.sh
```

 

#### E. Desktop Build   

```bash
 # build the executables and add them into the /public directory
meteor add-platform ios
meteor add omega:meteor-desktop-watcher@=0.11.1 omega:meteor-desktop-bundler@=0.11.1 omega:meteor-desktop-localstorage@=0.0.11

# install meteor-desktop / electron
meteor npm install --save meteor-desktop

# add the .desktop directory, which has files needed by omega:meteor-desktop
npm run desktop -- init

# if there is already a desktop directory, move it to the .desktop dir
# this will override the previous step
mv webapp/desktop webapp/.desktop


# run the app server locally, as if you were doing a mobile build
# (you may be able to just use the running mobile build server)
NODE_ENV=dev meteor --mobile-server http://localhost:3000 --settings configs/settings.galaxy.json

# then to run the desktop app locally...
# npm run desktop

# or try the shortcut script
# meteor npm run-script desktop

# If you want to build a production release, that connects to the main server, you'll need to specify a different URL
# meteor --mobile-server http://www.symptomatic.io --settings configs/settings.galaxy.json
# npm run desktop -- build-installer http://www.symptomatic.io

meteor --mobile-server https://meteor-on-fhir.meteorapp.com --settings packages/landing-page/configs/settings.symptomatic.io.json
meteor npm run desktop -- build-installer http://meteor-on-fhir.meteorapp.com

```    


#### F. Deploy to Galaxy  

```sh
# remove the desktop pipeline before building for Galaxy
mv webapp/.desktop webapp/desktop
git commit -a -m 'desktop' 

meteor reset
meteor remove-platform ios
meteor remove omega:meteor-desktop-watcher omega:meteor-desktop-bundler omega:meteor-desktop-localstorage
meteor npm remove meteor-desktop
rm -rf node_modules
rm -rf .desktop-installer
meteor npm install

# upload to Galaxy
TIMEOUT_SCALE_FACTOR=10 DEPLOY_HOSTNAME=us-east-1.galaxy-deploy.meteor.com meteor deploy --settings configs/settings.galaxy.json meteor-on-fhir.meteorapp.com
```   

#### G. Azure Configuration  

```sh
az webapp deployment user set --user-name admin --password password
az appservice list-locations
az group create --name appName --location 'Central US'
az appservice plan create --name appServicePlan --resource-group appName --sku S1 
az webapp create --resource-group appResourceGroup --plan appServicePlan --name appname 
```    

#### H. Azure Deployment 

```sh
# prepare environment variables
export METEOR_SETTINGS=""$(cat ../../webapp/packages/example-plugin/configs/settings.blank.json )""
export ROOT_URL=https://appname.azurewebsites.net
export MONGO_URL=mongodb://user:password@cosmodb.documents.azure.com:10255/?ssl=true

# Now that Azure is configured, go to application
cd webapp/packages
git clone https://github.com/clinical-meteor/example-plugin
cd webapp

# stringify the settings.json file; and add to Azure METEOR_SETTINGS
cat packages/example-plugin/configs/settings.json | tr -d ' ' | tr -d '\n'

# add required packages
meteor add clinical:example-plugin

# remove unnecessary packages
meteor remove-platform ios

# run local production build
npm install
node start

# meteor-azure
meteor-azure --settings packages/example-plugin/configs/settings.blank.json

# debugging
curl -u admin https://appname.scm.azurewebsites.net/api/logstream
curl -u admin https://appname.scm.azurewebsites.net/api/logstream
curl -u admin https://appname.scm.azurewebsites.net/api/logstream/application
curl -u admin https://appname.scm.azurewebsites.net/api/logstream/kudu/deployment
```


#### I. Synchronizing With Other Datalakes  

To enable network synchronizing, you'll need to specify an upstream sync partner in your `settings.json` file.  Afterwards, you can enable manual synchronization in the **Data Management* page.  

```javascript
{
  ""public"": {
    ""meshNetwork"": {
      ""upstreamSync"": ""http://meteor-on-fhir.meteorapp.com/fhir-3.0.0"", 
      ""autosync"": false
    },
  }
}
```


#### J. Connect to an External EMR   
[HL7 v2 to FHIR Interface Mapping](https://medium.com/@awatson1978/hl7-v2-to-fhir-interface-mapping-f83c6ecf6bee)  



#### Trouble Shooting
```sh
# Browser ERROR: 404 ""/example-route"" does not exist
# A quick fix is edit the ""route"" to ""/hello-world"" in the webapp/packages/example-plugin/configs/settings.example.json 
# ""defaults"": {
#       ""route"": ""/hello-world"",
#       ...
#       }

# ERROR: Failed to connect to 127.0.0.1:27017
# You may need to restart mongod with the correct dbpath. Example:  
mongod --dbpath ~/meteor-on-fhir/webapp/packages/example-plugin/data


```

#### Miscellaneous References    
[Supporting Interoperability – Terminology, Subsets and Other Resources from Natl. Library of Medicine](https://www.nlm.nih.gov/hit_interoperability.html)  
[Health IT Standards for Health Information Management Practices](http://ihe.net/uploadedFiles/Documents/ITI/IHE_ITI_WP_HITStdsforHIMPratices_Rev1.1_2015-09-18.pdf)  
"
34,digital-asset/ex-healthcare-claims-processing,Haskell,"# Reference Application: Healthcare Claims Processing

## Overview

This application simulates processing a healthcare claim, starting with the referral from the Primary Care Provider (PCP) and including the creation of an appointment with the radiologist, checking in the patient on the date of the appointment, checking out the patient after service delivery, generation of the claim, and finally, payment for the procedure.

## Getting Started

### Installing

**Disclaimer:** This reference application is intended to demonstrate the capabilities of Daml. You are recommended to consider other non-functional aspects, like security, resiliency, recoverability, etc prior to production use.

#### Prerequisites

Be sure you have the following installed.
- [Daml SDK](https://docs.daml.com/)
- Java 8 or higher
- Make
- Node v14.16.0 or higher
- NPM v7.14.0 or higher
- [Python Pipenv](https://pipenv.pypa.io/)

### Starting the App

1. Build the App. Type:
    ```shell
    make build
    ```
    **Note:** If you change the Daml models locally, you need to re-run this command before starting the application.

2. Use **separate terminals** to launch the individual components:

    ```shell
    launchers/sandbox+populate
    launchers/automation
    launchers/ui
    ```

### Stopping the App

1. Stop each running command by pressing **Ctrl+C**.

## Working with Daml Hub

**Note**: The custom UI does not work on Daml Hub yet, but you can use Daml Hub's live explorer to interact with the contracts by following the instructions below.

1. As a first step, build the whole project
    ```shell
    make clean build
    ```
2. Create a project and a ledger in Daml Hub
3. Upload the DARs
4. Add the parties to the ledger
   - PrimaryCareProvider
   - Radiologist
   - Patient1
   - Operator
   - InsuranceCompany
5. Download `participants.json` from the ledger settings
6. Create the `ledger-setup.json` file manually or by running
    ```shell
    node scripts/create-ledger-setup.js participants.json ledger-setup.json
    ```

    The resulting file should like this:
    ```json
    {
      ""parties"": {
        ""payer1"": ""ledger-party-92d3fc64-a589-4a18-9e47-30541fdc7824"",
        ""operator"": ""ledger-party-01328c4d-a7b1-49d4-92cc-400badcb46c2"",
        ""patient1"": ""ledger-party-841214e1-cb38-42fa-88a9-08710592f74d"",
        ""provider1"": ""ledger-party-5292e717-bbd6-43d5-8cdc-67b463427ee9"",
        ""provider2"": ""ledger-party-bd952624-9142-412d-ae39-f6025cd94ac8""
      }
    }
    ```

    The following table contains the necessary name mapping:

    | Daml Hub name (in `participants.json`) | Ledger Setup name |
    | :------------------------------------: | :---------------: |
    |          primaryCareProvider           |     provider1     |
    |              radiologist               |     provider2     |
    |                patient1                |     patient1      |
    |                operator                |     operator      |
    |            insuranceCompany            |      payer1       |
7. Run the ledger setup
    ```shell
    daml script \
      --participant-config participants.json \
      --json-api \
      --dar models.dar \
      --script-name DemoOnboardScenario.StartScript:setupLedger \
      --input-file ledger-setup.json
    ```
8. Run the triggers from the Daml Hub UI

   | Party            | Trigger                                                                        |
   | :--------------- | :----------------------------------------------------------------------------- |
   | InsuranceCompany | Triggers.AcceptClaimTrigger:acceptClaimTrigger                                 |
   | InsuranceCompany | Triggers.AcknowledgeAppointmentTrigger:acknowledgeAppointmentTrigger           |
   | Radiologist      | Triggers.EvaluateReferralTrigger:evaluateReferralTrigger                       |
   | Radiologist      | Triggers.UpdateReferralDetailsTrigger:updateReferralDetailsTrigger             |
   | Patient1         | Triggers.AcknowledgeAndDiscloseTrigger:acknowledgeAndDiscloseTrigger           |
   | Patient1         | Triggers.AcceptPatientPaymentRequestTrigger:acceptPatientPaymentRequestTrigger |

## User Guide

This User Guide will take you step-by-step through healthcare claims processing, executing one successful claim.

**Note:** This demo is designed to show successful processing of a claim without exceptions or error conditions. A full production implementation would include additional features, handle errors and exceptions, and incorporate appropriate security controls.


## Workflow

**Roles and Responsibilities**


<table>
<thead>
  <tr>
    <th>Role</th>
    <th>Responsibility</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>Primary Care Provider</td>
    <td>A physician, who creates a referral for a Patient to a Radiologist</td>
  </tr>
  <tr>
    <td>Patient</td>
    <td>Visits the Primary Care Provider and is referred to a Radiologist<br>Pays their portion of the Bill/Claim after the Radiologist submits a Claim</td>
  </tr>
  <tr>
    <td>Radiologist</td>
    <td>Checks Referrals and schedules an Appointment for a Patient<br>On the Appointment date they Check-In the Patient in and perform a treatment <br>Marks the Treatment as Completed which creates a Claim for the Insurance Company</td>
  </tr>
  <tr>
    <td>Insurance Company</td>
    <td>Pays their portion of the Claim/Bill after the Radiologist submits a Claim</td>
  </tr>
</tbody>
</table>


**Steps**

The Healthcare Process workflow involves these steps:



1. **Referral**

    The Primary Care Provider creates a referral for ""John Doe"" in the system, sending the patient to a radiology lab (Radiologist) for an x-ray of a possible fracture. The system checks to verify that the patient is eligible for treatment under their insurance and calculates the cost of the procedure for this patient.


    Checks include:

    *   Validity of the patient’s insurance policy (in good standing, not expired)
    *   Network status of the radiologist (whether in or out of the insurance company’s approved provider list)
    *   Verification of eligibility and pre-authorization for the treatment

2. **Appointment**

    The Radiologist now creates an appointment for the patient in the system. The system ensures that the treatment is appropriate for the diagnosis and that any necessary pre-authorization has been done. It checks again to ensure that the patient insurance status has not changed since the referral was created.

3. **Check-In**

    The patient goes to the lab and is checked in. Again the system reruns all the previous checks to determine if any parameter has changed, for example, whether the patient has satisfied more of their deductible before this date.

4. **Treatment Completion and Claim Creation**

    The x-ray is done. The treatment is completed, and the claim is automatically created. The system creates an obligation for the patient to pay their portion of the cost (if any) and for the insurance company to pay its portion.

5. **Payment**

    The insurance company now pays the claim to the lab. The patient pays any required amount as well. The amounts paid are the verified amount established in first steps of the process.



## Running the Application


### Choosing and Changing Roles

When you launch the application, you will see a login screen with the option to choose your Role.

To switch from one Role to another click on ""Change Roles"" in the lower left hand corner of the screen.

Note: In this application each Role is represented by a different Party, this is a simplified design for demonstration purposes.


## Refer the Patient (""John Doe"") to the Radiologist

The workflow begins with the patient visiting their Primary Care Provider physician (PCP) for treatment. The PCP decides the patient needs an X-Ray and creates a referral to a Radiologist.

### Create a Referral

1. Log in as the Primary Care Provider Role
1. Go to **Patients** tab
1. Click on the Patient ""John Doe""
1. Select ""Refer Patient""
1. Fill out the ""Create Referral"" screen and click ""Create Referral.
    * You can select the ""Policy"", ""Diagnosis Code"", and ""Procedure Code"" from their respective dropdowns
    * Receiver must be ""Radiologist"" (without quotes)
    * All other fields can contain any text


## Schedule an Appointment for the Patient as the Radiologist

The next step is scheduling the appointment for the x-ray.

### Schedule the Patient


1. Log in as the Radiologist
1. Choose the **Referrals** tab
1. Click on the referral for ""John Doe"" that you just created
4. Choose **Schedule Appointment**
5. Select the date and time for the appointment on the New Appointment pane and click the **Schedule Appointment** button.
    * You'll typically want to leave this as the current date and time, otherwise the system won't let you check in ""John Doe"" until the scheduled appointment time has passed.
    * This new appointment is now visible to the Radiologist and ""John Doe"".

    * The various checks are run again, and the payment requirements are displayed, showing now what payment the lab will receive and what the patient will owe.
    
    * The Primary Care Provider cannot see this part of the workflow, as the appointment scheduling is only disclosed to the Patient, the Radiologist, and the Insurance Company.

## Check-In the Patient as the Radiologist

The next step is for the patient to arrive at the lab for the x-ray and be checked in.

### Check-In

1. Choose the **Appointments** tab as the Radiologist
1. Click on ""John Doe""s appointment
1. Click ""Check In Patient"" and confirm in the dialog window

    The various checks are run again to confirm that the patient is still eligible and to recalculate the payments to account for any changes, such as a situation where the patient has satisfied part of their deductible.


## Complete Treatment and Create the Claim as the Radiologist

After the x-ray is done, the patient is checked out from the facility, and the claim is created.

### Complete Treatment

1. Choose the **Treatments** tab as the Radiologist
1. On the Treatments tab, click on the treatment with ""John Doe""s name and click **Complete Treatment** and confirm in the dialog window
    * You can see the pending unpaid claim by locating it on the Claims tab. It will show both the Patient and Insurance Company's payment responsibilities.


## Make Payments from Insurance Company and Patient

The last step of this workflow is for payment to be made to the lab by both the Insurance Company and the Patient

### Make Payment

1. Log in as Insurance Company and choose the **Claims** tab
1. On the Claims list screen, click on the claim made from the Radiologist to the Insurance Company

    * Details of this claim will be displayed.

1. Click the **Pay Claim** button, and confirm in the dialog window

1. Log in as the Patient and choose the **Bills** tab

    * In a production system, the patient would likely log in through a patient portal rather than through this application.

1. Click on the open claim from the Radiologist, click the **Pay Bill** button and confirm on the dialog window


And that's the whole workflow! You've just worked through a complicated but typical workflow involving 4 separate parties with their respective privacy preserved throughout and information disclosed only where necessary.


CONFIDENTIAL © 2019 Digital Asset (Switzerland) GmbH and/or its affiliates. All rights reserved.
Any unauthorized use, duplication or distribution is strictly prohibited.
"
35,TheDesignMedium/healthcare-website,HTML,"[{""name"":"".gitignore"",""path"":"".gitignore"",""sha"":""e43b0f988953ae3a84b00331d0ccf5f7d51cb3cf"",""size"":10,""url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/.gitignore?ref=master"",""html_url"":""https://github.com/wanghaisheng/healthcaredatastandard/blob/master/.gitignore"",""git_url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/e43b0f988953ae3a84b00331d0ccf5f7d51cb3cf"",""download_url"":""https://raw.githubusercontent.com/wanghaisheng/healthcaredatastandard/master/.gitignore"",""type"":""file"",""_links"":{""self"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/.gitignore?ref=master"",""git"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/e43b0f988953ae3a84b00331d0ccf5f7d51cb3cf"",""html"":""https://github.com/wanghaisheng/healthcaredatastandard/blob/master/.gitignore""}},{""name"":""README.md"",""path"":""README.md"",""sha"":""fc6bd9a7b0a339af5ee38d7481d24302a18d395c"",""size"":29010,""url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/README.md?ref=master"",""html_url"":""https://github.com/wanghaisheng/healthcaredatastandard/blob/master/README.md"",""git_url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/fc6bd9a7b0a339af5ee38d7481d24302a18d395c"",""download_url"":""https://raw.githubusercontent.com/wanghaisheng/healthcaredatastandard/master/README.md"",""type"":""file"",""_links"":{""self"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/README.md?ref=master"",""git"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/fc6bd9a7b0a339af5ee38d7481d24302a18d395c"",""html"":""https://github.com/wanghaisheng/healthcaredatastandard/blob/master/README.md""}},{""name"":""overview.png"",""path"":""overview.png"",""sha"":""5e49110c0ac25125bf0f277548f85389bd9178da"",""size"":559586,""url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/overview.png?ref=master"",""html_url"":""https://github.com/wanghaisheng/healthcaredatastandard/blob/master/overview.png"",""git_url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/5e49110c0ac25125bf0f277548f85389bd9178da"",""download_url"":""https://raw.githubusercontent.com/wanghaisheng/healthcaredatastandard/master/overview.png"",""type"":""file"",""_links"":{""self"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/overview.png?ref=master"",""git"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/5e49110c0ac25125bf0f277548f85389bd9178da"",""html"":""https://github.com/wanghaisheng/healthcaredatastandard/blob/master/overview.png""}},{""name"":""standard number -201506.png"",""path"":""standard number -201506.png"",""sha"":""10d20f19dadd0de6c6740685c16ad3d98bceb4eb"",""size"":552959,""url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/standard%20number%20-201506.png?ref=master"",""html_url"":""https://github.com/wanghaisheng/healthcaredatastandard/blob/master/standard%20number%20-201506.png"",""git_url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/10d20f19dadd0de6c6740685c16ad3d98bceb4eb"",""download_url"":""https://raw.githubusercontent.com/wanghaisheng/healthcaredatastandard/master/standard%20number%20-201506.png"",""type"":""file"",""_links"":{""self"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/standard%20number%20-201506.png?ref=master"",""git"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/10d20f19dadd0de6c6740685c16ad3d98bceb4eb"",""html"":""https://github.com/wanghaisheng/healthcaredatastandard/blob/master/standard%20number%20-201506.png""}},{""name"":""基础类标准"",""path"":""基础类标准"",""sha"":""945a3b3a1831fbad09264b9dea530af3f0fb737a"",""size"":0,""url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E5%9F%BA%E7%A1%80%E7%B1%BB%E6%A0%87%E5%87%86?ref=master"",""html_url"":""https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E5%9F%BA%E7%A1%80%E7%B1%BB%E6%A0%87%E5%87%86"",""git_url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/945a3b3a1831fbad09264b9dea530af3f0fb737a"",""download_url"":null,""type"":""dir"",""_links"":{""self"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E5%9F%BA%E7%A1%80%E7%B1%BB%E6%A0%87%E5%87%86?ref=master"",""git"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/945a3b3a1831fbad09264b9dea530af3f0fb737a"",""html"":""https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E5%9F%BA%E7%A1%80%E7%B1%BB%E6%A0%87%E5%87%86""}},{""name"":""已整理材料"",""path"":""已整理材料"",""sha"":""e9f14bd3afda272e5e3f310b779e115d0c125d29"",""size"":0,""url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E5%B7%B2%E6%95%B4%E7%90%86%E6%9D%90%E6%96%99?ref=master"",""html_url"":""https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E5%B7%B2%E6%95%B4%E7%90%86%E6%9D%90%E6%96%99"",""git_url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/e9f14bd3afda272e5e3f310b779e115d0c125d29"",""download_url"":null,""type"":""dir"",""_links"":{""self"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E5%B7%B2%E6%95%B4%E7%90%86%E6%9D%90%E6%96%99?ref=master"",""git"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/e9f14bd3afda272e5e3f310b779e115d0c125d29"",""html"":""https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E5%B7%B2%E6%95%B4%E7%90%86%E6%9D%90%E6%96%99""}},{""name"":""技术类标准"",""path"":""技术类标准"",""sha"":""de30b9a40cd054b6d7fb7fcebbe6f7e01b5e5770"",""size"":0,""url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E6%8A%80%E6%9C%AF%E7%B1%BB%E6%A0%87%E5%87%86?ref=master"",""html_url"":""https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E6%8A%80%E6%9C%AF%E7%B1%BB%E6%A0%87%E5%87%86"",""git_url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/de30b9a40cd054b6d7fb7fcebbe6f7e01b5e5770"",""download_url"":null,""type"":""dir"",""_links"":{""self"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E6%8A%80%E6%9C%AF%E7%B1%BB%E6%A0%87%E5%87%86?ref=master"",""git"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/de30b9a40cd054b6d7fb7fcebbe6f7e01b5e5770"",""html"":""https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E6%8A%80%E6%9C%AF%E7%B1%BB%E6%A0%87%E5%87%86""}},{""name"":""数据类标准"",""path"":""数据类标准"",""sha"":""b07085f5d932d491dc4776309fc799305e1b4838"",""size"":0,""url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E6%95%B0%E6%8D%AE%E7%B1%BB%E6%A0%87%E5%87%86?ref=master"",""html_url"":""https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E6%95%B0%E6%8D%AE%E7%B1%BB%E6%A0%87%E5%87%86"",""git_url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/b07085f5d932d491dc4776309fc799305e1b4838"",""download_url"":null,""type"":""dir"",""_links"":{""self"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E6%95%B0%E6%8D%AE%E7%B1%BB%E6%A0%87%E5%87%86?ref=master"",""git"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/b07085f5d932d491dc4776309fc799305e1b4838"",""html"":""https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E6%95%B0%E6%8D%AE%E7%B1%BB%E6%A0%87%E5%87%86""}},{""name"":""标准化测评相关规范"",""path"":""标准化测评相关规范"",""sha"":""5bf75d1217960dfa55654ed55bb07f644330a763"",""size"":0,""url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E6%A0%87%E5%87%86%E5%8C%96%E6%B5%8B%E8%AF%84%E7%9B%B8%E5%85%B3%E8%A7%84%E8%8C%83?ref=master"",""html_url"":""https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E6%A0%87%E5%87%86%E5%8C%96%E6%B5%8B%E8%AF%84%E7%9B%B8%E5%85%B3%E8%A7%84%E8%8C%83"",""git_url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/5bf75d1217960dfa55654ed55bb07f644330a763"",""download_url"":null,""type"":""dir"",""_links"":{""self"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E6%A0%87%E5%87%86%E5%8C%96%E6%B5%8B%E8%AF%84%E7%9B%B8%E5%85%B3%E8%A7%84%E8%8C%83?ref=master"",""git"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/5bf75d1217960dfa55654ed55bb07f644330a763"",""html"":""https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E6%A0%87%E5%87%86%E5%8C%96%E6%B5%8B%E8%AF%84%E7%9B%B8%E5%85%B3%E8%A7%84%E8%8C%83""}},{""name"":""管理类标准"",""path"":""管理类标准"",""sha"":""697c02441646c251192f32f1bdf86ea52042e7e4"",""size"":0,""url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E7%AE%A1%E7%90%86%E7%B1%BB%E6%A0%87%E5%87%86?ref=master"",""html_url"":""https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E7%AE%A1%E7%90%86%E7%B1%BB%E6%A0%87%E5%87%86"",""git_url"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/697c02441646c251192f32f1bdf86ea52042e7e4"",""download_url"":null,""type"":""dir"",""_links"":{""self"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E7%AE%A1%E7%90%86%E7%B1%BB%E6%A0%87%E5%87%86?ref=master"",""git"":""https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/697c02441646c251192f32f1bdf86ea52042e7e4"",""html"":""https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E7%AE%A1%E7%90%86%E7%B1%BB%E6%A0%87%E5%87%86""}}]"
36,Ivanzgj/HealthCare,Java,"# HealthCare
毕设：一个血压实时监控app，该app主要功能为与测量设备进行通信，获取测量数据并在客户端进行处理，由服务器进行数据分析，为用户提供健康评估及建议。

## 目标
##### 实现与蓝牙设备通信，获取使用者的心率数据和血压数据
##### 实现数据可视化
##### 实现将数据上传到服务器，并进行进一步分析
##### 实现其它辅助性功能：个人信息，设置等
##### 在完成上述功能之后，可以进一步实现其它功能，例如测量光照，温度，振动等数据

## 已完成功能
### 蓝牙功能
可以打开蓝牙并连接到指定设备获取数据流。
### 数据图表
已完成图表UI设计以及模块功能搭建，已实现图表数据的数据库读取功能。
### 个人设置
已搭建好UI，完成个人信息页面全部功能。已完成全部网络通信接口。
### 搭建好数据库模块以及网络通信模块
数据库功能已经实现并抽象，网络通信功能也已实现并抽象，服务器初步搭建了框架。
服务器和客户端已完成了关于User数据和测量数据的上传下载以及清空等一系列操作，本机已通过花生壳映射到外网作为测试服务器。
服务器已有比较简单的UI可供查询指定用户的测量数据。
### 状态计算
根据监控数据（振动，屏幕控制）计算用户状态，客户端算法已初步完成。
### 一些附加功能
已完成监听加速度计获取振动数据；已完成监听屏幕亮灭解锁功能；已完成上述两种数据的数据库读写以及图表呈现功能。
### 服务器
服务器已完成所有与客户端通信的功能，已初步构建了一个可视化的网页对数据进行初步的查询和修改操作。应用eCharts将数据以图表形式显示出来。

## PHP服务器端代码托管地址
https://github.com/Ivanzgj/HealthCare_PHP
"
37,cevheri/healthcare,Java,"# healthcare

This application was generated using JHipster 6.8.0, you can find documentation and help at [https://www.jhipster.tech/documentation-archive/v6.8.0](https://www.jhipster.tech/documentation-archive/v6.8.0).

## Development

Before you can build this project, you must install and configure the following dependencies on your machine:

1. [Node.js][]: We use Node to run a development web server and build the project.
   Depending on your system, you can install Node either from source or as a pre-packaged bundle.

After installing Node, you should be able to run the following command to install development tools.
You will only need to run this command when dependencies change in [package.json](package.json).

    npm install

We use npm scripts and [Webpack][] as our build system.

Run the following commands in two separate terminals to create a blissful development experience where your browser
auto-refreshes when files change on your hard drive.

    ./mvnw
    npm start

Npm is also used to manage CSS and JavaScript dependencies used in this application. You can upgrade dependencies by
specifying a newer version in [package.json](package.json). You can also run `npm update` and `npm install` to manage dependencies.
Add the `help` flag on any command to see how you can use it. For example, `npm help update`.

The `npm run` command will list all of the scripts available to run for this project.

### PWA Support

JHipster ships with PWA (Progressive Web App) support, and it's turned off by default. One of the main components of a PWA is a service worker.

The service worker initialization code is commented out by default. To enable it, uncomment the following code in `src/main/webapp/index.html`:

```html
<script>
  if ('serviceWorker' in navigator) {
    navigator.serviceWorker.register('./service-worker.js').then(function() {
      console.log('Service Worker Registered');
    });
  }
</script>
```

Note: [Workbox](https://developers.google.com/web/tools/workbox/) powers JHipster's service worker. It dynamically generates the `service-worker.js` file.

### Managing dependencies

For example, to add [Leaflet][] library as a runtime dependency of your application, you would run following command:

    npm install --save --save-exact leaflet

To benefit from TypeScript type definitions from [DefinitelyTyped][] repository in development, you would run following command:

    npm install --save-dev --save-exact @types/leaflet

Then you would import the JS and CSS files specified in library's installation instructions so that [Webpack][] knows about them:
Edit [src/main/webapp/app/vendor.ts](src/main/webapp/app/vendor.ts) file:

```
import 'leaflet/dist/leaflet.js';
```

Edit [src/main/webapp/content/scss/vendor.scss](src/main/webapp/content/scss/vendor.scss) file:

```
@import '~leaflet/dist/leaflet.css';
```

Note: There are still a few other things remaining to do for Leaflet that we won't detail here.

For further instructions on how to develop with JHipster, have a look at [Using JHipster in development][].

### Using Angular CLI

You can also use [Angular CLI][] to generate some custom client code.

For example, the following command:

    ng generate component my-component

will generate few files:

    create src/main/webapp/app/my-component/my-component.component.html
    create src/main/webapp/app/my-component/my-component.component.ts
    update src/main/webapp/app/app.module.ts

## Building for production

### Packaging as jar

To build the final jar and optimize the healthcare application for production, run:

    ./mvnw -Pprod clean verify

This will concatenate and minify the client CSS and JavaScript files. It will also modify `index.html` so it references these new files.
To ensure everything worked, run:

    java -jar target/*.jar

Then navigate to [http://localhost:8080](http://localhost:8080) in your browser.

Refer to [Using JHipster in production][] for more details.

### Packaging as war

To package your application as a war in order to deploy it to an application server, run:

    ./mvnw -Pprod,war clean verify

## Testing

To launch your application's tests, run:

    ./mvnw verify

### Client tests

Unit tests are run by [Jest][] and written with [Jasmine][]. They're located in [src/test/javascript/](src/test/javascript/) and can be run with:

    npm test

For more information, refer to the [Running tests page][].

### Code quality

Sonar is used to analyse code quality. You can start a local Sonar server (accessible on http://localhost:9001) with:

```
docker-compose -f src/main/docker/sonar.yml up -d
```

You can run a Sonar analysis with using the [sonar-scanner](https://docs.sonarqube.org/display/SCAN/Analyzing+with+SonarQube+Scanner) or by using the maven plugin.

Then, run a Sonar analysis:

```
./mvnw -Pprod clean verify sonar:sonar
```

If you need to re-run the Sonar phase, please be sure to specify at least the `initialize` phase since Sonar properties are loaded from the sonar-project.properties file.

```
./mvnw initialize sonar:sonar
```

or

For more information, refer to the [Code quality page][].

## Using Docker to simplify development (optional)

You can use Docker to improve your JHipster development experience. A number of docker-compose configuration are available in the [src/main/docker](src/main/docker) folder to launch required third party services.

For example, to start a postgresql database in a docker container, run:

    docker-compose -f src/main/docker/postgresql.yml up -d

To stop it and remove the container, run:

    docker-compose -f src/main/docker/postgresql.yml down

You can also fully dockerize your application and all the services that it depends on.
To achieve this, first build a docker image of your app by running:

    ./mvnw -Pprod verify jib:dockerBuild

Then run:

    docker-compose -f src/main/docker/app.yml up -d

For more information refer to [Using Docker and Docker-Compose][], this page also contains information on the docker-compose sub-generator (`jhipster docker-compose`), which is able to generate docker configurations for one or several JHipster applications.

## Continuous Integration (optional)

To configure CI for your project, run the ci-cd sub-generator (`jhipster ci-cd`), this will let you generate configuration files for a number of Continuous Integration systems. Consult the [Setting up Continuous Integration][] page for more information.

[jhipster homepage and latest documentation]: https://www.jhipster.tech
[jhipster 6.8.0 archive]: https://www.jhipster.tech/documentation-archive/v6.8.0
[using jhipster in development]: https://www.jhipster.tech/documentation-archive/v6.8.0/development/
[using docker and docker-compose]: https://www.jhipster.tech/documentation-archive/v6.8.0/docker-compose
[using jhipster in production]: https://www.jhipster.tech/documentation-archive/v6.8.0/production/
[running tests page]: https://www.jhipster.tech/documentation-archive/v6.8.0/running-tests/
[code quality page]: https://www.jhipster.tech/documentation-archive/v6.8.0/code-quality/
[setting up continuous integration]: https://www.jhipster.tech/documentation-archive/v6.8.0/setting-up-ci/
[node.js]: https://nodejs.org/
[yarn]: https://yarnpkg.org/
[webpack]: https://webpack.github.io/
[angular cli]: https://cli.angular.io/
[browsersync]: https://www.browsersync.io/
[jest]: https://facebook.github.io/jest/
[jasmine]: https://jasmine.github.io/2.0/introduction.html
[protractor]: https://angular.github.io/protractor/
[leaflet]: https://leafletjs.com/
[definitelytyped]: https://definitelytyped.org/
"
38,wso2/open-healthcare-docs,CSS,"# WSO2 Open Healthcare Documentation

This is the source documentation of WSO2 Open Healthcare.

## Prerequisites

To run the project locally, it requires [python](https://www.python.org/downloads/) & [pip](https://pypi.org/project/pip/).

### Install Python

Check if you already have Python installed by running the following command.

```bash
$ python --version
Python 2.7.10
```

If you receive a response similar to the one shown above, `Python 2.7.10` is your default version.

You should also check if you have Python 3 installed. 

```bash
$ python3 --version
Python 3.8.0
```

If you don't seem to have `Python` installed, grab the latest release from the [official downloads page](https://www.python.org/downloads/).

### Install pip

pip is already installed if you are using Python 2 >=2.7.9 or Python 3 >=3.4 downloaded from [python.org](https://www.python.org/) or if you are working in a [Virtual Environment](https://packaging.python.org/tutorials/installing-packages/#creating-and-using-virtual-environments) created by [virtualenv](https://packaging.python.org/key_projects/#virtualenv) or [pyvenv](https://packaging.python.org/key_projects/#venv). Just make sure to [upgrade pip](https://pip.pypa.io/en/stable/installing/#upgrading-pip).

#### Installing with get-pip.py

To install pip with `curl`, execute the following command. Alternatively you can download `get-pip.py` by clicking [here](https://bootstrap.pypa.io/get-pip.py). 

```bash
$ curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py
```

Then run the following command in the folder where you have downloaded get-pip.py

```bash
$ python get-pip.py
```

## Run project locally (Dev Mode)

**Clone the repo**

```bash
$ git clone https://github.com/wso2/open-healthcare-docs.git
```

**Install the dependencies**

```bash
$ cd open-healthcare-docs && pip install -r requirements.txt
```

**Run mkdocs**

Execute the following command from inside the `<Lang folder>`.

```bash
$ cd en && mkdocs serve
```

## License

Licenses this source under the Apache License, Version 2.0 ([LICENSE](LICENSE)), You may not use this file except in compliance with the License.
"
39,OmRajpurkar/Healthcare-Chatbot,PHP,"# Healthcare-Chatbot
Healthcare is essential in daily life. Unfortunately, consultation with a doctor can be difficult to obtain, especially if we need advice on non-life threatening problems. The proposed idea is to create a system with Dialog Flow that can meet the patients requirements. Healthcare chatbot is built with medical applications having the potential to reduce healthcare cost and improves accessibility to medical knowledge by a simple chat through method. Chatbots are useful for patients and for those who want to learn more about health. The real benefit of the chatbot is to provide advice and information for an healthy life. A text-to-text diagnosis engages patients in conversation about their medical issues and provides a personalized diagnosis based on their symptoms and also sets appointment for the user. Hence, people will have an idea about their health and have the right protection and prevention.


**Start Page**

![](Healthcare%20Chatbot%20Start%20Page.png)


**Login Page (Screenshot of Errors When Directly Clicked the 'Sign In' Button)**

![](Healthcare%20Chatbot%20Login%20Page.png)


**Registration Page**

![](Healthcare%20Chatbot%20Register.png)


**Chat Page**

![](Healthcare%20Chatbot%20Chat.png)
"
40,AmitXShukla/Healthcare-Management-App-Flutter_Firebase,Dart,"# Flutter FireBase Healthcare Management App
Complete Healthcare Management (Patient, OPD, IPD, Rx, Lab) in Flutter Firebase App for iOS Android and Web

```diff
- If you like this project, please consider giving it a star (*) and follow me at GitHub & YouTube.
```
[<img src=""https://github.com/AmitXShukla/AmitXShukla.github.io/blob/master/assets/icons/youtube.svg"" width=40 height=50>](https://youtube.com/AmitShukla_AI)
[<img src=""https://github.com/AmitXShukla/AmitXShukla.github.io/blob/master/assets/icons/github.svg"" width=40 height=50>](https://github.com/AmitXShukla)
[<img src=""https://github.com/AmitXShukla/AmitXShukla.github.io/blob/master/assets/icons/medium.svg"" width=40 height=50>](https://medium.com/@Amit_Shukla)
[<img src=""https://github.com/AmitXShukla/AmitXShukla.github.io/blob/master/assets/icons/twitter_1.svg"" width=40 height=50>](https://twitter.com/ashuklax)

# Elish HMS

Elish Healthcare Management System App

## Objective 
Manage OPD, IPD, Pathology, WebMD, Rx, Patient Appointments<br/><br/>

<i>Due to current Covid-19 situation,<br/>
Patient's private data is not stored in app and location tracing functionality is not available with out government/authorities approval.</i>
## Getting Started

This project is a community version and is absolutely free for private use.<br/>
<a href=""https://www.youtube.com/playlist?list=PLp0TENYyY8lHcc8mZiYG83sbsCea2xd3r"">click here for Demo & Video tutorials</a>

## Technologies
```sbtshell)
Frontend: Flutter
Backend:Google Firestore/Firebase
Messages: LOOM SDK
WebView: loom-app (using Angular version
``` 

## Related Apps
<ul>
<li><a href=""https://getcovidvaccine.web.app/"">Vaccine Distribution App</a></li>
<li><a href=""https://www.youtube.com/watch?v=MkV413X2Kmw&list=PLp0TENYyY8lHL-G7jGbhpJBhVb2UdTOhQ&index=1&t=698s"">Pandemic Contact Tracing, Visitor Management, Mobile Assets/Employee Attendance App</a></li>
</ul>

## Features
<ul>
<li>Store millions of records with lightening fast data retrieval</li>
<li>hands free /voice activated typing</li>
<li>Secured App (Role based access with Admin panel)</li>
<li>Local dictionary based auto-completion</li>
<li>Global dictionary based auto-completion/auto-sync (Pro)</li>
<li>GBs of pictures, documents, Lab reports, Receipts (Pro)</li>
<li>Self learning (auto complete) data entry (Pro)</li>
<li>Social authentication (Pro)</li>
<li>SMS, EMAIL, WhatsAPP API (Pro)</li>
</ul>
<i>send email to info@elishcosulting.com for Pro version enquiries.</i>

## Product Images

![Pic 1](./images/hms_pic_1.png)
![Pic 2](./images/hms_pic_2.png)
![Pic 3](./images/hms_pic_3.png)
![Pic 4](./images/hms_pic_4.png)



## How to Install

<ul>
    <li>Install Flutter environment</li>
    <li>Download This GitHub repository</li>
    <li>install Flutter packages *pub get) and Flutter web -> Flutter create .</li>
    <li>Setup firebase account/project</li>
    <li>Copy Firebase Project Config settings and replace variable firebaseConfig at src/web/index.html</li>
    <li>enable Firebase social authentications</li>
    <li>update Firebase Rules</li>

```sbtshell
    rules_version = '2';
    service cloud.firestore {
    match /databases/{database}/documents {
    match /{document=**} {
      allow read, write: if false;
    }
    match /roles/{document} {
    // fix this, anyone who is logged in, can read these document & passwords
    //  allow read: if isSignedIn();
  	allow read, write: if false;
    }
    
    match /users/{document} {
    allow create: if true;
    allow read : if isSignedIn() && (isDocOwner() || isAdmin());
    allow update: if isSignedIn() && isDocOwner() && onlyContentChanged();
    allow update, delete: if isAdmin();
    }
    
    match /person/{document=**} {
    allow create: if true;
    allow read, update : if isSignedIn() && (isDocOwner() || isAdmin());
    allow delete : if isSignedIn() && isAdmin();
    }
    
    match /person/{document}/Vaccine/{doc=**} {
    allow create: if true;
    // allow read, update : if isSignedIn() && (isDocOwner() || isAdmin());
    // fix this later
    allow read, update : if true;
    allow delete : if isSignedIn() && isAdmin();
    }
    
    match /person/{document}/OPD/{doc} {
    allow create: if true;
    // allow read, update : if isSignedIn() && (isDocOwner() || isAdmin());
    // fix this later
    allow read, update : if true;
    allow delete : if isSignedIn() && isAdmin();
    }
    
    match /person/{document}/Lab/{doc} {
    allow create: if true;
    // allow read, update : if isSignedIn() && (isDocOwner() || isAdmin());
    // fix this later
    allow read, update : if true;allow read, update : if isSignedIn() && (isDocOwner() || isAdmin());
    allow delete : if isSignedIn() && isAdmin();
    }
    
    match /person/{document}/Rx/{doc} {
    allow create: if true;
    // allow read, update : if isSignedIn() && (isDocOwner() || isAdmin());
    // fix this later
    allow read, update : if true;
    allow delete : if isSignedIn() && isAdmin();
    }
    
    match /person/{document}/Messages/{doc} {
    allow create: if true;
    // allow read, update : if isSignedIn() && (isDocOwner() || isAdmin());
    // fix this later
    allow read, update : if true;
    allow delete : if isSignedIn() && isAdmin();
    }
    
    match /appointments/{document} {
    allow create: if true;
    allow read, update : if isSignedIn() && (isDocOwner() || isAdmin());
    allow delete : if isSignedIn() && isAdmin();
    }
    
    match /records/{document} {
    allow create: if true;
    allow read, update : if isSignedIn() && (isDocOwner() || isAdmin());
    }
    
    match /vaccine/{document} {
    allow create: if true;
    allow read, update : if isSignedIn() && (isDocOwner() || isAdmin());
    }
    
    match /purchase/{document} {
    allow create: if true;
    allow read, update : if isSignedIn() && (isDocOwner() || isAdmin());
    allow delete : if isSignedIn() && isAdmin();
    }
    
		match /msr/{document} {
    allow create: if true;
    allow read, update : if isSignedIn() && (isDocOwner() || isAdmin());
    allow delete : if isSignedIn() && isAdmin();
    }
    
    match /vendor/{document} {
    allow create: if true;
    allow read, update : if isSignedIn() && (isDocOwner() || isAdmin());
    allow delete : if isSignedIn() && isAdmin();
    }
    
    match /warehouse/{document} {
    allow create: if true;
    allow read: if isSignedIn()
    allow update : if isSignedIn() && (isDocOwner() || isAdmin());
    allow delete : if isSignedIn() && isAdmin();
    }
    match /item/{document} {
    allow create: if true;
    allow read: if isSignedIn()
    allow update : if isSignedIn() && (isDocOwner() || isAdmin());
    allow delete : if isSignedIn() && isAdmin();
    }
    
    // helper functions
    function isSignedIn() {
    return request.auth.uid != null;
    }
    
    function onlyContentChanged() {
    return request.resource.data.role == resource.data.role;
    // make sure user is not signing in with any role or changin his role during update
    }
    function isDocOwner() {
    return request.auth.uid == resource.data.author;
    }
    // function isDocCreater() {
    // return request.auth.uid == request.resource.data.author;
    // }
    function isAdmin() {
    return get(/databases/$(database)/documents/users/$(request.auth.uid)).data.role == ""admin"";
    }
    // function isEmployee() {
    // return get(/databases/$(database)/documents/settings/$(request.auth.uid)).data.role == ""employee"";
    // }
    }
    }
```
</ul>

![Pic 4](./images/env_variable.png)
![Pic 4](./images/social_auth.png)
![Pic 4](./images/rules.png)"
41,IRCAD/sight,C++,"# Sight

| Branch |    Status |
|--------|-----------|
| Dev    | [![pipeline status](https://git.ircad.fr/Sight/sight/badges/dev/pipeline.svg)](https://git.ircad.fr/Sight/sight/commits/dev) |
| Master | [![pipeline status](https://git.ircad.fr/Sight/sight/badges/master/pipeline.svg)](https://git.ircad.fr/Sight/sight/commits/master) |

## Description
[//]: # (cspell: disable)
**Sight**, the **S**urgical **I**mage **G**uidance and **H**ealthcare **T**oolkit aims to ease the creation of
applications based on medical imaging.
[//]: # (cspell: enable)

It includes various functionalities such as 2D and 3D digital image processing, visualization, augmented reality and
medical interaction simulation. It runs on Microsoft Windows and Linux, is written in C++, and features rapid interface
design using XML files. It is freely available under the LGPL.

**Sight** is mainly developed by the Surgical Data Sciences Team of [IRCAD France](https://www.ircad.fr), where it is
used everyday to develop innovative applications for the operating room and medical research centers.

Many **tutorials** and **examples**, which can help you to learn smoothly how to use **Sight**, are located in the
`tutorials` and `examples` directories.
Detailed steps are described [here](https://sight.pages.ircad.fr/sight-doc/Tutorials/index.html).

### Features

- 2D/3D visualization of medical images, meshes, and many widgets.
- Import / export medical data from various formats (DICOM, [VTK](https://www.vtk.org/), ...) and sources
  (files, devices, PACS, ...).
- Playing, recording, processing videos (webcams, network streams, Intel RealSense devices, ...).
- Easy GUI configuration and customization (XML description and stylesheets support).
- Timeline, allowing to store various data (video, matrices, markers, etc...) and synchronize these data across time.
- Mono and stereo camera calibration,
- [ArUco](https://sourceforge.net/projects/aruco/) optical markers tracking,
- [openIGTLink](http://openigtlink.org/) support through client and server services,
- Advanced memory management to support large data. Unused data can be offloaded to disk, saving memory for foreground
  tasks.
- Work session or any part of it, can be saved and restored on disk. The data itself can be encrypted using AES256 to
  ensure a high level of security and privacy


### Hardware / Operating System / Compiler support

**Sight** is written in standard C++17 and use [CMake](https://cmake.org/) as its build system, which means that Sight
should at least compile on any operating system that provide support for a decent C++17 compiler, CMake, **AND** Sight's
dependencies (see [Install](#install) for a list of dependencies for Linux platform). However, we currently have access
to a limited set of hardware/OS/compiler combinations where the code is actually tested on a regular basis.

Such combination includes:
-  [Debian 11 stable on AMD64 with GCC 10.2.1](https://www.debian.org/ports/amd64)
-  [Ubuntu 21.04 on AMD64 with GCC 10.3.0 or CLang 12](https://releases.ubuntu.com/21.04/)
-  [Microsoft Windows 10 on AMD64 with VisualStudio 2019](https://www.microsoft.com/windows/)

> If your platform is not listed, that *doesn't* mean **Sight** will not work, just we cannot guarantee that it is well
> tested. If you are on this kind of platform and are able to build and use **Sight**, feel free to share with us your
> success !

> We use some fine tuned compiler flags (like `/arch:AVX2`) to optimize and generate code specifically for CPUs that
> were released around 2013 and later. It means, if your CPU is too old, **Sight** will crash at runtime because some
> CPU instructions are not implemented. In such situation, you can modify hidden cmake variable `SIGHT_ARCH` at
> configuring time or modify the default compiler flag directly in **Sight** CMake code.

## Applications

### SightViewer

**SightViewer** is a full featured medical image and mesh viewer with advanced rendering features such as volume
rendering. It supports most medical image formats, and can also retrieve DICOM files from a PACS. It demonstrates many
useful features of Sight.

<div align=center style=""text-align: center; display: flex; flex-flow: row wrap; justify-content: space-around;"">
<figure>
    <img src=""https://git.ircad.fr/sight/sight-doc/-/raw/dev/Introduction/media/SightViewer01.gif"">
    <figcaption>
        <b><i>MPR view of a medical 3D image with additional volume rendering</i></b>
    </figcaption>
</figure>
<figure>
    <img src=""https://git.ircad.fr/sight/sight-doc/-/raw/dev/Introduction/media/SightViewer02.gif"">
    <figcaption>
        <b><i>Volume rendering and transfer function tuning</i></b>
    </figcaption>
</figure>
<figure>
    <img src=""https://git.ircad.fr/sight/sight-doc/-/raw/dev/Introduction/media/mixed_vr_reconstructions.gif"">
    <figcaption>
        <b><i>Volume rendering mixed with 3D surfacic meshes</i></b>
    </figcaption>
</figure>
</div>

### DicomXplorer

**DicomXplorer** is a simple medical image viewer that can connect to a PACS to retrieve DICOM data. It supports CT-scan
and MRI images.

<div align=center style=""text-align: center; display: flex; flex-flow: row wrap; justify-content: space-around;"">
<figure>
    <img src=""https://git.ircad.fr/sight/sight-doc/-/raw/dev/Introduction/media/DicomXplorer01.gif"">
    <figcaption>
        <b><i>DICOM and medical image files navigation</i></b>
    </figcaption>
</figure>
<figure>
    <img src=""https://git.ircad.fr/sight/sight-doc/-/raw/dev/Introduction/media/DicomXplorer02.gif"">
    <figcaption>
        <b><i>MPR view of a medical 3D image</i></b>
    </figcaption>
</figure>
</div>

### SightCalibrator

**SightCalibrator** is a user-friendly application to calibrate mono and stereo cameras.
This software is a must-have since camera calibration is a mandatory step in any AR application.

<div align=center style=""text-align: center; display: flex; flex-flow: row wrap; justify-content: space-around;"">
<figure style="""">
    <img src=""https://git.ircad.fr/sight/sight-doc/-/raw/dev/Introduction/media/SightCalibrator01.gif"">
    <figcaption>
        <b><i>Intrinsic & extrinsic calibration of mono/stereo cameras with live reprojection error display</i></b>
    </figcaption>
</figure>
</div>

## Install

See [detailed install instructions](https://sight.pages.ircad.fr/sight-doc/Installation/index.html) for Windows and
Linux.

## Documentation

* [Documentation](https://sight.pages.ircad.fr/sight-doc)
* [Tutorials](https://sight.pages.ircad.fr/sight-doc/Tutorials/index.html)
* [Doxygen](https://sight.pages.ircad.fr/sight)

## Support

Please note that our GitLab is currently only available in read-only access for external developers and users. This is a
restriction because of the licensing model of GitLab. Since we use an EE version, we would be forced to pay for every
community user, and unfortunately we cannot afford it. This licensing model might change in the future
https://gitlab.com/gitlab-org/gitlab-ee/issues/4382 though.

Until then, we gently ask our community users to use our GitHub mirror to
[report any issues](https://github.com/IRCAD/sight/issues) or propose
[contributions](https://github.com/IRCAD/sight/pulls).

You can also get live community support on the [gitter chat room](https://gitter.im/IRCAD-IHU/sight-support).

"
42,hasyed/HealthCareApp,Java,"HealthCareApp
=============

The Mobile Solution to maintain consumption of daily use edibles and calorie balance with interactive user interfaces, Chart and Nutrition labels calculated in such a way that are readable to user.

This app takes an image of  nutrition chart of the product which user wants to intake. OpenCV is used to clean the captured image. Then the image goes to OCR(Optical Character Recognation) which extract the information from the image and added them to user database that he has consumed it, the information  includes Calories, Total Fats and other Nutritions. 

If user want to gain or reduce weight, the formula in the main of the app helps user to input in how many days he want to reduce the weight and how much he wants to reduce. This will give him the Calories he wanted to take take everyday.
User can manually add products or exercise too. Products that he intake increase the calories and exercise that he do reduces the calories.

There is a chart that helps user to see his previouse performance regards calories as well.

I have forked [android-ocr](https://github.com/rmtheis/android-ocr/tree/master/android/src) with some changes for openCV for cleansing the image for my help. 
##Requires
[tess-two](https://github.com/rmtheis/tess-two/tree/master/tess-two)

[OpenCV for android](http://opencv.org/)


"
43,Qingbao/HealthCareStepCounter,Java,"HealthCareStepCounter
=====================

Coming soon: rewritten with React Native

"
44,arvindsis11/Ai-Healthcare-Chatbot,CSS,"# flask-chatbot
Built on python 3.6
Flask==0.11
chatterbot==0.8.4
SQLAlchemy==1.1.11

#### A web implementation of [ChatterBot](https://github.com/gunthercox/ChatterBot) using Flask.

## Local Setup:
 1. Open command prompt and locate folder. run 'pip install -r requirements.txt'
 2. Run *train.py*
 3. Run *run.py*
 4. Demo will be live at http://localhost:5000/
 
 ## Git push cmd- for reference
 ```java
 echo ""# MyRestApi all crud operations using spring boot framework"" >> README.md
git init
git add .
git commit -m ""initial commit""
git branch -M main
git remote add origin https://github.com/arvindsis11/MyRestApi.git
git push -u origin main
git rm -r --cached .
////////////////////////////////////////
or push an existing repository from the command line
git remote add origin https://github.com/arvindsis11/springJPAdemo.git
git branch -M main
git push -u origin main
https://github.com/arvindsis11/angular-todomanagement-app.git
/////////////////////////////////////
common git error:
use this:
git pull --rebase origin main
git push origin main
url:https://stackoverflow.com/questions/24114676/git-error-failed-to-push-some-refs-to-remote
 ```

## License
This source is free to use, but ChatterBot does have a license which still applies and can be found on the [LICENSE](https://github.com/gunthercox/ChatterBot/blob/master/LICENSE) page.
"
45,microsoft/Healthcare-Blockchain-Solution-Accelerator,C#,"# Blockchain Healthcare Solution Accelerator Guide

## About this repository
This accelerator was built to provide developers with all of the resources needed to quickly build an initial Hyperledger Fabric Healthcare data transactionary solution. Use this accelerator to jump start your development efforts with Hyperledger and Azure.

This repository contains the steps, scripts, code, and tools to create a Hyperledger Fabric blockchain application. 00_Resource_Deployment will create the necessary supporting resources in Azure (Storage, Kubernetes, and Cosmos DB). 01_Hyperledger_Fabric_Deployment will configure and deploy a Hyperledger Fabric blockchain network using Helm Packages and Kubernetes. 02_Hyperledger_Fabric_Client will install the necessary chaincode. Finally 03_Application_Deployment will deploy and host your application either locally or in your subscription.

## Prerequisites
In order to successfully complete your solution, you will need to have access to and or provisioned the following:
1. Access to an Azure subscription
2. Visual Studio 2017 or 2019
3. Kubectl, Helm, and Docker Command Line Tools installed
4. Service Fabric

Optional
1. Intellij CE

## Azure and Blockchain
The directions provided for this repository assume fundemental working knowledge of Azure, Cosmos DB, Azure Storage, Hyperledger Fabric, Service Fabric, and Kubernetes.  

For additional training and support, please see:
 1. [Kubernetes](https://kubernetes.io/)
 2. [Hyperledger Fabric](https://hyperledger-fabric.readthedocs.io/en/release-1.4/)
 3. [Service Fabric](https://azure.microsoft.com/en-us/services/service-fabric/)
 4. [Cosmos DB](https://docs.microsoft.com/en-us/azure/cosmos-db/introduction)

## Getting Started and Process Overview
Clone/download this repo onto your computer and then walk through each of these folders in order, following the steps outlined in each of the README files.  After completion of all steps, you will have a working end-to-end solution with the following architecture:

![Microservices Architecture](./References/architecture.JPG)


### [00 - Resource Deployment](./00_Resource_Deployment)
The resources in this folder can be used to deploy the required resources into your Azure Subscription. This can be done either via the [Azure Portal](https://portal.azure.com) or by using the [PowerShell script](./00_Resource_Deployment/deploy.ps1) included in the resource deployment folder.

After deployed, you will have a Cosmos DB account and database, Azure storage, and Kubernetes cluster deployed in your specified resource group.

### [01 - Hyperledger Fabric Deployment](./01_Hyperledger_Fabric_Deployment)
This folder contains the Hyperledger Fabric Deployment configuration files. To prepare the environment and deploy the infrastructer run the [deploy script](./01_Hyperledger_Fabric_Deployment/deploy.ps1).

Running this script will deploy a basic fabric network consisting of two organizations: one peer organization and one orderer organization. To read more about hyperledger reference the [Hyperledger Fabric Documentation](https://hyperledger-fabric.readthedocs.io/en/release-1.4/).

### [02 - Hyperledger Fabric Client](./02_Hyperledger_Fabric_Client)
This folder contains the Kotlin Chaincode and Hyperledger Fabric server used to communicate with the blockchain network. The script in this folder will pull the Fabric Chaincode, Client, and gRPC server. This image will install the chaincode and allow the application to execute against the Blockchain network. Follow the provided instructions.

### [03 - Application Deployment](./03_Application_Deployment)
This folder contains the .net services for the proof content storage service, transaction tracker, transaction indexer, and gRPC Fabric Client. The Angular web application is also started and hosted with these services. Service Fabric is used to host this application.

## Links
Hosted Site: [Healthcare Blockchain Solution](http://healthcare-apphosting.southcentralus.cloudapp.azure.com/login)

*Use income less than 11000 and a NY Zip Code for a profile to qualify*

Video: [Healthcare Blockchain Solution Video](https://msit.microsoftstream.com/video/7f62ce8c-39e1-40d6-8adb-cbf298f31dfe)

*Or download [Healthcare Blockchain Solution Video](healthcare_solution_video.mp4)*


## License
Copyright (c) Microsoft Corporation

All rights reserved.

MIT License

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the """"Software""""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED AS IS, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE

## Contributing

This project welcomes contributions and suggestions.  Most contributions require you to agree to a
Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us
the rights to use your contribution. For details, visit https://cla.microsoft.com.

When you submit a pull request, a CLA-bot will automatically determine whether you need to provide
a CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions
provided by the bot. You will only need to do this once across all repos using our CLA.

This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).
For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or
contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.
"
46,openmrs/openmrs-module-radiology,Java,"# openmrs-module-radiology

[![Build Status](https://travis-ci.org/openmrs/openmrs-module-radiology.svg?branch=master)](https://travis-ci.org/openmrs/openmrs-module-radiology) [![Coverage Status](https://coveralls.io/repos/openmrs/openmrs-module-radiology/badge.svg?branch=master&service=github)](https://coveralls.io/github/openmrs/openmrs-module-radiology?branch=master) [![Codacy Badge](https://api.codacy.com/project/badge/grade/5e0137f0c916494eaa3ba7de43149ef7)](https://www.codacy.com/app/teleivo/openmrs-module-radiology_2) [![Dependency Status](https://www.versioneye.com/user/projects/57a194fb3d8eb6002f560778/badge.svg?style=flat)](https://www.versioneye.com/user/projects/57a194fb3d8eb6002f560778)

####Table of Contents

1. [Overview](#overview)
2. [Build](#build)
3. [Install](#install)
  * [Docker](#docker-whale)
  * [Demo data](#demo-data)
4. [Documentation](#documentation)
  * [Website](#website)
  * [Developer guides](#developer-guides)
  * [Wiki](#wiki)
5. [Contributing](#contributing)
  * [Code](#code)
  * [Translation](#translation)
6. [Issues](#issues)
7. [Limitations](#limitations)
8. [Community](#community)
9. [Support](#support)
10. [License](#license)

## Overview

OpenMRS module radiology (previously called radiologydcm4chee) is a module adding capabilities of a Radiology
Information System (RIS) onto OpenMRS.

## Build

### Prerequisites

You need to have installed

* a Java JDK 8
* the build tool [Maven](https://maven.apache.org/)

You need to configure Maven to use the JAVA JDK 8

```bash
mvn -version
```

Should tell you what version Maven is using.

You need to clone this repository:

```bash
git clone https://github.com/openmrs/openmrs-module-radiology.git
```

### Command

After you have taken care of the [Prerequisites](#prerequisites)

Execute the following command:

```bash
cd openmrs-module-radiology
mvn clean package
```

This will generate the radiology module in `omod/target/radiology-{VERSION}.omod` which you will have to deploy into OpenMRS.

## Install

The easiest way to install the module is to use [Docker](https://www.docker.com/).

### Docker :whale:

This module can be baked into a Docker image so you can easily run and test it.

#### Prerequisites

After you have taken care of the [Build Prerequisites](#prerequisites)

Make sure you have [Docker](https://docs.docker.com/) installed.

#### Build

Build the Radiology Module and its Docker image:

```bash
cd openmrs-module-radiology
mvn clean package docker:build
```

#### Run

To run an instance of the OpenMRS Radiology Module execute (assumes you have
created a Docker image):

```bash
cd openmrs-module-radiology
mvn docker:start
```

OpenMRS will be accessible at `http://<IP ADDRESS>:8080/openmrs`

**NOTE: The IP address varies depending on your setup.**

If you are using [Docker machine](https://docs.docker.com/machine/) refer to its documentation on how to get the IP address.
If you are on Linux it will probably be will be `localhost`.

#### Documentation

Please read the corresponding [DOCKER.md](docs/DOCKER.md) for more detailed
explanations on using Docker with the Radiology Module.

### Demo data

You can import the demo data set [demo-data.sql](acceptanceTest/resources/demo-data.sql) into
your database which enables you to try out the modules features or test your
changes.

Please read the corresponding [DEMO-DATA.md](docs/DEMO-DATA.md).

## Documentation

### Website

For a detailed guide on ways to install and configure this module see

http://teleivo.github.io/docs-openmrs-module-radiology/

### Developer guides

Please check out the readme files at [docs](docs/).

### Wiki

For some more background informations on the module see

https://wiki.openmrs.org/display/docs/Radiology+Module

## Contributing

Contributions are very welcome, we can definitely use your help!

### Code

Check out our [contributing guidelines](CONTRIBUTING.md), read through the [Developer guides](#developer-guides).

After you've read up :eyeglasses: [grab an issue](https://issues.openmrs.org/browse/RAD) that is `Ready For Development`.

### Translation

We use

https://www.transifex.com/openmrs/OpenMRS/radiology-module/

to manage our translations.

The `messages.properties` file in this repository is our single source of
truth. It contains key, value pairs for the English language which is the
default.

Transifex fetches updates to this file every night which can then be translated
by you and me on transifex website itself. At any time we can pull new translations from transifex
back into this repository. Other languages like for ex. Spanish will then be in
the `messages_es.properties` file.

If you would like to know more about transifex from the coding side read

https://wiki.openmrs.org/display/docs/Maintaining+OpenMRS+Module+Translations+via+Transifex

## Issues

To file new issues or help to fix existing ones please check out

https://issues.openmrs.org/browse/RAD

## Limitations

This module is not yet officially released to the [openmrs modules](https://modules.openmrs.org/#/).

The API and UI are not yet stable and subject to frequent changes.

:exclamation: ATTENTION :exclamation: radiology orders created via the module will not be sent to the PACS
as HL7 order messages. This has previously been done in a hacky/synchronous way which was not fit for
production and only messy code which had to be removed. A message queue which takes care of sending HL7
order messages to the PACS once orders are created is needed. Such a queue would retry sending the order message
in case the PACS is currently down. Unfortunately, OpenMRS does not provide such a message queue for outgoing HL7 messages.
This is THE big missing piece in the puzzle of the radiology module which until
now has been bridged with communication servers such as mirth.

The module depends on [OpenMRS Version 2.0.0](https://github.com/openmrs/openmrs-core) so it cannot
run on any version lower than that.

The module currently depends on [OpenMRS Legacy UI](https://github.com/openmrs/openmrs-module-legacyui)
which provides the UI but it is [planned](https://issues.openmrs.org/browse/RAD-341)
to extract the UI into a separate module so this module only provides the Java and
REST API without forcing a specific UI onto anyone.

## Community

[![OpenMRS Talk](https://omrs-shields.psbrandt.io/custom/openmrs/talk/F26522?logo=openmrs)](http://talk.openmrs.org)
[![OpenMRS IRC](https://img.shields.io/badge/openmrs-irc-EEA616.svg?logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI2MTIiIGhlaWdodD0iNjEyIiB2aWV3Qm94PSIwIDAgNjEyIDYxMiI%2BPHBhdGggZD0iTTE1MyAyMjkuNWMtMjEuMTMzIDAtMzguMjUgMTcuMTE3LTM4LjI1IDM4LjI1UzEzMS44NjcgMzA2IDE1MyAzMDZjMjEuMTE0IDAgMzguMjUtMTcuMTE3IDM4LjI1LTM4LjI1UzE3NC4xMzMgMjI5LjUgMTUzIDIyOS41em0xNTMgMGMtMjEuMTMzIDAtMzguMjUgMTcuMTE3LTM4LjI1IDM4LjI1UzI4NC44NjcgMzA2IDMwNiAzMDZjMjEuMTE0IDAgMzguMjUtMTcuMTE3IDM4LjI1LTM4LjI1UzMyNy4xMzMgMjI5LjUgMzA2IDIyOS41em0xNTMgMGMtMjEuMTMzIDAtMzguMjUgMTcuMTE3LTM4LjI1IDM4LjI1UzQzNy44NjcgMzA2IDQ1OSAzMDZzMzguMjUtMTcuMTE3IDM4LjI1LTM4LjI1UzQ4MC4xMzMgMjI5LjUgNDU5IDIyOS41ek0zMDYgMEMxMzcuMDEyIDAgMCAxMTkuODc1IDAgMjY3Ljc1YzAgODQuNTE0IDQ0Ljg0OCAxNTkuNzUgMTE0Ljc1IDIwOC44MjZWNjEybDEzNC4wNDctODEuMzRjMTguNTUyIDMuMDYyIDM3LjYzOCA0Ljg0IDU3LjIwMyA0Ljg0IDE2OS4wMDggMCAzMDYtMTE5Ljg3NSAzMDYtMjY3Ljc1UzQ3NS4wMDggMCAzMDYgMHptMCA0OTcuMjVjLTIyLjMzOCAwLTQzLjkxLTIuNi02NC42NDMtNy4wMmwtOTAuMDQgNTQuMTI0IDEuMjA0LTg4LjdDODMuNSA0MTQuMTMzIDM4LjI1IDM0NS41MTMgMzguMjUgMjY3Ljc1YzAtMTI2Ljc0IDExOS44NzUtMjI5LjUgMjY3Ljc1LTIyOS41czI2Ny43NSAxMDIuNzYgMjY3Ljc1IDIyOS41UzQ1My44NzUgNDk3LjI1IDMwNiA0OTcuMjV6IiBmaWxsPSIjZmZmIi8%2BPC9zdmc%2B)](http://irc.openmrs.org)
[![OpenMRS Telegram](https://img.shields.io/badge/openmrs-telegram-009384.svg?logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNDAgMjQwIj48ZGVmcz48bGluZWFyR3JhZGllbnQgaWQ9ImEiIHgxPSIuNjY3IiB5MT0iLjE2NyIgeDI9Ii40MTciIHkyPSIuNzUiPjxzdG9wIHN0b3AtY29sb3I9IiMzN2FlZTIiIG9mZnNldD0iMCIvPjxzdG9wIHN0b3AtY29sb3I9IiMxZTk2YzgiIG9mZnNldD0iMSIvPjwvbGluZWFyR3JhZGllbnQ%2BPGxpbmVhckdyYWRpZW50IGlkPSJiIiB4MT0iLjY2IiB5MT0iLjQzNyIgeDI9Ii44NTEiIHkyPSIuODAyIj48c3RvcCBzdG9wLWNvbG9yPSIjZWZmN2ZjIiBvZmZzZXQ9IjAiLz48c3RvcCBzdG9wLWNvbG9yPSIjZmZmIiBvZmZzZXQ9IjEiLz48L2xpbmVhckdyYWRpZW50PjwvZGVmcz48Y2lyY2xlIGN4PSIxMjAiIGN5PSIxMjAiIHI9IjEyMCIgZmlsbD0idXJsKCNhKSIvPjxwYXRoIGZpbGw9IiNjOGRhZWEiIGQ9Ik05OCAxNzVjLTMuODg4IDAtMy4yMjctMS40NjgtNC41NjgtNS4xN0w4MiAxMzIuMjA3IDE3MCA4MCIvPjxwYXRoIGZpbGw9IiNhOWM5ZGQiIGQ9Ik05OCAxNzVjMyAwIDQuMzI1LTEuMzcyIDYtM2wxNi0xNS41NTgtMTkuOTU4LTEyLjAzNSIvPjxwYXRoIGZpbGw9InVybCgjYikiIGQ9Ik0xMDAuMDQgMTQ0LjQxbDQ4LjM2IDM1LjczYzUuNTIgMy4wNDQgOS41IDEuNDY3IDEwLjg3Ni01LjEyNGwxOS42ODUtOTIuNzYzYzIuMDE2LTguMDgtMy4wOC0xMS43NDYtOC4zNTgtOS4zNWwtMTE1LjU5IDQ0LjU3MmMtNy44OSAzLjE2NS03Ljg0NCA3LjU2Ny0xLjQ0IDkuNTI4bDI5LjY2NCA5LjI2IDY4LjY3My00My4zMjZjMy4yNC0xLjk2NiA2LjIxNy0uOTEgMy43NzUgMS4yNTgiLz48L3N2Zz4%3D)](https://telegram.me/openmrs)
[![OpenMRS Radiology Wiki](https://img.shields.io/badge/openmrs-wiki-5B57A6.svg?logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNjAiIGhlaWdodD0iMTQyIiB2aWV3Qm94PSIwIDAgMTYwIDE0MiI%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%3D%3D)](https://wiki.openmrs.org/display/docs/Radiology+Module)

## Support

Ask questions on [OpenMRS Talk](https://talk.openmrs.org/).

## License

[MPL 2.0 w/ HD](http://openmrs.org/license/) © [OpenMRS Inc.](http://www.openmrs.org/)
"
47,VectorInstitute/cyclops,Python,"![cyclops Logo](https://github.com/VectorInstitute/cyclops/blob/main/docs/source/theme/static/cyclops_logo-dark.png?raw=true)

--------------------------------------------------------------------------------

[![PyPI](https://img.shields.io/pypi/v/pycyclops)](https://pypi.org/project/pycyclops)
[![code checks](https://github.com/VectorInstitute/cyclops/actions/workflows/code_checks.yml/badge.svg)](https://github.com/VectorInstitute/cyclops/actions/workflows/code_checks.yml)
[![integration tests](https://github.com/VectorInstitute/cyclops/actions/workflows/integration_tests.yml/badge.svg)](https://github.com/VectorInstitute/cyclops/actions/workflows/integration_tests.yml)
[![docs](https://github.com/VectorInstitute/cyclops/actions/workflows/docs_deploy.yml/badge.svg)](https://github.com/VectorInstitute/cyclops/actions/workflows/docs_deploy.yml)
[![codecov](https://codecov.io/gh/VectorInstitute/cyclops/branch/main/graph/badge.svg)](https://codecov.io/gh/VectorInstitute/cyclops)
[![license](https://img.shields.io/github/license/VectorInstitute/cyclops.svg)](https://github.com/VectorInstitute/cyclops/blob/main/LICENSE)

``cyclops`` is a framework for facilitating research and deployment of ML models
in the health (or clinical) setting. It provides a few high-level APIs namely:


* `query` - Querying EHR databases (such as MIMIC-IV)
* `process` - Process static and temporal EHR data
* `evaluate` - Evaluate models on clinical prediction tasks
* `monitor` - Detect data drift relevant for clinical use cases

``cyclops`` also provides a library of use-cases on clinical datasets. The implemented
use cases include:

* Mortality decompensation prediction


## 🐣 Getting Started

### Installing cyclops using pip

```bash
python3 -m pip install pycyclops
```

The core package only includes support for the `process` API. To install support for
`query`, `evaluate` and `monitor` APIs, install them as extra dependency installs.

To install with `query` API support,

```bash
python3 -m pip install 'pycyclops[query]'
```

To install with `evaluate` API support,

```bash
python3 -m pip install 'pycyclops[evaluate]'
```

To install with `monitor` API support,

```bash
python3 -m pip install 'pycyclops[monitor]'
```

Multiple extras could also be combined, for example to install with both `query` and
`evaluate` API support:

```bash
python3 -m pip install 'pycyclops[query,evaluate]'
```


## 🧑🏿‍💻 Developing

The development environment has been tested on ``python = 3.9``.

The python virtual environment can be set up using
[poetry](https://python-poetry.org/docs/#installation). Hence, make sure it is
installed and then run:

```bash
python3 -m poetry install
source $(poetry env info --path)/bin/activate
```

API documentation is built using [Sphinx](https://www.sphinx-doc.org/en/master/) and
can be locally built by:

```bash
cd docs
make html SPHINXOPTS=""-D nbsphinx_allow_errors=True""
```

### Contributing
Contributing to cyclops is welcomed.
See [Contributing](https://vectorinstitute.github.io/cyclops/api/intro.html) for
guidelines.


## 📚 [Documentation](https://vectorinstitute.github.io/cyclops/)

## 📓 Notebooks

To use jupyter notebooks, the python virtual environment can be installed and
used inside an IPython kernel. After activating the virtual environment, run:

```bash
python3 -m ipykernel install --user --name <name_of_kernel>
```

Now, you can navigate to the notebook's ``Kernel`` tab and set it as
``<name_of_kernel>``.

## 🎓 Citation
Reference to cite when you use CyclOps in a project or a research paper:
```
@article {Krishnan2022.12.02.22283021,
	author = {Krishnan, Amrit and Subasri, Vallijah and McKeen, Kaden and Kore, Ali and Ogidi, Franklin and Alinoori, Mahshid and Lalani, Nadim and Dhalla, Azra and Verma, Amol and Razak, Fahad and Pandya, Deval and Dolatabadi, Elham},
	title = {CyclOps: Cyclical development towards operationalizing ML models for health},
	elocation-id = {2022.12.02.22283021},
	year = {2022},
	doi = {10.1101/2022.12.02.22283021},
	publisher = {Cold Spring Harbor Laboratory Press},
	URL = {https://www.medrxiv.org/content/early/2022/12/08/2022.12.02.22283021},
	journal = {medRxiv}
}
```
"
48,hapifhir/hapi-fhir,Java,"HAPI FHIR
=========

HAPI FHIR - Java API for HL7 FHIR Clients and Servers

[![License][Badge-License]][Link-License]

## CI/CD
| CI Status (master) | SNAPSHOT Pipeline | Current Release |
| :---: | :---: | :---: |
| [![Build Status][Badge-AzurePipelineMaster]][Link-AzurePipelinesMaster] | [![Build Status][Badge-AzureReleaseSnapshot]][Link-AzurePipelinesSnapshot] | [![Release Artifacts][Badge-MavenCentral]][Link-MavenCentral] |

## Coverage and Quality

[![codecov][Badge-CodeCov]][Link-CodeCov]
[![Language grade: Java](https://img.shields.io/lgtm/grade/java/g/hapifhir/hapi-fhir.svg?logo=lgtm&logoWidth=18)](https://lgtm.com/projects/g/hapifhir/hapi-fhir/context:java)

## Documentation and wiki

Complete project documentation is available here:
http://hapifhir.io

A demonstration of this project is available here:
http://hapi.fhir.org/

This project is Open Source, licensed under the Apache Software License 2.0.

Please see [this wiki page][Link-wiki] for information on where to get help with HAPI FHIR. 

Please see [Smile CDR][Link-SmileCDR] for information on commercial support.

[Link-AzurePipelines]: https://dev.azure.com/hapifhir/HAPI%20FHIR/_build
[Link-AzurePipelinesMaster]: https://dev.azure.com/hapifhir/HAPI%20FHIR/_build?definitionId=2
[Link-AzurePipelinesSnapshot]: https://dev.azure.com/hapifhir/HAPI%20FHIR/_build?definitionId=3
[Link-MavenCentral]: http://search.maven.org/#search|ga|1|ca.uhn.hapi.fhir
[Link-CodeCov]: https://codecov.io/gh/hapifhir/hapi-fhir
[Link-wiki]: https://github.com/hapifhir/hapi-fhir/wiki/Getting-Help
[Link-SmileCDR]: https://smilecdr.com
[Link-License]: https://hapifhir.io/hapi-fhir/license.html

[Badge-AzurePipelineMaster]: https://dev.azure.com/hapifhir/HAPI%20FHIR/_apis/build/status/hapifhir.hapi-fhir?branchName=refs%2Fpull%2F2319%2Fmerge
[Badge-AzureReleaseSnapshot]: https://dev.azure.com/hapifhir/HAPI%20FHIR/_apis/build/status/SNAPSHOT%20pipeline?branchName=master
[Badge-MavenCentral]: https://maven-badges.herokuapp.com/maven-central/ca.uhn.hapi.fhir/hapi-fhir-base/badge.svg
[Badge-CodeCov]: https://codecov.io/gh/hapifhir/hapi-fhir/branch/master/graph/badge.svg?token=zHfnKfQB9X
[Badge-License]: https://img.shields.io/badge/license-apache%202.0-60C060.svg


"
49,aws-samples/amazon-sagemaker-healthcare-fraud-detection,Jupyter Notebook,"

# Introduction

IDC study states that 40% of Enteprises in year 2019 will be working to include AI/ML as a part of their transformative strategy. Today, AI/ML is beyond the hype cycle and there are usecases that are providing real business value. 

In this workshop, we will work on a healthcare insurance fraud identification usecase. We will apply machine learning to identify anomalous claims that require further investigation. The technique used in the workshop is broadly applicable to multiple problems fraud, abuse and waste.

## **Launch an Amazon SageMaker Jupyter Notebook**

### Prerequisites and assumptions
1. To run this Jupyter Notebook, you need an personal Laptop and an AWS account that provides access to AWS services.

### Steps
1. Sign In to the [AWS Console](https://aws.amazon.com/)
2. Click Services, search for **Amazon SageMaker** and Click **Amazon SageMaker** in the dropdown![Find SageMaker](./images/find-sagemaker.png)
3. After you land on Amazon SageMaker console, click on **Notebook Instances**![SageMaker Console](./images/sagemaker-console.png)
4. Click **Create Notebook**![Create Notebook](./images/create-notebook.png)
5. Give Notebook a name you can remember and fill out configuration details as suggested in the screenshots below.![Create Notebook Instance](./images/create-notebook-instance.png)
6. Select IAM Role if one already exists in the dropdown![Select Existing Role](./images/select-role.png)
7. Create a new role if one doesn't exist. ![Create new role](./images/create-role.png)
8. Provide  a path to clone public git repo that we will use today for our workshop to download data dictionary and Jupyter IPython Notebook ![Select Git Repo](./images/select-gitrepo.png) 
9. Provide the path of [Git repo](https://github.com/aws-samples/amazon-sagemaker-healthcare-fraud-detection.git)
![Provide Git url](./images/clone-gitrepo.png) 
6. Click **Create Notebook Instance**
8. In the Amazon SageMaker Console-->Notebook Instances, wait for your notebook instance to start. Observe change from Pending to In Service status.![Creation pending](./images/creation-pending.png)![Notebook In Service](./images/notebook-inservice.png)
9. Remember the name of your notebook instance and Click **Open Jupyter** for your notebook.![Notebook In Service](./images/notebook-inservice.png)
10. Validate your data and notebook cloned from Git Repo![Validate Git Clone](./images/validate-git-clone.png)

## **Finish your Lab in Jupyter Notebook**
1. Click on **healthcare-fraud-identification-using-PCA-anomaly-detection.ipynb** and start working. From here onwards all the instruction will be in the Jupyter Notebook. Come back after you have completed all the steps in the Jupyter Notebook and finish rest of the steps as suggested below.


## Finish
1. **Congratulations!** 
2. Please make sure to delete all resources as mentioned in the section below.


## Cleanup Resources
1. Go to Amazon SageMaker console to shutdown your Amazon SageMaker Jupyter Notebook Instance, select your instance from the list.Select **Stop** from the **Actions** drop down menu.
![Stop Notebook Instance](./images/stop-notebook.png)
2. After your notebook instance is completely **Stopped**, select **Delete** fron the **Actions** drop down menu to **delete** your notebook instance.![Delete Notebook Instance](./images/delete-notebook.png)
4. Navigate to Amazon S3 Console. 
![S3 Console](./images/s3-console.png)
5. Find Amazon S3 bucket created for training and click to list objects in the bucket.![Find Bucket](./images/search-s3-bucket.png)
6. Navigate to the **model-tar.gz** and delete it by using **Actions** menu.![Delete Model](./images/delete-model.png) 
6. Navigate to the training data file **healthcare_fraud_identification_feature_store** and delete it by using **Actions** menu.![Delete Training Data](./images/delete-training-data.png)
7. After all the objects are deleted in the bucket. Go ahead and delete the bucket using the Actions menu.![Delete Bucket](./images/delete-bucket.png)













    

"
0,AmitXShukla/Healthcare-Management-App-Flutter_Firebase,Dart,"# Flutter FireBase Healthcare Management App
Complete Healthcare Management (Patient, OPD, IPD, Rx, Lab) in Flutter Firebase App for iOS Android and Web

```diff
- If you like this project, please consider giving it a star (*) and follow me at GitHub & YouTube.
```
[<img src=""https://github.com/AmitXShukla/AmitXShukla.github.io/blob/master/assets/icons/youtube.svg"" width=40 height=50>](https://youtube.com/AmitShukla_AI)
[<img src=""https://github.com/AmitXShukla/AmitXShukla.github.io/blob/master/assets/icons/github.svg"" width=40 height=50>](https://github.com/AmitXShukla)
[<img src=""https://github.com/AmitXShukla/AmitXShukla.github.io/blob/master/assets/icons/medium.svg"" width=40 height=50>](https://medium.com/@Amit_Shukla)
[<img src=""https://github.com/AmitXShukla/AmitXShukla.github.io/blob/master/assets/icons/twitter_1.svg"" width=40 height=50>](https://twitter.com/ashuklax)

# Elish HMS

Elish Healthcare Management System App

## Objective 
Manage OPD, IPD, Pathology, WebMD, Rx, Patient Appointments<br/><br/>

<i>Due to current Covid-19 situation,<br/>
Patient's private data is not stored in app and location tracing functionality is not available with out government/authorities approval.</i>
## Getting Started

This project is a community version and is absolutely free for private use.<br/>
<a href=""https://www.youtube.com/playlist?list=PLp0TENYyY8lHcc8mZiYG83sbsCea2xd3r"">click here for Demo & Video tutorials</a>

## Technologies
```sbtshell)
Frontend: Flutter
Backend:Google Firestore/Firebase
Messages: LOOM SDK
WebView: loom-app (using Angular version
``` 

## Related Apps
<ul>
<li><a href=""https://getcovidvaccine.web.app/"">Vaccine Distribution App</a></li>
<li><a href=""https://www.youtube.com/watch?v=MkV413X2Kmw&list=PLp0TENYyY8lHL-G7jGbhpJBhVb2UdTOhQ&index=1&t=698s"">Pandemic Contact Tracing, Visitor Management, Mobile Assets/Employee Attendance App</a></li>
</ul>

## Features
<ul>
<li>Store millions of records with lightening fast data retrieval</li>
<li>hands free /voice activated typing</li>
<li>Secured App (Role based access with Admin panel)</li>
<li>Local dictionary based auto-completion</li>
<li>Global dictionary based auto-completion/auto-sync (Pro)</li>
<li>GBs of pictures, documents, Lab reports, Receipts (Pro)</li>
<li>Self learning (auto complete) data entry (Pro)</li>
<li>Social authentication (Pro)</li>
<li>SMS, EMAIL, WhatsAPP API (Pro)</li>
</ul>
<i>send email to info@elishcosulting.com for Pro version enquiries.</i>

## Product Images

![Pic 1](./images/hms_pic_1.png)
![Pic 2](./images/hms_pic_2.png)
![Pic 3](./images/hms_pic_3.png)
![Pic 4](./images/hms_pic_4.png)



## How to Install

<ul>
    <li>Install Flutter environment</li>
    <li>Download This GitHub repository</li>
    <li>install Flutter packages *pub get) and Flutter web -> Flutter create .</li>
    <li>Setup firebase account/project</li>
    <li>Copy Firebase Project Config settings and replace variable firebaseConfig at src/web/index.html</li>
    <li>enable Firebase social authentications</li>
    <li>update Firebase Rules</li>

```sbtshell
    rules_version = '2';
    service cloud.firestore {
    match /databases/{database}/documents {
    match /{document=**} {
      allow read, write: if false;
    }
    match /roles/{document} {
    // fix this, anyone who is logged in, can read these document & passwords
    //  allow read: if isSignedIn();
  	allow read, write: if false;
    }
    
    match /users/{document} {
    allow create: if true;
    allow read : if isSignedIn() && (isDocOwner() || isAdmin());
    allow update: if isSignedIn() && isDocOwner() && onlyContentChanged();
    allow update, delete: if isAdmin();
    }
    
    match /person/{document=**} {
    allow create: if true;
    allow read, update : if isSignedIn() && (isDocOwner() || isAdmin());
    allow delete : if isSignedIn() && isAdmin();
    }
    
    match /person/{document}/Vaccine/{doc=**} {
    allow create: if true;
    // allow read, update : if isSignedIn() && (isDocOwner() || isAdmin());
    // fix this later
    allow read, update : if true;
    allow delete : if isSignedIn() && isAdmin();
    }
    
    match /person/{document}/OPD/{doc} {
    allow create: if true;
    // allow read, update : if isSignedIn() && (isDocOwner() || isAdmin());
    // fix this later
    allow read, update : if true;
    allow delete : if isSignedIn() && isAdmin();
    }
    
    match /person/{document}/Lab/{doc} {
    allow create: if true;
    // allow read, update : if isSignedIn() && (isDocOwner() || isAdmin());
    // fix this later
    allow read, update : if true;allow read, update : if isSignedIn() && (isDocOwner() || isAdmin());
    allow delete : if isSignedIn() && isAdmin();
    }
    
    match /person/{document}/Rx/{doc} {
    allow create: if true;
    // allow read, update : if isSignedIn() && (isDocOwner() || isAdmin());
    // fix this later
    allow read, update : if true;
    allow delete : if isSignedIn() && isAdmin();
    }
    
    match /person/{document}/Messages/{doc} {
    allow create: if true;
    // allow read, update : if isSignedIn() && (isDocOwner() || isAdmin());
    // fix this later
    allow read, update : if true;
    allow delete : if isSignedIn() && isAdmin();
    }
    
    match /appointments/{document} {
    allow create: if true;
    allow read, update : if isSignedIn() && (isDocOwner() || isAdmin());
    allow delete : if isSignedIn() && isAdmin();
    }
    
    match /records/{document} {
    allow create: if true;
    allow read, update : if isSignedIn() && (isDocOwner() || isAdmin());
    }
    
    match /vaccine/{document} {
    allow create: if true;
    allow read, update : if isSignedIn() && (isDocOwner() || isAdmin());
    }
    
    match /purchase/{document} {
    allow create: if true;
    allow read, update : if isSignedIn() && (isDocOwner() || isAdmin());
    allow delete : if isSignedIn() && isAdmin();
    }
    
		match /msr/{document} {
    allow create: if true;
    allow read, update : if isSignedIn() && (isDocOwner() || isAdmin());
    allow delete : if isSignedIn() && isAdmin();
    }
    
    match /vendor/{document} {
    allow create: if true;
    allow read, update : if isSignedIn() && (isDocOwner() || isAdmin());
    allow delete : if isSignedIn() && isAdmin();
    }
    
    match /warehouse/{document} {
    allow create: if true;
    allow read: if isSignedIn()
    allow update : if isSignedIn() && (isDocOwner() || isAdmin());
    allow delete : if isSignedIn() && isAdmin();
    }
    match /item/{document} {
    allow create: if true;
    allow read: if isSignedIn()
    allow update : if isSignedIn() && (isDocOwner() || isAdmin());
    allow delete : if isSignedIn() && isAdmin();
    }
    
    // helper functions
    function isSignedIn() {
    return request.auth.uid != null;
    }
    
    function onlyContentChanged() {
    return request.resource.data.role == resource.data.role;
    // make sure user is not signing in with any role or changin his role during update
    }
    function isDocOwner() {
    return request.auth.uid == resource.data.author;
    }
    // function isDocCreater() {
    // return request.auth.uid == request.resource.data.author;
    // }
    function isAdmin() {
    return get(/databases/$(database)/documents/users/$(request.auth.uid)).data.role == ""admin"";
    }
    // function isEmployee() {
    // return get(/databases/$(database)/documents/settings/$(request.auth.uid)).data.role == ""employee"";
    // }
    }
    }
```
</ul>

![Pic 4](./images/env_variable.png)
![Pic 4](./images/social_auth.png)
![Pic 4](./images/rules.png)"
1,IRCAD/sight,C++,"# Sight

| Branch |    Status |
|--------|-----------|
| Dev    | [![pipeline status](https://git.ircad.fr/Sight/sight/badges/dev/pipeline.svg)](https://git.ircad.fr/Sight/sight/commits/dev) |
| Master | [![pipeline status](https://git.ircad.fr/Sight/sight/badges/master/pipeline.svg)](https://git.ircad.fr/Sight/sight/commits/master) |

## Description
[//]: # (cspell: disable)
**Sight**, the **S**urgical **I**mage **G**uidance and **H**ealthcare **T**oolkit aims to ease the creation of
applications based on medical imaging.
[//]: # (cspell: enable)

It includes various functionalities such as 2D and 3D digital image processing, visualization, augmented reality and
medical interaction simulation. It runs on Microsoft Windows and Linux, is written in C++, and features rapid interface
design using XML files. It is freely available under the LGPL.

**Sight** is mainly developed by the Surgical Data Sciences Team of [IRCAD France](https://www.ircad.fr), where it is
used everyday to develop innovative applications for the operating room and medical research centers.

Many **tutorials** and **examples**, which can help you to learn smoothly how to use **Sight**, are located in the
`tutorials` and `examples` directories.
Detailed steps are described [here](https://sight.pages.ircad.fr/sight-doc/Tutorials/index.html).

### Features

- 2D/3D visualization of medical images, meshes, and many widgets.
- Import / export medical data from various formats (DICOM, [VTK](https://www.vtk.org/), ...) and sources
  (files, devices, PACS, ...).
- Playing, recording, processing videos (webcams, network streams, Intel RealSense devices, ...).
- Easy GUI configuration and customization (XML description and stylesheets support).
- Timeline, allowing to store various data (video, matrices, markers, etc...) and synchronize these data across time.
- Mono and stereo camera calibration,
- [ArUco](https://sourceforge.net/projects/aruco/) optical markers tracking,
- [openIGTLink](http://openigtlink.org/) support through client and server services,
- Advanced memory management to support large data. Unused data can be offloaded to disk, saving memory for foreground
  tasks.
- Work session or any part of it, can be saved and restored on disk. The data itself can be encrypted using AES256 to
  ensure a high level of security and privacy


### Hardware / Operating System / Compiler support

**Sight** is written in standard C++17 and use [CMake](https://cmake.org/) as its build system, which means that Sight
should at least compile on any operating system that provide support for a decent C++17 compiler, CMake, **AND** Sight's
dependencies (see [Install](#install) for a list of dependencies for Linux platform). However, we currently have access
to a limited set of hardware/OS/compiler combinations where the code is actually tested on a regular basis.

Such combination includes:
-  [Debian 11 stable on AMD64 with GCC 10.2.1](https://www.debian.org/ports/amd64)
-  [Ubuntu 21.04 on AMD64 with GCC 10.3.0 or CLang 12](https://releases.ubuntu.com/21.04/)
-  [Microsoft Windows 10 on AMD64 with VisualStudio 2019](https://www.microsoft.com/windows/)

> If your platform is not listed, that *doesn't* mean **Sight** will not work, just we cannot guarantee that it is well
> tested. If you are on this kind of platform and are able to build and use **Sight**, feel free to share with us your
> success !

> We use some fine tuned compiler flags (like `/arch:AVX2`) to optimize and generate code specifically for CPUs that
> were released around 2013 and later. It means, if your CPU is too old, **Sight** will crash at runtime because some
> CPU instructions are not implemented. In such situation, you can modify hidden cmake variable `SIGHT_ARCH` at
> configuring time or modify the default compiler flag directly in **Sight** CMake code.

## Applications

### SightViewer

**SightViewer** is a full featured medical image and mesh viewer with advanced rendering features such as volume
rendering. It supports most medical image formats, and can also retrieve DICOM files from a PACS. It demonstrates many
useful features of Sight.

<div align=center style=""text-align: center; display: flex; flex-flow: row wrap; justify-content: space-around;"">
<figure>
    <img src=""https://git.ircad.fr/sight/sight-doc/-/raw/dev/Introduction/media/SightViewer01.gif"">
    <figcaption>
        <b><i>MPR view of a medical 3D image with additional volume rendering</i></b>
    </figcaption>
</figure>
<figure>
    <img src=""https://git.ircad.fr/sight/sight-doc/-/raw/dev/Introduction/media/SightViewer02.gif"">
    <figcaption>
        <b><i>Volume rendering and transfer function tuning</i></b>
    </figcaption>
</figure>
<figure>
    <img src=""https://git.ircad.fr/sight/sight-doc/-/raw/dev/Introduction/media/mixed_vr_reconstructions.gif"">
    <figcaption>
        <b><i>Volume rendering mixed with 3D surfacic meshes</i></b>
    </figcaption>
</figure>
</div>

### DicomXplorer

**DicomXplorer** is a simple medical image viewer that can connect to a PACS to retrieve DICOM data. It supports CT-scan
and MRI images.

<div align=center style=""text-align: center; display: flex; flex-flow: row wrap; justify-content: space-around;"">
<figure>
    <img src=""https://git.ircad.fr/sight/sight-doc/-/raw/dev/Introduction/media/DicomXplorer01.gif"">
    <figcaption>
        <b><i>DICOM and medical image files navigation</i></b>
    </figcaption>
</figure>
<figure>
    <img src=""https://git.ircad.fr/sight/sight-doc/-/raw/dev/Introduction/media/DicomXplorer02.gif"">
    <figcaption>
        <b><i>MPR view of a medical 3D image</i></b>
    </figcaption>
</figure>
</div>

### SightCalibrator

**SightCalibrator** is a user-friendly application to calibrate mono and stereo cameras.
This software is a must-have since camera calibration is a mandatory step in any AR application.

<div align=center style=""text-align: center; display: flex; flex-flow: row wrap; justify-content: space-around;"">
<figure style="""">
    <img src=""https://git.ircad.fr/sight/sight-doc/-/raw/dev/Introduction/media/SightCalibrator01.gif"">
    <figcaption>
        <b><i>Intrinsic & extrinsic calibration of mono/stereo cameras with live reprojection error display</i></b>
    </figcaption>
</figure>
</div>

## Install

See [detailed install instructions](https://sight.pages.ircad.fr/sight-doc/Installation/index.html) for Windows and
Linux.

## Documentation

* [Documentation](https://sight.pages.ircad.fr/sight-doc)
* [Tutorials](https://sight.pages.ircad.fr/sight-doc/Tutorials/index.html)
* [Doxygen](https://sight.pages.ircad.fr/sight)

## Support

Please note that our GitLab is currently only available in read-only access for external developers and users. This is a
restriction because of the licensing model of GitLab. Since we use an EE version, we would be forced to pay for every
community user, and unfortunately we cannot afford it. This licensing model might change in the future
https://gitlab.com/gitlab-org/gitlab-ee/issues/4382 though.

Until then, we gently ask our community users to use our GitHub mirror to
[report any issues](https://github.com/IRCAD/sight/issues) or propose
[contributions](https://github.com/IRCAD/sight/pulls).

You can also get live community support on the [gitter chat room](https://gitter.im/IRCAD-IHU/sight-support).

"
2,hasyed/HealthCareApp,Java,"HealthCareApp
=============

The Mobile Solution to maintain consumption of daily use edibles and calorie balance with interactive user interfaces, Chart and Nutrition labels calculated in such a way that are readable to user.

This app takes an image of  nutrition chart of the product which user wants to intake. OpenCV is used to clean the captured image. Then the image goes to OCR(Optical Character Recognation) which extract the information from the image and added them to user database that he has consumed it, the information  includes Calories, Total Fats and other Nutritions. 

If user want to gain or reduce weight, the formula in the main of the app helps user to input in how many days he want to reduce the weight and how much he wants to reduce. This will give him the Calories he wanted to take take everyday.
User can manually add products or exercise too. Products that he intake increase the calories and exercise that he do reduces the calories.

There is a chart that helps user to see his previouse performance regards calories as well.

I have forked [android-ocr](https://github.com/rmtheis/android-ocr/tree/master/android/src) with some changes for openCV for cleansing the image for my help. 
##Requires
[tess-two](https://github.com/rmtheis/tess-two/tree/master/tess-two)

[OpenCV for android](http://opencv.org/)


"
3,Qingbao/HealthCareStepCounter,Java,"HealthCareStepCounter
=====================

Coming soon: rewritten with React Native

"
4,arvindsis11/Ai-Healthcare-Chatbot,CSS,"# flask-chatbot
Built on python 3.6
Flask==0.11
chatterbot==0.8.4
SQLAlchemy==1.1.11

#### A web implementation of [ChatterBot](https://github.com/gunthercox/ChatterBot) using Flask.

## Local Setup:
 1. Open command prompt and locate folder. run 'pip install -r requirements.txt'
 2. Run *train.py*
 3. Run *run.py*
 4. Demo will be live at http://localhost:5000/
 
 ## Git push cmd- for reference
 ```java
 echo ""# MyRestApi all crud operations using spring boot framework"" >> README.md
git init
git add .
git commit -m ""initial commit""
git branch -M main
git remote add origin https://github.com/arvindsis11/MyRestApi.git
git push -u origin main
git rm -r --cached .
////////////////////////////////////////
or push an existing repository from the command line
git remote add origin https://github.com/arvindsis11/springJPAdemo.git
git branch -M main
git push -u origin main
https://github.com/arvindsis11/angular-todomanagement-app.git
/////////////////////////////////////
common git error:
use this:
git pull --rebase origin main
git push origin main
url:https://stackoverflow.com/questions/24114676/git-error-failed-to-push-some-refs-to-remote
 ```

## License
This source is free to use, but ChatterBot does have a license which still applies and can be found on the [LICENSE](https://github.com/gunthercox/ChatterBot/blob/master/LICENSE) page.
"
5,microsoft/Healthcare-Blockchain-Solution-Accelerator,C#,"# Blockchain Healthcare Solution Accelerator Guide

## About this repository
This accelerator was built to provide developers with all of the resources needed to quickly build an initial Hyperledger Fabric Healthcare data transactionary solution. Use this accelerator to jump start your development efforts with Hyperledger and Azure.

This repository contains the steps, scripts, code, and tools to create a Hyperledger Fabric blockchain application. 00_Resource_Deployment will create the necessary supporting resources in Azure (Storage, Kubernetes, and Cosmos DB). 01_Hyperledger_Fabric_Deployment will configure and deploy a Hyperledger Fabric blockchain network using Helm Packages and Kubernetes. 02_Hyperledger_Fabric_Client will install the necessary chaincode. Finally 03_Application_Deployment will deploy and host your application either locally or in your subscription.

## Prerequisites
In order to successfully complete your solution, you will need to have access to and or provisioned the following:
1. Access to an Azure subscription
2. Visual Studio 2017 or 2019
3. Kubectl, Helm, and Docker Command Line Tools installed
4. Service Fabric

Optional
1. Intellij CE

## Azure and Blockchain
The directions provided for this repository assume fundemental working knowledge of Azure, Cosmos DB, Azure Storage, Hyperledger Fabric, Service Fabric, and Kubernetes.  

For additional training and support, please see:
 1. [Kubernetes](https://kubernetes.io/)
 2. [Hyperledger Fabric](https://hyperledger-fabric.readthedocs.io/en/release-1.4/)
 3. [Service Fabric](https://azure.microsoft.com/en-us/services/service-fabric/)
 4. [Cosmos DB](https://docs.microsoft.com/en-us/azure/cosmos-db/introduction)

## Getting Started and Process Overview
Clone/download this repo onto your computer and then walk through each of these folders in order, following the steps outlined in each of the README files.  After completion of all steps, you will have a working end-to-end solution with the following architecture:

![Microservices Architecture](./References/architecture.JPG)


### [00 - Resource Deployment](./00_Resource_Deployment)
The resources in this folder can be used to deploy the required resources into your Azure Subscription. This can be done either via the [Azure Portal](https://portal.azure.com) or by using the [PowerShell script](./00_Resource_Deployment/deploy.ps1) included in the resource deployment folder.

After deployed, you will have a Cosmos DB account and database, Azure storage, and Kubernetes cluster deployed in your specified resource group.

### [01 - Hyperledger Fabric Deployment](./01_Hyperledger_Fabric_Deployment)
This folder contains the Hyperledger Fabric Deployment configuration files. To prepare the environment and deploy the infrastructer run the [deploy script](./01_Hyperledger_Fabric_Deployment/deploy.ps1).

Running this script will deploy a basic fabric network consisting of two organizations: one peer organization and one orderer organization. To read more about hyperledger reference the [Hyperledger Fabric Documentation](https://hyperledger-fabric.readthedocs.io/en/release-1.4/).

### [02 - Hyperledger Fabric Client](./02_Hyperledger_Fabric_Client)
This folder contains the Kotlin Chaincode and Hyperledger Fabric server used to communicate with the blockchain network. The script in this folder will pull the Fabric Chaincode, Client, and gRPC server. This image will install the chaincode and allow the application to execute against the Blockchain network. Follow the provided instructions.

### [03 - Application Deployment](./03_Application_Deployment)
This folder contains the .net services for the proof content storage service, transaction tracker, transaction indexer, and gRPC Fabric Client. The Angular web application is also started and hosted with these services. Service Fabric is used to host this application.

## Links
Hosted Site: [Healthcare Blockchain Solution](http://healthcare-apphosting.southcentralus.cloudapp.azure.com/login)

*Use income less than 11000 and a NY Zip Code for a profile to qualify*

Video: [Healthcare Blockchain Solution Video](https://msit.microsoftstream.com/video/7f62ce8c-39e1-40d6-8adb-cbf298f31dfe)

*Or download [Healthcare Blockchain Solution Video](healthcare_solution_video.mp4)*


## License
Copyright (c) Microsoft Corporation

All rights reserved.

MIT License

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the """"Software""""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED AS IS, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE

## Contributing

This project welcomes contributions and suggestions.  Most contributions require you to agree to a
Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us
the rights to use your contribution. For details, visit https://cla.microsoft.com.

When you submit a pull request, a CLA-bot will automatically determine whether you need to provide
a CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions
provided by the bot. You will only need to do this once across all repos using our CLA.

This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).
For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or
contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.
"
6,openmrs/openmrs-module-radiology,Java,"# openmrs-module-radiology

[![Build Status](https://travis-ci.org/openmrs/openmrs-module-radiology.svg?branch=master)](https://travis-ci.org/openmrs/openmrs-module-radiology) [![Coverage Status](https://coveralls.io/repos/openmrs/openmrs-module-radiology/badge.svg?branch=master&service=github)](https://coveralls.io/github/openmrs/openmrs-module-radiology?branch=master) [![Codacy Badge](https://api.codacy.com/project/badge/grade/5e0137f0c916494eaa3ba7de43149ef7)](https://www.codacy.com/app/teleivo/openmrs-module-radiology_2) [![Dependency Status](https://www.versioneye.com/user/projects/57a194fb3d8eb6002f560778/badge.svg?style=flat)](https://www.versioneye.com/user/projects/57a194fb3d8eb6002f560778)

####Table of Contents

1. [Overview](#overview)
2. [Build](#build)
3. [Install](#install)
  * [Docker](#docker-whale)
  * [Demo data](#demo-data)
4. [Documentation](#documentation)
  * [Website](#website)
  * [Developer guides](#developer-guides)
  * [Wiki](#wiki)
5. [Contributing](#contributing)
  * [Code](#code)
  * [Translation](#translation)
6. [Issues](#issues)
7. [Limitations](#limitations)
8. [Community](#community)
9. [Support](#support)
10. [License](#license)

## Overview

OpenMRS module radiology (previously called radiologydcm4chee) is a module adding capabilities of a Radiology
Information System (RIS) onto OpenMRS.

## Build

### Prerequisites

You need to have installed

* a Java JDK 8
* the build tool [Maven](https://maven.apache.org/)

You need to configure Maven to use the JAVA JDK 8

```bash
mvn -version
```

Should tell you what version Maven is using.

You need to clone this repository:

```bash
git clone https://github.com/openmrs/openmrs-module-radiology.git
```

### Command

After you have taken care of the [Prerequisites](#prerequisites)

Execute the following command:

```bash
cd openmrs-module-radiology
mvn clean package
```

This will generate the radiology module in `omod/target/radiology-{VERSION}.omod` which you will have to deploy into OpenMRS.

## Install

The easiest way to install the module is to use [Docker](https://www.docker.com/).

### Docker :whale:

This module can be baked into a Docker image so you can easily run and test it.

#### Prerequisites

After you have taken care of the [Build Prerequisites](#prerequisites)

Make sure you have [Docker](https://docs.docker.com/) installed.

#### Build

Build the Radiology Module and its Docker image:

```bash
cd openmrs-module-radiology
mvn clean package docker:build
```

#### Run

To run an instance of the OpenMRS Radiology Module execute (assumes you have
created a Docker image):

```bash
cd openmrs-module-radiology
mvn docker:start
```

OpenMRS will be accessible at `http://<IP ADDRESS>:8080/openmrs`

**NOTE: The IP address varies depending on your setup.**

If you are using [Docker machine](https://docs.docker.com/machine/) refer to its documentation on how to get the IP address.
If you are on Linux it will probably be will be `localhost`.

#### Documentation

Please read the corresponding [DOCKER.md](docs/DOCKER.md) for more detailed
explanations on using Docker with the Radiology Module.

### Demo data

You can import the demo data set [demo-data.sql](acceptanceTest/resources/demo-data.sql) into
your database which enables you to try out the modules features or test your
changes.

Please read the corresponding [DEMO-DATA.md](docs/DEMO-DATA.md).

## Documentation

### Website

For a detailed guide on ways to install and configure this module see

http://teleivo.github.io/docs-openmrs-module-radiology/

### Developer guides

Please check out the readme files at [docs](docs/).

### Wiki

For some more background informations on the module see

https://wiki.openmrs.org/display/docs/Radiology+Module

## Contributing

Contributions are very welcome, we can definitely use your help!

### Code

Check out our [contributing guidelines](CONTRIBUTING.md), read through the [Developer guides](#developer-guides).

After you've read up :eyeglasses: [grab an issue](https://issues.openmrs.org/browse/RAD) that is `Ready For Development`.

### Translation

We use

https://www.transifex.com/openmrs/OpenMRS/radiology-module/

to manage our translations.

The `messages.properties` file in this repository is our single source of
truth. It contains key, value pairs for the English language which is the
default.

Transifex fetches updates to this file every night which can then be translated
by you and me on transifex website itself. At any time we can pull new translations from transifex
back into this repository. Other languages like for ex. Spanish will then be in
the `messages_es.properties` file.

If you would like to know more about transifex from the coding side read

https://wiki.openmrs.org/display/docs/Maintaining+OpenMRS+Module+Translations+via+Transifex

## Issues

To file new issues or help to fix existing ones please check out

https://issues.openmrs.org/browse/RAD

## Limitations

This module is not yet officially released to the [openmrs modules](https://modules.openmrs.org/#/).

The API and UI are not yet stable and subject to frequent changes.

:exclamation: ATTENTION :exclamation: radiology orders created via the module will not be sent to the PACS
as HL7 order messages. This has previously been done in a hacky/synchronous way which was not fit for
production and only messy code which had to be removed. A message queue which takes care of sending HL7
order messages to the PACS once orders are created is needed. Such a queue would retry sending the order message
in case the PACS is currently down. Unfortunately, OpenMRS does not provide such a message queue for outgoing HL7 messages.
This is THE big missing piece in the puzzle of the radiology module which until
now has been bridged with communication servers such as mirth.

The module depends on [OpenMRS Version 2.0.0](https://github.com/openmrs/openmrs-core) so it cannot
run on any version lower than that.

The module currently depends on [OpenMRS Legacy UI](https://github.com/openmrs/openmrs-module-legacyui)
which provides the UI but it is [planned](https://issues.openmrs.org/browse/RAD-341)
to extract the UI into a separate module so this module only provides the Java and
REST API without forcing a specific UI onto anyone.

## Community

[![OpenMRS Talk](https://omrs-shields.psbrandt.io/custom/openmrs/talk/F26522?logo=openmrs)](http://talk.openmrs.org)
[![OpenMRS IRC](https://img.shields.io/badge/openmrs-irc-EEA616.svg?logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI2MTIiIGhlaWdodD0iNjEyIiB2aWV3Qm94PSIwIDAgNjEyIDYxMiI%2BPHBhdGggZD0iTTE1MyAyMjkuNWMtMjEuMTMzIDAtMzguMjUgMTcuMTE3LTM4LjI1IDM4LjI1UzEzMS44NjcgMzA2IDE1MyAzMDZjMjEuMTE0IDAgMzguMjUtMTcuMTE3IDM4LjI1LTM4LjI1UzE3NC4xMzMgMjI5LjUgMTUzIDIyOS41em0xNTMgMGMtMjEuMTMzIDAtMzguMjUgMTcuMTE3LTM4LjI1IDM4LjI1UzI4NC44NjcgMzA2IDMwNiAzMDZjMjEuMTE0IDAgMzguMjUtMTcuMTE3IDM4LjI1LTM4LjI1UzMyNy4xMzMgMjI5LjUgMzA2IDIyOS41em0xNTMgMGMtMjEuMTMzIDAtMzguMjUgMTcuMTE3LTM4LjI1IDM4LjI1UzQzNy44NjcgMzA2IDQ1OSAzMDZzMzguMjUtMTcuMTE3IDM4LjI1LTM4LjI1UzQ4MC4xMzMgMjI5LjUgNDU5IDIyOS41ek0zMDYgMEMxMzcuMDEyIDAgMCAxMTkuODc1IDAgMjY3Ljc1YzAgODQuNTE0IDQ0Ljg0OCAxNTkuNzUgMTE0Ljc1IDIwOC44MjZWNjEybDEzNC4wNDctODEuMzRjMTguNTUyIDMuMDYyIDM3LjYzOCA0Ljg0IDU3LjIwMyA0Ljg0IDE2OS4wMDggMCAzMDYtMTE5Ljg3NSAzMDYtMjY3Ljc1UzQ3NS4wMDggMCAzMDYgMHptMCA0OTcuMjVjLTIyLjMzOCAwLTQzLjkxLTIuNi02NC42NDMtNy4wMmwtOTAuMDQgNTQuMTI0IDEuMjA0LTg4LjdDODMuNSA0MTQuMTMzIDM4LjI1IDM0NS41MTMgMzguMjUgMjY3Ljc1YzAtMTI2Ljc0IDExOS44NzUtMjI5LjUgMjY3Ljc1LTIyOS41czI2Ny43NSAxMDIuNzYgMjY3Ljc1IDIyOS41UzQ1My44NzUgNDk3LjI1IDMwNiA0OTcuMjV6IiBmaWxsPSIjZmZmIi8%2BPC9zdmc%2B)](http://irc.openmrs.org)
[![OpenMRS Telegram](https://img.shields.io/badge/openmrs-telegram-009384.svg?logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNDAgMjQwIj48ZGVmcz48bGluZWFyR3JhZGllbnQgaWQ9ImEiIHgxPSIuNjY3IiB5MT0iLjE2NyIgeDI9Ii40MTciIHkyPSIuNzUiPjxzdG9wIHN0b3AtY29sb3I9IiMzN2FlZTIiIG9mZnNldD0iMCIvPjxzdG9wIHN0b3AtY29sb3I9IiMxZTk2YzgiIG9mZnNldD0iMSIvPjwvbGluZWFyR3JhZGllbnQ%2BPGxpbmVhckdyYWRpZW50IGlkPSJiIiB4MT0iLjY2IiB5MT0iLjQzNyIgeDI9Ii44NTEiIHkyPSIuODAyIj48c3RvcCBzdG9wLWNvbG9yPSIjZWZmN2ZjIiBvZmZzZXQ9IjAiLz48c3RvcCBzdG9wLWNvbG9yPSIjZmZmIiBvZmZzZXQ9IjEiLz48L2xpbmVhckdyYWRpZW50PjwvZGVmcz48Y2lyY2xlIGN4PSIxMjAiIGN5PSIxMjAiIHI9IjEyMCIgZmlsbD0idXJsKCNhKSIvPjxwYXRoIGZpbGw9IiNjOGRhZWEiIGQ9Ik05OCAxNzVjLTMuODg4IDAtMy4yMjctMS40NjgtNC41NjgtNS4xN0w4MiAxMzIuMjA3IDE3MCA4MCIvPjxwYXRoIGZpbGw9IiNhOWM5ZGQiIGQ9Ik05OCAxNzVjMyAwIDQuMzI1LTEuMzcyIDYtM2wxNi0xNS41NTgtMTkuOTU4LTEyLjAzNSIvPjxwYXRoIGZpbGw9InVybCgjYikiIGQ9Ik0xMDAuMDQgMTQ0LjQxbDQ4LjM2IDM1LjczYzUuNTIgMy4wNDQgOS41IDEuNDY3IDEwLjg3Ni01LjEyNGwxOS42ODUtOTIuNzYzYzIuMDE2LTguMDgtMy4wOC0xMS43NDYtOC4zNTgtOS4zNWwtMTE1LjU5IDQ0LjU3MmMtNy44OSAzLjE2NS03Ljg0NCA3LjU2Ny0xLjQ0IDkuNTI4bDI5LjY2NCA5LjI2IDY4LjY3My00My4zMjZjMy4yNC0xLjk2NiA2LjIxNy0uOTEgMy43NzUgMS4yNTgiLz48L3N2Zz4%3D)](https://telegram.me/openmrs)
[![OpenMRS Radiology Wiki](https://img.shields.io/badge/openmrs-wiki-5B57A6.svg?logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNjAiIGhlaWdodD0iMTQyIiB2aWV3Qm94PSIwIDAgMTYwIDE0MiI%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%3D%3D)](https://wiki.openmrs.org/display/docs/Radiology+Module)

## Support

Ask questions on [OpenMRS Talk](https://talk.openmrs.org/).

## License

[MPL 2.0 w/ HD](http://openmrs.org/license/) © [OpenMRS Inc.](http://www.openmrs.org/)
"
7,VectorInstitute/cyclops,Python,"![cyclops Logo](https://github.com/VectorInstitute/cyclops/blob/main/docs/source/theme/static/cyclops_logo-dark.png?raw=true)

--------------------------------------------------------------------------------

[![PyPI](https://img.shields.io/pypi/v/pycyclops)](https://pypi.org/project/pycyclops)
[![code checks](https://github.com/VectorInstitute/cyclops/actions/workflows/code_checks.yml/badge.svg)](https://github.com/VectorInstitute/cyclops/actions/workflows/code_checks.yml)
[![integration tests](https://github.com/VectorInstitute/cyclops/actions/workflows/integration_tests.yml/badge.svg)](https://github.com/VectorInstitute/cyclops/actions/workflows/integration_tests.yml)
[![docs](https://github.com/VectorInstitute/cyclops/actions/workflows/docs_deploy.yml/badge.svg)](https://github.com/VectorInstitute/cyclops/actions/workflows/docs_deploy.yml)
[![codecov](https://codecov.io/gh/VectorInstitute/cyclops/branch/main/graph/badge.svg)](https://codecov.io/gh/VectorInstitute/cyclops)
[![license](https://img.shields.io/github/license/VectorInstitute/cyclops.svg)](https://github.com/VectorInstitute/cyclops/blob/main/LICENSE)

``cyclops`` is a framework for facilitating research and deployment of ML models
in the health (or clinical) setting. It provides a few high-level APIs namely:


* `query` - Querying EHR databases (such as MIMIC-IV)
* `process` - Process static and temporal EHR data
* `evaluate` - Evaluate models on clinical prediction tasks
* `monitor` - Detect data drift relevant for clinical use cases

``cyclops`` also provides a library of use-cases on clinical datasets. The implemented
use cases include:

* Mortality decompensation prediction


## 🐣 Getting Started

### Installing cyclops using pip

```bash
python3 -m pip install pycyclops
```

The core package only includes support for the `process` API. To install support for
`query`, `evaluate` and `monitor` APIs, install them as extra dependency installs.

To install with `query` API support,

```bash
python3 -m pip install 'pycyclops[query]'
```

To install with `evaluate` API support,

```bash
python3 -m pip install 'pycyclops[evaluate]'
```

To install with `monitor` API support,

```bash
python3 -m pip install 'pycyclops[monitor]'
```

Multiple extras could also be combined, for example to install with both `query` and
`evaluate` API support:

```bash
python3 -m pip install 'pycyclops[query,evaluate]'
```


## 🧑🏿‍💻 Developing

The development environment has been tested on ``python = 3.9``.

The python virtual environment can be set up using
[poetry](https://python-poetry.org/docs/#installation). Hence, make sure it is
installed and then run:

```bash
python3 -m poetry install
source $(poetry env info --path)/bin/activate
```

API documentation is built using [Sphinx](https://www.sphinx-doc.org/en/master/) and
can be locally built by:

```bash
cd docs
make html SPHINXOPTS=""-D nbsphinx_allow_errors=True""
```

### Contributing
Contributing to cyclops is welcomed.
See [Contributing](https://vectorinstitute.github.io/cyclops/api/intro.html) for
guidelines.


## 📚 [Documentation](https://vectorinstitute.github.io/cyclops/)

## 📓 Notebooks

To use jupyter notebooks, the python virtual environment can be installed and
used inside an IPython kernel. After activating the virtual environment, run:

```bash
python3 -m ipykernel install --user --name <name_of_kernel>
```

Now, you can navigate to the notebook's ``Kernel`` tab and set it as
``<name_of_kernel>``.

## 🎓 Citation
Reference to cite when you use CyclOps in a project or a research paper:
```
@article {Krishnan2022.12.02.22283021,
	author = {Krishnan, Amrit and Subasri, Vallijah and McKeen, Kaden and Kore, Ali and Ogidi, Franklin and Alinoori, Mahshid and Lalani, Nadim and Dhalla, Azra and Verma, Amol and Razak, Fahad and Pandya, Deval and Dolatabadi, Elham},
	title = {CyclOps: Cyclical development towards operationalizing ML models for health},
	elocation-id = {2022.12.02.22283021},
	year = {2022},
	doi = {10.1101/2022.12.02.22283021},
	publisher = {Cold Spring Harbor Laboratory Press},
	URL = {https://www.medrxiv.org/content/early/2022/12/08/2022.12.02.22283021},
	journal = {medRxiv}
}
```
"
8,hapifhir/hapi-fhir,Java,"HAPI FHIR
=========

HAPI FHIR - Java API for HL7 FHIR Clients and Servers

[![License][Badge-License]][Link-License]

## CI/CD
| CI Status (master) | SNAPSHOT Pipeline | Current Release |
| :---: | :---: | :---: |
| [![Build Status][Badge-AzurePipelineMaster]][Link-AzurePipelinesMaster] | [![Build Status][Badge-AzureReleaseSnapshot]][Link-AzurePipelinesSnapshot] | [![Release Artifacts][Badge-MavenCentral]][Link-MavenCentral] |

## Coverage and Quality

[![codecov][Badge-CodeCov]][Link-CodeCov]
[![Language grade: Java](https://img.shields.io/lgtm/grade/java/g/hapifhir/hapi-fhir.svg?logo=lgtm&logoWidth=18)](https://lgtm.com/projects/g/hapifhir/hapi-fhir/context:java)

## Documentation and wiki

Complete project documentation is available here:
http://hapifhir.io

A demonstration of this project is available here:
http://hapi.fhir.org/

This project is Open Source, licensed under the Apache Software License 2.0.

Please see [this wiki page][Link-wiki] for information on where to get help with HAPI FHIR. 

Please see [Smile CDR][Link-SmileCDR] for information on commercial support.

[Link-AzurePipelines]: https://dev.azure.com/hapifhir/HAPI%20FHIR/_build
[Link-AzurePipelinesMaster]: https://dev.azure.com/hapifhir/HAPI%20FHIR/_build?definitionId=2
[Link-AzurePipelinesSnapshot]: https://dev.azure.com/hapifhir/HAPI%20FHIR/_build?definitionId=3
[Link-MavenCentral]: http://search.maven.org/#search|ga|1|ca.uhn.hapi.fhir
[Link-CodeCov]: https://codecov.io/gh/hapifhir/hapi-fhir
[Link-wiki]: https://github.com/hapifhir/hapi-fhir/wiki/Getting-Help
[Link-SmileCDR]: https://smilecdr.com
[Link-License]: https://hapifhir.io/hapi-fhir/license.html

[Badge-AzurePipelineMaster]: https://dev.azure.com/hapifhir/HAPI%20FHIR/_apis/build/status/hapifhir.hapi-fhir?branchName=refs%2Fpull%2F2319%2Fmerge
[Badge-AzureReleaseSnapshot]: https://dev.azure.com/hapifhir/HAPI%20FHIR/_apis/build/status/SNAPSHOT%20pipeline?branchName=master
[Badge-MavenCentral]: https://maven-badges.herokuapp.com/maven-central/ca.uhn.hapi.fhir/hapi-fhir-base/badge.svg
[Badge-CodeCov]: https://codecov.io/gh/hapifhir/hapi-fhir/branch/master/graph/badge.svg?token=zHfnKfQB9X
[Badge-License]: https://img.shields.io/badge/license-apache%202.0-60C060.svg


"
9,aws-samples/amazon-sagemaker-healthcare-fraud-detection,Jupyter Notebook,"

# Introduction

IDC study states that 40% of Enteprises in year 2019 will be working to include AI/ML as a part of their transformative strategy. Today, AI/ML is beyond the hype cycle and there are usecases that are providing real business value. 

In this workshop, we will work on a healthcare insurance fraud identification usecase. We will apply machine learning to identify anomalous claims that require further investigation. The technique used in the workshop is broadly applicable to multiple problems fraud, abuse and waste.

## **Launch an Amazon SageMaker Jupyter Notebook**

### Prerequisites and assumptions
1. To run this Jupyter Notebook, you need an personal Laptop and an AWS account that provides access to AWS services.

### Steps
1. Sign In to the [AWS Console](https://aws.amazon.com/)
2. Click Services, search for **Amazon SageMaker** and Click **Amazon SageMaker** in the dropdown![Find SageMaker](./images/find-sagemaker.png)
3. After you land on Amazon SageMaker console, click on **Notebook Instances**![SageMaker Console](./images/sagemaker-console.png)
4. Click **Create Notebook**![Create Notebook](./images/create-notebook.png)
5. Give Notebook a name you can remember and fill out configuration details as suggested in the screenshots below.![Create Notebook Instance](./images/create-notebook-instance.png)
6. Select IAM Role if one already exists in the dropdown![Select Existing Role](./images/select-role.png)
7. Create a new role if one doesn't exist. ![Create new role](./images/create-role.png)
8. Provide  a path to clone public git repo that we will use today for our workshop to download data dictionary and Jupyter IPython Notebook ![Select Git Repo](./images/select-gitrepo.png) 
9. Provide the path of [Git repo](https://github.com/aws-samples/amazon-sagemaker-healthcare-fraud-detection.git)
![Provide Git url](./images/clone-gitrepo.png) 
6. Click **Create Notebook Instance**
8. In the Amazon SageMaker Console-->Notebook Instances, wait for your notebook instance to start. Observe change from Pending to In Service status.![Creation pending](./images/creation-pending.png)![Notebook In Service](./images/notebook-inservice.png)
9. Remember the name of your notebook instance and Click **Open Jupyter** for your notebook.![Notebook In Service](./images/notebook-inservice.png)
10. Validate your data and notebook cloned from Git Repo![Validate Git Clone](./images/validate-git-clone.png)

## **Finish your Lab in Jupyter Notebook**
1. Click on **healthcare-fraud-identification-using-PCA-anomaly-detection.ipynb** and start working. From here onwards all the instruction will be in the Jupyter Notebook. Come back after you have completed all the steps in the Jupyter Notebook and finish rest of the steps as suggested below.


## Finish
1. **Congratulations!** 
2. Please make sure to delete all resources as mentioned in the section below.


## Cleanup Resources
1. Go to Amazon SageMaker console to shutdown your Amazon SageMaker Jupyter Notebook Instance, select your instance from the list.Select **Stop** from the **Actions** drop down menu.
![Stop Notebook Instance](./images/stop-notebook.png)
2. After your notebook instance is completely **Stopped**, select **Delete** fron the **Actions** drop down menu to **delete** your notebook instance.![Delete Notebook Instance](./images/delete-notebook.png)
4. Navigate to Amazon S3 Console. 
![S3 Console](./images/s3-console.png)
5. Find Amazon S3 bucket created for training and click to list objects in the bucket.![Find Bucket](./images/search-s3-bucket.png)
6. Navigate to the **model-tar.gz** and delete it by using **Actions** menu.![Delete Model](./images/delete-model.png) 
6. Navigate to the training data file **healthcare_fraud_identification_feature_store** and delete it by using **Actions** menu.![Delete Training Data](./images/delete-training-data.png)
7. After all the objects are deleted in the bucket. Go ahead and delete the bucket using the Actions menu.![Delete Bucket](./images/delete-bucket.png)













    

"
10,Sid1608/E-HealthCare-Management-System,Java,"# E-HealthCare-Management-System
<h2>Table Of Content</h2>
<ol>
  <li><a href=""#description"">Description</a></li>
  <li><a href=""#lat"">Languages and Technology Used</a></li>
  <li><a href=""#Req"">Requirements</li>
  <li><a href=""#features"">Features</a></li>
  <li><a href=""#steps"">Steps to run the project in your machine</a></li>
  <li ><a href=""#ws"">Working-Snippets</a></li>
  <li><a href=""#cs""> Database-Snippets</a></li>

</ol>
<h2 id=""description"">Description</h2>
 E-HealthCare-Management-System is a console based application which is built using java.This application helps in management of  Patients, doctors, admin in a easy and comfortable way.using this Application patients can quickly Sign up, Login, view his/her profile, view doctors, book Appointment, view Report, choose doctor, view Appointments, give feedback, pay online and logout. Admin can add Doctors,view patients list, view Doctors list,remove doctors, see feedback given by patients,view reports,logout.Doctor can login, view profile, viewAppointments, Attend Patients and logout. 
 
 <h2 id=""lat"">Languages and Technology Used</h2>
 <ul>
  <li>Java</li>
  <li>MySql</li>
  <li>Jdbc</li>
</ul>
<h2 id=""Req"">Requirements</h2>
<ul>
  <li>Java [JDK 8+]</li>
  <li>Eclipse</li>
  <li>MySql</li>
  <li>Jdbc Driver</li>
  <li>MySql Connector</li>
</ul>
 <h2 id=""features"">Features</h2>
 <ul>
  <li><a href=""#login"">login</a></li>
  <li><a href=""#Admin"">Admin’s DashBoard</a></li>
  <li><a href=""#Patient"">Patient’s DashBoard</a></li>
  <li><a href=""#Doctor"">Doctor’s DashBoard</a></li>
  <li><a href=""#Report"">Report-Table</a></li>
  <li><a href=""#Appointment"">Appointment-Table</a></li>
  <li><a href=""#feedback"">Feedback Form</a></li>
  <li><a href=""#Booking"">Booking Appointment</li>
  <li ><a href=""#choose"">Choosing Doctor</a></li>
  <li ><a href=""#Payment"">Payment Process</a></li>
 </ul>
 <h2 id=""steps"">Steps to run the project in your machine</h2>
 <ol>
   <li>Download and install Eclipse in your machine</li>
    <li>Clone or download the repository</li>
    <li>Extract all the files and move it in your eclipse directory.Open EHMS Folder.</li>
   <li>Open EHMS.sql in your MySql workbench.download MySql connector(“mysql-connector-java-8.0.22.jar"" ) </li>
   <li>Now Open .classpath file in EHMS folder,in Line - 9 of This file Change the  path with the path where your .jar file is being downloaded. </li>
   <li>Open ConnectionProvider.java file and change the uname(username) and pass(password) variable according the user name and password of your MySql database</li>
   <li>Now it is ready to Run</li>
 </ol>
 <h2 id=""ws"">Working-Snippets</h2>
<img id=""login"" src=""snippets/Login.png"">
<img id=""Admin"" src=""snippets/Admin.png"">
<img id=""Patient"" src=""snippets/Patient.png"">
<img id=""Doctor"" src=""snippets/Doctor.png"">
<img id=""Report"" src=""snippets/Report.png"">
<img id =""Appointment"" src=""snippets/Appointment.png"">
<img id=""feedback"" src=""snippets/Feedback.png"">
<img id=""Booking"" src=""snippets/BookingAppointment.png"">
<img id=""choose"" src=""snippets/choosingDoctor.png"">
<img id=""Payment"" src=""snippets/paymentProcess.png"">
<h2 id=""cs"">Database-Snippets</h2>
<img id=""a"" src=""snippets/Database/Schema.png"">
<img id=""b"" src=""snippets/Database/User-PatientTable.png"">
<img id=""c"" src=""snippets/Database/Doctor-AppointmentTable.png"">
<img id=""d"" src=""snippets/Database/ExampleDoctorInputs.png"">
<img id=""e"" src=""snippets/Database/Report-FeebackTable.png"">
"
11,GeneSourceCodeChain/AI_Components,C,"# AI-components
### Introduction
AI Components of GeneSourceCode project is a subproject taking charge of machine learning related tasks. AI Components aim to make full use of gene and other medical data with the facilities of modern AI technologies. AI Components currently focus on 

1.Prediction of diseases and traits directly from raw DNA sequence.
We will test both traditional classification/regression algorithm and popular deep neural network ways such as LSTM, p-LSTM, IndRNN, attention model and so on to process raw DNA sequential data.

2.Prediction of diseases and traits from hand-designed feature.
The hand-designed feature extracted from raw DNA, RNA or histone sometime may be discriminative enough to make prediction task viable. We will try to extract and learn on features this way.

3.Medical application based on visual clues.
Computer Vision has become a reliable way of prediction after deep learning prevails. Medical scientists have adopted this method to various applications such as predicting or detecting certain diseases, image processing on X ray pictures, and so on. We will implement all these applications in this subproject and make them optional service modules.

4.Mining fitness status on physical examination and motion data,
We will also mining data provided by users to detect potential fitness problem or reveal healthy status. 

### Components
1.Prediction of diseases and traits directly from raw DNA sequence.

(1)rawDNA/LSTM: classification base on DNA subsequence:

You can train a classifier with train_LSTM. The dataset generation tools will be released soon.

2.Prediction of disease and trais from hand-designed feature.

(1)extractedDNA/AllelesClassifier: classification base on Alleles

You can train a classifier on polymorphic alleles.

3.Medical appliation based on visual clues.

(1)visual/facial: classification based on facial images:

(2)visual/iris: biometric identification and illness detection according to visual information from iris.

You can train a classifier with train_facial_classifier. The dataset generation tools will be released soon.

4.Mining fitness status on physical examination and motion data.
"
12,christian-posta/healthcare-poc,Java,"# HL7 use cases with JBoss Fuse

[HL7 over MLLP](http://www.hl7.org) is a very common transport mechanisms for systems that can speak the HL7 protocol format. [JBoss Fuse](http://www.jboss.org/products/fuse/download/) is a very powerful microservices-style integration platform and has a proven track record for building flexibile, resilient, highly available integration scenarios for critical health-care providers. Additionally, replacing legacy vendors like SeeBeyond on JCAPS is the sweet spot for these types of Fuse implementations. 

## Criticality of integrations
The integrations that get deployed as part of a Fuse implementation that support health-care usecases, including HL7 integrations, are typically part of Tier 1 applications with utmost uptime and resilience requirements. These applications include, but not limited, patient admission, scheduling, lab results, and even the critical of all critical use cases: transmitting patient vitals in real time. Additionally, high levels of throughput and performance are expected.   

## Overall architecture
This POC divides a typical flow into 3 individually deployable microservices:

* [hl7-ingress](hl7-ingress) - an MLLP/HL7 collector of events
* [hl7-transform-1](hl7-transform-1) - able to transform HL7 payloads from one message to another
* [hl7-consumer-1](hl7-consumer-1) - able to marshal HL7 payloads and send to downstream systems, EHR, etc

We also leverage [ActiveMQ](http://activemq.apache.org) to provide resilient/guaranteed messaging in a Staged Event Driven Architecture pattern. 
 
With these building blocks, we can build a powerful physical deployment that has proven to withstand faults, invalid formats, network connectivity issues, failover, and perform well above expected performance (or legacy performance) metrics. 

## JBoss Fuse 
For this POC, we will build out the following architecture locally (on our laptops) but do so using process-isolation constructs to illustrate a physical deployment. Physical deployments can very based on resources you have (VMs, CPU//mem, etc). For illustration purposes, this is the architecture we will start with for this POC:

![sample architecture](docs/images/example-arch.png)

In this architecture we see these relevant components:

* 3 fuse instances, isolated at the process level
* 2 ActiveMQ brokers, in a master/slave set up
* 1 Fabric8 node which manages deployments, master/slave elections, versions, service discovery, etc.

Note, that this is the use case depicted in this POC, though is intended to help the reader understand the components and concepts at a high level. A typical deployment in a production-like setting is NOT being depicted above, however, you may be able to deduct what a more resilient environment may look like based on the pieces. Also note, with Fuse and how we've architected these services, we can choose *how* we want to deploy. In this POC we've chosen to deploy the components into individual processes but this is not a technical rule. We can deploy them all into the same process as well (though it may or may not be recommended depending on your desired architecture).

### Fuse insight!
Another alternative deployment depicted by this POC is the following:

![sample architecture](docs/images/insight-arch.png)

In this depiction, we have the same above deployment of Fuse and ActiveMQ, but we also have 3 additional nodes which provide a highly-scalable, centralized logging and insight framework built on top of [Elasticsearch](https://github.com/elastic/elasticsearch). With Fuse, we can spin up ""Fuse Insight"" nodes and have all logging dumped into one spot and then use the Fuse web console to query, chart, and graph the results of calls/transactions that have propogated through the platform including debugging and SLA diagnosis. 

## Getting Started
To get started learning about how this POC is put together, [jump to the Getting Started docs](docs/getting-started.md)

"
13,GoogleCloudPlatform/healthcare-federated-access-services,Go,"# `healthcare-federated-access-services`

## Purpose

The Global Alliance for Genomics and Health (""GA4GH"") has [launched](https://www.ga4gh.org/news/ga4gh-passports-and-the-authorization-and-authentication-infrastructure/) an open standard for requesting and granting access to genomic datasets, known as the ""GA4GH Passport"". This allows different identity providers and data hosts to interact with each other, independent of their hosting platform and identity provider. For example, the owner of a genomic dataset hosted on Google Cloud (e.g. a national genomics institute) can grant access to a researcher with an organizational identity (e.g. an academic or corporate email address) via a GA4GH passport.

The GA4GH Passport specification is a technology to eliminate barriers between users and data, even in complex multi-cloud and hybrid-cloud environments, while still adhering to data consents and strict sharing policies between the parties involved.

### Data Access Manager

This repository contains the Data Access Manager (""DAM""), which performs the role of a [GA4GH Passport Clearinghouse](http://bit.ly/ga4gh-passport-v1#passport-clearinghouse).

#### The problem

Sensitive data is often organized in controlled-access datasets where only qualified individuals or organizations should have access. Data controllers must identify these data accessors ahead of time, and then configure their datasets to permit access. This manual and error-prone process slows down collaboration and can make some use-cases impossible.

#### The solution

GA4GH Passports are a standard way to securely communicate information between data controllers and data accessors. The Data Access Manager (DAM) enables data controllers to seamlessly leverage GA4GH passports to make their data accessible, but also secure.

DAM enables the translation of abstract qualifications (e.g. I am a physician, I am an academic researcher, etc) into platform-specific access management configurations (e.g. I can access this file, I can run this operation). Once an administrator configures DAM with policies describing how qualifications should translate into data access (e.g. academic researchers should have access to files A and B, but not C), verification of those qualifications and the resulting reconfiguration of underlying permissions will occur automatically as data access requests are received.

DAM evaluates identities against policies in real-time, which means data controllers do not need to have a relationship with data accessors – in fact, data controllers and accessors do not need to know one another exist prior to a transaction. DAM provides the option for data accessors to be billed directly for expenses associated with their requests, rather than those costs being incurred by the data controller. DAM is designed to work as a component within a broader data hosting platform, and also as a standalone service.

### Identity Concentrator

This repository contains the Identity Concentrator (""IC""), which performs the role of a [GA4GH Passport Broker](http://bit.ly/ga4gh-passport-v1#passport-broker)

#### The problem

In order to access controlled-access datasets, data accessors must prove to data controllers that they have the qualifications required by the data controller. This is done by submitting an application to the data controller who manually reviews the information provided. If acceptable, the data controller adds the data accessor to an allowlist or other static access control mechanism. The data accessor must then use the specific identity (e.g. a Google Cloud credential) for which the access was granted. The data accessor must repeat this process for each dataset that they wish to work with. This results in data accessors accumulating many disparate identities, each specific to a different data controller.

#### The solution

The IC is an open-source service that securely combines identity qualifications (e.g. I am an academic researcher, I am a physician, I have taken ethics training XYZ, etc) collected from disparate sources into a single identity that can be used to access controlled-access datasets. Without the IC, data accessors must obtain and manage identities that are specific to a given data controller (e.g. a data controller hosting data on Google Cloud may have required data accessors to obtain Google Cloud credentials rather than using their existing corporate or academic credential).

Because data accessors often require access to data siloed across many locations, data accessors must shift between identities to obtain the data that they need. This makes running complex workflows that depend on data from diverse sources challenging and unreliable. With IC, data accessors (and the workbench platforms that they use) are able to combine relevant identities before executing a given workflow. This enables the workflow to leverage all data that the data accessor is permitted to access, regardless of how fragmented their identity qualifications may be. IC is designed to work as a component within a broader platform, but can also be deployed as a standalone service.

Some datasets will have visa requirements that can be collected from multiple sources, but need to be presented on one passport. The IC can combine lists of visas pertaining to one user from various visa sources.

For more information, visit:

*  [GA4GH Overview of Passports](http://bit.ly/ga4gh-passport-v1#overview) and
   [GA4GH Researcher Identity Introduction](http://bit.ly/ga4gh-ri-intro).
*  [GA4GH Passport v1.0](http://bit.ly/ga4gh-passport-v1) full specification.
*  [GA4GH AAI OpenID Connect Profile v1.0](http://bit.ly/ga4gh-aai-profile) specification.
*  [GA4GH](https://www.ga4gh.org/)

## Contributing to the repository

For information on how to contribute to the repository, see [How to Contribute](CONTRIBUTING.md).

## Notice

This is not an officially supported Google product.

## How to Deploy

For information on how to deploy Federated Access, see [How To Deploy a
Federated Access Playground](docs/playground/deploy.md).
The `deploy.bash` script is designed to get a test environment up and running
quickly and make it easy to develop services that use them in a non-sensitive
environment.

When planning the next phase where these services need to be prepared for a
production environment with live, sensitive data, the [productionization
documentation](docs/shared/admin/productionization.md) can be helpful.

## Troubleshooting

See the [how-to](docs/shared/admin/howto.md) guide.

## Configuration

For DAM:
*  **Documentation**: [DAM Configuration](docs/dam/admin/README.md)
*  **Example Configurations**: see [deploy/config/dam-template](deploy/config/dam-template)
*  **Config Definitions**: see [DamConfig](proto/dam/v1/dam_service.proto)

For IC:
*  **Documentation**: [IC Configuration](docs/ic/admin/README.md)
*  **Example Configurations**: [deploy/config/ic-template](deploy/config/ic-template)
*  **Config Definitions**: see [IcConfig](proto/ic/v1/ic_service.proto)

## Test Personas

Test Personas are a means to create mock test users that are defined to hold a set of visas. The DAM can use test personas to verify that access privileges behave as expected for users with such visas. Each test persona reports an ""access list"" that describes the resources and roles their visas provide access to.

A playground environment includes a Test Persona Broker (""Persona Broker"") that allows users to impersonate Test Personas. If the DAM and IC are both set up to trust a Persona Broker, then end to end tests and training can be conducted.

**Note:** Production deployments of DAM and IC should never be configured to trust Persona Brokers. However, production DAMs can still use Test Personas to verify access without allowing users to impersonate them.

## APIs

For information about API endpoints available in Federated Access components,
please refer to [API documentation](apis.md).

## Bugs, feature requests and general feedback

Please consult the open [issues](https://github.com/GoogleCloudPlatform/healthcare-federated-access-services/issues), or file a new issue. Your feedback is appreciated!
"
14,nhs-r-community/NHSRdatasets,R,"---
output: github_document
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = ""#>"",
  fig.path = ""man/figures/README-"",
  out.width = ""100%""
)
```

# NHS R-community Datasets <a href='https://nhsrcommunity.com/'><img src='https://nhs-r-community.github.io/assets/logo/nhsr-logo.png' align=""right"" height=""80"" /></a>


<!-- badges: start -->
[![R-CMD-check](https://github.com/nhs-r-community/NHSRdatasets/workflows/R-CMD-check/badge.svg)](https://github.com/nhs-r-community/NHSRdatasets/actions)
[![Project Status: Active – The project has reached a stable, usable state and is being actively developed.](https://www.repostatus.org/badges/latest/active.svg)](https://www.repostatus.org/#active)
[![CRAN version](https://www.r-pkg.org/badges/version/NHSRdatasets)](https://cran.r-project.org/package=NHSRdatasets)
[![Downloads](https://cranlogs.r-pkg.org/badges/grand-total/NHSRdatasets)](https://cran.r-project.org/package=NHSRdatasets)
<!-- badges: end -->
 
<br><br>
 
Please visit: [nhsrcommunity.com](https://nhsrcommunity.com/)

## Datasources for reuse

This package has been created to help NHS, Public Health and related analysts/data scientists learn to use `R`. It contains several free datasets (just one at the moment), help files explaining their structure, and `vignette` examples of their use.  We encourage contributions to the package, both to expand the set of training material, but also as development for newer `R`/github users as a first contribution.  Please add relevant free, open source data sets that you think may benefit the NHS R-community.

## Installation instructions

This packages is available on CRAN or the development version can be installed from source, via this Github repository.  You will need [`Rtools`](https://cran.r-project.org/bin/windows/Rtools/) installed to build the package, and the `remotes` package.

```{r install, eval=FALSE}
remotes::install_github(""https://github.com/nhs-r-community/NHSRdatasets"")
```

## Contribution

Please contribute to this repository, and please cite it when you use it in training or publications.

__To contribute, please:__

* Fork the repository.
* Add your dataset in the `data` folder, in `.rda` format.  The best way to do this is with the `usethis` package with ""gzip"" compression:  `usethis::use_data(data, compress=""gzip"")` 
* Please add a minimal `R` function to act as a help file. You can use the `LOS_model` as a guide.
* Please add a `vignette` demonstrating how the data has been/can be used.
* Create a pull request, detailing your additions, and we will review it before merging.

<br>
___When contributing a dataset, the contributor certifies that:___

* They are the data owner, or are authorised to republish the dataset in question.
* The dataset does not contain real patient-level data.
* Where based on patient data, the contributor takes full responsibility for sharing the data and certifies that. it is has been processed, anonymised, aggregated or otherwise protected in accordance with all legal requirements under General Data Protection Regulation (GDPR), or other relevant legislation.


Please note that the 'NHSRdatasets' project is released with a
[Contributor Code of Conduct](https://github.com/nhs-r-community/NHSRdatasets/blob/master/CODE_OF_CONDUCT.md).
By contributing to this project, you agree to abide by its terms.

"
15,RasaHQ/medicare_locator,Python,"﻿# Medicare Locator built with the Rasa Stack

## 🏥 Introduction

This is an open source starter pack for developers to show how to automate full conversations in healthcare sector.

It supports the following user goals:

- Searching for a hospital, nursing home or home health agency in a US city.
- Handling basic chitchat.

## 💾 How to install and setup Medicare Locator

**Step 1**: To install Medicare Locator, please clone the repo:
```
git clone https://github.com/RasaHQ/medicare_locator.git
cd medicare_locator
```
The Medicare Locator uses **Python 3.5 and 3.6** and has not been tested with other versions.
Use the requirements.txt file to install the appropriate dependencies
via pip. If you do not have pip installed yet first do:
```
sudo easy_install pip
```
otherwise move to the next step directly.

**Step 2**: Install requirements:
```
pip install -r requirements.txt
```

**Step 3**: Install the spaCy English language model by running:
```
python3 -m spacy download en
```

This will install the bot and all of its requirements.

## 🤖 How to run Medicare Locator

**Step 1**: Train the core model by running:
```
make train-core
```
This will train the Rasa Core model and store it inside the `/models/current/dialogue` folder of your project directory.

**Step 2**: Train the NLU model by running:
```
make train-nlu
```
This will train the NLU model and store it inside the `/models/current/nlu` folder of your project directory.

**Step 3**: In a new terminal start the server for the custom action by running:
```
make action-server
```

**Step 4**: Now to test the Medicare Locator with both these models you can run:
```
make cmdline
```
After the bot has loaded you can start chatting to it. If you start by saying `Hi` for example,
the bot will reply by asking you what you are looking for and show you a number of options in form of buttons.
Since those buttons do not show when testing the bot in the command line, you can imitate a button click by copy
and pasting the intent of the button of your choice as your input.

An example conversation in the command line could look something like this:
```
Your input ->  Hi
Hi. What are you looking for ?
Buttons:
1: Hospital (/inform{""selected_type_slot"": ""rbry-mqwu""})
2: Nursing Home (/inform{""selected_type_slot"": ""b27b-2uc7""})
3: Home Health Agency (/inform{""selected_type_slot"": ""9wzi-peqs""})
Your input ->  /inform{""selected_type_slot"": ""rbry-mqwu""}
What is you current city?
Your input ->  Seattle
...
```

Try out different conversations and see what the current state of the bot can do!
After playing around a bit you can try to modify and extend the bot by adding custom actions and intents for example.
Find help for this in the [Rasa Docs](https://rasa.com/docs/).

A helpful option to extend training data and get to know your bot is interactive learning,
here you can correct your bot at every step in the conversation and automatically save the data for future training.

**Step 5**: To run Medicare Locator in interactive learning mode run:
```
make interactive
```

## 📱 Use Telegram as Chat platform
In order to chat to the Medicare Locator through Telegram you can do the following:

**Step 1**: First if you don't already use Telegram, download it and set it up with your phone.
Once you are registered with Telegram you start by setting up a Telegram bot.

**Step 2**: To setup your own bot go to the [Telegram BotFather](https://web.telegram.org/#/im?p=@BotFather),
enter `/newbot` and follow the instructions.
You should get your `access_token`, and the username you set will be your `verify`. Save this information as you will need it later.

**Step 3**: Now you will need to connect to Telegram via a webhook. To create a local webhook from your machine you can use [Ngrok](https://ngrok.com/). Follow the instructions on their site to
set it up on your computer. Move `ngrok` to your working directory and in a new terminal run:
```
./ngrok http 5005
```
Ngrok will create a https address for your computer. For Telegram you need the address in this format:
`https://xxxxxx.ngrok.io/webhooks/telegram/webhook`

**Step 4**: Go to the *credentials.yml* file that you downloaded from the repo and input your personal `access_token`, `verify` and `webhook_url`.
You will have to update the `webhook_url` everytime you do redo Step 3, the `access_token` and `verify` will stay the same.

**Step 5**: In a new terminal start the server for the custom action by running:
```
make action-server
```

**Step 6**: In a new terminal connect to Telegram by running:
```
make telegram
```

**Step 7**: Now you and anyone on Telegram are able to chat to your bot. You can find it by searching for its name on Telegram.

Detailed information about this can also be found in the [Rasa Docs](https://rasa.com/docs/core/connectors/#telegram-connector).


## More about the Medicare Locator demo bot
There are some custom actions that require connections to external services,
specifically `FacilityForm` and `FindHealthCareAddress`. These two actions
connect to Medicare APIs. These APIs do not require tokens or any form of authentication.

For more information about Medicare APIs please visit [data.medicare.gov](https://data.medicare.gov/)

If you would like to run Medicare Locator on your website, follow the instructions
[here](https://github.com/mrbot-ai/rasa-webchat) to place the chat widget on
your website.


## 👩‍💻 Overview of the files

`data/core/` - contains stories for Rasa Core

`data/nlu_data.md` - contains example NLU training data

`actions.py` - contains custom action/api code

`domain.yml` - the domain file for Core

`nlu_config.yml` - the NLU config file

`core_config.yml` - the Core config file

`credentials.yml` - contains credentials for the use with Telegram

`endpoints.yml` - contains url for endpoint

## 🛠 Makefile overview
Run `make help` to see an overview of all make commands available.

`train-nlu` - Train the NLU model.

`train-core` - Train the Core model.

`interactive` - Run the Medicare Locator interactive learning mode.

`cmdline` - Run the bot on the command line.

`action-server` - Start the action server.

`telegram` - Run the bot in the Telegram channel.

## :gift: License
Licensed under the GNU General Public License v3. Copyright 2019 Rasa Technologies
GmbH. [Copy of the license](https://github.com/RasaHQ/rasa-demo/blob/master/LICENSE).
Licensees may convey the work under this license. There is no warranty for the work.
"
16,ZainMustafaaa/HealthCare-Scan-Nearby-Hospital-Locations,Java,"# HealthCare-Nearby-Hospital-Locations
I developed this android application to help beginner developers to know how to use google maps API and how to convert JSON data into Java object.
## Functionality
1. Hard-Coded solutions for common medical problems
2. Scan nearby hospital locations from your current location by using GPS and Google Maps API.
## Getting Started
This application is uploaded for learning purpose you just clone this project to your android studio and make sure to add all dependencies  to your project file.
## Manifest
  1. uses-permission android:name=""android.permission.INTERNET""
  2. uses-permission android:name=""android.permission.ACCESS_COARSE_LOCATION""
  3. uses-permission android:name=""android.permission.ACCESS_FINE_LOCATION""
  4. uses-permission android:name=""android.permission.ACCESS_NETWORK_STATE""
## Dependencies
  1. compile 'com.google.android.gms:play-services-location:11.0.1'
  2. compile 'com.google.android.gms:play-services:11.0.2'
  3. compile files('libs/json-20170516.jar')
## Built with
Android Studio 2.3.3
"
17,leonibr/healthcaredemo,C#,"[![Gitpod ready-to-code](https://img.shields.io/badge/Gitpod-ready--to--code-blue?logo=gitpod)](https://gitpod.io/#https://github.com/leonibr/healthcaredemo)

### Realtime - HealthCare Central

Start by opening multiple browser windows and see all being updated accordingly

## [Online demo here](https://healthcare.marques.top)

### Quickstart

```bash
git clone https://github.com/leonibr/healthcaredemo
```

```bash
cd healthcaredemo
```

Now there is two options:

- Using docker:

```bash
docker-compose run --service-ports healthcare_demo
# it uses port 5015
```

- Or using dotnet cli:

```bash
 dotnet run --project Host\Host.csproj
# it uses port 5005
# watch out for folder navigation in your OS if not Windows
```

## Or check the screenshots:

1. Home Screen
   ![homescreen.png](homescreen.png)
   ![rate](ocuprate.png)

1. Place patients by dragging and droping
   ![healthcare_centrarl.gif](healthcare_central.gif)

#### Objective:

- simulate realtime administration of hospitals

#### Scenario:

- Operators can place or remove patients on hospital beds
- Operators do not register patients to waiting list, to simulate new patient to the list click: ""Add Patient to Waiting List""
- Operators get always updated data whenever is ivalidated by other operator (or other browser window)
- The time is show as duration

#### Constraints:

- Dual mode (WebAssembly and SSB)
- Dragging and Droping without external lib.

#### Modify whatever you like! but please share if you can! 😉

- It was built on top of Fusion's MudBlazor template.

### Changes:

    - updated to .net 7 and Fusion 4.1.38

### Road map:

- Maybe a dashboard

## License

- MIT
"
18,swar-it/D3.js-Dash,,"# D3.js and SQLite #
## Data visualization and Proof of Concept ##
A simple hospital dashboard illustrating concurrent clinical operations. Written predominately in Javascript and conforming to MVC, it uses a SQLite data store and some simple PHP accessors.
[![image](./Screen Shot 2014-06-24 at 3.04.52 PM.png)](http://colinwhite.net/Dash2.5/) 

Based on the following Creative Commons and Open Source prior work .

#### HTML5 Boilerplate ####
by Catalin Maris [https://github.com/alrra](https://github.com/kamisama/cal-heatmap) 

#### D3.js Data Driven Documents ####
by Mike Bostock

[https://github.com/mbostock/d3](https://github.com/mbostock/d3)

[https://github.com/mbostock/queue](https://github.com/mbostock/queue)

[https://github.com/mbostock/topojson](https://github.com/mbostock/topojson)

[https://github.com/d3/d3-plugins/tree/master/sankey](https://github.com/d3/d3-plugins/tree/master/sankey)

#### D3.js Tool Tips ####
by Justin Palmer [https://github.com/Caged/d3-tip](https://github.com/Caged/d3-tip)

#### Cal-HeatMap ####
by Wan Qi Chen [https://github.com/kamisama/cal-heatmap](https://github.com/kamisama/cal-heatmap) 

#### Special thanks...####
Lars Kuttohff

[http://stackoverflow.com/users/1172002/lars-kotthoff](http://stackoverflow.com/users/1172002/lars-kotthoff)"
19,advikmaniar/ML-Healthcare-Web-App,Python,"# ML-Healthcare-Web-App

This is an interactive Machine Learning Web App ""ML in Healthcare"" developed using Python and StreamLit. It uses ML algorithms to build powerful and accurate models to predict the risk (High / Low) of the user of having a Heart Attack or Breast Cancer based on the user's specific attributes like age, sex, heart rate, blood sugar, etc.

<h2><b> View App Here: </b></h2>

[![StreamLit App](https://static.streamlit.io/badges/streamlit_badge_white.svg)](https://share.streamlit.io/advikmaniar/ml-healthcare-web-app/main/ML_Healthcare.py)

<hr>

This applications has two basic sections:

<h2>1) - Model Building </h2>
In this section 7 different models are built using different ML algorithms. They are: 

```
1. Logistic Regression 
2. KNN
3. SVM 
4. Decision Trees 
5. Random Forest 
6. Gradient Boosting 
7. XGBoost
```
The models are trained using data from https://archive.ics.uci.edu/ml/index.php, particularly the [Heart Attack Prediction](https://github.com/advikmaniar/ML-Heathcare-Web-App/blob/main/Data/heart.csv) and [Breast Cancer (Wisconsin)](https://github.com/advikmaniar/ML-Heathcare-Web-App/blob/main/Data/BreastCancer.csv) datasets.

An interactive side-dashboard is created using the streamlit `st.sidebar` call which enables the user to do the following:
1. Choose dataset - `Heart Attack / Breast Cancer`
2. Choose algorithm - `Logistic Regression , KNN , SVM , Decision Trees , Random Forest , Gradient Boosting , XGBoost.`
3. Change the important parameters for each model - `Learning Rate, Random State, Regularization Coeff, Gamma, Kernel, n_estimators` etc. 

After training using the parameters selected by the user, the tuned model is built and ready to be tested on our testing data. The classification plot and confusion matrix is displayed for the model selected along with the model metrics: `Accuracy, Precision, Recall, F1-Score, Mean Squared Error, Execution Time`. The user can observe real-time changes in the plots and metrics as they change the model parameters further. 
> **This is a great way to understand the different ML algorithms and how they are influenced by tuning the hyperparameters.**
> 
![image](https://user-images.githubusercontent.com/72503778/123002403-85b73700-d3cf-11eb-80a1-71262561b9c8.png)

The 7 models (optimum tuning) performed as follows: <br>
`Criterion: Accuracy`
Model | Accuracy (Heart Attack / Breast Cancer)
------------ | -------------
Logistic Regression | **91.803% / 100.0%**
KNN | **86.89% / 96.49%**
SVM | **93.44% / 100.0%**
Decision Trees | **52.56% / 60.53%**
Random Forest | **90.164% / 98.24%**
Gradient Boosting | **88.53% / 96.49%**
XGBoost | **95.08% / 94.737%**

<h2>2) - User Prediction </h2>
In this section, the user can use any model developed above to predict their status (High Risk / Low Risk) using their own values. (Either for Heart Attack or Breast Cancer)

![image](https://user-images.githubusercontent.com/72503778/123003157-6d93e780-d3d0-11eb-81fc-8dd6abe89efa.png)

![image](https://user-images.githubusercontent.com/72503778/123003260-93b98780-d3d0-11eb-9ff0-bb27da6a105e.png)


View the final video [here](https://github.com/advikmaniar/ML-Healthcare-Web-App/blob/main/Results/Video.mp4).
<hr>

<h1> Thank You! </h1>

<hr>



"
20,no13bus/baymax,Python,"baymax
========

Build your personal life database, including of internet, taxi, sports and health data analysis.

[中文文档](https://github.com/no13bus/baymax/blob/master/README_CN.md)

# Let's start
- pip install -r requirements.txt
- Modify the config file, such as celery, MySQL configuration, APP callback address and apps' client_id.
- python manage.py initdb
- python manage.py insert
- python manage.py run

# Deployment
- nginx+gunicorn+supervisor

# Which app we support now
- [GitHub](http://github.com)
- [Health App: Fitbit](https://dev.fitbit.com)
- [rescuetime](https://www.rescuetime.com/developers)

# Which app we will support
- [ledongli](http://ledongli.cn)
- [bong](http://www.bong.cn/)
- [xiaomi](http://www.mi.com/shouhuan)
- [Nike+](https://developer.nike.com/index.html)
- [Moves](https://dev.moves-app.com/)
- [Withings](http://oauth.withings.com/api)
- [Uber](http://uber.com)
- ..............

# Mechanism
- Users first use GitHub account to sign in, after we get the authentication for the apps, 
the backend will to grab the app life data every day.
- And then baymax will display the life data, including of walking, running, surfing the net time distribution, 
GitHub code submitted times and statistics.


# The tech we use
- Flask
- sqlalchemy
- Bootstrap
- celery
- redis

# change log
### version 0.1
- update the framework version. Flask2.x Python3.x


# Screen
![1](https://raw.githubusercontent.com/no13bus/baymax/master/screen/1.png)
![2](https://raw.githubusercontent.com/no13bus/baymax/master/screen/2.png)
![3](https://raw.githubusercontent.com/no13bus/baymax/master/screen/3.png)
![4](https://raw.githubusercontent.com/no13bus/baymax/master/screen/4.png)
![5](https://raw.githubusercontent.com/no13bus/baymax/master/screen/5.png)
![6](https://raw.githubusercontent.com/no13bus/baymax/master/screen/6.png)
![7](https://raw.githubusercontent.com/no13bus/baymax/master/screen/7.png)
"
21,OpenConceptLab/oclapi,Python,"# This project has been deprecated. Please see https://github.com/OpenConceptLab/oclapi2 for the latest version.

OCL API
======

## Contributing

We welcome all pull requests. Before starting any work, please check https://github.com/OpenConceptLab/ocl_issues/issues if the change you want to work on has been already reported there. If it's not there, create a new issue so that it can be discussed. We should triage the issue and get back to you in a few days.

All pull requests should contain a single commit (unless you have a very good reason to include multiple commits). A commit message should be in the following format: `OpenConceptLab/ocl_issues#id Short title`, where `id` is the issue number e.g. 170. Please always rebase your commit on the master branch and make sure all tests pass, before creating a pull request.

## What you'll need:
* git
* docker-compose

Source for the Open Concept Lab APIs

## Docker Environment Setup (preferred)

Fork the repo on github and clone your fork:
````sh
git clone https://github.com/{youruser}/oclapi
````

Add a remote repo to upstream in order to be able to fetch updates:
````sh
git remote add upstream https://github.com/OpenConceptLab/oclapi
````

Go to:
````sh
cd oclapi
````

Build containers explicitly (only the first time to go around oclapi:dev not found):
````sh
docker-compose build
````

Fire up containers:
````sh
docker-compose up
````

You can access the API at http://localhost:8000

The root password and the API token can be found in docker-compose.yml under api/environment.

### Docker Environment Settings

Docker `.env` file should be located under the root project folder. On development environment you don't need this file.

#### .env file details

`ENVIRONMENT=` Python module for environment, e.g. production, staging, local, qa

`AWS_ACCESS_KEY_ID=` Amazon Web Services access key.

`AWS_SECRET_ACCESS_KEY=` Amazon Web Services secret key.

`AWS_STORAGE_BUCKET_NAME=` Amazon Web Services bucket name.

`ROOT_PASSWORD=` API root user password.

`OCL_API_TOKEN=` API root token.

`SECRET_KEY=` DJANGO secret key.

`EMAIL_HOST_PASSWORD=` no-reply@openconceptlab.org password.

`SENTRY_DSN=` Sentry unique URL for the given environment.

`IMPORT_DEMO_DATA=` Set to 'true' to import ~2k concepts from the CIEL demo data.

`FLOWER_USER=` Flower user (Default value - floweruser).

`FLOWER_PWD=` Flower password (Default value - Flower123).

### Running commands in a container

You can run any command in a running container. Open up a new terminal and run for example:
````sh
docker-compose exec api python manage.py syncdb
````

### Running tests in a container
You can run tests in a container as any other command.

#### Unit Tests

````sh
docker-compose run --rm api python manage.py run_test --configuration=Dev
````

#### Integration Tests

See integration-tests/README.md

To run locally:
````sh
docker-comopse up -d
docker build integration-tests/. --network=""host"" --build-arg CACHEBUST=$(date +%s)
````

Deprecated integration tests can be run with:
````sh
docker-compose run --rm api python manage.py test integration_tests --configuration=Dev
````

#### Rebuilding SOLR index

If the SOLR index gets out of sync, you can run the following command:
````sh
docker-compose run --rm -d api python manage.py rebuild_index --batch-size 100 --workers 4 --verbosity 2 --noinput
````
It's asynchronous. To follow logs run:
````sh
docker logs -f oclapistg_api_run_1
````
, where oclapistg_api_run_1 is the container id returned by the `run` command.

### Backups

By default backups are taken every night at midnight. You can trigger a manual backup by running:
````sh
docker-compose run --rm backup bash backup.sh
````
Backups are saved in a backup directory configured via the BACKUP_DIR env property (./backups by default).
You can restore a particular backup by running:
````sh
docker-compose run --rm backup bash restore.sh 2017-09-27_00-00-01
````
### Connecting to mongo in container

````sh
docker-compose exec mongo mongo
````

### Debugging in container

To setup debugging PyCharm Professional Edition is required.

Docker-compose up starts the server in a development mode by default. It exposes all services on the host machine as well as enables SSH to the API service.

In Pycharm IDE open oclapi project and go to `Settings-> Project: oclapi -> Project Interpreter`

Click on gear icon and choose `Add Remote` option

Configure interpreter with SSH credentials as in the image (default password is `Root123`):

![alt](img/remote_interpreter_config.png)

There will be warnings about unknown host etc. but don't don't worry, just confirm.

Setup django debug configuration as in the image (Path mapping should be `absolute path to project directory=/code`):

![alt](img/docker_debug_config.png)

Run your configuration! Debugging server will run on [http://0.0.0.0:8001/](http://0.0.0.0:8001/)

In case of any problems with `.pycharm_helpers` just delete remote interpreter and create new with same configuration, it will write pycharm helpers in Your ocl container again.

## Continuous Integration

The project is built by CI at https://ci.openmrs.org/browse/OCL

You can see 3 plans there:
* OCL API
* OCL WEB
* OCL QA UI Tests

OCL API and OCL WEB are triggered by commits to respective repos. First docker images are built and pushed with a nightly tag to dockerhub at https://hub.docker.com/u/openconceptlab/dashboard/. Next unit and integration tests are being run. Finally a qa tag is being pushed to dockerhub and deployed to https://ocl-qa.openmrs.org/. On each deployment data is wiped out of the qa environment. You can login to the server using username 'admin' and password 'Admin123'.

### Deploying to staging and production

If you want to deploy to staging or production, you need to be logged in to Bamboo. Please request access via helpdesk@openmrs.org

1. Go to https://ci.openmrs.org/browse/OCL and click the cloud icon next to the project you want to deploy.
2. Click the related deployment plan.
3. Click the cloud icon next in the actions column for the chosen environment.
4. Choose whether to create a new release from build result or redeploy an existing release. You will choose the latter when promoting a release from staging to production, downgrading to a previous release or restarting services.
5. When creating a new release, choose the build result, which you want to deploy (usually the latest successful build). Leave the release title unchanged and click the Start deployment button.
6. Wait for the release to complete.

### Importing CIEL to staging and production

In order to import a newer version of the CIEL dictionary you need to have an SSH root access to staging.openconceptlab.org and openconceptlab.org.
Download the zip file with concepts and mappings in the OCL format and run the following commands for staging:
```sh
sudo -s
cd /root/docker/oclapi-stg 
unzip /path/to/zip/ciel_20180223.zip
docker-compose run -d --rm -v /root/docker/oclapi-stg:/ciel api python manage.py import_concepts_to_source --source 57cd60e2ba0d489c55039465 --token REPLACE_WITH_ROOT_API_TOKEN --retire-missing-records /ciel/ciel_20180223_concepts.json
docker logs -f oclapistg_api_run_1
docker-compose run -d --rm -v /root/docker/oclapi-stg:/ciel api python manage.py import_mappings_to_source --source 57cd60e2ba0d489c55039465 --token REPLACE_WITH_ROOT_API_TOKEN --retire-missing-records /ciel/ciel_20180223_mappings.json
docker logs -f oclapistg_api_run_2
```

Or for production:
```sh
sudo -s
cd /root/docker/oclapi-prd 
unzip /path/to/zip/ciel_20180223.zip
docker-compose run -d --rm -v /root/docker/oclapi-prd:/ciel api python manage.py import_concepts_to_source --source 5821b7a564d700001440f44a --token REPLACE_WITH_ROOT_API_TOKEN --retire-missing-records /ciel/ciel_20180223_concepts.json
docker logs -f oclapiprd_api_run_1
docker-compose run -d --rm -v /root/docker/oclapi-prd:/ciel api python manage.py import_mappings_to_source --source 5821b7a564d700001440f44a --token REPLACE_WITH_ROOT_API_TOKEN --retire-missing-records /ciel/ciel_20180223_mappings.json
docker logs -f oclapiprd_api_run_2
```

Imports run in background so you can disconnect from the server any time, but note that you must wait for concepts to be imported before importing mappings. You can get back to logs at any point by running: `docker logs -f CONTAINER_NAME`.

## Manual Environment Setup (on a Mac)

Follow this [guide](http://docs.python-guide.org/en/latest/starting/install/osx/) to install Python 2.7
and set up a virtual environment.  You may wish to name your virtual environment something more descriptive,
for example replace:

    virtualenv venv

With:

    virtualenv oclenv

And then run:

    source oclenv/bin/activate

### Mongo

The OCL API uses MongoDB as its backend datastore.  If you don't have it already, use Homebrew to install it:

    brew install mongodb

Once installed, use the `mongod` command to start a local instance of the MongoDB server.
Then, in a separate console window, run `mongo` to start the interactive command-line client.
Using the Mongo command-line, create a database named `ocl`:

     > use ocl

### Solr 4.9.0

Solr is used to support searching across OCL API entities.  To download Solr 4.9.0, visit the Solr [mirrors](http://www.apache.org/dyn/closer.cgi/lucene/solr/4.9.0) page and select a mirror.  Then download solr-4.9.0.tgz (NOT solr-4.9.0-src.tgz).

Choose an install directory (e.g. `~/third-party`, henceforth `$INSTALL_DIR`) and extract the tarball there.  You will then need to set 2 environment variables:

       export SOLR_ROOT=$INSTALL_DIR/solr-4.9.0
       export SOLR_HOME=$OCLAPI_ROOT/solr

`$OCLAPI_ROOT` refers to your Git project root (i.e. the location of this Readme file).

This should enable you to run `$OCLAPI_ROOT/run_solr.sh`, which starts Solr in a Jetty instance listening on port 8983.  Verify this by visiting:

     http://localhost:8983/solr

### The Django Project

Clone this repository, and `cd` into the `ocl` directory.
Before you can run the server, you will need to execute the following steps:

1. Install the project dependencies:

    pip install -r requirements.txt

2. Use `syncdb` to create your backing Mongo collections.

   ```sh
   ./manage.py syncdb
   ```

   If you are starting with a clean Mongo database, `syncdb` will prompt you to create a superuser.
   Follow that prompt.

   If you are not prompted to create a superuser, or wish to do so later, you can also use the command:

   ```sh
   ./manage.py createsuperuser
   ```
   
3. Verify your superuser and make note of your token.

   ```sh
   $ mongo
   > use ocl
   > db.auth_user.find({'is_superuser':true})
   ```

   This should revel the superuser you just created.  Note the user's _id (e.g. `ObjectId(""528927fb2f3e986be1627d6d"")`),
   and use it to locate your token:

   ```sh
   > db.authtoken_token.find({'user_id': ObjectId(""528927fb2f3e986be1627d6d"")})[0]
   ```

   Make note of the token `_id` (e.g. `""20e6ac8fe09129debac2929f4a20a56bea801165""`).  You will need this to access your endpoints
   once you start up your server.

4. Run the lightweight web server that ships with Django.

   ./manage.py runserver

   The OCL API should now be running at `http://localhost:8000`.

5. Test an endpoint.
   
   Remember, the API uses token-based authentication, so you can't just plug an endpoint into a browser and hit Return.
   You'll need to use a tool that allows you to specify a header with your request.  One simple example is `curl`:

   ```sh   
   curl -H ""Authorization: Token c1328d443285f2c933775574e83fe3abfe6d7c0d"" http://localhost:8000/users/
   ```

   I recommend using the [Advanced REST Client](https://chrome.google.com/webstore/detail/advanced-rest-client/hgmloofddffdnphfgcellkdfbfbjeloo?hl=en-US) app for Chrome.
   This provides you with a nice editor for passing parameters along with your `POST` and `PUT` requests.

6. Create an API user.
   
   Your superuser is not a valid API user, because it was not created via the `POST /users/` operation.
   However, you can use your superuser to access that endpoint and _create_ an API user:

   ```sh
   curl -H ""Authorization: Token c1328d443285f2c933775574e83fe3abfe6d7c0d"" -H ""Content-Type: application/json"" -d '{""username"":""test"",""email"":""test@test.com"", ""name"":""TestyMcTest""}' http://localhost:8000/users/   
   ```

7. (Optional) Make your API user an admin (staff) user.

   Log into the Django admin console with the superuser credentials you established in step 4:

   ```sh
   http://localhost:8000/admin/
   ```

   Then navigate to the user list:

   ```sh
   http://localhost:8000/admin/auth/user/
   ```

   Select the user you just created, and check the box next to ""staff status"".  Now your user is an admin within the context of the OCL API.
   
   

## Data Import Before Concept Creation
We need to have data before we go on creating a concept. 

The dropdowns that require preloaded data are Concept Class, Datatype, Name/Description Type, Locale, Map Type. 


### How to import Data
1. Create a new org `OCL`. 
2. Create a new user source `Classes` under org `OCL`. This will be be used for Concept Class dropdown.
3. Import the data as concepts in `Classes` from https://github.com/OpenConceptLab/ocl_import/blob/master/OCL_Classes/classes.json .

Follow https://github.com/OpenConceptLab/oclapi/wiki/Bulk-Importing#how-to-import to know how to import concepts in a source.

Proceed in same fashion for rest of the dropdown fields. Create sources `Datatypes`, `NameTypes`, `DescriptionTypes`, `Locales`, `MapTypes` under org `OCL`. 

Refer to following files for data: 

Datatypes: https://github.com/OpenConceptLab/ocl_import/blob/master/OCL_Datatypes/datatypes_fixed.json

NameTypes: https://github.com/OpenConceptLab/ocl_import/blob/master/OCL_NameTypes/nametypes_fixed.json

DescriptionTypes: https://github.com/OpenConceptLab/ocl_import/blob/master/OCL_DescriptionTypes/description_types.json

Locales: https://github.com/OpenConceptLab/ocl_import/blob/master/OCL_Locales/locales.json

MapTypes: https://github.com/OpenConceptLab/ocl_import/blob/master/OCL_MapTypes/maptypes_fixed.json


---------------------------------------------------------------------
Copyright (C) 2016 Open Concept Lab. Use of this software is subject
to the terms of the Mozille Public License v2.0. Open Concept Lab is
also distributed under the terms the Healthcare Disclaimer
described at http://www.openconceptlab.com/license/.
---------------------------------------------------------------------
"
22,aws-quickstart/quickstart-tableau-server-healthcare,Python,"# quickstart-tableau-server-healthcare
## Tableau Server for Healthcare on the AWS Cloud

**Important note:** You must have an AWS Business Associate Addendum (BAA) in place, and follow its configuration requirements, before running protected health information (PHI) workloads on AWS. For details, see the [deployment guide](https://aws-quickstart.s3.amazonaws.com/quickstart-tableau-server-healthcare/doc/tableau-server-for-healthcare-on-the-aws-cloud.pdf).

This Quick Start helps you deploy a Tableau Server standalone environment on the AWS Cloud, following best practices from AWS and Tableau Software. Specifically, this environment can help organizations with workloads that fall within the scope of the U.S. Health Insurance Portability and Accountability Act (HIPAA). The Quick Start addresses certain technical requirements in the Privacy, Security, and Breach Notification Rules under the HIPAA Administrative Simplification Regulations (45 C.F.R. Parts 160 and 164). 

The Quick Start includes AWS CloudFormation templates, which automatically configure the Tableau Server environment in less than an hour. The [security controls reference](https://aws-quickstart.s3.amazonaws.com/quickstart-tableau-server-healthcare/assets/HIPAA-Security-Controls-Mapping_TableauServer_181022.xlsx) (Microsoft Excel spreadsheet) shows how Quick Start architecture decisions, components, and configurations map to HIPAA regulatory requirements. The Quick Start also includes a [deployment guide](https://aws-quickstart.s3.amazonaws.com/quickstart-tableau-server-healthcare/doc/tableau-server-for-healthcare-on-the-aws-cloud.pdf), which describes the reference architecture in detail and provides step-by-step instructions for deploying, configuring, and validating the AWS environment.

The Quick Start offers two deployment options:

- Deploying Tableau Server for healthcare into a new virtual private cloud (VPC) on AWS
- Deploying Tableau Server for healthcare into an existing VPC on AWS

You can also use the AWS CloudFormation templates as a starting point for your own implementation.

![Quick Start architecture for Tableau Server for healthcare on AWS](https://d0.awsstatic.com/partner-network/QuickStart/datasheets/tableau-server-healthcare-architecture-on-aws.png)


To post feedback, submit feature ideas, or report bugs, use the **Issues** section of this GitHub repo.
If you'd like to submit code for this Quick Start, please review the [AWS Quick Start Contributor's Kit](https://aws-quickstart.github.io/). 
"
23,codefordenver/encorelink,JavaScript,"# EncoreLink

A web application to connect musicians with healthcare centers.

[![Stories Ready to Work On](https://badge.waffle.io/codefordenver/music-volunteers.svg?label=ready&title=Cards%20Ready%20To%20Work%20On)](https://waffle.io/codefordenver/music-volunteers)
[![Build Status](https://travis-ci.org/codefordenver/encorelink.svg?branch=master)](https://travis-ci.org/codefordenver/encorelink)

![](./docs/screenshot_2018-11-05.png)

## General Documentation
The documents we created when building EncoreLink are [here](https://drive.google.com/drive/folders/0BzPSX8eOfTADckNXd3VIc1U3UUE).
Probably the most helpful will be:

* [EncoreLink Specification](https://docs.google.com/document/d/1Mwo-pOyveza1XXKrpr966admHFanHzy5Hn2r6ewE3vk/edit#heading=h.6qqugcr09y1p) - this is our current spec

## Developer Documentation
Developer documentation currently lives [here](/docs/DEVDOCS.md)

## Getting Started

### Basic Setup

1. Install [Node.js](https://nodejs.org/) (The official node verion for this app is 6.11, although other modern versions will probably work fine)
2. Clone this repo
3. Navigate to your repo folder
4. Run `npm install`
5. Get a Google api key with the Google Maps Embed API and the Google Maps JavaScript API enabled (you can probably get this from one of the team members on the project)
6. Copy `.env.sample` to `.env` and set the `REACT_APP_GOOGLE_API_KEY` environment variable
7. Run `npm start`

If this doesn't open a browser for you, you can navigate to http://localhost:3000 to view the app.
There is also an api explorer available at http://localhost:54321/explorer/

### Advanced Setup - Postgres

This is an _optional_ setup to run the app against postgres. This is good if you want to persist data or test how the app interacts with the actual database that we use in production, however, it can be a bit more complicated, so we don't recommend it generally.

1. Install [PostgreSQL](https://www.postgresql.org/download/) (for mac we'd recommend installing http://postgresapp.com/)
2. Create a new database in postgres (you can call it `encorelink`)
3. Copy the [server/datasources.local.example.json](server/datasources.local.example.json) to `server/datasources.local.json` and update the config for `postgres` in that file to match the info for that postgres database (i.e. setting the `host`, `port`, `database`, `username`, and `password`)

## Usage

### Linting

This project uses [eslint](http://eslint.org/) for checking coding practices and standards.
It is expected that any opened pull requests have a passing eslint run.

It is _highly recommended_ that you configure your editor to run eslint on the fly
while you code.

Additionally, you can run eslint on the command line with `npm run lint` (or
`npm run lint -- --fix` to have eslint attempt to fix some of the issues it finds)

### Testing

This project uses Facebook's [jest](https://facebook.github.io/jest/) library for testing,
and takes advantage of their [snapshot testing](https://facebook.github.io/jest/docs/tutorial-react.html#snapshot-testing).

For development run:

```bash
npm test -- --watch
```

This will run the tests in an interactive mode, where tests will automatically be
re-run when files are changed, and snapshots can be updated on the fly.

### Things work locally but not on Heroku...
We run the app with a different configuration for local development than we do
for deploying. If things work when running locally, but fail when deploying,
run `npm prune --production` to set your `node_modules` to match production and
run `npm run heroku` to emulate the config used for production (visible on
localhost:3000).

You might also want to make sure you have the same npm modules that will be
installed on heroku (this can be done with `rm -rf node_modules && npm install
--production`). In this case, you'll have to start the app with
`NODE_ENV=production npm start` (or otherwise export `NODE_ENV=production`
before starting).

### Client App State
This project uses Redux for managing state on the client. There is a neat
[Redux DevTools browser extension](http://extension.remotedev.io/) that can help with
understanding and debugging what is happening in the app as a user interacts with the client.

The [Chrome version of the plugin can be found here](https://chrome.google.com/webstore/detail/redux-devtools/lmhkpmbekcpmknklioeibfkpmmfibljd)

### React Storybook

We have integrated [React Storybook](https://getstorybook.io) for development of React components
in isolation independent of having to wire up data from the app.

To run react storybook, run `npm run storybook`
This will start storybook running at http://localhost:9001

Stories are defined for components in [client/stories/index.js](client/stories/index.js).
For docs on how to write stories see the [storybook docs](https://getstorybook.io/docs/react-storybook/basics/writing-stories).

## Built With

* [Node.js](https://nodejs.org/en/about/) - Executes JavaScript code server-side
* [Loopback](https://loopback.io/) - Node.js API framework
* [Netlify](https://www.netlify.com/docs/) - Frontend hosting; platform for automated deployment of static webpages
* [Heroku](https://www.heroku.com/platform) - Backend hosting; Cloud application platform for web application deployment
* [PostgreSQL](https://www.postgresql.org/about/) - An object-relational database
* [React Storybook](https://github.com/storybooks/storybook) - Development environment for UI components
* [Redux](https://redux.js.org/) - Manages state on the client
"
24,terraform-google-modules/terraform-google-healthcare,HCL,"# terraform-google-healthcare

This module handles opinionated Google Cloud Platform Healthcare datasets and stores.

## Usage

Basic usage of this module is as follows:

```hcl
module ""healthcare"" {
  source  = ""terraform-google-modules/healthcare/google""
  version = ""~> 2.3""

  project  = ""<PROJECT_ID>""
  name     = ""example-dataset""
  location = ""us-central1""
  dicom_stores = [{
    name = ""example-dicom-store""
    iam_members = [
      { role = ""roles/healthcare.dicomEditor"", member = ""user:example@domain.com"" }
    ]
  }]
  fhir_stores = [{
    name         = ""example-fhir-store""
    version      = ""R4""
    notification_config = {
      pubsub_topic = ""projects/<PROJECT_ID>/topics/example_topic""
    }
  }]
}
```

Functional examples are included in the
[examples](./examples/) directory.

## Requirements

These sections describe requirements for using this module.

### Software

The following dependencies must be available:

- [Terraform][terraform] v0.13
- [Terraform Provider for GCP][terraform-provider-gcp] plugin v4.39.0

### Service Account

A service account with the following roles must be used to provision
the resources of this module:

- Healthcare Dataset Admin: `roles/healthcare.datasetAdmin`
- Healthcare DICOM Admin: `roles/healthcare.dicomStoreAdmin`
- Healthcare FHIR Admin: `roles/healthcare.fhirStoreAdmin`
- Healthcare HL7 V2 Admin: `roles/healthcare.hl7V2StoreAdmin`
- Healthcare Consent Admin: `roles/healthcare.ConsentStoreAdmin`

The [Project Factory module][project-factory-module] and the
[IAM module][iam-module] may be used in combination to provision a
service account with the necessary roles applied.

To allow messages to be published from the Cloud Healthcare API to Pub/Sub,
you must add the `roles/pubsub.publisher` role to your project's [Cloud Healthcare
Service Agent service account](https://cloud.google.com/healthcare/docs/how-tos/controlling-access-other-products#the_cloud_healthcare_service_agent).

### APIs

A project with the following APIs enabled must be used to host the
resources of this module:

- Google Cloud Healthcare API: `healthcare.googleapis.com`

To allow messages to be published from the Cloud Healthcare API to Pub/Sub,
the following API also needs to be enabled:
- Google Pub/Sub API: `pubsub.googleapis.com`

The [Project Factory module][project-factory-module] can be used to
provision a project with the necessary APIs enabled.

<!-- BEGINNING OF PRE-COMMIT-TERRAFORM DOCS HOOK -->
## Inputs

| Name | Description | Type | Default | Required |
|------|-------------|------|---------|:--------:|
| consent\_stores | Datastore that contain all information related to the configuration and operation of the Consent Management API (https://cloud.google.com/healthcare/docs/how-tos/consent-managing). | `any` | `[]` | no |
| dicom\_stores | Datastore that conforms to the DICOM (https://www.dicomstandard.org/about/) standard for Healthcare information exchange. | `any` | `[]` | no |
| fhir\_stores | Datastore that conforms to the FHIR standard for Healthcare information exchange. | `any` | `[]` | no |
| hl7\_v2\_stores | Datastore that conforms to the HL7 V2 (https://www.hl7.org/hl7V2/STU3/) standard for Healthcare information exchange. | `any` | `[]` | no |
| iam\_members | Updates the IAM policy to grant a role to a new member. Other members for the role for the dataset are preserved. | <pre>list(object({<br>    role   = string<br>    member = string<br>  }))</pre> | `[]` | no |
| location | The location for the Dataset. | `string` | n/a | yes |
| name | The resource name for the Dataset. | `string` | n/a | yes |
| project | The ID of the project in which the resource belongs. | `string` | n/a | yes |
| time\_zone | The default timezone used by this dataset. | `string` | `null` | no |

## Outputs

No output.

<!-- END OF PRE-COMMIT-TERRAFORM DOCS HOOK -->

## Contributing

Refer to the [contribution guidelines](./CONTRIBUTING.md) for
information on contributing to this module.

[project-factory-module]: https://registry.terraform.io/modules/terraform-google-modules/project-factory/google
[terraform-provider-gcp]: https://www.terraform.io/docs/providers/google/index.html
[terraform]: https://www.terraform.io/downloads.html
"
25,opencasestudies/ocs-healthexpenditure,HTML,"---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

# OpenCaseStudies

<!-- badges: start -->
[![Travis-CI Build Status](https://travis-ci.com/muschellij2/ocs-healthexpenditure.svg?branch=master)](https://travis-ci.com/muschellij2/ocs-healthexpenditure)
<!-- badges: end -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = ""#>"",
  fig.path = ""man/figures/README-"",
  out.width = ""100%""
)
```


### License 

This case study is part of the [OpenCaseStudies]() project. This work is licensed under the Creative Commons Attribution-NonCommercial 3.0 ([CC BY-NC 3.0](https://creativecommons.org/licenses/by-nc/3.0/us/)) United States License.

### Citation 

To cite this case study:

Kuo, Pei-Lun and Jager, Leah and Taub, Margaret and Hicks, Stephanie. (2019, February 14). opencasestudies/ocs-healthexpenditure: Exploring Health Expenditure using State-level data in the United States (Version v1.0.0). Zenodo. http://doi.org/10.5281/zenodo.2565307

[![DOI](https://zenodo.org/badge/151142096.svg)](https://zenodo.org/badge/latestdoi/151142096)

### Title 

Exploring health expenditure using state-level data in the United States

Health policy in the United States is complicated, and several 
forms of healthcare coverage exist, including both coverage by federal 
goverment-led healthcare policy, and by private insurance companies.
Before making any inference about the relationship between 
health condition and health policy, it is important for us to 
have a general idea about healthcare economics in the United 
States. Thus, We are interested in getting sense of healthcare 
coverage and healthcare spending across the United States.  

### Motivating questions

1. Is there a relationship between healthcare coverage and
healthcare spending in the United States?   
2. How does the spending distribution change across geographic 
regions in the Unied States?  
3. Does the relationship between healthcare coverage and 
healthcare spending in the United States change from 2013 to 2014?  

### Data

The data for this demonstration come from
[Henry J Kaiser Family Foundation (KFF)](https://www.kff.org). 

- [Health Insurance Coverage of the Total Population](https://www.kff.org/other/state-indicator/total-population/) (Includes years 2013-2016)
  
- [Health Care Expenditures by State of Residence (in millions)](https://www.kff.org/other/state-indicator/health-care-expenditures-by-state-of-residence-in-millions/) (Includes years 1991-2014)
 
For educational purposes, the data have been downloaded 
and relative paths are used for this demonstration.
**Note**: If students are not familiar with relative paths,
it will be helpful to briefly introduce the idea for absolute
paths and relative paths.

We also introduce `library(datasets)` for States information.

### Learning Objetives

The skills, methods, and concepts that students will be familiar with by the end of this case study are:

<u>**Data Science Learning Objectives:**</u>

1. Load data from a package (`datasets`)  
2. Import data from a csv (`readr`)  
3. View, filter, join, and summarize data (`dplyr`)   
4. Reshape data into different formats (`tidyr`)  
5. Create data visualizations (`ggplot2`) with labels (`ggrepel`) and facets for different groups    

#### Data Import 

We use the R package `library(readr)` for data import in this tutorial.  

#### Data wrangling 

Two R package `library(tidyr)`, `library(dplyr)` are used for data wrangling in this tutorial.  

We explain what tidy data is, and further introduce the concepts of ""wide format"" 
and ""long format."" We also demonstrate how to convert from one format to the other using 
`gather()` and `spread()`.

We also demonstrate some other useful functions for data wrangling, including 
selecting columns using `select()`, 
Selecting rows using `filter()`, 
arranging or re-orderomg rows using `arrange()`, 
joining two datasets using `join()`, 
adding columns using `mutate()`, 
creating summaries of columns using `summarize()`, 
and grouping operations using `group_by()`. 

#### Data exploration (exploratory analysis)   

For exploratory analysis, we use data visulization for exploratory analysis. `ggplot2` is the R package 
we demonstrate in this tutorial. 

We explain how to create plots using `ggplot()` with basic syntax for `ggplot2`. 
We also demonstrate how to create scatter plots using `geom_point()`,
how to add layers of text using `geom_text()`, 
how to facet across a variable using `facet_wrap()`, 
how to create boxplots using `geom_boxplot()`, 
and how to facet by two variables using `facet_grid`. 

#### Summary   

The total healthcare expenditure is associated with 
the population. To make a fair comparison, 
we create ""healthcare expenditure per capita."" 
Further, the exploratory analysis via data visualization showed 
higher speding in healthcare per capita 
is positively associated with higher 
employer coverage proportion and is 
negatively associated with the porportion 
of uninsured population across the States. 

### Other notes and resources 

<u>**Packages used in this case study:** </u>

 Package   | Use in this case study                                                                       
---------- |-------------
[datasets](https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/00Index.html){target=""_blank""} | to get the state data
[tibble](https://tibble.tidyverse.org/){target=""_blank""} | to create tibbles (the tidyverse version of a data frame)
[readr](https://readr.tidyverse.org/){target=""_blank""} |  to read in the data from the csv files
[tidyr](https://tidyr.tidyverse.org/){target=""_blank""}      | to change the shape or format of tibbles to wide and long  
[dplyr](https://dplyr.tidyverse.org/){target=""_blank""}      | to subset and filter the data for specific groups, to summarize the data
[ggplot2](https://ggplot2.tidyverse.org/){target=""_blank""}      | to create plots  
[ggrepel](https://cran.r-project.org/web/packages/ggrepel/ggrepel.pdf){target=""_blank""} | to add labels that do not overlap to plots

In order to run this code please ensure you have these packages installed.

### For instructors:  

The objective of this tutorial is for student to get familiar with important skills in data science, including data import (`readr`), data wrangling (`dplyr`), and data visualization (`ggplot2`). This material is designed for 4.5 teaching hours. (One potential way to teach this tutorial is to divide the material into three 1.5 hour sessions. The first session focuses on data import, the second session focuses on data wrangling, and the third portion focuses on visualization.) The session starting with (*) can be made as exercise for students' practice.

 
"
26,Dana-Farber/automl-in-healthcare-review,,"# AutoML in Healthcare Review
Automated machine learning: Review of the state-of-the-art and opportunities for healthcare

Selected highlights from the 2020 AutoML Review [https://doi.org/10.1016/j.artmed.2020.101822] that reviewed over **2,160 works related to the field of automated machine learning**. 

## The curated list of automated feature engineering tools for Automated Machine Learning
Full details in https://www.sciencedirect.com/science/article/pii/S0933365719310437?via%3Dihub#tbl0005
| Method                  | Work                                                                                                                                                                                                                | Feature Engineering Technique | Used by how many works |
|-------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------|---------------------------------------|
| Deep Feature Synthesis  | [LINK](https://dai.lids.mit.edu/wp-content/uploads/2017/10/DSAA_DSM_2015.pdf)                                                                                                                                      | Expand-Reduce                 | 151                                   |
| Explore Kit             | [LINK](http://people.eecs.berkeley.edu/~dawnsong/papers/icdm-2016.pdf)                                                                                                                                               | Expand-Reduce                 | 53                                    |
| One Button Machine      | [LINK](https://arxiv.org/pdf/1706.00327.pdf)                                                                                                                                                                         | Expand-Reduce                 | 32                                    |
| AutoLearn               | [LINK](http://web2py.iiit.ac.in/research_centres/publications/download/inproceedings.pdf.88535e0ea3a74e72.4943444d2d20323031372e706466.pdf)                                                                          | Expand-Reduce                 | 16                                    |
| GP Feature Construction | [LINK](https://homepages.ecs.vuw.ac.nz/~xuebing/Papers/GPFCFSmemeticComputing.pdf)                                                                                                                                   | Genetic Programming           | 68                                    |
| Cognito                 | [LINK](https://ieeexplore.ieee.org/abstract/document/7836821)                                                                                                                                                        | Hierarchical Greedy Search    | 38                                    |
| RLFE                    | [LINK](https://arxiv.org/pdf/1709.07150.pdf)                                                                                                                                                                         | Reinforcement Learning        | 21                                    |
| LFE                     | [LINK](https://www.researchgate.net/profile/Udayan_Khurana/publication/318829821_Learning_Feature_Engineering_for_Classification/links/5a13e08a0f7e9b1e5730a735/Learning-Feature-Engineering-for-Classification.pdf) | Meta-Learning                 | 34                                    |


## Automated machine learning pipeline optimizers
Full details in https://www.sciencedirect.com/science/article/pii/S0933365719310437?via%3Dihub#tbl0010
| Method                    | Work                                                                                                           | Optimization Algorithm                               | Data Pre-Processing | Feature Engineering | Model Selection    | Hyperparameter Optimization | Ensemble Learning  | Meta-Learning      | Used by how many works |
|---------------------------|-----------------------------------------------------------------------------------------------------------------|------------------------------------------------------|---------------------|---------------------|--------------------|-----------------------------|--------------------|--------------------|---------------------------------------|
| Auto-Weka                 | [LINK](https://arxiv.org/pdf/1208.3719.pdf)                                                                     | Bayesian Optimization (SMAC)                         | :heavy_check_mark:  |                     | :heavy_check_mark: | :heavy_check_mark:          |                    |                    | 703                                   |
| Auto-Sklearn              | [LINK](http://papers.nips.cc/paper/5872-efficient-and-robust-automated-machine-learning.pdf)                    | Joint Bayesian Optimization and Bandit Search (BOHB) | :heavy_check_mark:  |                     | :heavy_check_mark: | :heavy_check_mark:          | :heavy_check_mark: | :heavy_check_mark: | 542                                   |
| TPOT                      | [LINK](https://arxiv.org/pdf/1601.07925.pdf)                                                                    | Evolutionary Algorithm                               | :heavy_check_mark:  | :heavy_check_mark:  | :heavy_check_mark: | :heavy_check_mark:          |                    |                    | 84                                    |
| TuPAQ                     | [LINK](https://thisisdhaas.com/papers/SOCC2015TuPAQ.pdf)                                                        | Bandit Search                                        |                     |                     | :heavy_check_mark: | :heavy_check_mark:          |                    |                    | 94                                    |
| ATM                       | [LINK](http://www.thswear.com/files/SwearingenEtAl-ATM-BigData2017.pdf)                                         | Joint Bayesian Optimization and Bandit Search        |                     | :heavy_check_mark:  |                    | :heavy_check_mark:          |                    | :heavy_check_mark: | 29                                    |
| Automatic Frankensteining | [LINK](https://www.ismll.uni-hildesheim.de/pub/pdfs/wistuba_et_al_SDM_2017.pdf)                                 | Bayesian Optimization                                |                     |                     | :heavy_check_mark: | :heavy_check_mark:          | :heavy_check_mark: |                    | 12                                    |
| ML-Plan                   | [LINK](https://link.springer.com/article/10.1007/s10994-018-5735-z)                                             | Hierarchical Task Networks (HTN)                     | :heavy_check_mark:  |                     | :heavy_check_mark: | :heavy_check_mark:          |                    |                    | 24                                    |
| Autostacker               | [LINK](https://arxiv.org/pdf/1803.00684.pdf)                                                                    | Evolutionary Algorithm                               |                     |                     | :heavy_check_mark: | :heavy_check_mark:          | :heavy_check_mark: |                    | 18                                    |
| AlphaD3M                  | [LINK](https://www.cs.columbia.edu/~idrori/AlphaD3M.pdf)                                                        | Reinforcement Learning/Monte Carlo Tree Search       | :heavy_check_mark:  |                     | :heavy_check_mark: | :heavy_check_mark:          |                    |                    | 8                                     |
| Collaborative Filtering   | [LINK](https://papers.nips.cc/paper/7595-probabilistic-matrix-factorization-for-automated-machine-learning.pdf) | Probabilistic Matrix Factorization                   | :heavy_check_mark:  |                     | :heavy_check_mark: | :heavy_check_mark:          |                    | :heavy_check_mark: | 29                                    |

## Neural Architecture Search algorithms, based on performance on the CIFAR-10 dataset
Full details in https://www.sciencedirect.com/science/article/pii/S0933365719310437?via%3Dihub#tbl0015
| NAS Algorithm           | Work                                                                                                                                             | Search Space            | Search Strategy                             | Performance Estimation Strategy              | Number of Parameters | Search Time (GPU-days) | Test Error (%) |
|-------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------|---------------------------------------------|----------------------------------------------|----------------------|------------------------|----------------|
| Large-scale Evolution   | [LINK](https://arxiv.org/pdf/1703.01041.pdf)                                                                                                      | Feed-Forward Networks   | Evolutionary Algorithm                      | Naive Training and Validation                | 5.4M                 | 2600                   | 5.4            |
| EAS                     | [LINK](https://arxiv.org/pdf/1707.04873.pdf)                                                                                                      | Feed-Forward Networks   | Reinforcement Learning and Network Morphism | Short Training and Validation                | 23.4M                | 10                     | 4.23           |
| Hierarchical Evolution  | [LINK](https://arxiv.org/pdf/1711.00436.pdf)                                                                                                      | Cell Motifs             | Evolutionary Algorithm                      | Training and Validation on proposed CNN Cell | 15.7M                | 300                    | 3.75           |
| NAS v3                  | [LINK](https://arxiv.org/pdf/1611.01578.pdf)                                                                                                      | Multi-branched Networks | Reinforcement Learning                      | Naive Training and Validation                | 37.4M                | 22400                  | 3.65           |
| PNAS                    | [LINK](https://openaccess.thecvf.com/content_ECCV_2018/papers/Chenxi_Liu_Progressive_Neural_Architecture_ECCV_2018_paper.pdf)                     | Cell Motifs             | Sequential Model-Based Optimization (SMBO)  | Performance Prediction                       | 3.2M                 | 225                    | 3.41           |
| ENAS                    | [LINK](https://arxiv.org/pdf/1802.03268.pdf)                                                                                                      | Cell Motifs             | Reinforcement Learning                      | One Shot                                     | 4.6M                 | 0.45                   | 2.89           |
| ResNet + Regularization | [LINK](https://arxiv.org/pdf/1705.07485.pdf)                                                                                                      | HUMAN BASELINE          | HUMAN BASELINE                              | HUMAN BASELINE                               | 26.2M                | -                      | 2.86           |
| DARTS                   | [LINK](https://arxiv.org/pdf/1806.09055.pdf)                                                                                                      | Cell Motifs             | Gradient-Based Optimization                 | Training and Validation on proposed CNN Cell | 3.4M                 | 4                      | 2.83           |
| NASNet-A                | [LINK](https://openaccess.thecvf.com/content_cvpr_2018/papers/Zoph_Learning_Transferable_Architectures_CVPR_2018_paper.pdf)                       | Cell Motifs             | Reinforcement Learning                      | Naive Training and Validation                | 3.3M                 | 2000                   | 2.65           |
| EENA                    | [LINK](https://openaccess.thecvf.com/content_ICCVW_2019/papers/NeurArch/Zhu_EENA_Efficient_Evolution_of_Neural_Architecture_ICCVW_2019_paper.pdf) | Cell Motifs             | Evolutionary Algorithm                      | Performance Prediction                       | 8.5M                 | 0.65                   | 2.56           |
| Path-Level EAS          | [LINK](https://arxiv.org/pdf/1806.02639.pdf)                                                                                                      | Cell Motifs             | Reinforcement Learning                      | Short Training and Validation                | 14.3M                | 200                    | 2.30           |
| NAO                     | [LINK](http://papers.nips.cc/paper/8007-neural-architecture-optimization.pdf)                                                                     | Cell Motifs             | Gradient-Based Optimization                 | Performance Prediction                       | 128M                 | 200                    | 2.11           |
"
27,pik1989/EDAforHealthcare,Jupyter Notebook,"# EDA for Healthcare in under 30 minutes :)

🔴 Follow this video for the code walkthrough: (Link to be uploaded)

🔴 Download the code from here: https://github.com/pik1989/EDAforHealthcare/**
"
28,johnuberbacher/flutter_medical,Dart,"# flutter_medical

Functioning Doctor/Healthcare Catalog & Scheduling App created using Dart with Flutter. 
Stores and loads data from noSQL Firebase. 

![](https://img.shields.io/badge/Dart-0175C2?style=for-the-badge&logo=dart&logoColor=white) ![](https://img.shields.io/badge/Flutter-02569B?style=for-the-badge&logo=flutter&logoColor=white) ![](https://img.shields.io/badge/firebase-%23039BE5.svg?style=for-the-badge&logo=firebase)


![Screenshot](https://i.imgur.com/ebfJCdt.jpg)

### Installation
```
git clone https://github.com/johnuberbacher/flutter_medical.git

flutter pub get

flutter run
```

### TO-DO

- [x] Create Profile page
- [ ] MyHealth edit profile details
- [ ] Fix Top Doctors ""view more""
- [ ] Firebase Storage for user profile images and office gallery photos

### Meta

John Uberbacher – [johnuberbacher.com](https://johnuberbacher.com)
"
29,google/healthcare-text-annotation,,"# Healthcare Text Annotation Guidelines

Medical annotations capture a structured representation of knowledge stored in unstructured text. The task of mapping text to structured knowledge is done with the end goal of feeding the annotations into a machine learning algorithm that learns how to automatically extract the medical knowledge contained in the text. The guidelines defined below establish an annotation standard to be followed by human annotators. 


The Guidelines cover the annotation methodology, including recommendations for training and organizing the annotations team, as well as specific guidelines and examples for annotating medical entities, modifiers, entity temporal and certainty assessments, and entity relations. 


By sharing this document with the broader community we encourage researchers to follow the standardized approach for data annotation, hence producing high-quality medical text annotations. 



[1. Annotation Methodology](methodology/annotation-methodology.md)


[2. Annotation Guidelines (introduction)](guidelines/annotation-guidelines.md)

[- Defining Entity Categories](guidelines/defining-entity-categories.md)

[- Defining Entity Temporal Assessment](guidelines/defining-entity-temporal-assessment.md)

[- Defining Entity Certainty Assessment](guidelines/defining-entity-certainty-assessment.md)

[- Defining Entity Subject](guidelines/defining-entity-subject.md)

[- Rules for Annotating Temporal Assessment, Certainty Assessment, Subject](guidelines/annotating-rules.md)

[- Defining Entity Relations](guidelines/defining-entity-relations.md)

"
30,XindiWu/Awesome-Machine-Learning-in-Biomedical-Healthcare-Imaging,,"# Awesome Machine Learning in Biomedical(Healthcare) Imaging
> 🌈A list of awesome selected resources towards the application of machine learning in Biomedical/Healthcare Imaging, inspired by [awesome-php](https://github.com/ziadoz/awesome-php).

If you also want to contribute to this list, feel free to send me a pull request or contact me🙌[@XindiWu](mailto:wuxindi0709@gmail.com).


## Table of Contents


## Courses

### Bioimage Analysis

Harvard: [Bio-Image Analysis Course](https://iccb.med.harvard.edu/bio-image-analysis-course)

Stanford: [Introduction to Bioimaging](https://web.stanford.edu/class/ee169/EE_169.html)

CMU: [Bioimage Informatics](https://www.andrew.cmu.edu/course/42-731/index.html)

Caltech: [Data Analysis in the Biological Sciences](http://bebi103.caltech.edu.s3-website-us-east-1.amazonaws.com/2018/)

### Biomedical Image Analysis

University of Nebraska: [Introduction to Biomedical Imaging and Image Analysis](https://www.unmc.edu/radiology/education/biomedical-imaging.html)

Stanford: [Computational Methods for Biomedical Image Analysis and Interpretation](https://canvas.stanford.edu/courses/98045)

Dartmouth College: [Medical Image Visualization and Analysis](https://engineering.dartmouth.edu/academics/courses/engg199-03)

UCLA: [Signal and Image Processing for Biomedicine](https://sa.ucla.edu/ro/Public/SOC/Results/ClassDetailterm_cd=16W&subj_area_cd=PBMED%20%20&crs_catlg_no=0209%20%20%20%20&class_id=825054200&class_no=%20001%20%20)

MIT: [Biomedical Signal and Image Processing](https://ocw.mit.edu/courses/health-sciences-and-technology/hst-582j-biomedical-signal-and-image-processing-spring-2007/index.htm)

NYU: [Biomedical Imaging II](http://bulletin.engineering.nyu.edu/preview_course_nopop.php?catoid=11&coid=27762)

UCSD: [Introduction to biomedical imaging and sensing](http://circuit.ucsd.edu/~zhaowei/ECE187/info.php)

ILLINOIS: [Biomedical imaging](https://ece.illinois.edu/academics/courses/profile/ECE380)

### Medical image analysis

Johns Hopkins: [Applied Medical Image Processing](https://ep.jhu.edu/programs-and-courses/585.703-applied-medical-image-processing)

UCB: [Medical Imaging Signals and Systems](https://www2.eecs.berkeley.edu/Courses/EEC261/)

Brown University: [Medical Image Analysis](http://vision.lems.brown.edu/content/engn-2500-medical-image-analysis)

MIT: [Principles of Medical Imaging](https://ocw.mit.edu/courses/nuclear-engineering/22-058-principles-of-medical-imaging-fall-2002/)

Purdue: [MEDICAL IMAGING DIAGNOSTIC TECHNOLOGIES](https://engineering.purdue.edu/ProEd/courses/medical-imaging-diagnostic-technologies)

University of Michigan Ann Arbor: [MEDICAL IMAGING SYSTEMS](https://bme.umich.edu/course/biomede-516/)

University of Florida: [Introduction to Biomedical Image Analysis and Imaging Informatics](https://www.bme.ufl.edu/labs/yang/pdf/Syllabus_Yang_BME6938-Revise.pdf)

CMU: [Methods In (Bio)Medical Image Analysis](https://www.cs.cmu.edu/~galeotti/methods_course/)






## Conferences

2019 MICCAI: [22nd International Conference on Medical Image Computing and Computer Assisted Intervention](https://www.miccai2019.org/)

2019 AIME: [Artificial Intelligence in Medicine](http://aime19.aimedicine.info/)

2019 AMIA: [AMIA Symposium](https://www.amia.org/amia2019)

2020 RECOMB: [International Conference on Research in Computational Molecular Biology](https://www.recomb2020.org/)

2020 PSB: [Pacific Symposium on Biocomputing](https://psb.stanford.edu/)

2020 ICHI: [IEEE International Conference on Healthcare Informatics](https://hs-heilbronn.de/ichi2020) 

2020 CMIMI: [Conference on Machine Intelligence in Medical Imaging](https://siim.org/page/2019cmimi) 

2019 ISBI: [The IEEE International Symposium on Biomedical Imaging](https://biomedicalimaging.org/2019/)

## Journal Collections

BMC: [Artificial intelligence in biomedical imaging](https://www.biomedcentral.com/collections/ai)

JAMA: [Deep Learning and Artificial Intelligence in Health Care](https://sites.jamanetwork.com/machine-learning/)

PLOS: [Machine Learning in Health and Biomedicine](https://collections.plos.org/mlforhealth)

Nature Medicine: [Digital Medicine](https://www.nature.com/collections/egjifhdcih)

IEEE: [Journal of Biomedical and Health Informatics](https://ieeexplore.ieee.org/xpl/topAccessedArticles.jsp?punumber=6221020)



## Datasets

External Link Collections: https://github.com/beamandrew/medical-data

Kaggle: [Medical Image](https://www.kaggle.com/datasets?search=Medical+image)

Kaggle: [Biology Image](https://www.kaggle.com/datasets?search=biology+image)

[The Cancer Imaging Archive (TCIA)](https://www.cancerimagingarchive.net/)

### Radiology (Ultrasound, Mammographs, X-Ray, CT, MRI, fMRI, etc.)

[Center for Invivo Microscopy (CIVM), Embrionic and Neonatal Mouse (H&E, MR)](http://www.civm.duhs.duke.edu/devatlas/)
[user guide](http://www.civm.duhs.duke.edu/devatlas/UserGuide.pdf)

[Collaborative Informatics and Neuroimaging Suite (COINS)](https://portal.mrn.org/micis/index.php?subsite=dx)

[Alzheimer’s Disease Neuroimaging Initiative (ADNI)](http://adni.loni.ucla.edu/)

[The Open Access Series of Imaging Studies (OASIS)](http://www.oasis-brains.org/)

[Breast Cancer Digital Repository](https://bcdr.eu/)

[DDSM: Digital Database for Screening Mammography](http://marathon.csee.usf.edu/Mammography/Database.html)

[The Mammographic Image Analysis Society (MIAS) mini-database](http://peipa.essex.ac.uk/info/mias.html)

[Mammography Image Databases 100 or more images of mammograms with ground truth](http://marathon.csee.usf.edu/Mammography/Database.html)

[NLM HyperDoc Visible Human Project color, CAT and MRI image samples - over 30 images](http://www.nlm.nih.gov/research/visible/visible_human.html)

[CT Scans for Colon Cancer](https://wiki.cancerimagingarchive.net/display/Public/CT+COLONOGRAPHY#e88604ec5c654f60a897fa77906f88a6)




### Microscopy (Cell, Cytology, Biology, Protein, Molecular, Fluorescence, etc.)

[BDGP images from the FlyExpress database](www.flyexpress.net)

[The UCSB Bio-Segmentation Benchmark dataset](http://www.bioimage.ucsb.edu/research/biosegmentation)

[Pap Smear database](http://labs.fme.aegean.gr/decision/downloads)

[BIICBU Biological Image Repository](http://ome.grc.nia.nih.gov/iicbu2008/)

[RNAi dataset](http://ome.grc.nia.nih.gov/iicbu2008/rnai/index.html)

[Chinese Hamster Ovary cells (CHO) dataset](http://ome.grc.nia.nih.gov/iicbu2008/hela/index.html#cho)

[Locate Endogenus mouse sub-cellular organelles (END) databaset](http://locate.imb.uq.edu.au/)

[2D HeLa dataset (HeLa) datgaset](http://ome.grc.nia.nih.gov/iicbu2008/hela/index.html)

[Allen Brain Atlas](http://www.brain-map.org/)

[1000 Functional Connectomes Project](http://fcon_1000.projects.nitrc.org/)

[The Cell Centered Database (CCDB)]( http://ccdb.ucsd.edu/index.shtm)

[The Encyclopedia of DNA Elements (ENCODE)](http://genome.ucsc.edu/ENCODE/http://www.plosbiology.org/article/info:doi/10.1371/journal.pbio.1001046)

[The Human Protein Atlas](http://www.proteinatlas.org/)

[DRIVE: Digital Retinal Images for Vessel Extraction](http://www.isi.uu.nl/Research/Databases/DRIVE) / [Ground truth](http://www.cs.rug.nl/~imaging/databases/retina_database/retinalfeatures_database.html)

[El Salvador Atlas of Gastrointestinal VideoEndoscopy Images and Videos of his-res of studies taken from Gastrointestinal](http://www.gastrointestinalatlas.com)

### Histology and Histopathology

[The Histology Image Dataset (histologyDS)](http://www.informed.unal.edu.co/histologyDS)

[The Cancer Genome Atlas (TCGA)](http://cancergenome.nih.gov)

[International Cancer Genome Consortium](http://icgc.org) / [Data portal](http://dcc.icgc.org/)

[Stanford Tissue Microarray Database (TMA)](http://tma.im)

[MITOS dataset](http://ipal.cnrs.fr/ICPR2012/)

[DPA’s Whole Slide Imaging Repository](https://digitalpathologyassociation.org/whole-slide-imaging-repository)

[Atlas of bleast Histology](http://www.webmicroscope.net/atlases/breast/brcatlas_start.asp)

[ITK Analysis of Large Histology Datasets](http://www.na-mic.org/Wiki/index.php/ITK_Analysis_of_Large_Histology_Datasets)

[Histology Photo Album](http://www.histology-world.com/photoalbum/thumbnails.php?album=52)

[Slide Library of Virtual pathology, University of Leeds](http://www.virtualpathology.leeds.ac.uk/)

[Tissue Acquisition and Banking Services (TABS) of the NYU Experimental Pathology Core Facilities](http://pathology.med.nyu.edu/research/core-laboratories/tissue-banking)

[Aperio Images](http://images2.aperio.com/)

[HAPS Histology Image Database](http://hapshistology.wikifoundry.com/)

[NIH: chest x-ray datasets](https://nihcc.app.box.com/v/ChestXray-NIHCC)



## Tasks:  (Link: https://paperswithcode.com/area/medical)

Medical Image Segmentation

EEG

Electrocardiography (ECG)

Drug Discovery

Cancer

Sleep Quality

Medical Image Registration

Disease Prediction

Mortality Prediction

Medical Image Generation

Protein Secondary Structure Prediction

Medical Diagnosis

Length-of-stay prediction

Seizure Detection

Skin

Histopathological Image Classification

Mitosis Detection

Computational Phenotyping

Epidemiology

Lung Disease Classification

Diabetic Retinopathy Detection

X-Ray

Medical Relation Extraction

Metal Artifact Reduction

Photoplethysmography (PPG)

Lung Nodule Classification

Pneumonia Detection

Surgical Skills Evaluation

Readmission Prediction

Automatic Sleep Stage Classification

Eeg Decoding

Skull Stripping

Participant Intervention Comparison Outcome Extraction

Patient Outcomes

Medical Report Generation

Knee Osteoarthritis Prediction

Multi-Label Classification Of Biomedical Texts

breast density classification

Medical Super-Resolution

Molecule Interpretation

Mammogram

Cancer Metastasis Detection

Pain Intensity Regression

Electromyography (EMG)

Surgical Gesture Recognition

Protein Function Prediction

epilepsy prediction

Seizure prediction

White Matter Fiber Tractography

Single-cell modeling

Age-Related Macular Degeneration Classification

Sequential Diagnosis

Ecg Risk Stratification

Diabetes Prediction

Magnetic Resonance Fingerprinting

Tomography

Atrial Fibrillation

Malaria Risk Exposure Prediction

Muscular Movement Recognition

Medical Code Prediction

Motion Correction In Multishot Mri

Chemical Reaction Prediction

Ultrasound

## Competitions:

[Grand Challenges in Biomedical Image Analysis](https://grand-challenge.org/)

[The Cancer Imaging Archive (TCIA) Public Access](https://wiki.cancerimagingarchive.net/display/Public/Challenge+competitions)

[Competitions in Kaggle](https://www.kaggle.com/competitions?sortBy=relevance&group=general&search=medical&page=1&pageSize=20&turbolinks%5BrestorationIdentifier%5D=34d9733a-6ecc-4581-a23d-cc00703b91c8)  

[The MICCAI 2014 Machine Learning Challenge](https://competitions.codalab.org/competitions/1471)

[The ISBI 2019 Challenges](https://biomedicalimaging.org/2019/challenges/)

[Medical Segmentation Decathlon](http://medicaldecathlon.com/)




"
31,MIT-LCP/eicu-code,Jupyter Notebook,"# eICU Collaborative Research Database Code Repository [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.1249016.svg)](https://doi.org/10.5281/zenodo.1249016)

This is a repository of code shared by the research community. The repository is intended to be a central hub for sharing, refining, and reusing code used for analysis of the [eICU Collaborative Research Database](http://eicu-crd.mit.edu). To find out more about database, please see: http://eicu-crd.mit.edu

## How to contribute

Our team has worked hard to create and share the eICU Collaborative Research Database. We encourage you to share the code that you use for data processing and analysis. Sharing code helps to make studies reproducible and promotes collaborative research. To contribute, please:

- Fork the repository using the following link: https://github.com/mit-lcp/eicu-code/fork. For a background on GitHub forks, see: https://help.github.com/articles/fork-a-repo/
- Commit your changes to the forked repository.
- Submit a pull request to the [eICU code repository](https://github.com/mit-lcp/eicu-code), using the method described at: https://help.github.com/articles/using-pull-requests/

We encourage users to share concepts they have extracted by writing code which generates a materialized view. These materialized views can then be used by researchers around the world to speed up data extraction.

## License

By committing your code to the [eICU Code Repository](https://github.com/mit-lcp/eicu-code) you agree to release the code under the [MIT License attached to the repository](https://github.com/mit-lcp/eicu-code/blob/master/LICENSE).

## Coding style

Please refer to the [style guide](https://github.com/mit-lcp/eicu-code/blob/master/styleguide.md) for guidelines on formatting your code for the repository.
"
32,shantanu-deshmukh/vhealth-gatsby,TypeScript,"<h1 align=""center"">
  vHealth
</h1>

Open Source web template for a Healthcare Startup. It's built using gatsby but can be easily ported to create-react-app.

## Preview

![Demo vHealth](demo.gif)

[See Live Preview >> ](https://vhealth.openthemes.dev)

## 🚀 Get Up and Running in 5 Minutes

1. **Install the Gatsby CLI.**

   ```bash
   npm install -g gatsby-cli
   ```

2. **Download and install dependencies.**

   Clone this repo and install required dependencies:

   ```bash
   git clone https://github.com/shantanu-deshmukh/vhealth-gatsby.git
   cd vhealth-gatsby
   yarn install
   #or `npm install` if you prefer npm
   ```

3. **Start the site in `develop` mode.**

   Start the site in develop mode and make changes as per your requirement

   ```bash
   gatsby develop
   ```

4. **Deploy**

   Just build and deploy the `public` directory to a service that serves HTML pages.

   ```bash
   gatsby build
   ```

## 🤝 Contributing

Pull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.

## 👨🏻‍💻 Author

[Shantanu Deshmukh](https://shantanudeshmukh.com)

Full-stack developer with experience in building complete Web & mobile apps from scratch.

[Linkedin](https://www.linkedin.com/in/shantanud/)
/ [Twitter](https://twitter.com/askshantanu) / [AngelList](https://angel.co/u/dshantanu)

## 💜 Thanks

Special thanks to [SLAB Design Studio](https://dribbble.com/slabdsgn) for letting me use their design for this template.
"
33,TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials,Python,"# NEW LIST 2023 - 2024: Machine-Learning / Deep-Learning / AI + Web3 -Tutorials

Hi - Thanks for dropping by!<br>
<br>
I will be updating this tutorials site on a <b>daily basis</b> adding all relevant topcis for 2022 - 2024 especially pertaining to **GPU programming, Data Centric AI, Emerging topics like Sustainable AI with Web3AI.js (DeFI, DAO, NFT) and much more**.<br>

**NOTE: All these tutorials are supported and accelerated on NVIDIA GPUs**
<br>
More importantly the applications of ML/DL/AI into industry areas such as Transportation, Medicine/Healthcare etc. will be something I'll watch with keen interest and would love to share the same with you.
<br>
Finally, it is **YOUR** help I will seek to make it more useful and less boring, so please do suggest/comment/contribute!
<p align=""center"">
  <img src=""https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials/blob/master/images/DK.png"">
</p>

## Index

* [deep-learning](#deep-learning)
   * [UBER | Pyro](#uber-pyro-probabalistic-tutorials)
   * [Netflix | VectorFlow](#netflix-vectorflow-tutorials)
   * [PyTorch](#pytorch-tutorials)
   * [tensorflow](#tensor-flow-tutorials)
   * [theano](#theano-tutorials)
   * [keras](#keras-tutorials)
   * [caffe](#deep-learning-misc)
   * [Torch/Lua]()
   * [MXNET]()
   
* [scikit-learn](#scikit-learn)
* [statistical-inference-scipy](#statistical-inference-scipy)
* [pandas](#pandas)
* [matplotlib](#matplotlib)
* [numpy](#numpy)
* [python-data](#python-data)
* [kaggle-and-business-analyses](#kaggle-and-business-analyses)
* [spark](#spark)
* [mapreduce-python](#mapreduce-python)
* [amazon web services](#aws)
* [command lines](#commands)
* [misc](#misc)
* [notebook-installation](#notebook-installation)
* [Curated list of Deep Learning / AI blogs](#curated-list-of-deeplearning-blogs)
* [credits](#credits)
* [contributing](#contributing)
* [contact-info](#contact-info)
* [license](#license)

## deep-learning

IPython Notebook(s) and other programming tools such as Torch/Lua/D lang in demonstrating deep learning functionality.

### uber-pyro-probabalistic-tutorials
<p align=""center"">
  <img src=""https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials/blob/master/images/pyro.png"">
</p>

Additional PyRo tutorials:

* [pyro-examples/full examples](http://pyro.ai/examples/)
* [pyro-examples/Variational Autoencoders](http://pyro.ai/examples/vae.html)
* [pyro-examples/Bayesian Regression](http://pyro.ai/examples/bayesian_regression.html)
* [pyro-examples/Deep Markov Model](http://pyro.ai/examples/dmm.html)
* [pyro-examples/AIR(Attend Infer Repeat)](http://pyro.ai/examples/air.html)
* [pyro-examples/Semi-Supervised VE](http://pyro.ai/examples/ss-vae.html)
* [pyro-examples/GMM](http://pyro.ai/examples/gmm.html)
* [pyro-examples/Gaussian Process](http://pyro.ai/examples/gp.html)
* [pyro-examples/Bayesian Optimization](http://pyro.ai/examples/bo.html)
* [Full Pyro Code](https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials/tree/master/deep-learning/UBER-pyro)



### netflix-vectorflow-tutorials
<p align=""center"">
  <img src=""https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials/blob/master/images/VectorFlow.png"">
</p>

* [MNIST Example, running with Dlang](https://github.com/Netflix/vectorflow/tree/master/examples)

### pytorch-tutorials
<p align=""center"">
  <img src=""https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials/blob/master/images/PyTorch.png"">
</p>

| Level | Description |
|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [Beginners/Zakizhou](https://github.com/pytorch/tutorials/tree/master/beginner_source) | Learning the basics of PyTorch from Facebook. |
| [Intermedia/Quanvuong](https://github.com/pytorch/tutorials/tree/master/intermediate_source) | Learning the intermediate stuff about PyTorch of from Facebook. |
| [Advanced/Chsasank](https://github.com/pytorch/tutorials/tree/master/advanced_source) | Learning the advanced stuff about PyTorch of from Facebook. |
| [Learning PyTorch by Examples - Numpy, Tensors and Autograd](https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials/tree/master/pytorch) | At its core, PyTorch provides two main features an n-dimensional Tensor, similar to numpy but can run on GPUs AND automatic differentiation for building and training neural networks. |
| [PyTorch - Getting to know autograd.Variable, Gradient, Neural Network](https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials/blob/master/pytorch/PyTorch%20NN%20Basics%20-%20Autograd%20Gradient%20Neural%20Network%20Loss%20Backprop.ipynb) | Here we start with ultimate basics of Tensors, wrap a Tensor with Variable module, play with nn.Module and implement forward and backward function. |


### tensor-flow-tutorials
<br/>
<p align=""center"">
  <img src=""https://avatars0.githubusercontent.com/u/15658638?v=3&s=100"">
</p>
Additional TensorFlow tutorials:

* [pkmital/tensorflow_tutorials](https://github.com/pkmital/tensorflow_tutorials)
* [nlintz/TensorFlow-Tutorials](https://github.com/nlintz/TensorFlow-Tutorials)
* [alrojo/tensorflow-tutorial](https://github.com/alrojo/tensorflow-tutorial)
* [BinRoot/TensorFlow-Book](https://github.com/BinRoot/TensorFlow-Book)

| Notebook | Description |
|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [tsf-basics](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/1_intro/basic_operations.ipynb) | Learn basic operations in TensorFlow, a library for various kinds of perceptual and language understanding tasks from Google. |
| [tsf-linear](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/2_basic_classifiers/linear_regression.ipynb) | Implement linear regression in TensorFlow. |
| [tsf-logistic](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/2_basic_classifiers/logistic_regression.ipynb) | Implement logistic regression in TensorFlow. |
| [tsf-nn](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/2_basic_classifiers/nearest_neighbor.ipynb) | Implement nearest neighboars in TensorFlow. |
| [tsf-alex](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/alexnet.ipynb) | Implement AlexNet in TensorFlow. |
| [tsf-cnn](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/convolutional_network.ipynb) | Implement convolutional neural networks in TensorFlow. |
| [tsf-mlp](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/multilayer_perceptron.ipynb) | Implement multilayer perceptrons in TensorFlow. |
| [tsf-rnn](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/recurrent_network.ipynb) | Implement recurrent neural networks in TensorFlow. |
| [tsf-gpu](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/4_multi_gpu/multigpu_basics.ipynb) | Learn about basic multi-GPU computation in TensorFlow. |
| [tsf-gviz](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/5_ui/graph_visualization.ipynb) | Learn about graph visualization in TensorFlow. |
| [tsf-lviz](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/5_ui/loss_visualization.ipynb) | Learn about loss visualization in TensorFlow. |

### tensor-flow-exercises

| Notebook | Description |
|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [tsf-not-mnist](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-exercises/1_notmnist.ipynb) | Learn simple data curation by creating a pickle with formatted datasets for training, development and testing in TensorFlow. |
| [tsf-fully-connected](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-exercises/2_fullyconnected.ipynb) | Progressively train deeper and more accurate models using logistic regression and neural networks in TensorFlow. |
| [tsf-regularization](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-exercises/3_regularization.ipynb) | Explore regularization techniques by training fully connected networks to classify notMNIST characters in TensorFlow. |
| [tsf-convolutions](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-exercises/4_convolutions.ipynb) | Create convolutional neural networks in TensorFlow. |
| [tsf-word2vec](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-exercises/5_word2vec.ipynb) | Train a skip-gram model over Text8 data in TensorFlow. |
| [tsf-lstm](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-exercises/6_lstm.ipynb) | Train a LSTM character model over Text8 data in TensorFlow. |

<br/>
<p align=""center"">
  <img src=""http://www.deeplearning.net/software/theano/_static/theano_logo_allblue_200x46.png"">
</p>

### theano-tutorials

| Notebook | Description |
|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [theano-intro](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/theano-tutorial/intro_theano/intro_theano.ipynb) | Intro to Theano, which allows you to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently. It can use GPUs and perform efficient symbolic differentiation. |
| [theano-scan](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/theano-tutorial/scan_tutorial/scan_tutorial.ipynb) | Learn scans, a mechanism to perform loops in a Theano graph. |
| [theano-logistic](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/theano-tutorial/intro_theano/logistic_regression.ipynb) | Implement logistic regression in Theano. |
| [theano-rnn](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/theano-tutorial/rnn_tutorial/simple_rnn.ipynb) | Implement recurrent neural networks in Theano. |
| [theano-mlp](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/theano-tutorial/theano_mlp/theano_mlp.ipynb) | Implement multilayer perceptrons in Theano. |

<br/>
<p align=""center"">
  <img src=""http://i.imgur.com/L45Q8c2.jpg"">
</p>

### keras-tutorials

| Notebook | Description |
|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| keras | Keras is an open source neural network library written in Python. It is capable of running on top of either Tensorflow or Theano. |
| [setup](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/README.md) | Learn about the tutorial goals and how to set up your Keras environment. |
| [intro-deep-learning-ann](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/1.%20ANN/1.1%20Introduction%20-%20Deep%20Learning%20and%20ANN.ipynb) | Get an intro to deep learning with Keras and Artificial Neural Networks (ANN). |
| [Perceptrons and Adaline](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/1.%20ANN/1.1.1%20Perceptron%20and%20Adaline.ipynb) | Implement Peceptron and adaptive linear neurons. |
| [MLP and MNIST Data](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/1.%20ANN/1.1.2%20MLP%20and%20MNIST.ipynb) | Classifying handwritten digits,implement MLP, train and debug ANN |
| [theano](http://nbviewer.ipython.org/github/leriomaggio/deep-learning-keras-tensorflow/blob/master/1.2%20Introduction%20-%20Theano.ipynb) | Learn about Theano by working with weights matrices and gradients. |
| [keras-otto](http://nbviewer.ipython.org/github/leriomaggio/deep-learning-keras-tensorflow/blob/master/1.3%20Introduction%20-%20Keras.ipynb) | Learn about Keras by looking at the Kaggle Otto challenge. |
| [ann-mnist](http://nbviewer.ipython.org/github/leriomaggio/deep-learning-keras-tensorflow/blob/master/1.4%20(Extra)%20A%20Simple%20Implementation%20of%20ANN%20for%20MNIST.ipynb) | Review a simple implementation of ANN for MNIST using Keras. |
| [conv-nets](http://nbviewer.ipython.org/github/leriomaggio/deep-learning-keras-tensorflow/blob/master/2.1%20Supervised%20Learning%20-%20ConvNets.ipynb) | Learn about Convolutional Neural Networks (CNNs) with Keras. |
| [conv-net-1](http://nbviewer.ipython.org/github/leriomaggio/deep-learning-keras-tensorflow/blob/master/2.2.1%20Supervised%20Learning%20-%20ConvNet%20HandsOn%20Part%20I.ipynb) | Recognize handwritten digits from MNIST using Keras - Part 1. |
| [conv-net-2](http://nbviewer.ipython.org/github/leriomaggio/deep-learning-keras-tensorflow/blob/master/2.2.2%20Supervised%20Learning%20-%20ConvNet%20HandsOn%20Part%20II.ipynb) | Recognize handwritten digits from MNIST using Keras - Part 2. |
| [keras-models](http://nbviewer.ipython.org/github/leriomaggio/deep-learning-keras-tensorflow/blob/master/2.3%20Supervised%20Learning%20-%20Famous%20Models%20with%20Keras.ipynb) | Use pre-trained models such as VGG16, VGG19, ResNet50, and Inception v3 with Keras. |
| [auto-encoders](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/6.%20AutoEncoders%20and%20Embeddings/6.1.%20AutoEncoders%20and%20Embeddings.ipynb) | Learn about Autoencoders with Keras. |
| [rnn-lstm](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/7.%20Recurrent%20Neural%20Networks/7.1%20RNN%20and%20LSTM.ipynb) | Learn about Recurrent Neural Networks (RNNs) with Keras. |
| [lstm-sentence-gen](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/7.%20Recurrent%20Neural%20Networks/7.2%20LSTM%20for%20Sentence%20Generation.ipynb) |  Learn about RNNs using Long Short Term Memory (LSTM) networks with Keras. |
| [nlp-deep-learning](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/6.%20AutoEncoders%20and%20Embeddings/6.2%20NLP%20and%20Deep%20Learning.ipynb) | Learn about NLP using ANN (Artificial Neural Networks. |
| [hyperparamter-tuning](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/5.%20HyperParameter%20Tuning%20and%20Transfer%20Learning/5.1%20HyperParameter%20Tuning.ipynb) | Hyperparamters tuning using keras-wrapper.scikit-learn |

### deep-learning-misc

| Notebook | Description |
|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [deep-dream](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/deep-dream/dream.ipynb) | Caffe-based computer vision program which uses a convolutional neural network to find and enhance patterns in images. |

<br/>
<p align=""center"">
  <img src=""https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/scikitlearn.png"">
</p>

## scikit-learn

IPython Notebook(s) demonstrating scikit-learn functionality.

| Notebook | Description |
|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [intro](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-intro.ipynb) | Intro notebook to scikit-learn.  Scikit-learn adds Python support for large, multi-dimensional arrays and matrices, along with a large library of high-level mathematical functions to operate on these arrays. |
| [knn](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-intro.ipynb#K-Nearest-Neighbors-Classifier) | Implement k-nearest neighbors in scikit-learn. |
| [linear-reg](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-linear-reg.ipynb) | Implement linear regression in scikit-learn. |
| [svm](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-svm.ipynb) | Implement support vector machine classifiers with and without kernels in scikit-learn. |
| [random-forest](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-random-forest.ipynb) | Implement random forest classifiers and regressors in scikit-learn. |
| [k-means](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-k-means.ipynb) | Implement k-means clustering in scikit-learn. |
| [pca](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-pca.ipynb) | Implement principal component analysis in scikit-learn. |
| [gmm](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-gmm.ipynb) | Implement Gaussian mixture models in scikit-learn. |
| [validation](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-validation.ipynb) | Implement validation and model selection in scikit-learn. |

<br/>
<p align=""center"">
  <img src=""https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/scipy.png"">
</p>

## statistical-inference-scipy

IPython Notebook(s) demonstrating statistical inference with SciPy functionality.

| Notebook | Description |
|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| scipy | SciPy is a collection of mathematical algorithms and convenience functions built on the Numpy extension of Python. It adds significant power to the interactive Python session by providing the user with high-level commands and classes for manipulating and visualizing data. |
| [effect-size](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scipy/effect_size.ipynb) | Explore statistics that quantify effect size by analyzing the difference in height between men and women.  Uses data from the Behavioral Risk Factor Surveillance System (BRFSS) to estimate the mean and standard deviation of height for adult women and men in the United States. |
| [sampling](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scipy/sampling.ipynb) | Explore random sampling by analyzing the average weight of men and women in the United States using BRFSS data. |
| [hypothesis](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scipy/hypothesis.ipynb) | Explore hypothesis testing by analyzing the difference of first-born babies compared with others. |

<br/>
<p align=""center"">
  <img src=""https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/pandas.png"">
</p>

## pandas

IPython Notebook(s) demonstrating pandas functionality.

| Notebook | Description |
|--------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [pandas](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/pandas.ipynb) | Software library written for data manipulation and analysis in Python. Offers data structures and operations for manipulating numerical tables and time series. |
| [github-data-wrangling](https://github.com/donnemartin/viz/blob/master/githubstats/data_wrangling.ipynb) | Learn how to load, clean, merge, and feature engineer by analyzing GitHub data from the [`Viz`](https://github.com/donnemartin/viz) repo. |
| [Introduction-to-Pandas](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.00-Introduction-to-Pandas.ipynb) | Introduction to Pandas. |
| [Introducing-Pandas-Objects](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.01-Introducing-Pandas-Objects.ipynb) | Learn about Pandas objects. |
| [Data Indexing and Selection](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.02-Data-Indexing-and-Selection.ipynb) | Learn about data indexing and selection in Pandas. |
| [Operations-in-Pandas](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.03-Operations-in-Pandas.ipynb) | Learn about operating on data in Pandas. |
| [Missing-Values](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.04-Missing-Values.ipynb) | Learn about handling missing data in Pandas. |
| [Hierarchical-Indexing](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.05-Hierarchical-Indexing.ipynb) | Learn about hierarchical indexing in Pandas. |
| [Concat-And-Append](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.06-Concat-And-Append.ipynb) | Learn about combining datasets: concat and append in Pandas. |
| [Merge-and-Join](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.07-Merge-and-Join.ipynb) | Learn about combining datasets: merge and join in Pandas. |
| [Aggregation-and-Grouping](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.08-Aggregation-and-Grouping.ipynb) | Learn about aggregation and grouping in Pandas. |
| [Pivot-Tables](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.09-Pivot-Tables.ipynb) | Learn about pivot tables in Pandas. |
| [Working-With-Strings](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.10-Working-With-Strings.ipynb) | Learn about vectorized string operations in Pandas. |
| [Working-with-Time-Series](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.11-Working-with-Time-Series.ipynb) | Learn about working with time series in pandas. |
| [Performance-Eval-and-Query](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.12-Performance-Eval-and-Query.ipynb) | Learn about high-performance Pandas: eval() and query() in Pandas. |

<br/>
<p align=""center"">
  <img src=""https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/matplotlib.png"">
</p>

## matplotlib

IPython Notebook(s) demonstrating matplotlib functionality.

| Notebook | Description |
|-----------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------|
| [matplotlib](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/matplotlib.ipynb) | Python 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms. |
| [matplotlib-applied](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/matplotlib-applied.ipynb) | Apply matplotlib visualizations to Kaggle competitions for exploratory data analysis.  Learn how to create bar plots, histograms, subplot2grid, normalized plots, scatter plots, subplots, and kernel density estimation plots. |
| [Introduction-To-Matplotlib](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.00-Introduction-To-Matplotlib.ipynb) | Introduction to Matplotlib. |
| [Simple-Line-Plots](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.01-Simple-Line-Plots.ipynb) | Learn about simple line plots in Matplotlib. |
| [Simple-Scatter-Plots](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.02-Simple-Scatter-Plots.ipynb) | Learn about simple scatter plots in Matplotlib. |
| [Errorbars.ipynb](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.03-Errorbars.ipynb) | Learn about visualizing errors in Matplotlib. |
| [Density-and-Contour-Plots](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.04-Density-and-Contour-Plots.ipynb) | Learn about density and contour plots in Matplotlib. |
| [Histograms-and-Binnings](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.05-Histograms-and-Binnings.ipynb) | Learn about histograms, binnings, and density in Matplotlib. |
| [Customizing-Legends](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.06-Customizing-Legends.ipynb) | Learn about customizing plot legends in Matplotlib. |
| [Customizing-Colorbars](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.07-Customizing-Colorbars.ipynb) | Learn about customizing colorbars in Matplotlib. |
| [Multiple-Subplots](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.08-Multiple-Subplots.ipynb) | Learn about multiple subplots in Matplotlib. |
| [Text-and-Annotation](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.09-Text-and-Annotation.ipynb) | Learn about text and annotation in Matplotlib. |
| [Customizing-Ticks](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.10-Customizing-Ticks.ipynb) | Learn about customizing ticks in Matplotlib. |
| [Settings-and-Stylesheets](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.11-Settings-and-Stylesheets.ipynb) | Learn about customizing Matplotlib: configurations and stylesheets. |
| [Three-Dimensional-Plotting](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.12-Three-Dimensional-Plotting.ipynb) | Learn about three-dimensional plotting in Matplotlib. |
| [Geographic-Data-With-Basemap](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.13-Geographic-Data-With-Basemap.ipynb) | Learn about geographic data with basemap in Matplotlib. |
| [Visualization-With-Seaborn](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.14-Visualization-With-Seaborn.ipynb) | Learn about visualization with Seaborn. |

<br/>
<p align=""center"">
  <img src=""https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/numpy.png"">
</p>

## numpy

IPython Notebook(s) demonstrating NumPy functionality.

| Notebook | Description |
|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [numpy](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/numpy.ipynb) | Adds Python support for large, multi-dimensional arrays and matrices, along with a large library of high-level mathematical functions to operate on these arrays. |
| [Introduction-to-NumPy](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.00-Introduction-to-NumPy.ipynb) | Introduction to NumPy. |
| [Understanding-Data-Types](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.01-Understanding-Data-Types.ipynb) | Learn about data types in Python. |
| [The-Basics-Of-NumPy-Arrays](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.02-The-Basics-Of-NumPy-Arrays.ipynb) | Learn about the basics of NumPy arrays. |
| [Computation-on-arrays-ufuncs](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.03-Computation-on-arrays-ufuncs.ipynb) | Learn about computations on NumPy arrays: universal functions. |
| [Computation-on-arrays-aggregates](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.04-Computation-on-arrays-aggregates.ipynb) | Learn about aggregations: min, max, and everything in between in NumPy. |
| [Computation-on-arrays-broadcasting](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.05-Computation-on-arrays-broadcasting.ipynb) | Learn about computation on arrays: broadcasting in NumPy. |
| [Boolean-Arrays-and-Masks](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.06-Boolean-Arrays-and-Masks.ipynb) | Learn about comparisons, masks, and boolean logic in NumPy. |
| [Fancy-Indexing](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.07-Fancy-Indexing.ipynb) | Learn about fancy indexing in NumPy. |
| [Sorting](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.08-Sorting.ipynb) | Learn about sorting arrays in NumPy. |
| [Structured-Data-NumPy](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.09-Structured-Data-NumPy.ipynb) | Learn about structured data: NumPy's structured arrays. |

<br/>
<p align=""center"">
  <img src=""https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/python.png"">
</p>

## python-data

IPython Notebook(s) demonstrating Python functionality geared towards data analysis.

| Notebook | Description |
|-----------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------|
| [data structures](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/python-data/structs.ipynb) | Learn Python basics with tuples, lists, dicts, sets. |
| [data structure utilities](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/python-data/structs_utils.ipynb) | Learn Python operations such as slice, range, xrange, bisect, sort, sorted, reversed, enumerate, zip, list comprehensions. |
| [functions](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/python-data/functions.ipynb) | Learn about more advanced Python features: Functions as objects, lambda functions, closures, *args, **kwargs currying, generators, generator expressions, itertools. |
| [datetime](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/python-data/datetime.ipynb) | Learn how to work with Python dates and times: datetime, strftime, strptime, timedelta. |
| [logging](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/python-data/logs.ipynb) | Learn about Python logging with RotatingFileHandler and TimedRotatingFileHandler. |
| [pdb](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/python-data/pdb.ipynb) | Learn how to debug in Python with the interactive source code debugger. |
| [unit tests](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/python-data/unit_tests.ipynb) | Learn how to test in Python with Nose unit tests. |

<br/>
<p align=""center"">
  <img src=""https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/kaggle.png"">
</p>

## kaggle-and-business-analyses

IPython Notebook(s) used in [kaggle](https://www.kaggle.com/) competitions and business analyses.

| Notebook | Description |
|-------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------|
| [titanic](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/kaggle/titanic.ipynb) | Predict survival on the Titanic.  Learn data cleaning, exploratory data analysis, and machine learning. |
| [churn-analysis](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/analyses/churn.ipynb) | Predict customer churn.  Exercise logistic regression, gradient boosting classifers, support vector machines, random forests, and k-nearest-neighbors.  Includes discussions of confusion matrices, ROC plots, feature importances, prediction probabilities, and calibration/descrimination.|

<br/>
<p align=""center"">
  <img src=""https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/spark.png"">
</p>

## spark

IPython Notebook(s) demonstrating spark and HDFS functionality.

| Notebook | Description |
|--------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------|
| [spark](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/spark/spark.ipynb) | In-memory cluster computing framework, up to 100 times faster for certain applications and is well suited for machine learning algorithms. |
| [hdfs](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/spark/hdfs.ipynb) | Reliably stores very large files across machines in a large cluster. |

<br/>
<p align=""center"">
  <img src=""https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/mrjob.png"">
</p>

## mapreduce-python

IPython Notebook(s) demonstrating Hadoop MapReduce with mrjob functionality.

| Notebook | Description |
|--------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------|
| [mapreduce-python](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/mapreduce/mapreduce-python.ipynb) | Runs MapReduce jobs in Python, executing jobs locally or on Hadoop clusters. Demonstrates Hadoop Streaming in Python code with unit test and [mrjob](https://github.com/Yelp/mrjob) config file to analyze Amazon S3 bucket logs on Elastic MapReduce.  [Disco](https://github.com/discoproject/disco/) is another python-based alternative.|

<br/>

<p align=""center"">
  <img src=""https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/aws.png"">
</p>

## aws

IPython Notebook(s) demonstrating Amazon Web Services (AWS) and AWS tools functionality.


Also check out:

* [SAWS](https://github.com/donnemartin/saws): A Supercharged AWS command line interface (CLI).
* [Awesome AWS](https://github.com/donnemartin/awesome-aws): A curated list of libraries, open source repos, guides, blogs, and other resources.

| Notebook | Description |
|------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [boto](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/aws/aws.ipynb#Boto) | Official AWS SDK for Python. |
| [s3cmd](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/aws/aws.ipynb#s3cmd) | Interacts with S3 through the command line. |
| [s3distcp](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/aws/aws.ipynb#s3distcp) | Combines smaller files and aggregates them together by taking in a pattern and target file.  S3DistCp can also be used to transfer large volumes of data from S3 to your Hadoop cluster. |
| [s3-parallel-put](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/aws/aws.ipynb#s3-parallel-put) | Uploads multiple files to S3 in parallel. |
| [redshift](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/aws/aws.ipynb#redshift) | Acts as a fast data warehouse built on top of technology from massive parallel processing (MPP). |
| [kinesis](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/aws/aws.ipynb#kinesis) | Streams data in real time with the ability to process thousands of data streams per second. |
| [lambda](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/aws/aws.ipynb#lambda) | Runs code in response to events, automatically managing compute resources. |

<br/>
<p align=""center"">
  <img src=""https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/commands.png"">
</p>

## commands

IPython Notebook(s) demonstrating various command lines for Linux, Git, etc.

| Notebook | Description |
|--------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [linux](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/commands/linux.ipynb) | Unix-like and mostly POSIX-compliant computer operating system.  Disk usage, splitting files, grep, sed, curl, viewing running processes, terminal syntax highlighting, and Vim.|
| [anaconda](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/commands/misc.ipynb#anaconda) | Distribution of the Python programming language for large-scale data processing, predictive analytics, and scientific computing, that aims to simplify package management and deployment. |
| [ipython notebook](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/commands/misc.ipynb#ipython-notebook) | Web-based interactive computational environment where you can combine code execution, text, mathematics, plots and rich media into a single document. |
| [git](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/commands/misc.ipynb#git) | Distributed revision control system with an emphasis on speed, data integrity, and support for distributed, non-linear workflows. |
| [ruby](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/commands/misc.ipynb#ruby) | Used to interact with the AWS command line and for Jekyll, a blog framework that can be hosted on GitHub Pages. |
| [jekyll](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/commands/misc.ipynb#jekyll) | Simple, blog-aware, static site generator for personal, project, or organization sites.  Renders Markdown or Textile and Liquid templates, and produces a complete, static website ready to be served by Apache HTTP Server, Nginx or another web server. |
| [pelican](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/commands/misc.ipynb#pelican) | Python-based alternative to Jekyll. |
| [django](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/commands/misc.ipynb#django) | High-level Python Web framework that encourages rapid development and clean, pragmatic design. It can be useful to share reports/analyses and for blogging. Lighter-weight alternatives include [Pyramid](https://github.com/Pylons/pyramid), [Flask](https://github.com/pallets/flask), [Tornado](https://github.com/tornadoweb/tornado), and [Bottle](https://github.com/bottlepy/bottle).

## misc

IPython Notebook(s) demonstrating miscellaneous functionality.

| Notebook | Description |
|--------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [regex](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/misc/regex.ipynb) | Regular expression cheat sheet useful in data wrangling.|
[algorithmia](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/misc/Algorithmia.ipynb) | Algorithmia is a marketplace for algorithms. This notebook showcases 4 different algorithms: Face Detection, Content Summarizer, Latent Dirichlet Allocation and Optical Character Recognition.|

## notebook-installation

### anaconda

Anaconda is a free distribution of the Python programming language for large-scale data processing, predictive analytics, and scientific computing that aims to simplify package management and deployment.

Follow instructions to install [Anaconda](https://docs.continuum.io/anaconda/install) or the more lightweight [miniconda](http://conda.pydata.org/miniconda.html).

### dev-setup

For detailed instructions, scripts, and tools to set up your development environment for data analysis, check out the [dev-setup](https://github.com/donnemartin/dev-setup) repo.

### running-notebooks

Note: If you intend to learn the hard way (preferred method)then I'd strongly advice to write as much code as you can yourself and not just run pre-written code. If you still want to test it, then do the following: 

To view interactive content or to modify elements within the IPython notebooks, you must first clone or download the repository then run the notebook.  More information on IPython Notebooks can be found [here.](http://ipython.org/notebook.html)

    $ git clone https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials.git
    $ cd Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials
    $ jupyter notebook
    

Notebooks tested with Python 3.7+

## curated-list-of-deeplearning-blogs

* A Blog From a Human-engineer-being http://www.erogol.com/ [(RSS)](http://www.erogol.com/feed/)
* Aakash Japi http://aakashjapi.com/ [(RSS)](http://logicx24.github.io/feed.xml)
* Adit Deshpande https://adeshpande3.github.io/ [(RSS)](https://adeshpande3.github.io/adeshpande3.github.io/feed.xml)
* Advanced Analytics & R http://advanceddataanalytics.net/ [(RSS)](http://advanceddataanalytics.net/feed/)
* Adventures in Data Land http://blog.smola.org [(RSS)](http://blog.smola.org/rss)
* Agile Data Science http://blog.sense.io/ [(RSS)](http://blog.sense.io/rss/)
* Ahmed El Deeb https://medium.com/@D33B [(RSS)](https://medium.com/feed/@D33B)
* Airbnb Data blog http://nerds.airbnb.com/data/ [(RSS)](http://nerds.airbnb.com/feed/)
* Alex Castrounis | InnoArchiTech http://www.innoarchitech.com/ [(RSS)](http://www.innoarchitech.com/feed.xml)
* Alex Perrier http://alexperrier.github.io/ [(RSS)](http://alexperrier.github.io/feed.xml)
* Algobeans | Data Analytics Tutorials & Experiments for the Layman https://algobeans.com [(RSS)](https://algobeans.com/feed/)
* Amazon AWS AI Blog https://aws.amazon.com/blogs/ai/ [(RSS)](https://aws.amazon.com/blogs/amazon-ai/feed/)
* Analytics Vidhya http://www.analyticsvidhya.com/blog/ [(RSS)](http://feeds.feedburner.com/AnalyticsVidhya)
* Analytics and Visualization in Big Data @ Sicara https://blog.sicara.com [(RSS)](https://blog.sicara.com/feed)
* Andreas Müller http://peekaboo-vision.blogspot.com/ [(RSS)](http://peekaboo-vision.blogspot.com/atom.xml)
* Andrej Karpathy blog http://karpathy.github.io/ [(RSS)](http://karpathy.github.io/feed.xml)
* Andrew Brooks http://brooksandrew.github.io/simpleblog/ [(RSS)](http://brooksandrew.github.io/simpleblog/feed.xml)
* Andrey Kurenkov http://www.andreykurenkov.com/writing/ [(RSS)](http://www.andreykurenkov.com/writing/feed.xml/)
* Anton Lebedevich's Blog http://mabrek.github.io/ [(RSS)](http://mabrek.github.io/feed.xml)
* Arthur Juliani https://medium.com/@awjuliani [(RSS)](https://medium.com/feed/@awjuliani)
* Audun M. Øygard http://www.auduno.com/ [(RSS)](http://auduno.tumblr.com/rss)
* Avi Singh https://avisingh599.github.io/ [(RSS)](http://avisingh599.github.io/feed.xml)
* Beautiful Data http://beautifuldata.net/ [(RSS)](http://beautifuldata.net/feed/)
* Beckerfuffle http://mdbecker.github.io/ [(RSS)](http://mdbecker.github.io/atom.xml)
* Becoming A Data Scientist http://www.becomingadatascientist.com/ [(RSS)](http://www.becomingadatascientist.com/feed/)
* Ben Bolte's Blog http://benjaminbolte.com/ml/ [(RSS)](http://benjaminbolte.com/ml/)
* Ben Frederickson http://www.benfrederickson.com/blog/ [(RSS)](http://www.benfrederickson.com/atom.xml)
* Berkeley AI Research http://bair.berkeley.edu/blog/ [(RSS)](http://bair.berkeley.edu/blog/feed.xml)
* Big-Ish Data http://bigishdata.com/ [(RSS)](http://bigishdata.com/feed/)
* Blog on neural networks http://yerevann.github.io/ [(RSS)](http://yerevann.github.io/atom.xml)
* Blogistic RegressionAbout Projects http://d10genes.github.io/blog/ [(RSS)](http://d10genes.github.io/blog/feed.xml)
* blogR | R tips and tricks from a scientist https://drsimonj.svbtle.com/ [(RSS)](https://drsimonj.svbtle.com/)
* Brain of mat kelcey http://matpalm.com/blog/ [(RSS)](http://matpalm.com/blog/feed)
* Brilliantly wrong thoughts on science and programming https://arogozhnikov.github.io/ [(RSS)](http://arogozhnikov.github.io/feed.xml)
* Bugra Akyildiz http://bugra.github.io/ [(RSS)](http://bugra.github.io/feeds/all.atom.xml)
* Building Babylon https://building-babylon.net/ [(RSS)](http://building-babylon.net/feed/)
* Carl Shan http://carlshan.com/ [(RSS)](http://feeds.feedburner.com/carlshan)
* Chris Stucchio https://www.chrisstucchio.com/blog/index.html [(RSS)](http://www.chrisstucchio.com/blog/atom.xml)
* Christophe Bourguignat https://medium.com/@chris_bour [(RSS)](https://medium.com/feed/@chris_bour)
* Christopher Nguyen https://medium.com/@ctn [(RSS)](https://medium.com/feed/@ctn)
* Cloudera Data Science Posts http://blog.cloudera.com/blog/category/data-science/ [(RSS)](http://blog.cloudera.com/blog/category/data-science/feed/)
* colah's blog http://colah.github.io/archive.html [(RSS)](http://colah.github.io/rss.xml)
* Cortana Intelligence and Machine Learning Blog https://blogs.technet.microsoft.com/machinelearning/ [(RSS)](http://blogs.technet.com/b/machinelearning/rss.aspx)
* Daniel Forsyth http://www.danielforsyth.me/ [(RSS)](http://www.danielforsyth.me/rss/)
* Daniel Homola http://danielhomola.com/category/blog/ [(RSS)](http://danielhomola.com/feed/)
* Daniel Nee http://danielnee.com [(RSS)](http://danielnee.com/?feed=rss2)
* Data Based Inventions http://datalab.lu/ [(RSS)](http://datalab.lu/atom.xml)
* Data Blogger https://www.data-blogger.com/ [(RSS)](https://www.data-blogger.com/feed/)
* Data Labs http://blog.insightdatalabs.com/ [(RSS)](http://blog.insightdatalabs.com/rss/)
* Data Meets Media http://datameetsmedia.com/ [(RSS)](http://datameetsmedia.com/feed/)
* Data Miners Blog http://blog.data-miners.com/ [(RSS)](http://blog.data-miners.com/feeds/posts/default?alt=rss)
* Data Mining Research http://www.dataminingblog.com/ [(RSS)](http://feeds.feedburner.com/dataminingblog)
* Data Mining: Text Mining, Visualization and Social Media http://datamining.typepad.com/data_mining/ [(RSS)](http://datamining.typepad.com/data_mining/atom.xml)
* Data Piques http://blog.ethanrosenthal.com/ [(RSS)](http://blog.ethanrosenthal.com/feeds/all.atom.xml)
* Data School http://www.dataschool.io/ [(RSS)](http://www.dataschool.io/rss/)
* Data Science 101 http://101.datascience.community/ [(RSS)](http://101.datascience.community/feed/)
* Data Science @ Facebook https://research.facebook.com/blog/datascience/ [(RSS)](https://research.facebook.com/blog/datascience/)
* Data Science Insights http://www.datasciencebowl.com/data-science-insights/ [(RSS)](http://www.datasciencebowl.com/feed/)
* Data Science Tutorials https://codementor.io/data-science/tutorial [(RSS)](https://www.codementor.io/data-science/tutorial/feed)
* Data Science Vademecum http://datasciencevademecum.wordpress.com/ [(RSS)](http://datasciencevademecum.wordpress.com/feed/)
* Dataaspirant http://dataaspirant.com/ [(RSS)](http://dataaspirant.wordpress.com/feed/)
* Dataclysm http://blog.okcupid.com/ [(RSS)](http://blog.okcupid.com/index.php/feed/)
* DataGenetics http://datagenetics.com/blog.html [(RSS)](http://datagenetics.com/feed/rss.xml)
* Dataiku https://www.dataiku.com/blog/ [(RSS)](http://www.dataiku.com/feed.xml)
* DataKind http://www.datakind.org/blog [(RSS)](http://feeds.feedburner.com/DataKin)
* DataLook http://blog.datalook.io/ [(RSS)](http://blog.datalook.io/feed/)
* Datanice https://datanice.wordpress.com/ [(RSS)](https://datanice.wordpress.com/feed/)
* Dataquest Blog https://www.dataquest.io/blog/ [(RSS)](https://www.dataquest.io/blog/atom.xml)
* DataRobot http://www.datarobot.com/blog/ [(RSS)](http://www.datarobot.com/feed/)
* Datascope http://datascopeanalytics.com/blog [(RSS)](http://datascopeanalytics.com/rss)
* DatasFrame http://tomaugspurger.github.io/ [(RSS)](http://tomaugspurger.github.io/feeds/all.rss.xml)
* David Mimno http://www.mimno.org/ [(RSS)](http://mimno.infosci.cornell.edu/b/feed.xml)
* Dayne Batten http://daynebatten.com [(RSS)](http://daynebatten.com/feed/)
* Deep Learning http://deeplearning.net/blog/ [(RSS)](http://deeplearning.net/feed/)
* Deepdish http://deepdish.io/ [(RSS)](http://deepdish.io/atom.xml)
* Delip Rao http://deliprao.com/ [(RSS)](http://deliprao.com/feed)
* DENNY'S BLOG http://blog.dennybritz.com/ [(RSS)](http://blog.dennybritz.com/feed/)
* Dimensionless https://dimensionless.in/blog/ [(RSS)](https://dimensionless.in/feed)
* Distill http://distill.pub/ [(RSS)](http://distill.pub/rss.xml)
* District Data Labs http://districtdatalabs.silvrback.com/ [(RSS)](https://districtdatalabs.silvrback.com/feed)
* Diving into data https://blog.datadive.net/ [(RSS)](http://blog.datadive.net/feed/)
* Domino Data Lab's blog http://blog.dominodatalab.com/ [(RSS)](http://blog.dominodatalab.com/rss/)
* Dr. Randal S. Olson http://www.randalolson.com/blog/ [(RSS)](http://www.randalolson.com/feed/)
* Drew Conway https://medium.com/@drewconway [(RSS)](https://medium.com/feed/@drewconway)
* Dustin Tran http://dustintran.com/blog/ [(RSS)](http://dustintran.com/blog/rss/)
* Eder Santana https://edersantana.github.io/blog.html [(RSS)](http://edersantana.github.io/feed.xml)
* Edwin Chen http://blog.echen.me [(RSS)](http://blog.echen.me/feeds/all.rss.xml)
* EFavDB http://efavdb.com/ [(RSS)](http://efavdb.com/feed/)
* Emilio Ferrara, Ph.D.  http://www.emilio.ferrara.name/ [(RSS)](http://www.emilio.ferrara.name/feed/)
* Entrepreneurial Geekiness http://ianozsvald.com/ [(RSS)](http://ianozsvald.com/feed/)
* Eric Jonas http://ericjonas.com/archives.html [(RSS)](http://ericjonas.com/archives.html)
* Eric Siegel http://www.predictiveanalyticsworld.com/blog [(RSS)](http://feeds.feedburner.com/predictiveanalyticsworld/GXRy)
* Erik Bern http://erikbern.com [(RSS)](http://erikbern.com/feed/)
* ERIN SHELLMAN http://www.erinshellman.com/ [(RSS)](http://www.erinshellman.com/feed/)
* Eugenio Culurciello http://culurciello.github.io/ [(RSS)](http://culurciello.github.io/feed.xml)
* Fabian Pedregosa http://fa.bianp.net/ [(RSS)](http://fa.bianp.net/blog/feed/)
* Fast Forward Labs http://blog.fastforwardlabs.com/ [(RSS)](http://blog.fastforwardlabs.com/rss)
* FastML http://fastml.com/ [(RSS)](http://fastml.com/atom.xml)
* Florian Hartl http://florianhartl.com/ [(RSS)](http://florianhartl.com/feed/)
* FlowingData http://flowingdata.com/ [(RSS)](http://flowingdata.com/feed/)
* Full Stack ML http://fullstackml.com/ [(RSS)](http://fullstackml.com/feed/)
* GAB41 http://www.lab41.org/gab41/ [(RSS)](http://www.lab41.org/feed/)
* Garbled Notes http://www.chioka.in/ [(RSS)](http://www.chioka.in/feed.xml)
* Greg Reda http://www.gregreda.com/blog/ [(RSS)](http://www.gregreda.com/feeds/all.atom.xml)
* Hyon S Chu https://medium.com/@adailyventure [(RSS)](https://medium.com/feed/@adailyventure)
* i am trask http://iamtrask.github.io/ [(RSS)](http://iamtrask.github.io/feed.xml)
* I Quant NY http://iquantny.tumblr.com/ [(RSS)](http://iquantny.tumblr.com/rss)
* inFERENCe http://www.inference.vc/ [(RSS)](http://www.inference.vc/rss/)
* Insight Data Science https://blog.insightdatascience.com/ [(RSS)](https://blog.insightdatascience.com/feed)
* INSPIRATION INFORMATION http://myinspirationinformation.com/ [(RSS)](http://myinspirationinformation.com/feed/)
* Ira Korshunova http://irakorshunova.github.io/ [(RSS)](http://irakorshunova.github.io/feed.xml)
* I’m a bandit https://blogs.princeton.edu/imabandit/ [(RSS)](https://blogs.princeton.edu/imabandit/feed/)
* Jason Toy http://www.jtoy.net/ [(RSS)](http://jtoy.net/atom.xml)
* Jeremy D. Jackson, PhD http://www.jeremydjacksonphd.com/ [(RSS)](http://www.jeremydjacksonphd.com/?feed=rss2)
* Jesse Steinweg-Woods https://jessesw.com/ [(RSS)](https://jessesw.com/feed.xml)
* Joe Cauteruccio http://www.joecjr.com/ [(RSS)](http://www.joecjr.com/feed/)
* John Myles White http://www.johnmyleswhite.com/ [(RSS)](http://www.johnmyleswhite.com/feed/)
* John's Soapbox http://joschu.github.io/ [(RSS)](http://joschu.github.io/feed.xml)
* Jonas Degrave http://317070.github.io/ [(RSS)](http://317070.github.io/feed.xml)
* Joy Of Data http://www.joyofdata.de/blog/ [(RSS)](http://www.joyofdata.de/blog/feed/)
* Julia Evans http://jvns.ca/ [(RSS)](http://jvns.ca/atom.xml)
* KDnuggets http://www.kdnuggets.com/ [(RSS)](http://feeds.feedburner.com/kdnuggets-data-mining-analytics)
* Keeping Up With The Latest Techniques http://colinpriest.com/ [(RSS)](http://colinpriest.com/feed/)
* Kenny Bastani http://www.kennybastani.com/ [(RSS)](http://www.kennybastani.com/feeds/posts/default?alt=rss)
* Kevin Davenport http://kldavenport.com/ [(RSS)](http://kldavenport.com/feed/)
* kevin frans http://kvfrans.com/ [(RSS)](http://kvfrans.com/rss/)
* korbonits | Math ∩ Data http://korbonits.github.io/ [(RSS)](http://korbonits.github.io/feed.xml)
* Large Scale Machine Learning  http://bickson.blogspot.com/ [(RSS)](http://bickson.blogspot.com/feeds/posts/default)
* LATERAL BLOG https://blog.lateral.io/ [(RSS)](https://blog.lateral.io/feed/)
* Lazy Programmer http://lazyprogrammer.me/ [(RSS)](http://lazyprogrammer.me/feed/)
* Learn Analytics Here https://learnanalyticshere.wordpress.com/ [(RSS)](https://learnanalyticshere.wordpress.com/feed/)
* LearnDataSci http://www.learndatasci.com/ [(RSS)](http://www.learndatasci.com/feed/)
* Learning With Data http://learningwithdata.com/ [(RSS)](http://learningwithdata.com/rss_feed.xml)
* Life, Language, Learning http://daoudclarke.github.io/ [(RSS)](http://daoudclarke.github.io/atom.xml)
* Locke Data https://itsalocke.com/blog/ [(RSS)](https://itsalocke.com/feed)
* Louis Dorard http://www.louisdorard.com/blog/ [(RSS)](http://www.louisdorard.com/blog?format=rss)
* M.E.Driscoll http://medriscoll.com/ [(RSS)](http://medriscoll.com/rss)
* Machinalis http://www.machinalis.com/blog [(RSS)](http://www.machinalis.com/blog/feeds/rss/)
* Machine Learning (Theory) http://hunch.net/ [(RSS)](http://hunch.net/?feed=rss2)
* Machine Learning and Data Science http://alexhwoods.com/blog/ [(RSS)](http://alexhwoods.com/feed/)
* Machine Learning https://charlesmartin14.wordpress.com/ [(RSS)](http://charlesmartin14.wordpress.com/feed/)
* Machine Learning Mastery http://machinelearningmastery.com/blog/ [(RSS)](http://machinelearningmastery.com/feed/)
* Machine Learning Blogs https://machinelearningblogs.com/ [(RSS)](https://machinelearningblogs.com/feed/)
* Machine Learning, etc http://yaroslavvb.blogspot.com [(RSS)](http://yaroslavvb.blogspot.com/feeds/posts/default)
* Machine Learning, Maths and Physics https://mlopezm.wordpress.com/ [(RSS)](https://mlopezm.wordpress.com/feed/)
* Machine Learning Flashcards https://machinelearningflashcards.com/ $10, but a nicely illustrated set of 300 flash cards
* Machined Learnings http://www.machinedlearnings.com/ [(RSS)](http://www.machinedlearnings.com/feeds/posts/default)
* MAPPING BABEL https://jack-clark.net/ [(RSS)](https://jack-clark.net/feed/)
* MAPR Blog https://www.mapr.com/blog [(RSS)](https://www.mapr.com/bigdata.xml)
* MAREK REI http://www.marekrei.com/blog/ [(RSS)](http://www.marekrei.com/blog/feed/)
* MARGINALLY INTERESTING http://blog.mikiobraun.de/ [(RSS)](http://feeds.feedburner.com/MarginallyInteresting)
* Math ∩ Programming http://jeremykun.com/ [(RSS)](http://jeremykun.wordpress.com/feed/)
* Matthew Rocklin http://matthewrocklin.com/blog/ [(RSS)](http://matthewrocklin.com/blog/atom.xml)
* Melody Wolk http://melodywolk.com/projects/ [(RSS)](http://melodywolk.com/feed/)
* Mic Farris http://www.micfarris.com/ [(RSS)](http://www.micfarris.com/feed/)
* Mike Tyka http://mtyka.github.io/ [(RSS)](http://mtyka.github.io//feed.xml)
* minimaxir | Max Woolf's Blog http://minimaxir.com/ [(RSS)](http://minimaxir.com/rss.xml)
* Mirror Image https://mirror2image.wordpress.com/ [(RSS)](http://mirror2image.wordpress.com/feed/)
* Mitch Crowe http://www.dataphoric.com/ [(RSS)](http://www.dataphoric.com/feed.xml)
* MLWave http://mlwave.com/ [(RSS)](http://mlwave.com/feed/)
* MLWhiz http://mlwhiz.com/ [(RSS)](http://mlwhiz.com/atom.xml)
* Models are illuminating and wrong https://peadarcoyle.wordpress.com/ [(RSS)](http://peadarcoyle.wordpress.com/feed/)
* Moody Rd http://blog.mrtz.org/ [(RSS)](http://blog.mrtz.org/feed.xml)
* Moonshots http://jxieeducation.com/ [(RSS)](http://jxieeducation.com/feed.xml)
* Mourad Mourafiq http://mourafiq.com/ [(RSS)](http://mourafiq.com/atom.xml)
* My thoughts on Data science, predictive analytics, Python http://shahramabyari.com/ [(RSS)](http://shahramabyari.com/feed/)
* Natural language processing blog http://nlpers.blogspot.fr/ [(RSS)](http://nlpers.blogspot.com/feeds/posts/default)
* Neil Lawrence http://inverseprobability.com/blog.html [(RSS)](http://inverseprobability.com/rss.xml)
* NLP and Deep Learning enthusiast http://camron.xyz/ [(RSS)](http://camron.xyz/index.php/feed/)
* no free hunch http://blog.kaggle.com/ [(RSS)](http://blog.kaggle.com/feed/)
* Nuit Blanche http://nuit-blanche.blogspot.com/ [(RSS)](http://nuit-blanche.blogspot.com/feeds/posts/default)
* Number 2147483647 https://no2147483647.wordpress.com/ [(RSS)](http://no2147483647.wordpress.com/feed/)
* On Machine Intelligence https://aimatters.wordpress.com/ [(RSS)](https://aimatters.wordpress.com/feed/)
* Opiate for the masses Data is our religion. http://opiateforthemass.es/ [(RSS)](http://opiateforthemass.es/feed.xml)
* p-value.info http://www.p-value.info/ [(RSS)](http://www.p-value.info/feeds/posts/default)
* Pete Warden's blog http://petewarden.com/ [(RSS)](http://feeds.feedburner.com/typepad/petewarden)
* Plotly Blog http://blog.plot.ly/ [(RSS)](http://blog.plot.ly/rss)
* Probably Overthinking It http://allendowney.blogspot.ca/ [(RSS)](http://allendowney.blogspot.com/feeds/posts/default)
* Prooffreader.com http://www.prooffreader.com [(RSS)](http://www.prooffreader.com/feeds/posts/default)
* ProoffreaderPlus http://prooffreaderplus.blogspot.ca/ [(RSS)](http://prooffreaderplus.blogspot.ca/feeds/posts/default)
* Publishable Stuff http://www.sumsar.net/ [(RSS)](http://www.sumsar.net/atom.xml)
* PyImageSearch http://www.pyimagesearch.com/ [(RSS)](http://feeds.feedburner.com/Pyimagesearch)
* Pythonic Perambulations https://jakevdp.github.io/ [(RSS)](http://jakevdp.github.com/atom.xml)
* quintuitive http://quintuitive.com/ [(RSS)](http://quintuitive.com/feed/)
* R and Data Mining https://rdatamining.wordpress.com/ [(RSS)](http://rdatamining.wordpress.com/feed/)
* R-bloggers http://www.r-bloggers.com/ [(RSS)](http://feeds.feedburner.com/RBloggers)
* R2RT http://r2rt.com/ [(RSS)](http://r2rt.com/feeds/all.atom.xml)
* Ramiro Gómez http://ramiro.org/notebooks/ [(RSS)](http://ramiro.org/notebook/rss.xml)
* Random notes on Computer Science, Mathematics and Software Engineering http://barmaley-exe.github.io/ [(RSS)](http://feeds.feedburner.com/barmaley-exe-blog-feed)
* Randy Zwitch http://randyzwitch.com/ [(RSS)](http://randyzwitch.com/feed.xml)
* RaRe Technologies http://rare-technologies.com/blog/ [(RSS)](http://rare-technologies.com/feed/)
* Rayli.Net http://rayli.net/blog/ [(RSS)](http://rayli.net/blog/feed/)
* Revolutions http://blog.revolutionanalytics.com/ [(RSS)](http://blog.revolutionanalytics.com/atom.xml)
* Rinu Boney http://rinuboney.github.io/ [(RSS)](http://rinuboney.github.io/feed.xml)
* RNDuja Blog http://rnduja.github.io/ [(RSS)](http://rnduja.github.io/feed.xml)
* Robert Chang https://medium.com/@rchang [(RSS)](https://medium.com/feed/@rchang)
* Rocket-Powered Data Science http://rocketdatascience.org [(RSS)](http://rocketdatascience.org/?feed=rss2)
* Sachin Joglekar's blog https://codesachin.wordpress.com/ [(RSS)](https://codesachin.wordpress.com/feed/)
* samim https://medium.com/@samim [(RSS)](https://medium.com/feed/@samim)
* Sean J. Taylor http://seanjtaylor.com/ [(RSS)](http://seanjtaylor.com/rss)
* Sebastian Raschka http://sebastianraschka.com/blog/index.html [(RSS)](http://sebastianraschka.com/rss_feed.xml)
* Sebastian Ruder http://sebastianruder.com/ [(RSS)](http://sebastianruder.com/rss/)
* Sebastian's slow blog http://www.nowozin.net/sebastian/blog/ [(RSS)](http://www.nowozin.net/sebastian/blog/feeds/all.atom.xml)
* SFL Scientific Blog https://sflscientific.com/blog/ [(RSS)](http://sflscientific.com/blog/?format=rss)
* Shakir's Machine Learning Blog http://blog.shakirm.com/ [(RSS)](http://blog.shakirm.com/feed/)
* Simply Statistics http://simplystatistics.org [(RSS)](http://simplystatistics.org/feed/)
* Springboard Blog http://springboard.com/blog
* Startup.ML Blog http://startup.ml/blog [(RSS)](http://www.startup.ml/blog?format=RSS)
* Statistical Modeling, Causal Inference, and Social Science http://andrewgelman.com/ [(RSS)](http://andrewgelman.com/feed/)
* Stigler Diet http://stiglerdiet.com/ [(RSS)](http://stiglerdiet.com/feeds/all.atom.xml)
* Stitch Fix Tech Blog http://multithreaded.stitchfix.com/blog/ [(RSS)](http://multithreaded.stitchfix.com/feed.xml)
* Stochastic R&D Notes http://arseny.info/ [(RSS)](http://arseny.info/feeds/all.rss.xml)
* Storytelling with Statistics on Quora http://datastories.quora.com/ [(RSS)](http://datastories.quora.com/rss)
* StreamHacker http://streamhacker.com/ [(RSS)](http://feeds.feedburner.com/StreamHacker)
* Subconscious Musings http://blogs.sas.com/content/subconsciousmusings/ [(RSS)](http://feeds.feedburner.com/advanalytics)
* Swan Intelligence http://swanintelligence.com/ [(RSS)](http://swanintelligence.com/feeds/all.rss.xml)
* TechnoCalifornia http://technocalifornia.blogspot.se/ [(RSS)](http://technocalifornia.blogspot.com/feeds/posts/default)
* TEXT ANALYSIS BLOG | AYLIEN http://blog.aylien.com/ [(RSS)](http://blog.aylien.com/rss)
* The Angry Statistician http://angrystatistician.blogspot.com/ [(RSS)](http://angrystatistician.blogspot.com/feeds/posts/default)
* The Clever Machine https://theclevermachine.wordpress.com/ [(RSS)](http://theclevermachine.wordpress.com/feed/)
* The Data Camp Blog https://www.datacamp.com/community/blog [(RSS)](http://blog.datacamp.com/feed/)
* The Data Incubator http://blog.thedataincubator.com/ [(RSS)](http://blog.thedataincubator.com/feed/)
* The Data Science Lab https://datasciencelab.wordpress.com/ [(RSS)](http://datasciencelab.wordpress.com/feed/)
* THE ETZ-FILES http://alexanderetz.com/ [(RSS)](http://nicebrain.wordpress.com/feed/)
* The Science of Data http://www.martingoodson.com [(RSS)](http://www.martingoodson.com/rss/)
* The Shape of Data https://shapeofdata.wordpress.com [(RSS)](https://shapeofdata.wordpress.com/feed/)
* The unofficial Google data science Blog http://www.unofficialgoogledatascience.com/ [(RSS)](http://www.unofficialgoogledatascience.com/feeds/posts/default)
* Tim Dettmers http://timdettmers.com/ [(RSS)](http://timdettmers.com/feed/)
* Tombone's Computer Vision Blog http://www.computervisionblog.com/ [(RSS)](http://www.computervisionblog.com/feeds/posts/default)
* Tommy Blanchard http://tommyblanchard.com/category/projects [(RSS)](http://tommyblanchard.com/feeds/all.atom.xml)
* Trevor Stephens http://trevorstephens.com/ [(RSS)](http://trevorstephens.com/feed.xml)
* Trey Causey http://treycausey.com/ [(RSS)](http://treycausey.com/feeds/all.atom.xml)
* UW Data Science Blog http://datasciencedegree.wisconsin.edu/blog/ [(RSS)](http://datasciencedegree.wisconsin.edu/feed/)
* Wellecks http://wellecks.wordpress.com/ [(RSS)](http://wellecks.wordpress.com/feed/)
* Wes McKinney http://wesmckinney.com/archives.html [(RSS)](http://wesmckinney.com/feeds/all.atom.xml)
* While My MCMC Gently Samples http://twiecki.github.io/ [(RSS)](http://twiecki.github.io/atom.xml)
* WildML http://www.wildml.com/ [(RSS)](http://www.wildml.com/feed/)
* Will do stuff for stuff http://rinzewind.org/blog-en [(RSS)](http://rinzewind.org/feed-en)
* Will wolf http://willwolf.io/ [(RSS)](http://willwolf.io/feed/)
* WILL'S NOISE http://www.willmcginnis.com/ [(RSS)](http://www.willmcginnis.com/feed/)
* William Lyon http://www.lyonwj.com/ [(RSS)](http://www.lyonwj.com/atom.xml)
* Win-Vector Blog http://www.win-vector.com/blog/ [(RSS)](http://www.win-vector.com/blog/feed/)
* Yanir Seroussi http://yanirseroussi.com/ [(RSS)](http://yanirseroussi.com/feed/)
* Zac Stewart http://zacstewart.com/ [(RSS)](http://zacstewart.com/feed.xml)
* ŷhat http://blog.yhat.com/ [(RSS)](http://blog.yhat.com/rss.xml)
* ℚuantitative √ourney http://outlace.com/ [(RSS)](http://outlace.com/feed.xml)
* 大トロ http://blog.otoro.net/ [(RSS)](http://blog.otoro.net/feed.xml)


## credits

* [Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython](http://www.amazon.com/Python-Data-Analysis-Wrangling-IPython/dp/1449319793) by Wes McKinney
* [PyCon 2015 Scikit-learn Tutorial](https://github.com/jakevdp/sklearn_pycon2015) by Jake VanderPlas
* [Python Data Science Handbook](https://github.com/jakevdp/PythonDataScienceHandbook) by Jake VanderPlas
* [Parallel Machine Learning with scikit-learn and IPython](https://github.com/ogrisel/parallel_ml_tutorial) by Olivier Grisel
* [Statistical Interference Using Computational Methods in Python](https://github.com/AllenDowney/CompStats) by Allen Downey
* [TensorFlow Examples](https://github.com/aymericdamien/TensorFlow-Examples) by Aymeric Damien
* [TensorFlow Tutorials](https://github.com/pkmital/tensorflow_tutorials) by Parag K Mital
* [TensorFlow Tutorials](https://github.com/nlintz/TensorFlow-Tutorials) by Nathan Lintz
* [TensorFlow Tutorials](https://github.com/alrojo/tensorflow-tutorial) by Alexander R Johansen
* [TensorFlow Book](https://github.com/BinRoot/TensorFlow-Book) by Nishant Shukla
* [Summer School 2015](https://github.com/mila-udem/summerschool2015) by mila-udem
* [Keras tutorials](https://github.com/leriomaggio/deep-learning-keras-tensorflow) by Valerio Maggio
* [Kaggle](https://www.kaggle.com/)
* [Yhat Blog](http://blog.yhat.com/)

## contributing

Contributions are welcome!  For bug reports or requests please [submit an issue](https://github.com/tarrysingh/Machine-Learning-Tutorials//issues).

## contact-info

Feel free to contact me to discuss any issues, questions, or comments.

* Email: [tarry.singh@gmail.com](mailto:tarry.singh@gmail.com)
* Twitter: [@tarrysingh](https://twitter.com/tarrysingh)
* GitHub: [tarrysingh](https://github.com/tarrysingh.com)
* LinkedIn: [Tarry Singh](https://www.linkedin.com/in/tarrysingh)
* Website: [tarrysingh.com](https://tarrysingh.com)
* Medium: [tarry@Medium](https://medium.com/@tarrysingh)
* Quora : [Answers from Tarry on Quora](https://www.quora.com/profile/Tarry-Singh)

## license

This repository contains a variety of content; some developed by Tarry Singh and some from third-parties and a lot will be maintained by me. The third-party content is distributed under the license provided by those parties.

The content was originally started by Donne Martin is distributed under the following license in 2017. I have been further developing and maintaining it by adding PyTorch, Torch/Lua, MXNET and much more:

*I am providing code and resources in this repository to you under an open source license.*

    Copyright 2017 Tarry Singh

    Licensed under the Apache License, Version 2.0 (the ""License"");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an ""AS IS"" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.
"
34,msasnur/Healthcare-Analytics,Jupyter Notebook,"# Healthcare-Analytics
Contents of Repository:
- Python Notebook file contains project code for Data Exploration, Feature Engineering, and Machine Learning models (Naive Bayes, XGBoost, Neural Networks).
- PDF Report file contains overview of the project, predicitions and results.
- Datasets.zip contains both the test and train data used in the project.
- HTML file is a markdown of the jupyter notebook with alll the outputs to View without python or its IDE.

Introduction:

  Healthcare organizations are under increasing pressure to improve patient care outcomes and achieve better care. While this situation represents a challenge, it also offers organizations an opportunity to dramatically improve the quality of care by leveraging more value and insights from their data. Health care analytics refers to the analysis of data using quantitative and qualitative techniques to explore trends and patterns in the acquired data. While healthcare management uses various metrics for performance, a patient’s length of stay is an important one.

  Being able to predict the length of stay (LOS) allows hospitals to optimize their treatment plans to reduce LOS, to reduce infection rates among patients, staff, and visitors.

Project Highligths:

Hospital admission data was analyzed to accurately predict the patient’s Length of Stay at the time of admit so that the hospitals can optimize resources and function better. Built 3 models in Python to predict the length of stay,

-	A supervised algorithm Naïve Bayes which was classifying with an accuracy of 34.55%.

-	An ensemble method XGBoost which was predicting with an accuracy of 43.05%.

-	A dense neural network with 6 layers which yields an accuracy of 42.5%.

"
35,glungu/udacity-healthcare-ai,Jupyter Notebook,"# udacity-healthcare-ai
Udacity AI for Healthcare Nanodegree Projects
"
36,popsolutions/openventilator,OpenSCAD,"# OpenVentilator

> Welcome to the OpenVentilator project. This is an Open Source Ventilator / Mechanical Respirator for the Covid-19 Crisis.
> Specially Designed for countries in Africa / South America / Middle East and other poor regions in the world

[![N|Solid](https://popsolutions.co/web/image/65243/CommunitySupport.png)](https://popsolutions.co/forum/openventilator-5)   [![N|Solid](https://popsolutions.co/web/image/65245/t_logo.png)](https://t.me/openventilator) 

<img src=""images/OpenVentilatorLogo.png"" height=300> <img src=""images/OpenVentilatorSpartanModel.png"" height=300>

# :heavy_exclamation_mark::heavy_exclamation_mark:DISCLAIMER 
**PROJECT STATUS:** We still need validation with health regulatory institutions and compliance with clinical requirements. - The tests on Lung Simulators are Sucessfull, limited on application depending on hardware availability but viable on emergency cases

**PLEASE DO NOT USE THIS MACHINE IF NOT NEEDED**, WE DO NOT GUARANTEE THE OPERATION OF THIS MACHINE | THIS MACHINE IS FOR EMERGENCY and HEALTH SYSTEM COLLAPSE SCENARIOS :warning: 

# Main Goal

Design, Build, Validate a reliable Ventilation Medical Equipment Project for people, regions, countries in difficult economical situations with a component-agnostic philosophy. This is why we didn't continue putting efforts into the projects being developed by other teams, who have a different society and economic reality.

**The equipment must have as few industrial parts as possible. If necessary, parts must be easily accessible, even in small towns and villages.**

## Technical highlights

OpenVentilor has adjustable PEEP and maximum pressure threshold, with a wide range. It has adjustable timing for the inspiratory and expiratory phases, allowing a wide range of BPM and I/E. The volume per breath is adjustable mechanically.

# Getting Started
Summary

- [Join the Team](https://t.me/openventilator)
- Documentation
  - [Specifications](Specifications.md)
  - [System description](SystemDescription.md)
  - [Part List](00_Documentation/TheSpartanModel/PartsList.md)
  - [Assembly Guide](Assembly.md)
  - [Testing Your Machine]()
  - [Regulations on your Country IYBITB]()
- [Project philosophy](projectPhilosophy.md)
- [Research we based on](00_Documentation/Research)
- [Test Results](/00_Documentation/SimulatorTest/SpartanV1.0/SpartanV1.0.zip)

## Community

- [Website](https://www.popsolutions.co/openventilator)
- [Forum](https://popsolutions.co/forum/openventilator-5)
- [Social Media]()
- [Problem / Issue Report]()

## If you want to help

[First, ** CLICK HERE ** to complete the form please, so we can organize everybody](https://www.popsolutions.co/openventilator-jointheteam) 

Then join the Whatsapp group and talk with Amanda (+55 11 99735-5042 ): https://chat.whatsapp.com/HRMx9xzVdt8Gpmwgm7ZVZ3

This initiative as other projects was born on the [Open Source COVID19 Medical Supplies](https://web.facebook.com/groups/opensourcecovid19medicalsupplies/) Facebook Group by the awareness of the need to create a Ventilator solution for the scarcity plaguing our society worldwide. I contacted Jeremias Almada from Argentina who by that time had presented an Ambu solution and a Cad Design. The idea was interesting but needed improvements.

Since then we tried to establish some development and community standards and evolved the project several times.

## Special thanks to

 - [Jose Ignácio Méndez](https://www.linkedin.com/in/jos%C3%A9-ignacio-m%C3%A9ndez-0ba3ab53/)
 - [Jeremias Almada](https://www.linkedin.com/in/almada-jerem%C3%ADas-43888680)
 - Fabian Franz
 - [Washington Perez](https://www.linkedin.com/in/washingtonperez/) 
 - [Jaqueline Passos](https://www.linkedin.com/in/jaquelinepassos/)
 - [Amanda Pellini](https://www.linkedin.com/in/amanda-cristina-maciel-pellini-9177226a/)
 - [Marguel Gutierrez](https://www.linkedin.com/in/marguelgtz/)
 - [Henrique Aguilar](https://www.linkedin.com/in/henriaguilar/)
 - [Vandeir Soares](https://www.facebook.com/vandeir.soares.7)
 - [Fábio Soares](https://www.linkedin.com/in/fabio-julio-sores-soares-58852630/)
 - [GlobaltTech](http://www.globaltechc.com.br/)
 - [Samtronic](http://www.samtronic.com.br/)
 - [Ethan Moses](https://www.cameradactyl.com/)
 - [Joris Robijn](https://www.linkedin.com/in/jorisrobijn/)
 - [Ramon Bastos]
 - [Faizan Shaikh](https://www.linkedin.com/in/faizanzshaikh)
 - [Matheus Prado]
 - [Leonardo Automni]
 - [Diego Sangiorgi]
 - [Rodrigo Song]
 - [Wendell Mendes](https://www.linkedin.com/in/1endell)
 - [Rodrigo Borges](http://linkedin.com/in/rborges111)
 - [Henrique Nery](https://www.linkedin.com/in/henrique-nery-650216a2/) 
 - [Duit](https://www.duit.com.br/)
 - [Carlos Delfino](https://github.com/CarlosDelfino)
 - [Marcio Dultra](https://www.linkedin.com/in/marciodultra)
 - [Baú da Eletrônica](https://www.baudaeletronica.com.br/)
 - [Três meninas hardware store](https://www.google.com/maps/place/Casa+das+3+Meninas/@-23.5391312,-46.6524764,19.5z/data=!4m5!3m4!1s0x0:0x377232460c40d90d!8m2!3d-23.5391706!4d-46.6524278)
 - [Rogers Guedes]
 - [The MIT guys from this paper](https://web.mit.edu/2.75/projects/DMD_2010_Al_Husseini.pdf): Abdul Mohsen Al Husseini, Heon Ju Lee, Justin Negrete, Stephen Powelson, Amelia Servil, Alexander Slocum, Jussi Saukkonen. 
 - [Draeger for supplying parts to test with]

All our families, wives and husbands that for the last days have been supporting us on our craziness.

All the doctors, nurses and paramedics in the field fighting this common enemy.
"
37,awslabs/fhir-works-on-aws-deployment,TypeScript,"# FHIR Works on AWS deployment

# This GitHub repository has been migrated. You can now find FHIR Works on AWS at https://github.com/aws-solutions/fhir-works-on-aws.

## Upgrade notice

Versions 3.1.1 and 3.1.2 of the `fhir-works-on-aws-authz-smart` package have been deprecated for necessary security updates. Please upgrade to version 3.1.3 or higher. For more information, see [the fhir-works-on-aws-authz-smart security advisory](https://github.com/awslabs/fhir-works-on-aws-authz-smart/security/advisories/GHSA-vv7x-7w4m-q72f).

## Summary

FHIR Works on AWS is a framework that can be used to deploy a [FHIR server](https://www.hl7.org/fhir/overview.html) on AWS. Using this framework, you can customize and add different FHIR functionality to best serve your use cases. When deploying this framework, by default [Cognito and role based access control](https://github.com/awslabs/fhir-works-on-aws-authz-rbac) is used. However, if preferred, you can be authenticated and authorized to access the FHIR server’s resources by using [SMART](https://github.com/awslabs/fhir-works-on-aws-authz-smart) instead of Cognito. Cognito is the default AuthN/AuthZ provider because it is easier to configure than SMART. It doesn’t require setting up a separate IDP server outside of AWS as compared to SMART. However, Cognito authentication is not granular. When a new user is created, it is assigned into the auditor, practitioner, or non-practitioner groups. Depending on the group, the user gets access to different groups of FHIR resources.
The AuthN/Z providers are defined in `package.json` and `config.ts`. You can choose  appropriate providers. SMART allows greater granularity into authentication than Cognito and is the FHIR standard. It allows you to access a FHIR record only if that record has reference to the user.

## FHIR Works on AWS features

FHIR Works on AWS utilizes AWS Lambda, Amazon DynamoDB, Amazon S3 and Amazon Elasticsearch Service to provide the following FHIR features:

+ Create, Read, Update, Delete (CRUD) operations for all R4 or STU3 base FHIR resources
+ Search capabilities per resource type
+ Ability to do versioned reads ([vread](https://www.hl7.org/fhir/http.html#vread))
+ Ability to post a transaction bundle of 25 entries or less. Presently, transaction bundles with only 25 entries or less are supported.

## Accessing FHIR Works on AWS

The easiest and quickest way to access FHIR Works on AWS is by using [AWS solution](https://aws.amazon.com/solutions/implementations/fhir-works-on-aws/). To modify the code and set up a developer environment, follow the steps below:

**Note**: AWS Solution provides an earlier version(See Solutions [CHANGELOG](https://github.com/awslabs/fhir-works-on-aws-deployment/blob/aws-solution/CHANGELOG.md) for more details) of FWoA install. Please follow the instruction below to install from GitHub repository if you wish to install the latest version.

1. Clone or download the repository to a local directory.

Example:

```sh
git clone https://github.com/awslabs/fhir-works-on-aws-deployment.git
```

**Note**: To modify FHIR Works on AWS, create your own fork of the GitHub repository. This allows you to check in any changes you make to your private copy of the code.

2. Use one of the following links to download FHIR Works on AWS:

- [Linux/macOS](./INSTALL.md#linux-or-macos-installation)
- [Windows](./INSTALL.md#windows-installation)
- [Docker](./INSTALL.md#docker-installation)


3. Refer to these [instructions](./DEVELOPMENT.md) for making code changes.

If you intend to use FHIR Implementation Guides read the [Using Implementation Guides](./USING_IMPLEMENTATION_GUIDES.md) documentation first.

If you intend to do a multi-tenant deployment read the [Using Multi-Tenancy](./USING_MULTI_TENANCY.md) documentation first.

If you intend to use FHIR Subscriptions read the [Using Subscriptions](./USING_SUBSCRIPTIONS.md) documentation first.

## Architecture

The system architecture consists of multiple layers of AWS serverless services. The endpoint is hosted using API Gateway. The database and storage layer consists of Amazon DynamoDB and S3, with Elasticsearch as the search index for the data written to DynamoDB. The endpoint is secured by API keys and Cognito for user-level authentication and user-group authorization. The diagram below shows the FHIR server’s system architecture components and how they are related.

![Architecture](resources/architecture.png)

## Components overview

FHIR Works on AWS is powered by single-function components. These functions provide you the flexibility to plug your own implementations, if needed. The components used in this deployment are:
+ [Interface](https://github.com/awslabs/fhir-works-on-aws-interface) - Defines communication between the components.
+ [Routing](https://github.com/awslabs/fhir-works-on-aws-routing) - Accepts HTTP FHIR requests, routes it to the other components, logs the errors, transforms output to HTTP responses and generates the [Capability Statement](https://www.hl7.org/fhir/capabilitystatement.html).
+ [Authorization](https://github.com/awslabs/fhir-works-on-aws-authz-rbac) - Accepts the access token found in HTTP header and the action the request is trying to perform. It then determines if that action is permitted.
+ [Persistence](https://github.com/awslabs/fhir-works-on-aws-persistence-ddb) - Contains the business logic for creating, reading, updating, and deleting the FHIR record from the database. FHIR also supports ‘conditional’ CRUD actions and patching.
   + Bundle - Supports multiple incoming requests as one request. Think of someone wanting to create five patients at once instead of five individual function calls. There are two types of bundles, batch and transaction. We currently only support transaction bundles of size 25 entries or fewer, but support batch bundles of up to 750 entries. This 750 limit was drawn from the Lambda payload limit of 6MB and an average request size of 4KB, divided in half to allow for flexibility in request size. This limit can also be configured in the `config.ts`, by specifying the `maxBatchSize` when constructing the `DynamoDBBundleService`.
+ [Search](https://github.com/awslabs/fhir-works-on-aws-search-es) - Enables system-wide searching (/?name=bob) and type searching (/Patient/?name=bob).
+ History - (*Not implemented*) Searches all archived/older versioned resources. This can be done at a system, type or instance level.

## License

This project is licensed under the Apache-2.0 license.

## Setting variables for FHIR on AWS

### Retrieving user variables

After installation, all user-specific variables (such as `USER_POOL_APP_CLIENT_ID`) can be found in the `Info_Output.log` file. You can also retrieve these values by running the following command:
```
serverless info --verbose --region <REGION> --stage <STAGE>.
```
**Note**: The default stage is `dev` and region is `us-west-2`.

If you are receiving `Error: EACCES: permission denied` when running a command, try re-running it using `sudo`.

### Accessing the FHIR API

The FHIR API can be accessed through `API_URL` using the following REST syntax:
```sh
curl -H ""Accept: application/json"" -H ""Authorization: Bearer <COGNITO_AUTH_TOKEN>"" -H ""x-api-key:<API_KEY>"" <API_URL>
```
For more information, click [here](http://hl7.org/fhir/http.html).

### Using Postman to make API requests

To access APIs, you can use Postman as well.  [Postman](https://www.postman.com/) is an API Client for RESTful services that can run on your development desktop for making requests to the FHIR Server. Postman is highly suggested and enables easier access to the FHRI API. You can use Postman to make API requests by following the steps below:

**Importing the collection file**

Under the Postman folder, you can access the JSON definitions for some API requests that you can make against the server. To import these requests into your Postman application, click [here](https://kb.datamotion.com/?ht_kb=postman-instructions-for-exporting-and-importing).

**Note**: Ensure that you import the [Fhir.postman_collection.json](./postman/Fhir.postman_collection.json) collection file.

After you import the collection, set up your environment. You can set up a local environment, a development environment, and a production environment. Each environment should have the correct values configured. For example, the value for `API_URL` for the local environment might be `localhost:3000` while the `API_URL` for the development environment would be your API gateway’s endpoint.

**Setting up environment variables**

Set up the following three Postman environments:

+ `Fhir_Local_Env.json`
+ `Fhir_Dev_Env.json`
+ `Fhir_Prod_Env.json`

For instructions on importing the environment JSON, click [here](https://thinkster.io/tutorials/testing-backend-apis-with-postman/managing-environments-in-postman).

The `COGNITO_AUTH_TOKEN` required for each of these files can be obtained by following the instructions under [Authorizing a user](#authorizing-a-user).

The following variables required in the Postman collection can be found in `Info_Output.log`:
+ API_URL: from Service Information:endpoints: ANY
+ API_KEY: from Service Information: api keys: developer-key

To find what FHIR Server supports, use the `GET Metadata` Postman request to retrieve the [Capability Statement](https://www.hl7.org/fhir/capabilitystatement.html)

**Authorizing a user**

FHIR Works on AWS uses Role-Based Access Control (RBAC) to determine what operations and what resource types a user can access. The default rule set can be found in [RBACRules.ts](https://github.com/awslabs/fhir-works-on-aws-deployment/blob/mainline/src/RBACRules.ts). To access the API, you must use the ID token. This ID token must include scopes of either `openid`, `profile` or `aws.cognito.signin.user.admin`.

Using either of these scopes provide information about users and their group. It helps determine what resources/records they can access.

+ The `openid` scope returns all user attributes in the ID token that are readable by the client. The ID token is not returned if the openid scope is not requested by the client.
+ The `profile` scope grants access to all user attributes that are readable by the client. This scope can only be requested with the openid scope.
+ The `aws.cognito.signin.user.admin` scope grants access to [Amazon Cognito User Pool](https://docs.aws.amazon.com/cognito-user-identity-pools/latest/APIReference/Welcome.html) API operations that require access tokens, such as `UpdateUserAttributes` and `VerifyUserAttribute`.

For more information, click [here](https://docs.aws.amazon.com/cognito/latest/developerguide/cognito-user-pools-app-idp-settings.html).

**Retrieving an ID token using aws.cognito.signin.user.admin**

To access the FHIR API, an ID token is required. A Cognito ID token can be obtained using the following command substituting all variables with their values from `Info_Output.log`.
+	For Windows, enter:
```sh
scripts/init-auth.py <CLIENT_ID> <REGION>
```
+	For Mac, enter:
```sh
python3 scripts/init-auth.py <CLIENT_ID> <REGION>
```
The return value is the `COGNITO_AUTH_TOKEN` (found in the postman collection) to be used for access to the FHIR APIs.

### Accessing binary resources

Binary resources are FHIR resources that consist of binary/unstructured data of any kind. This could be X-rays, PDF, video or other files. This implementation of the FHIR API has a dependency on the API Gateway and Lambda services, which currently have limitations in request/response sizes of 10 MB and 6 MB respectively. The workaround for this limitation is a hybrid approach of storing a binary resource’s metadata in DynamoDB and using S3's get/putPreSignedUrl APIs. So in your requests to the FHIR API, you will store/get the Binary's metadata from DynamoDB and in the response object it will also contain a pre-signed S3 URL, which should be used to interact directly with the binary file.

### Testing binary resources

**Using Postman**

To test, use Postman.  For steps, click [here](https://github.com/awslabs/fhir-works-on-aws-deployment/blob/mainline/README.md#using-postman-to-make-api-requests).

**Note**: We recommend you to test binary resources by using the `Binary` folder in Postman.

**Using cURL**

To test this with cURL, follow these steps:
1.	POST a binary resource to FHIR API using the following command:
```sh
curl -H ""Accept: application/json"" -H ""Authorization: Bearer <COGNITO_AUTH_TOKEN>"" -H ""x-api-key:<API_KEY>"" --request POST \
  --data '{""resourceType"": ""Binary"", ""contentType"": ""image/jpeg""}' \
  <API_URL>/Binary
```
2. Check the POST's response. There will be a presignedPutUrl parameter. Use that pre-signed url to upload your file. See below for command
```sh
curl -v -T ""<LOCATION_OF_FILE_TO_UPLOAD>"" ""<PRESIGNED_PUT_URL>""
```

### Testing bulk data export

Bulk Export allows you to export all of your data from DDB to S3. We currently support the [System Level](https://hl7.org/fhir/uv/bulkdata/export/index.html#endpoint---system-level-export) export. For more information about bulk export, refer to the FHIR [Implementation Guide](https://hl7.org/fhir/uv/bulkdata/export/index.html).

To test this feature on FHIR Works on AWS, make API requests using the [Fhir.postman_collection.json](./postman/Fhir.postman_collection.json) file by following these steps:
1.	In the FHIR Examples collection, under the **Export** folder, use `GET System Export` request to initiate an export request.
2.	In the response, check the Content-Location header field for a URL. The URL should be in the `<base-url>/$export/<jobId>` format.
3.	To get the status of the export job, in the **Export** folder, use the GET System Job Status request. Enter the `jobId` value from step 2 in that request.
4.	Check the response that is returned from `GET System Job Status`. If the job is in progress, the response header will have the field `x-progress: in-progress`. Keep polling that URL every 10 seconds until the job is complete. Once the job is complete, you'll get a JSON body with presigned S3 URLs of your exported data. You can download the exported data using those URLs.
Example:
```sh
{
    ""transactionTime"": ""2021-03-29T16:49:00.819Z"",
    ""request"": ""https://xyz.execute-api.us-west-2.amazonaws.com/$export?_outputFormat=ndjson&_since=1800-01-01T00%3A00%3A00.000Z&_type=Patient"",
    ""requiresAccessToken"": false,
    ""output"":
    [
        {
            ""type"": ""Patient"",
            ""url"": ""https://fhir-service-dev-bulkexportresultsbucket-.com/abc""
        }
    ],
    ""error"": []
}
```
**Note**: To cancel an export job, use the `Cancel Export Job` request in the ""Export"" folder located in the Postman collections.

## Troubleshooting FHIR Works on AWS

+ If changes are required for the Elasticsearch instances, you may have to redeploy. Redeployment deletes the Elasticsearch cluster and creates a new one. Redeployment also deletes the data inside your cluster. In future releases, we will create a one-off lambda instance that can retrieve the data from DynamoDB to Elasticsearch. To do this, you can currently use either of the following options:
   + You can manually push the DynamoDB data to Elasticsearch by creating a lambda instance.
   + You can refresh your DynamoDB table with a backup.
   + You can remove all data from the DynamoDB table and that will create parity between Elasticsearch and DynamoDB.

+ Support for STU3 and [R4](https://www.hl7.org/fhir/validation.html) releases of FHIR is based on the JSON schema provided by HL7. The schema for R4 is more restrictive than the schema for [STU3](http://hl7.org/fhir/STU3/validation.html). The STU3 schema doesn’t restrict appending additional fields into the POST/PUT requests of a resource, whereas the R4 schema has a strict definition of what is permitted in the request. You can access the schema [here](https://github.com/awslabs/fhir-works-on-aws-routing/blob/mainline/src/router/validation/schemas/fhir.schema.v3.json).

**Note**: We are using the official schema provided by [HL7](https://www.hl7.org/fhir/STU3/downloads.html).

+ When making a `POST`/`PUT` request to the server, if you get an error that includes the text `Failed to parse request body as JSON resource`, check that you've set the request headers correctly. The header for `Content-Type` should be either `application/json` or `application/fhir+json`. If you're using Postman for making requests, in the **Body** tab, make sure to change the setting to `raw` and `JSON`.
![Postman Body Request Settings](resources/postman_body_request_settings.png)

## Feedback
We'd love to hear from you! Please reach out to our team via [Github Issues](https://github.com/awslabs/fhir-works-on-aws-deployment/issues) for any feedback.
"
38,GoogleCloudPlatform/healthcare-nlp-visualizer-demo,JavaScript,"# Healthcare NLP Visualizer Demo

The demo application is a Node.js and React.js system to visualize the 
Google Cloud [Healthcare Natural Language API](https://cloud.google.com/healthcare/docs/how-tos/nlp).
You can upload your own sample medical text to visualize the output such as medical dictionaries,
entity extraction and relationships, context assessment and more. We have also provided sample
texts for a a medical record, research paper and lab form. 

![screencast](screencast-short.gif)

## Prerequisites 

1. A GCP Project with billing and the Healthcare NLP API enabled.
1. Complete the Healthcare NLP [How-to Guide](https://cloud.google.com/healthcare/docs/how-tos/nlp).
1. Familiarity with Google Cloud Functions and Vue.js.

## Set Up Instructions

### Backend

The HTTP Cloud Function can be found in the `/visualizer` directory. Please note, this code is NOT
meant for production use.

1. Download the service account key for your project.
1. Deploy the Cloud Function, you can follow the instructions [here](https://cloud.google.com/functions/docs/deploying).
1. Copy the endpoint for your Cloud Function.

### Frontend

The Vue.js app is found in the `/app` directory.

1. ```cd app/```
1. Paste your Cloud Function endpoint in to the placeholder in index.html. 
1. Start a local server of your choice and open the application in your 
browser.
"
39,informatici/openhospital-gui,Java,"# Open Hospital - GUI
[![Java CI](https://github.com/informatici/openhospital-gui/workflows/Java%20CI%20with%20Maven/badge.svg)](https://github.com/informatici/openhospital-gui/actions?query=workflow%3A%22Java+CI+with+Maven%22)

This is the GUI component of [Open Hospital][openhospital]: it contains a graphical user interface (GUI) made with Java Swing. 
This project depends on the [Core component][openhospital-core] for the business logic and the data abstraction layer. 
An alternative user interface based on React and currently still work-in-progress is available [here][openhospital-ui].

## How to build

To build this project you'll need Java JDK 8+ and Maven. 
Additionally, you'll need to build and install locally the [Core component][openhospital-core] of Open Hospital.
Once you do that, to build this project just issue:

  mvn package
  
To run the tests simply issue:

  mvn test
  
## How to launch Open Hospital

To launch Open Hospital GUI, use the scripts `oh.sh` (on Linux) or `oh.bat` (on Windows) from the maven `target` folder.
You will need a MySQL database running locally (e.g. the Docker container available in the Core project),
or any similar SQL database (e.g. MariaDB).

### Launch within IDE

Be sure to have configured properly the classpath for the project (see [5 Installing Open Hospital 1.13.0 in Eclipse EE](https://github.com/informatici/openhospital-doc/blob/develop/doc_admin/AdminManual.adoc#5-installing-open-hospital-1-13-0-in-eclipse-ee))

Before running the application, you should generate the config files with the `g)` option, or manually copying and renaming the files `*.dist` files in `rsc/` folder and edit them accordingly:

| Dist file                | Property file       | Properties to fill in                                         |
|--------------------------|---------------------|---------------------------------------------------------------|
| database.properties.dist | database.properties | DBSERVER, DBPORT, DBNAME, DBUSER, DBPASS                      |
| dicom.properties.dist    | dicom.properties    | OH_PATH_SUBSTITUTE/DICOM_DIR, DICOM_SIZE                      |
| log4j.properties.dist    | log4j.properties    | LOG_DEST, DBSERVER, DBPORT, DBNAME, DBUSER, DBPASS, LOG_LEVEL |
| settings.properties.dist | settings.properties | OH_LANGUAGE,(SINGLEUSER=)YES_OR_NO, PHOTO_DIR, OH_DOC_DIR     |

*For further information, please refer to the Admin and User manuals in the [Doc project][openhospital-doc].*

## How to contribute

You can find the contribution guidelines in the [Open Hospital wiki][contribution-guide]. 
A list of open issues is available on [Jira][jira].

## Community

You can reach out to the community of contributors by joining 
our [Slack workspace][slack] or by subscribing to our [mailing list][ml].

## Code style

This project uses a consistent code style and provides definitions for use in both IntelliJ and Eclipse IDEs.

<details><summary>IntelliJ IDEA instructions</summary>

For IntelliJ IDEA the process for importing the code style is:

* Select *Settings* in the *File* menu
* Select *Editor*
* Select *Code Style*
* Expand the menu item and select *Java*
* Go to *Scheme* at the top, click on the setting button by the side of the drop-down list
* Select *Import Scheme*
* Select *IntelliJ IDE code style XML*
* Navigate to the location of the file which relative to the project root is: `.ide-settings/idea/OpenHospital-code-style-configuration.xml`
* Select *OK* 
* At this point the code style is stored as part of the IDE and is used for **all** projects opened in the editor. To restrict the settings to just this project again select the setting button by the side of the *Scheme* list and select *Copy to Project...*. If successful a notice appears in the window that reads: *For current project*.

</details>

<details><summary>Eclipse instructions</summary>

For Eclipse the process requires loading the formatting style and the import order separately.

* Select *Preferences* in the *Window* menu
* Select *Java*
* Select *Code Style* and expand the menu
* Select *Formatter*
* Select the *Import...* button
* Navigate to the location of the file which relative to the project root is: `.ide-settings/eclipse/OpenHospital-Java-CodeStyle-Formatter.xml`
* Select *Open*
* At this point the code style is stored and is applicable to all projects opened in the IDE. To restrict the settings just to this project select *Configure Project Specific Settings...* in the upper right. In the next dialog select the *openhospital* repository and select *OK*. In the next dialog select the *Enable project specific settings* checkbox. Finally select *Apply and Close*.
* Back in the *Code Style* menu area, select *Organize Imports*
* Select *Import...*
* Navigate to the location of the file which relative to the project root is: `.ide-settings/eclipse/OpenHospital.importorder`
* Select *Open*
* As with the formatting styles the import order is applicable to all projects. In order to change it just for this project repeat the same steps as above for *Configure Project Specific Settings...*
 
</details> 

 [openhospital]: https://www.open-hospital.org/
 [openhospital-core]: https://github.com/informatici/openhospital-core
 [openhospital-ui]: https://github.com/informatici/openhospital-ui
 [openhospital-doc]: https://github.com/informatici/openhospital-doc
 [contribution-guide]: https://openhospital.atlassian.net/wiki/display/OH/Contribution+Guidelines
 [jira]: https://openhospital.atlassian.net/jira/software/c/projects/OP/issues/
 [database.prop]: https://github.com/informatici/openhospital-core/blob/develop/src/test/resources/database.properties
 [slack]: https://join.slack.com/t/openhospitalworkspace/shared_invite/enQtOTc1Nzc0MzE2NjQ0LWIyMzRlZTU5NmNlMjE2MDcwM2FhMjRkNmM4YzI0MTAzYTA0YTI3NjZiOTVhMDZlNWUwNWEzMjE5ZDgzNWQ1YzE
 [ml]: https://sourceforge.net/projects/openhospital/lists/openhospital-devel
"
40,Susmita-Dey/Sukoon,HTML,"# Sukoon 
This is a stress-relieving website project made for the hackathon [Hackofiesta](https://hack.iiitl.ac.in/). 
This project is under the theme **Healthcare.**
This was our first hackathon.

## 📃 Description 
""Welcome to our stress-relieving website : [Sukoon](https://sukoon-stress-free.netlify.app/)! Here, you'll find a variety of tools and resources to help you manage and reduce stress in your daily life. From carefully crafted playlists and relaxing podcasts, to articles and tips on stress management techniques, our goal is to provide you with a one-stop-shop for all of your stress-relief needs. Whether you're looking for a quick break during a hectic workday, or a longer practice to unwind at night, we've got you covered. Take a look around, try out some of our resources, and let us know if there's anything we can do to improve your experience. Remember, taking care of yourself is just as important as taking care of your work and projects, so don't hesitate to make time for stress relief in your busy schedule.""

## Website Link-
<a href=""https://sukoon-stress-free.netlify.app/"">Sukoon</a>

## 🕊 Our Tagline 
The one step solution to get relief from your stress.
Live a stress-free life.

## 📝 Table of Contents
- [Problem it Solves](#problem_statement)
- [Services](#services)
- [Get Started](#getStarted)
- [Logo](#logo)
- [Screenshots](#screenshots)
- [Technology Stack](#tech_stack)
- [Open-Source program](#open_source_programs)
- [Project Admin](#admin)
- [Contributors](#contributors)

## 🔎 Problems it Solves: <a name = ""problem_statement""></a>
- Gives mental peace 🧘‍♀️
- Reduces stress
- Refreshes mood
- Entertains people
- Motivates people
- Helps people to lead a healthy and succesful life.

## 💼 Our Services <a name = ""services""></a>
- Audio Therapy
- Reading Therapy
- Yoga Therapy
- Laughing Therapy
- Talking Therapy
- Consult A Doctor

## 🚀  Get Started <a name = ""getStarted""></a>
Every contribution counts.
1. Ensure that you have Git installed and working properly.
2. Fork the repo by clicking on 'Fork' above.
3. Clone the project by running git clone <forked_project_url>.
4. Confused about where to start? Check out [good-first-issue](https://github.com/Susmita-Dey/Sukoon/labels/good%20first%20issue).
5. Make a separate branch with the issue name ex. issue#485.
6. You are good to go. Change the code and we will be waiting for your exciting PRs.

For contributing guidelines and standards, visit [contributing.md](https://github.com/Susmita-Dey/Sukoon/blob/main/CONTRIBUTING.md).

## Our Logo <a name = ""logo""></a>
<img src=""./logo.png"" width=140px height=110px alt=""logo"">

## 📸 Screenshots <a name = ""screenshots""></a>
![readmeBanner](https://user-images.githubusercontent.com/98955085/184510782-3f699206-4768-4b3a-aa6d-40c924e13578.png)

## Tech Stack <a name = ""tech_stack""></a>
<img alt=""HTML5"" src=""https://img.shields.io/badge/html5-%23fca9ae.svg?style=for-the-badge&logo=html5&logoColor=140200""/>
<img alt=""CSS3"" src=""https://img.shields.io/badge/css3-%23ffd2ce.svg?style=for-the-badge&logo=css3&logoColor=140200""/>
<img alt=""JavaScript"" src=""https://img.shields.io/badge/javascript-%23e4626b.svg?style=for-the-badge&logo=javascript&logoColor=%23F7DF1E""/>

## Open Source Programs  <a name = ""open_source_programs""></a>
 
<table>
<tr>
 <td align=""center"">
<a href=""https://ssoc.devfolio.co/""><img src=""https://user-images.githubusercontent.com/72400676/182021806-e7439fdd-8f9b-46a6-a1da-0bf731bbe379.png"" width=100px height=100px /><br /><sub><b>Social Summer Of Code 2022</b></sub></a>
 </td>
 <td align=""center"">
<a href=""https://hacktoberfest.com/""><img src=""https://user-images.githubusercontent.com/79099734/195970153-ee19d55b-20fc-4ddb-a91d-000773699c37.png"" width=100px height=100px /><br /><sub><b>Hacktoberfest</b></sub></a>
 </td>
 </tr>
</table>

## 😎 Project Admin <a name = ""admin""></a>

<table>
  <tr>
<td align=""center""><a href=""https://github.com/Susmita-Dey""><img src=""https://avatars.githubusercontent.com/u/79099734?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Susmita Dey</b></sub></a></td>
  </tr>
</table>

<h2>Project Contributors⭐</h2>   <a name = ""contributors""></a>
<table align=""center"">
<tr>
<td>
<a href=""https://github.com/Susmita-Dey/Sukoon/graphs/contributors"" align=""center"">
  <img src=""https://contrib.rocks/image?repo=Susmita-Dey/Sukoon"" /> 
</a>
</td>
</tr>
</table>

---

<p align=""center"">
  Made with ❤ from India.
</p>
"
41,informatici/openhospital-api,Java,"# Open Hospital API

[![Java CI with Maven](https://github.com/informatici/openhospital-api/workflows/Java%20CI%20with%20Maven/badge.svg)](https://github.com/informatici/openhospital-api/actions?query=workflow%3A%22Java+CI+with+Maven%22)

This is the API project of [Open Hospital][openhospital]: it exposes a REST API of the business logic implemented in the [openhospital-core project][core].

## Summary

  * [How to build [WIP]](#how-to-build-wip)
    + [Using Swagger-UI](#using-swagger-ui)
    + [Using Postman](#using-postman)
  * [How to deploy backend in docker environment](#how-to-deploy-backend-in-docker-environment)
  * [Cleaning](#cleaning)
  * [How to contribute](#how-to-contribute)
  * [Community](#community)
  * [Code style](#code-style)

<small>Table of contents generated with <i><a href='http://ecotrust-canada.github.io/markdown-toc/'>markdown-toc</a></i></small>


## How to build [WIP]

For the moment, to build this project you should 

 1. fetch and build the [core] project
    
        git clone https://github.com/informatici/openhospital-core.git
        cd openhospital-core
        mvn clean install -DskipTests=true
        
 2. clone and build this project
 
        git clone https://github.com/informatici/openhospital-api
        cd openhospital-api
        mvn clean install -DskipTests=true
        
 3. prepare settings from each rsc/*.dist file
 
        rsc/application.properties <- set a SHA-256 jwt token
        rsc/database.properties
        rsc/log4j.properties
        rsc/...
 
 4. set target/rsc/database.properties
 
        DB can be created with `docker-compose up` from `openhospital-core` or using a dedicated MySQL server
        
 5. start openhospital-api (in `target` folder)
 
        # Windows
        java -cp ""openhospital-api-0.0.2.jar;rsc/;static/"" org.springframework.boot.loader.JarLauncher

        # Linux
        java -cp ""openhospital-api-0.0.2.jar:rsc/:static/"" org.springframework.boot.loader.JarLauncher
        
 6. call services
    - URL base: http://localhost:8080
    - URL login: http://localhost:8080/auth/login
    - URL patients: http://localhost:8080/patients
    - URL swagger: http://localhost:8080/swagger-ui/

You can see Swagger Api Documentation at: http://localhost:8080/swagger-ui/

![image](https://user-images.githubusercontent.com/2938553/215335720-73d59075-f0df-44c4-93ed-eae79945bb71.png)
   
### Using Swagger-UI

 1. use endpoint /auth/login to login and get the token
 
![image](https://user-images.githubusercontent.com/2938553/228294801-4d27dd2c-9053-4f62-9497-690706232c9f.png)
![image](https://user-images.githubusercontent.com/2938553/228294867-79d6a326-9e7d-4ca0-93cd-ce34c7b7373f.png)
 
 2. use the Authorize button at the top of the Swagger-UI and paste the token form step #1 prefixed by the string ""Bearer "" and click Authorize

![image](https://user-images.githubusercontent.com/2938553/228296149-64905464-441f-4b20-80af-4dcfb40aef4c.png)
 
 3. close the dialog

![image](https://user-images.githubusercontent.com/2938553/228294994-56c1ae3b-f7cb-49b6-94d4-c899fa20374e.png)

 4. now all the endpoints are automatically secured and the token will be added to the request

![image](https://user-images.githubusercontent.com/2938553/228295504-910a6036-4656-4645-8756-3dec0154eed4.png)
![image](https://user-images.githubusercontent.com/2938553/228295166-d1948976-fbdb-4f7e-ab12-8f0621b21373.png)


### Using Postman

 1. import postman_collection.json in your Postman installation
 
## How to deploy backend in Docker environment

Make sure you have docker with docker-compose installed, then run the following commands:

- copy `dotenv` file into `.env` and set variables as needed (the SHA-256 jwt token is needed)
- run `make`
- run `docker compose up -d database` (wait for some seconds the very first time to build the DB)
- (optional - demo data) run `docker compose run --rm oh-database-init`
- run `docker compose up backend`

When done successfully, head over at http://localhost:[API_PORT]/swagger-ui/

You can change the deployment branch using an .env file.

## Cleaning

	docker compose rm --stop --volumes --force
	make clean


## How to contribute

You can find the contribution guidelines in the [Open Hospital wiki][contribution-guide].  
A list of open issues is available on [Jira][jira].

## Community

You can reach out to the community of contributors by joining 
our [Slack workspace][slack] or by subscribing to our [mailing list][ml].


## Code style

This project uses a consistent code style and provides definitions for use in both IntelliJ and Eclipse IDEs.

<details><summary>IntelliJ IDEA instructions</summary>

For IntelliJ IDEA the process for importing the code style is:

* Select *Settings* in the *File* menu
* Select *Editor*
* Select *Code Style*
* Expand the menu item and select *Java*
* Go to *Scheme* at the top, click on the setting button by the side of the drop-down list
* Select *Import Scheme*
* Select *IntelliJ IDE code style XML*
* Navigate to the location of the file which relative to the project root is:  `.ide-settings/idea/OpenHospital-code-style-configuration.xml`
* Select *OK* 
* At this point the code style is stored as part of the IDE and is used for **all** projects opened in the editor.  To restrict the settings to just this project again select the setting button by the side of the *Scheme* list and select *Copy to Project...*. If successful a notice appears in the window that reads: *For current project*.

</details>

<details><summary>Eclipse instructions</summary>

For Eclipse the process requires loading the formatting style and the import order separately.

* Select *Preferences* in the *Window* menu
* Select *Java*
* Select *Code Style* and expand the menu
* Select *Formatter*
* Select the *Import...* button
* Navigate to the location of the file which relative to the project root is:  `.ide-settings/eclipse/OpenHospital-Java-CodeStyle-Formatter.xml`
* Select *Open*
* At this point the code style is stored and is applicable to all projects opened in the IDE.  To restrict the settings just to this project select *Configure Project Specific Settings...* in the upper right.  In the next dialog select the *openhospital* repository and select *OK*.  In the next dialog select the *Enable project specific settings* checkbox.  Finally select *Apply and Close*.
* Back in the *Code Style* menu area, select *Organize Imports*
* Select *Import...*
* Navigate to the location of the file which relative to the project root is:  `.ide-settings/eclipse/OpenHospital.importorder`
* Select *Open*
* As with the formatting styles the import order is applicable to all projects.  In order to change it just for this project repeat the same steps as above for *Configure Project Specific Settings...*
 
</details> 

[openhospital]: https://www.open-hospital.org/
[core]: https://github.com/informatici/openhospital-core
[contribution-guide]: https://openhospital.atlassian.net/wiki/display/OH/Contribution+Guidelines
[jira]: https://openhospital.atlassian.net/jira/software/c/projects/OP/issues/
[slack]: https://join.slack.com/t/openhospitalworkspace/shared_invite/enQtOTc1Nzc0MzE2NjQ0LWIyMzRlZTU5NmNlMjE2MDcwM2FhMjRkNmM4YzI0MTAzYTA0YTI3NjZiOTVhMDZlNWUwNWEzMjE5ZDgzNWQ1YzE
[ml]: https://sourceforge.net/projects/openhospital/lists/openhospital-devel
"
42,brishi19791/HealthCare-WebApplication,Java,"# HealthCare-WebApplication
Health care web application using Spring MVC, Hibernate, MySQL

In order to run the project, we have to create few useraccounts for login.

Should run java file present in below path which will create admin,doctor,nurse,lab assistant and pharmacist:
src\test\java\com\neu\project\Mapping.java

Flow of the Project:
======================
1) Admin can create doctor, nurse,lab assistant and pharmacist
2)Patient should register and select a primary doctor.
3)Nurse will take vitalSigns of the patient and send those to respective primary doctor
4)Doctor will see the vitalSigns of the patient and decides to diagnose or give medication to the patient.
	4.1) If doctor wants to diagnose he can send a work request to the lab assistant by selecting kind of lab test.
	4.2) If doctor wants to give medication, he can select a drug which should be manufactured by the pharmacist
5)Pharmacist will manufacture the drugs.
6)Lab assistant will get work request from the doctor to send the lab test reports for a patient.
7) Patient can login to see there encounterList, Lab test reports and medication provided by doctor.

"
43,baoxuliang/healthcaredatastandard,,"中国卫生信息标准
======================

## 概述

在09年新医改之后，国家层面上对卫生信息标准的重视程度也算是提高了，也有一些不错的进展，整体上还是偏慢，无法满足新形势下的医疗类应用和系统的开发。

引用汤处的一张图，目前国家层面上的卫生信息标准体系如下
![](overview.png)

目前已存在的数量
![](standard number -201506.png)


## 基础类

| 编号  | 名称 | 
| ----  | ---- | 
| WS/T 303-2009  | 卫生信息数据元标准化规则 | 
|  WS/T 304-2009  | 卫生信息数据模式描述指南 | 
|  WS/T 305-2009  | 卫生信息数据集元数据规范 | 
|  WS/T 306-2009  | 卫生信息数据集分类与编码规则 | 
|  WS/T 370-2012  | 卫生信息基本数据集编制规范 | 
|  WS/T 482-2016  | 卫生信息共享文档编制规范 | 


## 数据类
             
### 数据元

| 编号  | 名称 | 
| ----  | ---- | 
| WS 363-2011  | 卫生信息数据元目录 第1-17部分 | 
| WS 364-2011  | 卫生信息数据元值域代码 第1-17部分 | 

| 标准编号 |   标准中文名称 |  标识符范围 |  数据元数目 | 
| ----  | ---- |  ---- |  ---- | 
| WS363.1-2011| 卫生信息数据元目录第1部分:总则 	| 		| 	| 
| WS363.2-2011| 卫生信息数据元目录第2部分:标识	| DE01.00.001.00-DE01.00.015.00	| 13
| WS363.3-2011| 	卫生信息数据元目录第3部分:人口学及社会经济学特征	| DE02.01.001.00-DE02.01.058.00	| 62
| WS363.4-2011 |  	卫生信息数据元目录第4部分:健康史	| DE02.10.001.00-DE02.10.096.00	| 90
| WS363.5-2011 | 	卫生信息数据元目录第5部分:健康危险因素	| DE03.00.001.00-DE03.00.099.00	| 98
| WS363.6-2011 | 	卫生信息数据元目录第6部分:主诉与症状	| DE04.01.001.00-DE04.01.120.00	| 119
| WS363.7-2011 | 	卫生信息数据元目录第7部分:体格检查	| DE04.10.001.00-DE04.10.243.00	| 241
| WS363.8-2011 | 	卫生信息数据元目录第8部分:临床辅助检查	| DE04.30.001.00-DE04.30.051.00	| 51
| WS363.9-2011 | 	卫生信息数据元目录第9部分:实验室检查	| DE04.50.001.00-DE04.50.129.00	| 129
| WS363.10-2011| 	卫生信息数据元目录第10部分:医学诊断	| DE05.01.001.00-DE05.01.073.00	| 73
| WS363.11-2011	| 卫生信息数据元目录第11部分:医学评估	| DE05.10.001.00-DE05.10.128.00	| 127
| WS363.12-2011	| 卫生信息数据元目录第12部分:计划与干预	| DE06.00.001.00-DE06.00.177.00	| 175
| WS363.13-2011	| 卫生信息数据元目录第13部分:卫生费用	| DE07.00.001.00-DE07.00.010.00	| 10
| WS363.14-2011	| 卫生信息数据元目录第14部分:卫生机构	| DE08.10.001.00-DE08.10.053.00	| 53
| WS363.15-2011	| 卫生信息数据元目录第15部分:卫生人员	| DE08.30.001.00-DE08.30.031.00	| 31
| WS363.16-2011	| 卫生信息数据元目录第16部分:药品、设备与材料	| DE08.50.001.00-DE08.50.025.00	| 25
| WS363.17-2011	| 卫生信息数据元目录第17部分:卫生管理	| DE09.00.001.00-DE09.00.102.00	| 102

### 代码与编码

| 编号  | 名称 | 
| ----  | ---- | 
| WS 364-2011  | 卫生信息数据元值域代码 第1-17部分 | 
| WS xxx-2013  | 卫生统计指标目录 第1-10部分 | 
| GB xxx-2013  | 疾病分类与代码 | 
| WS 446-2014  |  居民健康档案医学检验项目常用代码 | 
| WS xxx-2013  |  医疗服务项目分类与编码 | 


### 数据集

| 编号  | 名称 | 
| ----  | ---- | 
| WS 365-2011  | 城乡居民健康档案基本数据集 | 
| WS 371-2012  | 基本信息基本数据集 个人信息 | 
| WS 372-2012  | 疾病管理基本数据集  第1-6部分 | 
| WS 373-2012  | 医疗服务基本数据集 第1-3部分 | 
| WS 374-2012  | 卫生管理基本数据集 第1-4部分 | 
| WS 375-2012  | 疾病控制基本数据集 第1-23部分 | 
| WS 376-2013  | 儿童保健基本数据集 第1-5部分 | 
| WS 377-2013  | 妇女保健基本数据集 第1-7部分 | 
| WS xxx-2013  | 卫生应急管理基本数据集 第1-5部分 | 
| WS xxx-2013  | 医学数字影像通信基本数据集 | 
| WS xxx-2013  | 新型农村合作医疗基本数据集 | 
| WS xxx-2013  | 居民健康卡数据集 | 
| WS xxx-2013  | 居民健康卡注册管理信息系统基本数据集 | 


| 数据集名称	| 所属类别	| 所属标准编号	| 所属标准名称   |   
| ----  | ---- |  ---- |  ---- |       
| 个人基本信息	| 基本信息	| WS365	| 城乡居民健康档案基本数据集      | 
| 健康体检信息	| 健康体检	| WS365	| 城乡居民健康档案基本数据集      | 
| 新生儿家庭访视信息	| 儿童保健	| WS365	| 城乡居民健康档案基本数据集         | 
| 儿童健康检查信息	| 儿童保健	| WS365	| 城乡居民健康档案基本数据集       | 
| 产前随访服务信息	| 妇女保健	| WS365	| 城乡居民健康档案基本数据集     | 
| 产后访视服务信息	| 妇女保健	| WS365	| 城乡居民健康档案基本数据集      | 
| 产后42天健康体检信息	| 妇女保健	| WS365	| 城乡居民健康档案基本数据集|       
| 预防接种卡信息	| 疾病控制	| WS365	| 城乡居民健康档案基本数据集  |     
| 传染病报告卡信息	| 疾病控制	| WS365	| 城乡居民健康档案基本数据集| 
| 职业病报告卡信息	| 疾病控制	| WS365| 城乡居民健康档案基本数据集       |  
| 食源性疾病报告卡信息	| 疾病控制	| WS365	| 城乡居民健康档案基本数据集 |       
| 高血压患者随访信息	| 疾病管理	| WS365	| 城乡居民健康档案基本数据集 |      
| 2型糖尿病患者随访信息	| 疾病管理	| WS365	| 城乡居民健康档案基本数据集  |      
| 重性精神疾病患者管理信息	| 疾病管理	| WS365	| 城乡居民健康档案基本数据集   |        
| 门诊摘要信息	| 医疗服务	| WS365	| 城乡居民健康档案基本数据集   |    
| 住院摘要信息	| 医疗服务	| WS365	| 城乡居民健康档案基本数据集  |    
| 会诊信息	| 医疗服务	| WS365	| 城乡居民健康档案基本数据集      | 
| 转院(诊)信息	| 医疗服务	| WS365	| 城乡居民健康档案基本数据集  | 

强制性卫生行业标准

| 标准编号 |   标准中文名称 | 数据元数目 | 性质 | 
| ----  | ---- |  ---- | 强制性卫生行业标准|  
| WS 371-2012 		| 基本信息基本数据集 个人信息		| 68
| WS 376.1-2013		| 儿童保健基本数据集 第1部分 出生医学证明		| 39
| WS 376.2-2013		| 儿童保健基本数据集 第2部分：儿童健康体检		| 61
| WS 376.3-2013		| 儿童保健基本数据集 第3部分：新生儿疾病筛查		| 41
| WS 376.4-2013		| 儿童保健基本数据集 第4部分：体弱儿童管理		| 33
| WS 376.5-2013		| 儿童保健基本数据集 第5部分：5岁以下儿童死亡报告		| 27
| WS 377.1-2013		| 妇女保健基本数据集 第1部分：婚前保健服务		| 122
| WS 377.2-2013		| 妇女保健基本数据集 第2部分 妇女病普查		| 74
| WS 377.3-2013		| 妇女保健基本数据集 第3部分计划生育技术服务		| 131
| WS 377.4-2013		| 妇女保健基本数据集 第4部分孕产期保健服务与高危管理		| 244
| WS 377.5-2013		| 妇女保健基本数据集 第5部分产前筛查与诊断		| 31
| WS 377.6-2013		| 妇女保健基本数据集 第6部分出生缺陷监测		| 48
| WS 377.7-2013		| 妇女保健基本数据集 第7部分孕产妇死亡报告		| 39
| WS 375.1-2012 	| 疾病控制基本数据集 第1部分：艾滋病综合防治		| 71
| WS 375.2-2012 	| 疾病控制基本数据集 第2部分：血吸虫病病人管理		| 115
| WS 375.3-2012		|  疾病控制基本数据集 第3部分：慢性丝虫病病人管理		| 73
| WS 375.4-2012	 	| 疾病控制基本数据集 第4部分：职业病报告		| 63
| WS 375.5-2012	    | 疾病控制基本数据集 第5部分：职业性健康监护		| 261
| WS 375.6-2012 	| 疾病控制基本数据集 第6部分：伤害监测报告		| 41
| WS 375.7-2012 	| 疾病控制基本数据集 第7部分：农药中毒报告		| 33
| WS 375.8-2012 	| 疾病控制基本数据集 第8部分：行为危险因素监测		| 56
| WS 375.9-2012 	| 疾病控制基本数据集 第9部分：死亡医学证明		| 49
| WS 375.10-2012 	| 疾病控制基本数据集 第10部分：传染病报告		| 33
| WS 375.11-2012 	| 疾病控制基本数据集 第11部分：结核病报告		| 78
| WS 375.12-2012 	| 疾病控制基本数据集 第12部分：预防接种		| 42
| WS 375.14-2016 	| 疾病控制基本数据集 第14部分：学校缺勤缺课监测报告 |          
| WS 375.15-2016 	| 疾病控制基本数据集 第15部分：托幼机构缺勤监测报告 |          
| WS 375.18-2016 	| 疾病控制基本数据集 第18部分：疑似预防接种异常反应报告 |          
| WS 375.19-2016 	| 疾病控制基本数据集 第19部分：疫苗管理 |        
| WS 375.20-2016 	| 疾病控制基本数据集 第20部分：脑卒中登记报告 |    
| WS 375.21-2016 	| 疾病控制基本数据集 第21部分：脑卒中病人管理 |    
| WS 375.22-2016 	| 疾病控制基本数据集 第22部分：宫颈癌筛查登记 |    
| WS 375.23-2016 	| 疾病控制基本数据集 第23部分：大肠癌筛查登记 |    
| WS 372.1-2012 	| 疾病管理基本数据集 第1部分：乙肝患者管理		| 106
| WS 372.2-2012		| 疾病管理基本数据集 第2部分：高血压患者健康管理	| 106
| WS 372.3-2012 	| 疾病管理基本数据集 第3部分：重性精神疾病患者管理		| 118
| WS 372.4-2012 	| 疾病管理基本数据集 第4部分：老年人健康管理		| 102
| WS 372.5-2012 	| 疾病管理基本数据集 第5部分：2型糖尿病患者健康管理		| 113
| WS 372.6-2012 	| 疾病管理基本数据集 第6部分：肿瘤病例管理		| 72
| WS 373.1-2012 	| 医疗服务基本数据集 第1部分：门诊摘要		| 62
| WS 373.2-2012 	| 医疗服务基本数据集 第2部分：住院摘要		| 72
| WS 373.3-2012	   | 医疗服务基本数据集 第3部分：成人健康体检		| 182
| WS 374.1-2012 		| 卫生管理基本数据集 第1部分：卫生监督检查与行政处罚		| 62
| WS 374.2-2012 		| 卫生管理基本数据集 第2部分：卫生监督行政许可与登记		|92
| WS 374.3-2012 		| 卫生管理基本数据集 第3部分：卫生监督监测与评价		|22
| WS 374.4-2012 		| 卫生管理基本数据集 第4部分：卫生监督机构与人员		|105




| 标准编号 |   标准中文名称 | 数据元数目 | 性质 | 
| ----  | ---- |  ---- | 强制性卫生行业标准|     
| WS 445.1-2014 		| 电子病历基本数据集 第1部分：病历概要  		|  xx               
| WS 445.2-2014 		| 电子病历基本数据集 第2部分：门（急）诊病历  		|  xx               
| WS 445.3-2014 		| 电子病历基本数据集 第3部分：门（急）诊处方  		|  xx               
| WS 445.4-2014 		| 电子病历基本数据集 第4部分：检查检验记录  		|  xx               
| WS 445.5-2014 		| 电子病历基本数据集 第5部分：一般治疗处置记录  		|  xx               
| WS 445.6-2014 		| 电子病历基本数据集 第6部分：助产记录  		|  xx               
| WS 445.7-2014 		| 电子病历基本数据集 第7部分：护理操作记录  		|  xx               
| WS 445.8-2014 		| 电子病历基本数据集 第8部分：护理评估与计划  		|  xx               
| WS 445.9-2014 		| 电子病历基本数据集 第9部分：知情告知信息  		|  xx               
| WS 445.10-2014 		| 电子病历基本数据集 第10部分：住院病案首页  		|  xx               
| WS 445.11-2014 		| 电子病历基本数据集 第11部分：中医住院病案首页  		|  xx               
| WS 445.12-2014 		| 电子病历基本数据集 第12部分：入院记录  		|  xx               
| WS 445.13-2014 		| 电子病历基本数据集 第13部分：住院病程记录  		|  xx               
| WS 445.14-2014 		| 电子病历基本数据集 第14部分：住院医嘱  		|  xx               
| WS 445.15-2014 		| 电子病历基本数据集 第15部分：出院小结  		|  xx               
| WS 445.16-2014 		| 电子病历基本数据集 第16部分：转诊(院)记录  		|  xx               
| WS 445.17-2014 		| 电子病历基本数据集 第17部分：医疗机构信息  		|  xx               



### 共享文档

## 技术类

### 功能规范

| 编号  | 名称 | 
| ----  | ---- | 
| WS/T 452-2014  | 卫生监督信息系统功能规范 | 
| WS/T xxx-2013  | 妇幼保健信息系统基本功能规范 | 
| WS/T xxx-2013  | 基层医疗卫生信息系统功能规范 | 
| WS/T 451-2014  | 院前医疗急救指挥信息系统基本功能规范 | 
| WS/T 450-2014  | 新型农村合作医疗信息系统基本功能规范 | 
| WS/T 449-2014  | 慢性病监测信息系统基本功能规范 | 
| WS/T 529-2016  | 远程医疗信息系统基本功能规范 | 推荐性卫生行业标准 |
| WS/T xxx-2013  | 医院感染管理信息系统基本功能规范 | 
| WS/T xxx-2013  | 免疫规划信息系统基本功能规范(征求意见稿) | 

### 技术规范

| 编号  | 名称 | 
| ----  | ---- | 
| WS/T 448-2014  | 基于健康档案的区域卫生信息平台技术规范 | 
| WS/T 447-2014  | 基于电子病历的医院信息平台技术规范 | 
| WS/T xxx-2013  | 居民健康卡技术规范 | 
| WS/T xxx-2013  | 远程医疗信息系统技术规范 | 
| WS/T 526-2016  | 妇幼保健服务信息系统技术规范 | 
| WS/T xxx-2013  | 医学数字影像中文封装与通信规则 | 
| WS/T xxx-2013  | 区域疾病控制业务应用子平台技术规范 | 
| WS/T 517-2016  | 基层医疗卫生信息系统技术规范 | 
| WS/T xxx-2013  | 远程医疗设备及统一通讯交互规范(征求意见稿) | 
| WS/T xxx-2013  | 区域卫生信息平台交互规范(征求意见稿) | 
| WS/T xxx-2013  | 医院信息平台交互规范(征求意见稿) | 

### 安全与隐私

### 传输与交换

| 编号  | 名称 |  性质 | 
| ----  | ---- |  ---- | 
| WS/T 483.1-2016  | 健康档案共享文档规范 第1部分：个人基本健康信息登记 | 推荐性卫生行业标准 |            
| WS/T 483.2-2016  | 健康档案共享文档规范 第2部分：出生医学证明 | 推荐性卫生行业标准 |            
| WS/T 483.3-2016  | 健康档案共享文档规范 第3部分：新生儿家庭访视 | 推荐性卫生行业标准 |            
| WS/T 483.4-2016  | 健康档案共享文档规范 第4部分：儿童健康体检 | 推荐性卫生行业标准 |            
| WS/T 483.5-2016  | 健康档案共享文档规范 第5部分：首次产前随访服务 | 推荐性卫生行业标准 |            
| WS/T 483.6-2016  | 健康档案共享文档规范 第6部分：产前随访服务 | 推荐性卫生行业标准 |            
| WS/T 483.7-2016  | 健康档案共享文档规范 第7部分：产后访视 | 推荐性卫生行业标准 |            
| WS/T 483.8-2016  | 健康档案共享文档规范 第8部分：产后42天健康检查 | 推荐性卫生行业标准 |            
| WS/T 483.9-2016  | 健康档案共享文档规范 第9部分：预防接种报告 | 推荐性卫生行业标准 |  
| WS/T 483.10-2016  | 健康档案共享文档规范 第10部分：传染病报告 | 推荐性卫生行业标准 |            
| WS/T 483.11-2016  | 健康档案共享文档规范 第11部分：死亡医学证明 | 推荐性卫生行业标准 |            
| WS/T 483.12-2016  | 健康档案共享文档规范 第12部分：高血压患者随访服务 | 推荐性卫生行业标准 |            
| WS/T 483.13-2016  | 健康档案共享文档规范 第13部分：2型糖尿病患者随访服务 | 推荐性卫生行业标准 |            
| WS/T 483.14-2016  | 健康档案共享文档规范 第14部分：重性精神疾病患者个人信息登记 | 推荐性卫生行业标准 |            
| WS/T 483.15-2016  | 健康档案共享文档规范 第15部分：重性精神疾病患者随访服务 | 推荐性卫生行业标准 |            
| WS/T 483.16-2016  | 健康档案共享文档规范 第16部分：成人健康体检 | 推荐性卫生行业标准 |            
| WS/T 483.17-2016  | 健康档案共享文档规范 第17部分：门诊摘要 | 推荐性卫生行业标准 |            
| WS/T 483.18-2016  | 健康档案共享文档规范 第18部分：住院摘要 | 推荐性卫生行业标准 |            
| WS/T 483.19-2016  | 健康档案共享文档规范 第19部分：会诊记录 | 推荐性卫生行业标准 |            
| WS/T 483.20-2016  | 健康档案共享文档规范 第20部分：转诊(院)记录 | 推荐性卫生行业标准 |            

| 编号  | 名称 |  性质 | 
| ----  | ---- |  ---- | 
| WS/T 500.1-2016  | 电子病历共享文档规范 第1部分：病历概要 | 推荐性卫生行业标准 |            
| WS/T 500.2-2016  | 电子病历共享文档规范 第2部分：门(急)诊病历 | 推荐性卫生行业标准 |            
| WS/T 500.3-2016  | 电子病历共享文档规范 第3部分：急诊留观病历 | 推荐性卫生行业标准 |            
| WS/T 500.4-2016  | 电子病历共享文档规范 第4部分：西药处方 | 推荐性卫生行业标准 |            
| WS/T 500.5-2016  | 电子病历共享文档规范 第5部分：中药处方 | 推荐性卫生行业标准 |            
| WS/T 500.6-2016  | 电子病历共享文档规范 第6部分：检查报告 | 推荐性卫生行业标准 |            
| WS/T 500.7-2016  | 电子病历共享文档规范 第7部分：检验报告 | 推荐性卫生行业标准 |            
| WS/T 500.8-2016  | 电子病历共享文档规范 第8部分：治疗记录 | 推荐性卫生行业标准 |            
| WS/T 500.9-2016  | 电子病历共享文档规范 第9部分：一般手术记录 | 推荐性卫生行业标准 |            
| WS/T 500.10-2016  | 电子病历共享文档规范 第10部分：麻醉术前访视记录 | 推荐性卫生行业标准 |            
| WS/T 500.11-2016  | 电子病历共享文档规范 第11部分：麻醉记录 | 推荐性卫生行业标准 |            
| WS/T 500.12-2016  | 电子病历共享文档规范 第12部分：麻醉术后访视记录 | 推荐性卫生行业标准 |            
| WS/T 500.13-2016  | 电子病历共享文档规范 第13部分：输血记录 | 推荐性卫生行业标准 |            
| WS/T 500.14-2016  | 电子病历共享文档规范 第14部分：待产记录 | 推荐性卫生行业标准 |            
| WS/T 500.15-2016  | 电子病历共享文档规范 第15部分：阴道分娩记录 | 推荐性卫生行业标准 |            
| WS/T 500.16-2016  | 电子病历共享文档规范 第16部分：剖宫产记录 | 推荐性卫生行业标准 |            
| WS/T 500.17-2016  | 电子病历共享文档规范 第17部分：一般护理记录 | 推荐性卫生行业标准 |            
| WS/T 500.18-2016  | 电子病历共享文档规范 第18部分：病重（病危）护理记录 | 推荐性卫生行业标准 |            
| WS/T 500.19-2016  | 电子病历共享文档规范 第19部分：手术护理记录 | 推荐性卫生行业标准 |            
| WS/T 500.20-2016  | 电子病历共享文档规范 第20部分：生命体征测量记录 | 推荐性卫生行业标准 |            
| WS/T 500.21-2016  | 电子病历共享文档规范 第21部分：出入量记录 | 推荐性卫生行业标准 |            
| WS/T 500.22-2016  | 电子病历共享文档规范 第22部分：高值耗材使用记录 | 推荐性卫生行业标准 |            
| WS/T 500.23-2016  | 电子病历共享文档规范 第23部分：入院评估 | 推荐性卫生行业标准 |            
| WS/T 500.24-2016  | 电子病历共享文档规范 第24部分：护理计划 | 推荐性卫生行业标准 |            
| WS/T 500.25-2016  | 电子病历共享文档规范 第25部分：出院评估与指导 | 推荐性卫生行业标准 |            
| WS/T 500.26-2016  | 电子病历共享文档规范 第26部分：手术知情同意书 | 推荐性卫生行业标准 |            
| WS/T 500.27-2016  | 电子病历共享文档规范 第27部分：麻醉知情同意书 | 推荐性卫生行业标准 |            
| WS/T 500.28-2016  | 电子病历共享文档规范 第28部分：输血治疗同意书 | 推荐性卫生行业标准 |            
| WS/T 500.29-2016  | 电子病历共享文档规范 第29部分：特殊检查及特殊治疗同意书 | 推荐性卫生行业标准 |            
| WS/T 500.30-2016  | 电子病历共享文档规范 第30部分：病危(重)通知书 | 推荐性卫生行业标准 |            
| WS/T 500.31-2016  | 电子病历共享文档规范 第31部分：其他知情告知同意书 | 推荐性卫生行业标准 |            
| WS/T 500.32-2016  | 电子病历共享文档规范 第32部分：住院病案首页 | 推荐性卫生行业标准 |            
| WS/T 500.33-2016  | 电子病历共享文档规范 第33部分：中医住院病案首页 | 推荐性卫生行业标准 |            
| WS/T 500.34-2016  | 电子病历共享文档规范 第34部分：入院记录 | 推荐性卫生行业标准 |            
| WS/T 500.35-2016  | 电子病历共享文档规范 第35部分：24小时内入出院记录 | 推荐性卫生行业标准 |            
| WS/T 500.36-2016  | 电子病历共享文档规范 第36部分：24小时内入院死亡记录 | 推荐性卫生行业标准 |            
| WS/T 500.37-2016  | 电子病历共享文档规范 第37部分：住院病程记录  首次病程记录 | 推荐性卫生行业标准 |            
| WS/T 500.38-2016  | 电子病历共享文档规范 第38部分：住院病程记录  日常病程记录 | 推荐性卫生行业标准 |            
| WS/T 500.39-2016  | 电子病历共享文档规范 第39部分：住院病程记录  上级医师查房记录 | 推荐性卫生行业标准 |            
| WS/T 500.40-2016  | 电子病历共享文档规范 第40部分：住院病程记录  疑难病例讨论记录 | 推荐性卫生行业标准 |            
| WS/T 500.41-2016  | 电子病历共享文档规范 第41部分：住院病程记录  交接班记录 | 推荐性卫生行业标准 |            
| WS/T 500.42-2016  | 电子病历共享文档规范 第42部分：住院病程记录 转科记录 | 推荐性卫生行业标准 |            
| WS/T 500.43-2016  | 电子病历共享文档规范 第43部分：住院病程记录 阶段小结 | 推荐性卫生行业标准 |            
| WS/T 500.44-2016  | 电子病历共享文档规范 第44部分：住院病程记录 抢救记录 | 推荐性卫生行业标准 |            
| WS/T 500.45-2016  | 电子病历共享文档规范 第45部分：住院病程记录 会诊记录 | 推荐性卫生行业标准 |            
| WS/T 500.46-2016  | 电子病历共享文档规范 第46部分：住院病程记录 术前小结 | 推荐性卫生行业标准 |           
| WS/T 500.47-2016  | 电子病历共享文档规范 第47部分：住院病程记录 术前讨论 | 推荐性卫生行业标准 |            
| WS/T 500.48-2016  | 电子病历共享文档规范 第48部分：住院病程记录术后 首次病程记录 | 推荐性卫生行业标准 |            
| WS/T 500.49-2016  | 电子病历共享文档规范 第49部分：住院病程记录 出院记录 | 推荐性卫生行业标准 |            
| WS/T 500.50-2016  | 电子病历共享文档规范 第50部分：住院病程记录 死亡记录 | 推荐性卫生行业标准 |            
| WS/T 500.51-2016  | 电子病历共享文档规范 第51部分：住院病程记录 死亡病例讨论记录 | 推荐性卫生行业标准 |            
| WS/T 500.52-2016  | 电子病历共享文档规范 第52部分：住院医嘱 | 推荐性卫生行业标准 |            
| WS/T 500.53-2016  | 电子病历共享文档规范 第53部分：出院小结 | 推荐性卫生行业标准 |            
          


## 管理类

### 建设指南

| 编号  | 名称 | 
| ----  | ---- | 
| WS/T xxx-2009  | 综合卫生管理信息平台建设指南（征求意见稿） | 


### 测试与评价

| 编号  | 名称 | 
| ----  | ---- | 
| WS/T 502-2016  | 电子健康档案与区域卫生信息平台标准符合性测试规范 | 
| WS/T 501-2016  | 电子病历与医院信息平台标准符合性测试规范 | 

### 运维管理

### 监理与验收

## 参考          

1、[国家卫生信息标准与实施评价 汤学军 CHINC2015]()
2、[中国卫生信息标准网](http://www.chiss.org.cn/hism/wcmpub/hism1029/index/)
## 更新日志

2017-03-07日更新
1.对于 README.md 中的标准编号进行了更新          
参考国卫通[2016]12号    


2014-11-13日更新
1.对于 ""数据集标准/Excel/WS365城乡居民健康档案基本数据集.xlsx""      
* 5.2.03新生儿家庭访视信息第56行 HDSD00.01,261 修改为 5.2.03新生儿家庭访视信息第56行 HDSD00.01.261(逗号改为点)       
* 5.2.01个人基本信息 第二行为空行 移除       
* 5.2.04儿童健康检查信息 第一列删除 与其他表单保持格式一致        
* 5.2.09传染病报告卡信息第23行 Hr)SD00.01.379  修改为 5.2.09传染病报告卡信息第23行 HDSD00.01.379                 
* 5.2.09传染病报告卡信息第33行 HDSD00. 01.407 修改为 5.2.09传染病报告卡信息第33行 HDSD00.01.407(00.01.407 原来01前面有空格)     
* 5.2.09传染病报告卡信息第38行 HDSD00. 01.412 修改为 5.2.09传染病报告卡信息第38行 HDSD00.01.412 (00.01.412原来01前面有空格)      
* 5.2.18转诊(院)信息第49行 HDSD00,01.571 修改为 5.2.18转诊(院)信息第49行 HDSD00.01.571(逗号改为点)      
2.对于""WS369-375卫生信息基本数据集.xlsx""      
* 儿童保健基本数据集 第2部分 儿童健康体检第62行 29  删除第62行                
* 疾病管理基本数据集 第1部分 乙肝患者管理第37行 HDSB04,01.037 修改为 疾病管理基本数据集 第1部分 乙肝患者管理第37行 HDSB04.01.037(逗号改为点)     
* 疾病管理基本数据集 第1部分 乙肝患者管理第97行  HDSB04,01.097  修改为   HDSB04.01.097  (逗号改为点)       
* 疾病管理基本数据集 第4部分 老年人健康管理第90行  HDSB04,04.090 修改为  HDSB04.04.090       
* 疾病管理基本数据集 第6部分 肿瘤病例管理第30行  HDSB04,06.030 修改为  HDSB04.06.030     
* 疾病管理基本数据集 第6部分 肿瘤病例管理第61行  HDSB04.06.06] 修改为  HDSB04.06.061(拿掉] )       
3.对于""数据元标准/Excel/卫生信息数据元目录.xlsx""          
*                   
*
*
*




"
44,abhishek-ch/streamlit-healthcare-ML-App,Python,"
![](https://assets.website-files.com/5dc3b47ddc6c0c2a1af74ad0/5e0a328bedb754beb8a973f9_logomark_website.png)

# Streamlit Healthcare Machine Learning Data App

![](extra/StreamlitML.gif)

## Objective
1. How easy is it to create a Web App using Streamlit
2. Integrating multiple #machinelearning technologies in the same app
3. Code reusability
4. Streamlit functions & feature usage

>  of-course Dockerize!

## Running the App

1. Checkout the code
 ```
 git checkout
``` 
2. Build the docker image
```buildoutcfg
docker build --tag streamlit-healthcare:1.0 .
```
3. Run the docker image
```buildoutcfg
docker run -it -p 8501:8501 streamlit-healthcare:1.0
```
4. Browse the [url](http://localhost:8501)

## Features
* Load Healthcare data from Kaggle https://www.kaggle.com/sulianova/cardiovascular-disease-dataset
* Use __scikit-learn__ ML lib to run classification.
* Provide Tuning param options in the UI 
* Provide Switch to enable __PySpark__
* Provide Pyspark MLlib options over the same data, technically one can compare 
the result between 2 seperate libraries
* Plotting using Seaborn chart

## Conclusion

Streamlit is essentially a very straightforward easy library to create
python based Webapp. 
I am Convinced 👏👏👏"
45,GoogleCloudPlatform/healthcare-api-dicomweb-cli,Python,"# DICOMweb command line tool
DICOMweb command line tool is a command line utility for interacting with DICOMweb servers.

## Requirements

- python (3.5+)
- pip

## Installation

### Using GitHub:

```bash
pip install https://github.com/GoogleCloudPlatform/healthcare-api-dicomweb-cli/archive/v1.0.2.zip
```

NOTE: Getting errors due to not having Python3? See [instructions below](#running-on-machine-with-python2).

## Interface

### dcmweb [-m] \<host> \<store|retrieve|search|delete> [parameters]

* **-m**
\
 Whether to perform batch operations in parallel or sequentially, default is sequentially.

* **host**
\
 The full DICOMweb endpoint URL. E.g. `https://healthcare.googleapis.com/v1/projects/<project_id>/locations/<location_id>/datasets/<dataset_id>/dicomStores/<dicom_store_id>/dicomWeb`

* **store**
\
 Stores one or more files by posting multiple StoreInstances requests. Requests will be sent in sequence or in parallel based on the -m flag.
 
 	* --masks \*string
	\
	Positional argument, contains list of file paths or masks to upload, mask support wildcard(\*) and cross directory boundaries wildcard(\*\*) char, 


* **retrieve**
\
 Retrieves one or more studies, series, instances, or frames from the server. Outputs the instances to the directory specified by the --output option.

	* --path string
	\
	Positional argument, can either be empty (indicates downloading of all studies) or specify a resource path (studies/<uid>[/series/<uid>[/instances/<uid>[/frames/<frame_num]]]) to download from the server

	* --type string
	\
	Controls what format to request the files in (defaults to application/dicom; transfer-syntax=*). The tool will use this as the part content type in the multipart accept header being sent to the server. 

	* --output string
	\
	Controls where to write the files to (defaults to current directory).
	The following folder structure will be created:
	\
		```
		- study_uid
			- series_uid
				- instance_uid[_frame_X].<ext>
		```



* **search**
\
Performs a search over studies, series, or instances and outputs the result to stdout, limited to 5000 items by default. You can specify limit/offset parameters to change this.

    * --path string
	\
	Positional argument, specifies a path (studies/[<uid>/series/[<uid>/instances/]]) to search on the server, default is ""/studies""

    * --parameters string
	\
	QIDO search parameters formatted as URL query parameters.

* **delete**
\
 Deletes the given study, series, or instance from the server. Uses an un-standardized extension to the DICOMweb spec.

    * --path string
    \
	Positional argument, specifies a resource path (studies/<uid>[/series/<uid>[/instances/<uid>[/frames/<frame_num]]]) to delete from the server

## Examples

**search**

```bash
# will return json list of instances in dicomstore with date==1994.10.13
dcmweb $host search instances StudyDate=19941013 
```

```bash
# will return list of studies without any filter
dcmweb $host search 
```

Since search returns JSON data it can be redirected into parse tools like [jq](https://stedolan.github.io/jq/).

```bash
# will parse StudyUIDs/PatientNames for each study in search results
dcmweb $host search | jq '.[] | .[""0020000D""].Value[0],.[""00100010""].Value[0]'
```

Output of jq may be redirected as well:
```bash
# will parse StudyUIDs for each study in search results
# and count lines of jq output by wc
dcmweb $host search | jq '.[] | .[""0020000D""].Value[0]' | wc -l
```
The list of DICOM tags can be found in this [page](https://dicom.innolitics.com/ciods/).

**store**

```bash
# will upload list of files generated from current folder by shell
dcmweb $host store ./* 
```

```bash
# will upload list of files generated from current folder by python
dcmweb $host store ""./*"" 
```

```bash
# will upload list of files generated from current folder recursively by python
dcmweb $host store ""./**"" 
```

```bash
# will upload list of files in parallel
dcmweb -m $host store ""./**"" 
```
**retrieve**

```bash
# will download all instances from dicomstore into current folder
dcmweb $host retrieve 
```

```bash
# will download all instances from dicomstore into current folder in parallel
dcmweb -m $host retrieve 
```

```bash
# will download all instances from dicomstore into ./data folder
dcmweb $host retrieve --output ./data 
```

```bash
# will download all instances from dicomstore into ./data folder as png images,
# in instance is multiframe, frames will be saved as separate files
dcmweb $host retrieve --output ./data --type ""image/png"" 
```

```bash
# will download all instances from study 1 into ./data folder
dcmweb $host retrieve studies/1 --output ./data 
```

**delete**

```bash
# will delete study 1
dcmweb $host delete studies/1
```

## Build

```bash
python ./setup.py sdist bdist_wheel 
```
## Run tests

```bash
pip install tox
tox
```

## Developing

See [CONTRIBUTING.md](CONTRIBUTING.md)

## Running on machine with Python2

This tool requires Python3 to be run which may cause issues for environments that
have Python2 installed and can't upgrade due to other dependencies. Here are 2 options
for getting the tool to work in this enviornment:

### Using pip local install

1.  Install python3 & python3-pip (e.g. `sudo apt install python3 python3-pip`)
1.  Download zip file from latest release from
    [GitHub](https://github.com/GoogleCloudPlatform/healthcare-api-dicomweb-cli/releases)
1.  Run `python3 -m pip install healthcare-api-dicomweb-cli-X.Y.zip --user`
1.  Run `export PATH=$PATH:""${HOME}/.local/bin""` -- this is where pip --user
    installs things to
1.  Then you should be able to run `dcmweb`

### Using virtualenv

1.  Install python3 & python3-venv (e.g. `sudo apt install python3 python3-venv`)
1.  Start a virtualenv `python3 -m venv py3-env && cd py3-env && source ./bin/activate`
1.  Download zip file from latest release from
    [GitHub](https://github.com/GoogleCloudPlatform/healthcare-api-dicomweb-cli/releases)
1.  Install within virtualenv`pip install healthcare-api-dicomweb-cli-X.Y.zip`
1.  Then you should be able to run `dcmweb`

## Apache License 2.0
Project License can be found [here](LICENSE).

"
46,techshot25/HealthCare,Jupyter Notebook,"# HealthCare

This includes a dataset representing insurance costs for individuals. It uses information such as age, sex, bmi, and smoking habits to determine the cost on the insurance company for that person.

The idea is to present a machine learning model that predicts the cost with the highest accuracy.

Documentation and code provided in the file: `HealthCare.ipynb`. If GitHub cannot render the file [click here](https://nbviewer.jupyter.org/github/techshot25/HealthCare/blob/master/HealthCare.ipynb).
"
47,simpledotorg/simple-server,Ruby,"# Simple Server

[![Build Status](https://simple.semaphoreci.com/badges/simple-server/branches/master.svg)](https://simple.semaphoreci.com/projects/simple-server)
[![Ruby Style Guide](https://img.shields.io/badge/code_style-standard-brightgreen.svg)](https://github.com/testdouble/standard)

This is the backend for the Simple app to help track hypertensive patients across a population.

## Development

We have a `bin/setup` script that does most of the work of getting things setup, but you need a few things in place first.
If you are on a Mac, install [homebrew](https://brew.sh) and then install rbenv, redis, postgres@14, and yarn:

```
brew install rbenv ruby-build redis yarn postgresql@14
```

After this is done, it is highly recommended to tune your local PostgreSQL installation, otherwise your server will get bogged down when doing things like refreshing materialized views.
You can use [PGTune](https://pgtune.leopard.in.ua) to do this, it takes about 2 minutes. You can find your local postgresql.conf file at `/opt/homebrew/var/postgresql@14/postgresql.conf` on M1 Macs,
and `/usr/local/var/postgresql@14/postgresql.conf` on Intel Macs.

### bin/setup

To set up the Simple server for local development, clone the git repository and run the setup script included:

```
$ git clone git@github.com:simpledotorg/simple-server.git
$ cd simple-server
$ bin/setup
```

Note: If you already have a previous dev environment you're trying to refresh, it's easiest to drop your database run setup again.
```
$ rails db:drop
$ rails parallel:drop
$ bin/setup
```

If you encounter issues with this script, please open [a new issue with details](https://github.com/simpledotorg/simple-server/issues/new?title=Problems+with+bin/setup). Please include the entire log from bin/setup, as well as your computer / OS details.

### Setup Troubleshooting

#### Setup fails when bundler tries to resolve `nokogiri`

The error message will look like:
```
Extracting libxml2-2.9.13.tar.xz into <...>
========================================================================
tar (child): xz: Cannot exec: No such file or directory
tar (child): Error is not recoverable: exiting now
/bin/tar: Child returned status 2
/bin/tar: Error is not recoverable: exiting now
========================================================================
```

Ensure that you have `xz` installed and *linked* with `brew link xz`.

#### Apple Silicon M1 Macs

With recent gem updates, all of our gems and dependencies now build ARM native on m1 macs. This means you do **not** need to use Rosetta to set up simple-server, and in fact using Rosetta will make things more complicated and confusing in day to day dev experience, and also hurts performance.

There is one possible caveat to this -- if you see any problems with google-protobuf, run the following:

```
gem uninstall google-protobuf
gem install google-protobuf -v 3.21.5 --platform=ruby
```

Then rerun bundler and everything will work. This is being tracked over in https://github.com/protocolbuffers/protobuf/issues/8682, hopefully there will be a better fix soon.

Beyond that, the setup instructions are now the same for Intel or M1 macs, as you can install homebrew normally and go from there.

#### Docker Compose
Dev environment setup using docker and docker-compose

##### Prerequisite
- [Docker](https://docs.docker.com/engine/install/)
- [Docker compose](https://docs.docker.com/compose/install/)

###### Install docker and docker-compose on Mac
```
brew install docker
brew install docker-compose
```

##### Setup
```
bin/docker-up
```

After a successful docker-compose initialisation, an admin dashboard account is automatically created.
```
username: admin@simple.org
password: Resolve2SaveLives
```

Open http://localhost:3000 in your browser to view the simple dashboard

Use below Ngrok [guide](#developing-with-the-android-app) for Android development setup

##### Teardown (delete docker containers and volumes)
```
bin/docker-down
```

#### Manual Setup

If the included `bin/setup` script fails for some reason, you can also manually
set up the application step by step. You can do so as follows.

First, you need to [install ruby](https://www.ruby-lang.org/en/documentation/installation). It is recommended to use [rbenv](https://github.com/rbenv/rbenv) to manage ruby versions. Note that we currently use Bundler version 2.3.22, so that is also hardcoded below.

Next, [install NodeJS v18.11.0](https://nodejs.org/en/) using [nvm](https://github.com/nvm-sh/nvm).

```bash
gem install bundler -v 2.3.22
bundle _2.3.22_ install
brew install nvm
nvm install 18.11.0
rake yarn:install
rails db:setup
```

We cleanup old migration files every once in a while and so running `db:migrate` would not work for the initial setup.
When setting up a new database, `db:setup` will take care of everything (it runs `db:structure:load` under the hood).

#### Developing with the Android app

To run [simple-android](https://github.com/simpledotorg/simple-android/) app with the server running locally, you can
use [ngrok](https://ngrok.com).

```bash
brew install --cask ngrok
rails server
ngrok http 3000
```

The output of the ngrok command is HTTP and HTTPS URLs that can be used to access your local server. The HTTP URL cannot
be used since HTTP traffic will not be supported by the emulator. Configure the following places with the HTTPS URL.

In the `gradle.properties` file in the `simple-android` repository, set:
```
manifestEndpoint=<HTTPS URL>/api/
fallbackApiEndpoint=<HTTPS URL>/api/
```

In the `.env.development.local` (you can create this file if it doesn't exist),
```
SIMPLE_SERVER_HOST=<URL>  # i.e. without https://
SIMPLE_SERVER_HOST_PROTOCOL=https
```

Alternatively, you can make the change on the server side. In the server repo, open `app/views/api/manifests/show.json.jbuilder`. Change:
```
json.endpoint ""#{ENV[""SIMPLE_SERVER_HOST_PROTOCOL""]}://#{ENV[""SIMPLE_SERVER_HOST""]}/api/""
```
to:
```
json.endpoint ""<HTTPS URL>/api/""
```

#### Workers

We use [sidekiq](https://github.com/mperham/sidekiq) to run async tasks. To run them locally you need to start redis:

```bash
redis-server -v
```

### Testing Email

We use [Mailcatcher](https://mailcatcher.me/) for testing email in development. Please use the
following to set it up on your machine.

_Note: Please don't add Mailcatcher to the `Gemfile`, as it causes conflicts._

```bash
gem install mailcatcher
mailcatcher
```

Now you should be able to see test emails at http://localhost:1080

### Testing Web Views

When testing web views like the progress tab or help screens, you will need to authenticate yourself with specific
request headers. You can run the following command to get a set of request headers for a user that you can attach to
your requests.

```
$ bundle exec rails get_user_credentials
```

The command will output a set of request headers that you can attach to your requests using tools like
[Postman](https://www.postman.com/) or [ModHeader](https://bewisse.com/modheader/).

```
Attach the following request headers to your requests:
Authorization: Bearer 9b54814d4b422ee37dad46e7ebee673c59eed088c264e479880cbe7fb5ac1ce7
X-User-ID: 452b96c2-e0cf-49e7-ab73-c328acd3f1e5
X-Facility-ID: dcda7d9d-48f9-47d2-b1cc-93d90c94386e
```

Here are two Simple App pages you can test on your browser:
* ""Progress Tab"": `http://localhost:3000/api/v3/analytics/user_analytics.html`
* ""Help Page"": `http://localhost:3000/api/v3/help.html`

### Review Apps

Every pull request opened on the `simple-server` repo creates a [Heroku review app](https://devcenter.heroku.com/articles/github-integration-review-apps)
with the branch's code deployed to it. The review app is hosted at the URL [https://simple-review-pr-<PR number>.herokuapp.com](#).
This temporary environment can be used to test your changes in a production-like environment easily.

If you need to test your changes with a mobile app build as well, you can generate a mobile app build that points to
your review app. To do so:

* Navigate to the GitHub Actions page on the `simple-server` repository
* Select the ""Mobile Review App Build"" action
* Trigger a ""workflow dispatch"" at the top of the screen. You can keep the branch as `master` (it doesn't matter) and
  enter your PR number in the required input
* Once the Action is complete, its page will contain the APK as an artifact.

![trigger-mobile-review-app](https://user-images.githubusercontent.com/4241399/139230709-1604df1f-ad7d-4690-8bae-80d2a48cab37.gif)

<img width=""1557"" alt=""Screen Shot 2021-10-28 at 3 11 44 PM"" src=""https://user-images.githubusercontent.com/4241399/139230802-39a38e26-7a96-4e00-9599-c8f7ce48d62d.png"">


#### Testing messages

Messages sent through Twilio are currently fixed to specific countries. To override this setting, go to the [heroku console](https://dashboard.heroku.com/pipelines/30a12deb-f419-4dca-ad4a-6f26bf192e6f) and [add/update](https://devcenter.heroku.com/articles/config-vars#managing-config-vars) the `DEFAULT_COUNTRY` config variable on your review app to your desired country. The supported country codes are listed [here](https://github.com/simpledotorg/simple-server/blob/master/config/initializers/countries.rb).

```
# for US/Canada
DEFAULT_COUNTRY = US

# for UK
DEFAULT_COUNTRY = UK
```

Updating this config will automatically restart the review app and should allow one to receive messages in their appropriate ISD codes.

### Configuration

The app uses a base development configuration using `.env.development`. To add or override any configurations during
local development, create a `.env.development.local` file and add your necessary configurations there. If a
configuration change is applicable to all dev environments, ensure that it is added to `.env.development` and checked
into the codebase.

### Running the application locally

Foreman can be used to run the application locally. First, install foreman.

```bash
$ gem install foreman
```

Then, run the following command to start the Rails and Sidekiq together.

```bash
$ foreman start -f Procfile.dev
```

**Note:** Foreman will also execute the `whenever` gem in trial mode. This will validate that the `whenever`
configuration is valid, but will not actually schedule any cron jobs.

Alternatively, you can start these services locally _without_ foreman by using the following commands individually.

* Rails: `bundle exec rails server` or `bundle exec puma`
* Sidekiq: `bundle exec sidekiq`

### Running the tests

```bash
bin/rspec
```

Run tests interactively quickly while developing:

```
bin/guard
```

### Code

We use the [standard](https://github.com/testdouble/standard#how-do-i-run-standard-in-my-editor) gem as our default formatter and linter. To enable it directly in your editor, follow [this](https://github.com/testdouble/standard#how-do-i-run-standard-in-my-editor).

To check all the offenses throughout the codebase:

```bash
$ bundle exec standardrb
```

To fix any offenses that standard can autofix, run

```bash
$ bundle exec standardrb --fix
```

### Generating seed data

NOTE: Its highly recommended to tune your local PostgreSQL before generating new seed data, especially large seed data sets. See the docs for that under [Development](#development).
To generate a full set of seed data, including facilities, users, patients with BPs, etc, run the following:

```bash
bin/rails db:seed
```

You can always do a full reset to get back to a working dataset locally - note that reset clears all DBs, recreates them, runs seed, and refreshes matviews.

```bash
bin/rails db:reset
```

Need a larger dataset? Try adding the `SEED_TYPE` ENV variable. Available sizes are `small`, `medium`, and `large`, and `profiling`. Large and profiling take a long time to run (20 mins to an hour), but they are very helpful for performance testing.

```bash
SEED_TYPE=medium bin/rails db:reset
# You also may want an entirely new large dataset, with more facilities and regions, and more patients per facility.
SEED_TYPE=large bin/rails db:reset
```

To purge the generated patient data _only_, run the following. Note that you usually don't want this, and a full `db:reset` is safer in terms of generating a valid data set.

```bash
$ bin/rails db:purge_users_data
```

### Creating an admin user

If you need new admin users, you can run the following command from the project root. Note that the standard seed process already creates various admins for you, so you probably don't need this for typical dev.

```bash
$ bin/rails 'create_admin_user[<name>,<email>,<password>]'
```

### View Sandbox data in your local environment

NOTE: generating seed data locally is the recommended way to get data in your env. Sandbox data is actually just generated via `db:seed`, so the below
process really just adds SCP overhead to the process.

1. Follow the steps in the ""How to add an SSH key..."" section [here](https://github.com/simpledotorg/deployment) to add your SSH key to the deployment repo
2. Ask someone from the Simple team to add you as an admin to Sandbox
3. Create a password for your Sandbox account and use that to log into the Sandbox dashboard on https://api-sandbox.simple.org
4. Run `ssh deploy@ec2-13-235-33-14.ap-south-1.compute.amazonaws.com` to verify that your SSH access from step 1 was completed successfully.
5. Run `bundle exec cap sandbox db:pull` to sync Sandbox data with your local machine.
6. Use your Sandbox email and password to log into your local environment (http://localhost:3000).

### Profiling

We use the [vegeta](https://github.com/tsenart/vegeta) utility to run performance benchmarks. The suite and additional instructions are [here](./profiling/README.md).

### Security audits

Security audits generally require some test data to be set up in a specific way, and account credentials and other
information to be shared with the auditor. Run the following command to set up the necessary test data and print out
an information sheet to be shared.

```
$ bin/rails 'prepare_security_environment'
```

This task can only be executed in development and security environments.

## Documentation

### API

API Documentation can be accessed at `/api-docs` on local server and hosted at https://api.simple.org/api-docs

To regenerate the Swagger API documentation, run the following command.

```
$ bundle exec rake docs
```

### ADRs

Architecture decisions are captured in ADR format and are available in `/doc/arch`

### Wiki

Guides, instructions and long-form maintenance documentation can go in `/doc/wiki`

### ERD (Entity-Relationship Diagram)

These are not actively committed into the repository. But can be generated by running `bundle exec erd`

## Deployment

Simple Server is continuously deployed from master to all environments via [Semaphore Workflows](https://docs.semaphoreci.com/essentials/modeling-complex-workflows/) as long as the build passes. We use a mixture of tools under the hood for deployments:

* Ansible: Server management and configuration is done using Ansible. See the [deployment repository](https://github.com/simpledotorg/deployment/tree/master/ansible)
  for more information.
* Capistrano: Application code is deployed to servers for a specific country and environment using Capistrano.
* SemaphoreCI: Continuous deployment - all merges to master are auto-deployed to all environments.

If you need to make a manual production release, run the release script from master:

```
bin/release
```

This will create a git release tag and automatically trigger a deployment to all environments through Semaphore. You can monitor the deployment progress [in Semaphore](https://simple.semaphoreci.com/projects/simple-server) via the tagged release's workflow. Please make sure to copy / paste the changelog from `bin/release` so you can post it in the #releases channel.

### Deployment to a specific environment

* We use Capistrano [multi-config](https://github.com/railsware/capistrano-multiconfig) to do multi-country deploys.
* Most `cap` commands are namespaced with the country name. For eg: `bundle exec cap india:staging deploy` to deploy to India staging. Note that some (like sandbox) are do not have a country, so the command would be `bundle exec cap sandbox deploy`.
* The available country names are listed under `config/deploy`. The subsequent envs, under the country directory, like
  `config/deploy/india/staging.rb`

Simple Server can be deployed to a specific environment and/or specific country via `bundle exec cap <country>:<enviroment> deploy`.
Note that Sandbox does _not_ have a country prefix:

```bash
# Sandbox (deploys master)
bundle exec cap sandbox deploy
# Sandbox from a specific branch
BRANCH=my-branch-name bundle exec cap sandbox deploy
# Bangladesh demo
bundle exec cap bangladesh:demo deploy
```

Rake tasks can be run on the deployed server using Capistrano as well. For example,

```bash
bundle exec cap india:staging deploy:rake task=db:seed
```

### Deployment to a new environment

When setting up a new environment to deploy Simple Server to, follow these steps.

#### 1. Create a config file

Create a new file in `config/deploy/<env_name>.rb` for the new environment. It can be placed inside a subdirectory if
desired. Populate the new config file with relevant IP address info. Use an existing file for reference. For example,
the configuration for a deployment with two EC2 instances may look like:
```
server ""ec2-12-111-34-45.ap-south-1.compute.amazonaws.com"", user: ""deploy"", roles: %w[web app db cron whitelist_phone_numbers seed_data]
server ""ec2-12-222-67-89.ap-south-1.compute.amazonaws.com"", user: ""deploy"", roles: %w[web sidekiq]
```

The first server runs the web application and cron tasks, the second server runs Sidekiq to process background jobs.

#### 2. Install Sidekiq

A one-time installation of Sidekiq is required in new environments. Run the following command:

```bash
bundle exec cap <environment> sidekiq:install
```

#### 2. Deploy

You can now run a regular Capistrano deployment:

```bash
FIRST_DEPLOY=true bundle exec cap <environment> deploy
```

This may take a long time for the first deployment, since several dependencies (like Ruby) need to be installed.
Subsequent deployments will be much faster.

Note that `FIRST_DEPLOY=true` only needs to be specified on the first run. Any deployments afterwards don't need the flag.

### Deployment Resources

The infrastructure setup including the ansible and terraform scripts are documented in the [deployment repository](https://github.com/simpledotorg/deployment).

## Contributing

If you're working on a project that will affect any of the indicators listed in [this document](https://docs.simple.org/), please contact the product / design team.
"
48,greggersh/healthcare.gov,JavaScript,"# HealthCare.gov-Open-Source-Release

This project includes the source code and content for the healthcare.gov website. For more information, please visit https://www.healthcare.gov/developers

## Local Installation Requirements

- Linux, Unix, Windows or Mac OS X
- [Ruby](http://www.ruby-lang.org/en/downloads/)
- [RubyGems](http://rubygems.org/pages/download)
- [Jekyll](http://jekyllrb.com)


## Ruby

### To install ruby on unix:

`yum install ruby` (or `sudo apt-get install ruby1.9.1`)


### To install ruby on Mac OS X:

`curl -L https://get.rvm.io | bash -s stable --ruby`

Visit the following links for more detailed information on how to set up Ruby using a method applicable to your environment:

Three Ways of Installing Ruby (Linux/Unix)
http://www.ruby-lang.org/en/downloads/
 
RubyInstaller for Windows
http://rubyinstaller.org/

How to Install Ruby on a Mac
http://net.tutsplus.com/tutorials/ruby/how-to-install-ruby-on-a-mac/


## Install rubygems: 

- `cd ~/`
- `wget http://production.cf.rubygems.org/rubygems/rubygems-1.8.24.tgz`
- `tar xzvf rubygems-1.8.24.tgz`
- `cd rubygems-1.8.24`
- `ruby setup.rb`


## Managing Dependencies Using Bundler

We recommend using Bundler to manage dependencies. Once you have Ruby installed, install Bundler by running the following command: 'gem install bundler'

Once Bundler is installed, you install/update depencies by simply running 'bundle install' within your project folder.

More information on Bundler may be found here: http://gembundler.com/


## Install Jekyll

- `cd healthcare.gov` (or the location of your cloned repository)
- `bundle install`

For more information and detailed documentation on Jekyll, visit the following sites:

Jekyll Project Home
http://jekyllrb.com

Jekyll on GitHub
https://github.com/mojombo/jekyll


## Clone the repository

- `cd /var/www/html` (or the location you would like the compiled site to live)
- `git clone https://github.com/CMSgov/HealthCare.gov-Open-Source-Release.git healthcare.gov`


## Generate the site and serve

- `jekyll serve`
- Browse to [localhost:4000](http://localhost:4000) to view the site"
49,UCDS/health4all_v3,PHP,"# Health4All

Contact On [gunaranjan@yousee.one]

Softwares to be installed
    - WAMP / XAMPP Server
    - Recommendation: SQLYog Community IDE [Instead of phpmyadmin if available and familiar for the programmer]


Steps to be followed : 
    1. Create a Github account .
    2. Fork (health4all_v3) from https://github.com/UCDS/health4all_v3.
    3. Clone health4all_v3 from your forked respository to your system 
    4. Move this app to either www folder if you are using WAMP, or to htdocs in case of XAMPP server
    5. Navigate to http://localhost/phpmyadmin/index.php  and create a new database with name 'health4all'.
    6. Import the sql file from health4all_v3/db/health4all.sql into 'health4all' database created in above step.
    7. Run the script SET GLOBAL sql_mode=''; in phpmyadmin sql editor
    8. Open health4all_v3 app in browser (http://localhost/health4all_v3/) and login with below credentials
        credentials-
                username  : admin
                password  : password  

Note :  To hide the errors  , change environment from 'development' to 'production' health4all_v3/index.php line number 20 
    
 

DB Migration,
    - After taking code pull, run all the files after the version mentioned in the table db_version
    - To add new migration, create new version file & at the end of the sql file add db_version update query, rever 1.0.2.sql for reference.
    - NOTE: DO NOT ADD DATABASE IN THE QUERIES.


TODOs,
    - DB Migration needs to be automated --> https://www.youtube.com/watch?v=i07XXM37VFk

References,
    - Database Migrations
        - https://codeinphp.github.io/post/database-migrations-in-codeigniter/
"
