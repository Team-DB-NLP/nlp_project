[
 {
  "repo": "AileenNielsen/OReillyHealthcareData",
  "language": "Jupyter Notebook",
  "readme_contents": "[{\"name\":\".gitignore\",\"path\":\".gitignore\",\"sha\":\"e43b0f988953ae3a84b00331d0ccf5f7d51cb3cf\",\"size\":10,\"url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/.gitignore?ref=master\",\"html_url\":\"https://github.com/wanghaisheng/healthcaredatastandard/blob/master/.gitignore\",\"git_url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/e43b0f988953ae3a84b00331d0ccf5f7d51cb3cf\",\"download_url\":\"https://raw.githubusercontent.com/wanghaisheng/healthcaredatastandard/master/.gitignore\",\"type\":\"file\",\"_links\":{\"self\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/.gitignore?ref=master\",\"git\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/e43b0f988953ae3a84b00331d0ccf5f7d51cb3cf\",\"html\":\"https://github.com/wanghaisheng/healthcaredatastandard/blob/master/.gitignore\"}},{\"name\":\"README.md\",\"path\":\"README.md\",\"sha\":\"fc6bd9a7b0a339af5ee38d7481d24302a18d395c\",\"size\":29010,\"url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/README.md?ref=master\",\"html_url\":\"https://github.com/wanghaisheng/healthcaredatastandard/blob/master/README.md\",\"git_url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/fc6bd9a7b0a339af5ee38d7481d24302a18d395c\",\"download_url\":\"https://raw.githubusercontent.com/wanghaisheng/healthcaredatastandard/master/README.md\",\"type\":\"file\",\"_links\":{\"self\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/README.md?ref=master\",\"git\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/fc6bd9a7b0a339af5ee38d7481d24302a18d395c\",\"html\":\"https://github.com/wanghaisheng/healthcaredatastandard/blob/master/README.md\"}},{\"name\":\"overview.png\",\"path\":\"overview.png\",\"sha\":\"5e49110c0ac25125bf0f277548f85389bd9178da\",\"size\":559586,\"url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/overview.png?ref=master\",\"html_url\":\"https://github.com/wanghaisheng/healthcaredatastandard/blob/master/overview.png\",\"git_url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/5e49110c0ac25125bf0f277548f85389bd9178da\",\"download_url\":\"https://raw.githubusercontent.com/wanghaisheng/healthcaredatastandard/master/overview.png\",\"type\":\"file\",\"_links\":{\"self\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/overview.png?ref=master\",\"git\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/5e49110c0ac25125bf0f277548f85389bd9178da\",\"html\":\"https://github.com/wanghaisheng/healthcaredatastandard/blob/master/overview.png\"}},{\"name\":\"standard number -201506.png\",\"path\":\"standard number -201506.png\",\"sha\":\"10d20f19dadd0de6c6740685c16ad3d98bceb4eb\",\"size\":552959,\"url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/standard%20number%20-201506.png?ref=master\",\"html_url\":\"https://github.com/wanghaisheng/healthcaredatastandard/blob/master/standard%20number%20-201506.png\",\"git_url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/10d20f19dadd0de6c6740685c16ad3d98bceb4eb\",\"download_url\":\"https://raw.githubusercontent.com/wanghaisheng/healthcaredatastandard/master/standard%20number%20-201506.png\",\"type\":\"file\",\"_links\":{\"self\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/standard%20number%20-201506.png?ref=master\",\"git\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/10d20f19dadd0de6c6740685c16ad3d98bceb4eb\",\"html\":\"https://github.com/wanghaisheng/healthcaredatastandard/blob/master/standard%20number%20-201506.png\"}},{\"name\":\"\u57fa\u7840\u7c7b\u6807\u51c6\",\"path\":\"\u57fa\u7840\u7c7b\u6807\u51c6\",\"sha\":\"945a3b3a1831fbad09264b9dea530af3f0fb737a\",\"size\":0,\"url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E5%9F%BA%E7%A1%80%E7%B1%BB%E6%A0%87%E5%87%86?ref=master\",\"html_url\":\"https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E5%9F%BA%E7%A1%80%E7%B1%BB%E6%A0%87%E5%87%86\",\"git_url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/945a3b3a1831fbad09264b9dea530af3f0fb737a\",\"download_url\":null,\"type\":\"dir\",\"_links\":{\"self\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E5%9F%BA%E7%A1%80%E7%B1%BB%E6%A0%87%E5%87%86?ref=master\",\"git\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/945a3b3a1831fbad09264b9dea530af3f0fb737a\",\"html\":\"https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E5%9F%BA%E7%A1%80%E7%B1%BB%E6%A0%87%E5%87%86\"}},{\"name\":\"\u5df2\u6574\u7406\u6750\u6599\",\"path\":\"\u5df2\u6574\u7406\u6750\u6599\",\"sha\":\"e9f14bd3afda272e5e3f310b779e115d0c125d29\",\"size\":0,\"url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E5%B7%B2%E6%95%B4%E7%90%86%E6%9D%90%E6%96%99?ref=master\",\"html_url\":\"https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E5%B7%B2%E6%95%B4%E7%90%86%E6%9D%90%E6%96%99\",\"git_url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/e9f14bd3afda272e5e3f310b779e115d0c125d29\",\"download_url\":null,\"type\":\"dir\",\"_links\":{\"self\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E5%B7%B2%E6%95%B4%E7%90%86%E6%9D%90%E6%96%99?ref=master\",\"git\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/e9f14bd3afda272e5e3f310b779e115d0c125d29\",\"html\":\"https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E5%B7%B2%E6%95%B4%E7%90%86%E6%9D%90%E6%96%99\"}},{\"name\":\"\u6280\u672f\u7c7b\u6807\u51c6\",\"path\":\"\u6280\u672f\u7c7b\u6807\u51c6\",\"sha\":\"de30b9a40cd054b6d7fb7fcebbe6f7e01b5e5770\",\"size\":0,\"url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E6%8A%80%E6%9C%AF%E7%B1%BB%E6%A0%87%E5%87%86?ref=master\",\"html_url\":\"https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E6%8A%80%E6%9C%AF%E7%B1%BB%E6%A0%87%E5%87%86\",\"git_url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/de30b9a40cd054b6d7fb7fcebbe6f7e01b5e5770\",\"download_url\":null,\"type\":\"dir\",\"_links\":{\"self\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E6%8A%80%E6%9C%AF%E7%B1%BB%E6%A0%87%E5%87%86?ref=master\",\"git\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/de30b9a40cd054b6d7fb7fcebbe6f7e01b5e5770\",\"html\":\"https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E6%8A%80%E6%9C%AF%E7%B1%BB%E6%A0%87%E5%87%86\"}},{\"name\":\"\u6570\u636e\u7c7b\u6807\u51c6\",\"path\":\"\u6570\u636e\u7c7b\u6807\u51c6\",\"sha\":\"b07085f5d932d491dc4776309fc799305e1b4838\",\"size\":0,\"url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E6%95%B0%E6%8D%AE%E7%B1%BB%E6%A0%87%E5%87%86?ref=master\",\"html_url\":\"https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E6%95%B0%E6%8D%AE%E7%B1%BB%E6%A0%87%E5%87%86\",\"git_url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/b07085f5d932d491dc4776309fc799305e1b4838\",\"download_url\":null,\"type\":\"dir\",\"_links\":{\"self\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E6%95%B0%E6%8D%AE%E7%B1%BB%E6%A0%87%E5%87%86?ref=master\",\"git\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/b07085f5d932d491dc4776309fc799305e1b4838\",\"html\":\"https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E6%95%B0%E6%8D%AE%E7%B1%BB%E6%A0%87%E5%87%86\"}},{\"name\":\"\u6807\u51c6\u5316\u6d4b\u8bc4\u76f8\u5173\u89c4\u8303\",\"path\":\"\u6807\u51c6\u5316\u6d4b\u8bc4\u76f8\u5173\u89c4\u8303\",\"sha\":\"5bf75d1217960dfa55654ed55bb07f644330a763\",\"size\":0,\"url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E6%A0%87%E5%87%86%E5%8C%96%E6%B5%8B%E8%AF%84%E7%9B%B8%E5%85%B3%E8%A7%84%E8%8C%83?ref=master\",\"html_url\":\"https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E6%A0%87%E5%87%86%E5%8C%96%E6%B5%8B%E8%AF%84%E7%9B%B8%E5%85%B3%E8%A7%84%E8%8C%83\",\"git_url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/5bf75d1217960dfa55654ed55bb07f644330a763\",\"download_url\":null,\"type\":\"dir\",\"_links\":{\"self\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E6%A0%87%E5%87%86%E5%8C%96%E6%B5%8B%E8%AF%84%E7%9B%B8%E5%85%B3%E8%A7%84%E8%8C%83?ref=master\",\"git\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/5bf75d1217960dfa55654ed55bb07f644330a763\",\"html\":\"https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E6%A0%87%E5%87%86%E5%8C%96%E6%B5%8B%E8%AF%84%E7%9B%B8%E5%85%B3%E8%A7%84%E8%8C%83\"}},{\"name\":\"\u7ba1\u7406\u7c7b\u6807\u51c6\",\"path\":\"\u7ba1\u7406\u7c7b\u6807\u51c6\",\"sha\":\"697c02441646c251192f32f1bdf86ea52042e7e4\",\"size\":0,\"url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E7%AE%A1%E7%90%86%E7%B1%BB%E6%A0%87%E5%87%86?ref=master\",\"html_url\":\"https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E7%AE%A1%E7%90%86%E7%B1%BB%E6%A0%87%E5%87%86\",\"git_url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/697c02441646c251192f32f1bdf86ea52042e7e4\",\"download_url\":null,\"type\":\"dir\",\"_links\":{\"self\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E7%AE%A1%E7%90%86%E7%B1%BB%E6%A0%87%E5%87%86?ref=master\",\"git\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/697c02441646c251192f32f1bdf86ea52042e7e4\",\"html\":\"https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E7%AE%A1%E7%90%86%E7%B1%BB%E6%A0%87%E5%87%86\"}}]"
 },
 {
  "repo": "informatici/openhospital",
  "language": "Makefile",
  "readme_contents": "# ![](./OH-icon.png) Open Hospital\n\n[![GitHub release](https://img.shields.io/github/v/release/informatici/openhospital?color=orange&label=latest%20release)](https://github.com/informatici/openhospital/releases/latest)\n[![License](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://github.com/informatici/openhospital/blob/master/LICENSE)\n![Release Date](https://img.shields.io/github/release-date/informatici/openhospital?label=Released)\n\n**[Open Hospital][openhospital]** is a free and open-source Health Information Management System (HIMS) software application.\n\n**This repository is used to assemble the portable (or all-in-one) packages of Open Hospital, which you can download also [here][download].**\n\n## Download\n\n[![Latest release](https://img.shields.io/github/v/release/informatici/openhospital?color=orange&label=download%20latest)](https://github.com/informatici/openhospital/releases/latest)\n\n[[Download latest release from github](https://github.com/informatici/openhospital/releases/latest)] [ [All releases](https://github.com/informatici/openhospital/releases) ]\n\n[[Download latest release from sourceforge](https://sourceforge.net/projects/openhospital/files/latest/download)] [ [All releases](https://sourceforge.net/projects/openhospital/files/) ]\n\n### Download stats\n\n![GitHub all releases](https://img.shields.io/github/downloads/informatici/openhospital/total?label=GitHub%20Downloads)\n![GitHub release (latest by date)](https://img.shields.io/github/downloads/informatici/openhospital/latest/total?label=latest)\n\n![SourceForge](https://img.shields.io/sourceforge/dt/openhospital?label=Sourceforge%20downloads)\n![SourceForge](https://img.shields.io/sourceforge/dm/openhospital?label=this%20month)\n![SourceForge](https://img.shields.io/sourceforge/dt/openhospital/v1.13.0?color=33ccff&label=latest&logoColor=33ccff)\n\n## Software\n\nOpen Hospital (OH) is deployed as a desktop application that can be used in a standalone, single user mode (PORTABLE mode)\nor in a client / server network configuration (CLIENT mode), where multiple clients and users connect to the same database server.\nOH is developed in Java and it is based on open-source tools and libraries; it runs on any computer, requires low resources and is designed to work without an internet connection.\nFor more information check the online documentation [here][documentation].\n\nOpen Hospital is composed by the following components, hosted in separated repositories:\n\n - [OH Core][core], a library that contains the business logic and the data abstraction layer\n - [OH GUI][gui], which provides a graphical user interface (GUI) made with Java Swing\n - [OH Doc][doc], which contains the user and admin documentation in Asciidoc format\n - [OH API][api], a web server that exposes REST APIs over the Core component, and it's used by the UI component [*WIP*]. \n - [OH UI][ui], a web user interface that consists of a React SPA (single page application) [*WIP*]\n\n## How to contribute\n\nThere are several ways in which you can contribute to Open Hospital:\n\n- try the [desktop application][releases] or the early versions of the [web UI][ui]\n- request new features or report issues on [JIRA][jira] ([here][good-first]'s a list of *good-first-issues*)\n- improve the [documentation][doc]\n- contribute code patches to one of the components\n\n## Documentation\n\nRead on about Open Hospital:\n\n - on the official [website][openhospital]\n - [user][user-man] and [admin][admin-man] manuals\n - [wiki]\n - [FAQ][faq]\n\n## Community\n\nYou can reach out to the community of contributors by joining \nour [Slack workspace][slack] or by subscribing to our [mailing list][ml].\n\n\n## How to create OH packages\n\n<details><summary>:construction_worker: :package:</summary>\nTo create the Open Hospital packages,\nmake sure to have installed the following dependencies on a Linux machine:\nJDK 8+, Maven, asciidoctor-pdf, zip, GNU make.\n\nThen follow these simple steps:\n\n 1. Clone this repository:\n\n        git clone https://github.com/informatici/openhospital\n\n 2. Run the script that compiles the components of Open Hospital, and assembles the portable distributions:\n\n        cd openhospital\n        make\n    \n    You can also parallelize some make tasks by using the `-j` flag (e.g. `make -j4`)\n    or use intermediate targets to build single parts of the distribution -\n    use `make help` to see a list of available targets.\n</details>\n\n [openhospital]: https://www.open-hospital.org/\n [documentation]: https://www.open-hospital.org/documentation\n [download]: https://www.open-hospital.org/download\n [core]: https://github.com/informatici/openhospital-core\n [gui]: https://github.com/informatici/openhospital-gui\n [ui]: https://github.com/informatici/openhospital-ui\n [api]: https://github.com/informatici/openhospital-api\n [doc]: https://github.com/informatici/openhospital-doc\n [releases]: https://github.com/informatici/openhospital/releases\n [jira]: https://openhospital.atlassian.net/browse/OP\n [good-first]: https://openhospital.atlassian.net/browse/OP-188?filter=10206\n [user-man]: https://github.com/informatici/openhospital-doc/blob/master/doc_user/UserManual.adoc\n [admin-man]: https://github.com/informatici/openhospital-doc/blob/master/doc_admin/AdminManual.adoc\n [faq]: https://openhospital.atlassian.net/wiki/spaces/OH/pages/568951013/Getting+Started+FAQ\n [wiki]: https://openhospital.atlassian.net/wiki/spaces/OH/overview\n [slack]: https://join.slack.com/t/openhospitalworkspace/shared_invite/enQtOTc1Nzc0MzE2NjQ0LWIyMzRlZTU5NmNlMjE2MDcwM2FhMjRkNmM4YzI0MTAzYTA0YTI3NjZiOTVhMDZlNWUwNWEzMjE5ZDgzNWQ1YzE\n [ml]: https://sourceforge.net/projects/openhospital/lists/openhospital-devel\n"
 },
 {
  "repo": "coronasafe/care",
  "language": "Python",
  "readme_contents": "# Care Backend\n\n<p align=\"center\">\n  <a href=\"https://ohc.network\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"./care/static/images/logos/light-logo.svg\">\n      <img alt=\"care logo\" src=\"./care/static/images/logos/black-logo.svg\"  width=\"300\">\n    </picture>\n  </a>\n</p>\n\n[![Deploy Care](https://github.com/coronasafe/care/actions/workflows/deployment.yaml/badge.svg)](https://github.com/coronasafe/care/actions/workflows/deployment.yaml)\n[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)\n[![Cookiecutter Django](https://img.shields.io/badge/built%20with-Cookiecutter%20Django-ff69b4.svg)](https://github.com/pydanny/cookiecutter-django/)\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)\n[![Chat](https://img.shields.io/badge/-Join%20us%20on%20slack-7b1c7d?logo=slack)](https://slack.coronasafe.in/)\n\nThis is the backend for care. an open source platform for managing patients, health workers, and hospitals.\n\n## Features\n\nCare backend makes the following features possible:\n\n- Realtime Analytics of Beds, ICUs, Ventilators, Oxygen and other resources in hospitals\n- Facility Management with Inventory Monitoring\n- Integrated Tele-medicine & Triage\n- Patient Management and Consultation History\n- Realtime video feed and vitals monitoring of patients\n- Clinical Data Visualizations.\n\n## Getting Started\n\n### Docs and Guides\n\nYou can find the docs at https://care-be-docs.coronasafe.network\n\n### Staging Deployments\n\nStaging instances for testing are automatically deployed on every commit to the `master` branch. The staging instances\nare available at:\n\n- https://careapi.ohc.network\n\n### Self hosting\n\n#### Compose\n\ndocker compose is the easiest way to get started with care.\nput the required environment variables in a `.env` file and run:\n\n```bash\nmake up\n```\n\n> \u26a0\ufe0f If you are unable to compose up care in windows, ensure line endings are set to `LF` (`docker-entrypoint.sh` won't\n> work with `CRLF` line endings).\n> ```\n> git config core.autocrlf false\n> ```\n\n#### Docker\n\nPrebuilt docker images for server deployments are available\non [ghcr](https://github.com/coronasafe/care/pkgs/container/care)\n\n## Contributing\n\nWe welcome contributions from everyone. Please read our [contributing guidelines](./CONTRIBUTING.md) to get started.\n"
 },
 {
  "repo": "technext/HealthCare",
  "language": "HTML",
  "readme_contents": "HealthCare\n==========\n\nA responsive theme for commercial medical purpose. Built with HTML5, CSS3, Bootstrap framework. Google fonts, Font Awesome Icon integrated\n\n==========\n\nBootstrap3 Powered\nBackgroundg Slider\nMultiple Page Options\nCode & Content Optimized for Speed\nResponsive Layout\nClean Code\nCross-browser Compatibility\nCSS3 Animations\n100% Fully Customisable\nNo Hardcoded Options\nSticky Header Options\nSuper Easy Installation & Setup With One Click Demo Installation\nCustom Background\nFont Awesome Icon Integration\nGoogle Fonts\nAdvanced Typography Options\nExtensive Documentation\nBuilt with HTML5 & CSS3\nStrong focus on Typography, Usability and Overall User Experience\nClean and Modern Design \u2013 can be used for any type of website\nLifetime Update & Free Support\n"
 },
 {
  "repo": "GoogleCloudPlatform/healthcare-deid",
  "language": "Python",
  "readme_contents": "# Healthcare De-Id\n\nThis project contains tools to run various tools for de-identifying medical\nrecords on Google Cloud Platform.\n\nFor example, see physionet/README.md for info on running PhysioNet De-Id.\n"
 },
 {
  "repo": "microsoft/healthcare-apis-samples",
  "language": "Jupyter Notebook",
  "readme_contents": "# Healthcare APIs Samples\n\nThis repo contains samples for Healthcare APIs, including FHIR, DICOM, IoT Connector and data related services. The workspace is a top level logical container that is created first within a resource group.\n\n![image.png](/docs/images/workspace.png)\n\nAll sample scripts have been tested in the Rest Client in Visual Studio Code, unless otherwise noted.\n\n- [How to deploy the Healthcare APIs](/docs/HowToDeploy.md)\n- [How to load data to the Healthcare APIs](/docs/HowToLoadData.md)\n- [How to access data in the Healthcare APIs](/docs/HowToAccessData.md)\n- [How to convert HL7v2 and C-CDA data](https://docs.microsoft.com/en-us/azure/healthcare-apis/azure-api-for-fhir/convert-data)\n- [How to export de-identified data](https://docs.microsoft.com/en-us/azure/healthcare-apis/fhir/de-identified-export)\n- [How to run performance tests using JMeter](/docs/HowToRunPerformanceTest.md)\n\n\n## Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\n\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## Trademarks\n\nThis project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft \ntrademarks or logos is subject to and must follow \n[Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).\nUse of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.\nAny use of third-party trademarks or logos are subject to those third-party's policies.\n"
 },
 {
  "repo": "coronasafe/care_fe",
  "language": "TypeScript",
  "readme_contents": "<a href=\"https://ohc.network/\">\n  <p align=\"center\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://cdn.coronasafe.network/light-logo.svg\">\n      <img alt=\"CARE Logo\" src=\"https://user-images.githubusercontent.com/25143503/193396107-27e0d587-b195-4e95-a795-5d0663d5cd81.svg\">\n    </picture>\n  </p>\n</a>\n<p align=\"center\"><b>Our goal is to continuously improve the quality and accessibility of public healthcare services using digital tools.</b></p>\n<h2></h2>\n<h3 align=\"center\"><a href=\"https://care.ohc.network\" target=\"_blank\">\ud83d\ude80 Staging Deploy</a></h3>\n<p align=\"center\"><img src=\"https://api.netlify.com/api/v1/badges/fd123f42-ef65-448c-9b03-39959d60e60b/deploy-status\"></p>\n<p align=\"center\">Auto deployed to <a href=\"https://care.ohc.network/\">care.ohc.network</a> for <code>develop</code> branch. All pull requests have preview builds powered by <a href=\"https://netlify.com\">Netlify</a>.</p>\n\n[![](https://sourcerer.io/fame/tomahawk-pilot/coronasafe/care_fe/images/0)](https://sourcerer.io/fame/tomahawk-pilot/coronasafe/care_fe/links/0)[![](https://sourcerer.io/fame/tomahawk-pilot/coronasafe/care_fe/images/1)](https://sourcerer.io/fame/tomahawk-pilot/coronasafe/care_fe/links/1)[![](https://sourcerer.io/fame/tomahawk-pilot/coronasafe/care_fe/images/2)](https://sourcerer.io/fame/tomahawk-pilot/coronasafe/care_fe/links/2)[![](https://sourcerer.io/fame/tomahawk-pilot/coronasafe/care_fe/images/3)](https://sourcerer.io/fame/tomahawk-pilot/coronasafe/care_fe/links/3)[![](https://sourcerer.io/fame/tomahawk-pilot/coronasafe/care_fe/images/4)](https://sourcerer.io/fame/tomahawk-pilot/coronasafe/care_fe/links/4)[![](https://sourcerer.io/fame/tomahawk-pilot/coronasafe/care_fe/images/5)](https://sourcerer.io/fame/tomahawk-pilot/coronasafe/care_fe/links/5)[![](https://sourcerer.io/fame/tomahawk-pilot/coronasafe/care_fe/images/6)](https://sourcerer.io/fame/tomahawk-pilot/coronasafe/care_fe/links/6)[![](https://sourcerer.io/fame/tomahawk-pilot/coronasafe/care_fe/images/7)](https://sourcerer.io/fame/tomahawk-pilot/coronasafe/care_fe/links/7)\n\n[![Storybook](https://raw.githubusercontent.com/storybooks/brand/master/badge/badge-storybook.svg)](https://careui.coronasafe.in)\n[![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=coronasafe_care_fe&metric=alert_status)](https://sonarcloud.io/summary/new_code?id=coronasafe_care_fe)\n![Code scanning - action](https://github.com/coronasafe/care_fe/workflows/Code%20scanning%20-%20action/badge.svg)\n![OSSAR](https://github.com/coronasafe/care_fe/workflows/OSSAR/badge.svg)\n[![Cypress Tests](https://github.com/coronasafe/care_fe/actions/workflows/cypress.yaml/badge.svg)](https://github.com/coronasafe/care_fe/actions/workflows/cypress.yaml)\n![Staging Release](https://github.com/coronasafe/care_fe/workflows/CARE%20Develop%20Registry/badge.svg)\n![Production Release](https://github.com/coronasafe/care_fe/workflows/Production%20Release/badge.svg)\n[![Codacy Badge](https://api.codacy.com/project/badge/Grade/200482ab117e4b5397ff3f5ae5719aa2)](https://www.codacy.com/gh/coronasafe/care_fe?utm_source=github.com&utm_medium=referral&utm_content=coronasafe/care_fe&utm_campaign=Badge_Grade)\n[![CircleCI](https://circleci.com/gh/coronasafe/care_fe.svg?style=svg)](https://circleci.com/gh/coronasafe/care_fe)\n[![Maintainability](https://api.codeclimate.com/v1/badges/f1438f693aa459805301/maintainability)](https://codeclimate.com/github/coronasafe/care_fe/maintainability)\n\n## Getting started\n\n- \ud83d\udcac Comment on the issue if you are willing to take it up, and link the pull request with the issue.\n- \ud83c\udff7\ufe0f Tag `@coronasafe/code-reviewers` for faster resolution.\n- \ud83d\udcf8 Attach screenshots in the pull requests showing the changes made in the UI.\n\n#### Install the required dependencies\n\n```sh\nnpm install --legacy-peer-deps\n```\n\n#### \ud83c\udfc3 Run the app in development mode\n\n```sh\nnpm run dev\n```\n\nOnce the development server has started, open [localhost:4000](http://localhost:4000) in your browser. The page will be automatically reloaded when you make edits and save. You will also see any lint errors in the console.\n\n#### \ud83d\udd11 Staging API Credentials\n\nAuthenticate to staging API with any of the following credentials\n\n```yaml\n- username: devdistrictadmin\n  password: Coronasafe@123\n  role: District Admin\n\n- username: staff-dev\n  password: Coronasafe@123\n  role: Staff\n\n- username: doc-dev\n  password: Coronasafe@123\n  role: Doctor\n```\n\n#### \ud83c\udff7\ufe0f Make use labels to update the PR/issue status\n\n- Mark your PRs as `work-in-progress` if it's still being worked on.\n- Once you have solved the related issue, mark your PR with `need testing` and `need review` labels.\n- When you\u2019re making a PR with lots of code changes that affects multiple functionalities, or is likely to break, make sure you tag it with `Major Code Change` label.\n\n#### \ud83e\uddea Run cypress tests\n\nEnsure that the development server is running and then run the cypress tests in either of the ways described below.\n\n```sh\n$ npm run cypress:run        # To run all tests in headless mode.\n$ npm run cypress:run:gui    # To run all tests in headed mode.\n$ npm run cypress:open       # To debug and run tests individually.\n```\n\n- Failed test screenshots are saved in `cypress/screenshots`\n- All test videos are saved in `cypress/videos`\n\n## \ud83d\udcd6 Documentations\n\n- [CARE Documentation](https://docs.coronasafe.network/coronasafe-care-documentation/)\n- [Swagger API Documentation](https://careapi.ohc.network/swagger/)\n- [Storybook component library](https://careui.coronasafe.in/)\n\n## \ud83d\ude80 Production\n\n#### Build the app for production\n\n```sh\nnpm run build\n```\n\nBuilds the app for production to the `build` folder. It correctly bundles React in production mode and optimizes the build for the best performance.\n\n#### Start a production `http-server`\n\n```sh\nnpm run preview\n```\n\nStarts a production http-server in local to run the project with Service worker.\nThe build is minified and the filenames include the hashes.\n\n**\ud83d\ude80 Your app is ready to be deployed!**\n"
 },
 {
  "repo": "openboxes/openboxes",
  "language": "Groovy",
  "readme_contents": "[![Build Status](https://travis-ci.org/openboxes/openboxes.svg?branch=develop)](https://travis-ci.org/openboxes/openboxes)\n[![Documentation Status](https://readthedocs.org/projects/openboxes/badge/?version=develop)](https://readthedocs.org/projects/openboxes/?badge=develop)\n[![Financial Contributors on Open Collective](https://opencollective.com/openboxes/all/badge.svg?label=financial+contributors)](https://opencollective.com/openboxes) \n[![Slack Signup](http://slack-signup.openboxes.com/badge.svg)](http://slack-signup.openboxes.com)\n[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com) [![Join the chat at https://gitter.im/openboxes/openboxes](https://badges.gitter.im/openboxes/openboxes.svg)](https://gitter.im/openboxes/openboxes?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n\nOpenBoxes\n=========\n\n## About\n\nOpenBoxes is an Open Source Inventory and Supply Chain Management System. The initial implementation of OpenBoxes will occur at Partners In Health-supported facilities in Haiti.\n\n## Contributors\n\n### Code Contributors\n\nThis project exists thanks to all the people who contribute. [[Contribute](CONTRIBUTING.md)].\n<a href=\"https://github.com/openboxes/openboxes/graphs/contributors\"><img src=\"https://opencollective.com/openboxes/contributors.svg?width=890&button=false\" /></a>\n\n### Financial Contributors\n\nBecome a financial contributor and help us sustain our community. [[Contribute](https://opencollective.com/openboxes/contribute)]\n\n#### Individuals\n\n<a href=\"https://opencollective.com/openboxes\"><img src=\"https://opencollective.com/openboxes/individuals.svg?width=890\"></a>\n\n#### Organizations\n\nSupport this project with your organization. Your logo will show up here with a link to your website. [[Contribute](https://opencollective.com/openboxes/contribute)]\n\n<a href=\"https://opencollective.com/openboxes/organization/0/website\"><img src=\"https://opencollective.com/openboxes/organization/0/avatar.svg\"></a>\n<a href=\"https://opencollective.com/openboxes/organization/1/website\"><img src=\"https://opencollective.com/openboxes/organization/1/avatar.svg\"></a>\n<a href=\"https://opencollective.com/openboxes/organization/2/website\"><img src=\"https://opencollective.com/openboxes/organization/2/avatar.svg\"></a>\n<a href=\"https://opencollective.com/openboxes/organization/3/website\"><img src=\"https://opencollective.com/openboxes/organization/3/avatar.svg\"></a>\n<a href=\"https://opencollective.com/openboxes/organization/4/website\"><img src=\"https://opencollective.com/openboxes/organization/4/avatar.svg\"></a>\n<a href=\"https://opencollective.com/openboxes/organization/5/website\"><img src=\"https://opencollective.com/openboxes/organization/5/avatar.svg\"></a>\n<a href=\"https://opencollective.com/openboxes/organization/6/website\"><img src=\"https://opencollective.com/openboxes/organization/6/avatar.svg\"></a>\n<a href=\"https://opencollective.com/openboxes/organization/7/website\"><img src=\"https://opencollective.com/openboxes/organization/7/avatar.svg\"></a>\n<a href=\"https://opencollective.com/openboxes/organization/8/website\"><img src=\"https://opencollective.com/openboxes/organization/8/avatar.svg\"></a>\n<a href=\"https://opencollective.com/openboxes/organization/9/website\"><img src=\"https://opencollective.com/openboxes/organization/9/avatar.svg\"></a>\n\n## License\n\nCopyright (c) 2012 Partners In Health.  All rights reserved.\nThe use and distribution terms for this software are covered by the\nEclipse Public License 1.0 (http://opensource.org/licenses/eclipse-1.0.php)\nwhich can be found in the file epl-v10.html at the root of this distribution.\nBy using this software in any fashion, you are agreeing to be bound by\nthe terms of this license.\nYou must not remove this notice, or any other, from this software.\n\n## Deploy to your Azure VPC\n\n*Deploy to Azure* button will bring you to Azure portal, where after filling a few of the properties you can get your OpenBoxes environment in a matter of minutes. In the Azure setup screen, look at each property's tooltip description to understand its purpose.\n\nFor more information and step-by-step instructions go to:\nhttps://openboxes.atlassian.net/wiki/spaces/OBW/pages/1719435265/Push-button+deployment\n\n*Deploy to Azure* uses the ARM template defined in [openboxes-devops](https://github.com/openboxes/openboxes-devops/tree/master/arm-template) repository.\n\n[![Deploy to Azure](https://aka.ms/deploytoazurebutton)](https://portal.azure.com/#create/Microsoft.Template/uri/https%3A%2F%2Fraw.githubusercontent.com%2Fopenboxes%2Fopenboxes-devops%2Fmaster%2Farm-template%2Fopenboxes-arm.json)\n\n*Visualize* will open armviz.io to display graph of all of the Azure resources, which the deployment will provision.\n\n[![Visualize](https://raw.githubusercontent.com/Azure/azure-quickstart-templates/master/1-CONTRIBUTION-GUIDE/images/visualizebutton.svg?sanitize=true)](http://armviz.io/#/?load=https%3A%2F%2Fraw.githubusercontent.com%2Fopenboxes%2Fopenboxes-devops%2Fmaster%2Farm-template%2Fopenboxes-arm.json)\n\n\n## Setup development environment\n\n### Install Dependencies\n\n#### Required\n* [Java 7 (must install Java 7)](https://www.azul.com/downloads/?version=java-7-lts&package=jdk)\n* [MySQL 5.7](https://downloads.mysql.com/archives/community/)\n  * Mac users: 5.7.31 is the latest 5.7.x with a pre-built installer and works fine\n* [SDK Man](https://sdkman.io/install)\n* [Grails 1.3.9](https://grails.org/download.html)\n* NPM 6.14.6\n* Node 14+\n\n#### Optional\n* [IntelliJ IDEA 14.1](https://www.jetbrains.com/idea/download/)\n* Chrome\n\n### Basic setup instructions for developers\n\nThese instructions are for developers only.  If you are a user/implementer, please check out our \n[Installation](http://docs.openboxes.com/en/latest/installation/) documentation.\n\n#### 1. Install Dependencies\nInstall required dependencies above\n\n#### 2. Install Grails\nCheck that you have SDK Man installed properly (otherwise follow instructions on the skdman install page).\n```\n$ sdk version\nSDKMAN 5.13.2\n```\n\nInstall Grails 1.3.9\n```\n$ sdk install grails 1.3.9\n```\n\n#### 3. Clone repository \nIf you are a core contributor:\n```\ngit clone git@github.com:openboxes/openboxes.git      \n```\nIf you are a not core contributor, fork [openboxes git repository](https://github.com/openboxes/openboxes)\nand replace git url with the one of your forked repository\n```\ngit clone git@github.com:<gitusername>/openboxes.git      \n```\n\n#### 4. Create database \nCreate openboxes database\n```\nmysql -u root -p -e 'create database openboxes default charset utf8;'\n```\n\nCreate openboxes user \n```\nmysql -u root -p -e 'grant all on openboxes.* to \"openboxes\"@\"localhost\" identified by \"openboxes\";'\n```\n\n#### 5. Create Openboxes configuration file \nEdit `$HOME/.grails/openboxes-config.properties`\n\n```\n# Database connection settings\n# You can use dataSource.url when you are using a non-dev/non-test database (test-app may not run properly).\n# If you want to run $ grails test-app you should comment out the dataSource.url below and create a new \n# openboxes_test database.  Eventually, we will move to an in-memory H2 database for testing, but we're \n# currently stuck with MySQL because I'm using some MySQL-specific stuff in the Liquibase changesets.  My bad.\n\ndataSource.url=jdbc:mysql://localhost:3306/openboxes\ndataSource.username=openboxes\ndataSource.password=openboxes\n\n# OpenBoxes mail settings (disabled by default)\ngrails.mail.enabled=false\n```\nNOTE: If you are running in development mode with a copy of an existing production database, you will need to\ninstruct the application to not setup test fixtures automatically by uncommenting the above property:\n```\nopenboxes.fixtures.enabled=false\n```\n\n#### 6. Install NPM dependencies\n```    \nnpm config set engine-strict true\nnpm install\n```\n\n#### 7. Build React frontend\nYou can build React frontend with this command, but it will be automatically build when starting the application.\n```    \nnpm run bundle\n```\n\n#### 8. React frontend Hot-Reload\nWhen using this command React fronted will be rebuild automatically after any change, you just need to refresh the \nbrowser to see the effect.\n```    \nnpm run watch\n```\n\n#### 9. Upgrade the project to the currently installed grails version \nEither of the following actions (upgrade, compile, run-app) should generate the all important Spring configuration \n(`/WEB-INF/applicationContext.xml`) and start the dependency resolution process.  \n\n```    \ngrails upgrade\n```\nOR\n\n```    \ngrails compile\n```\n\nThe `grails compile` step is not necessary since `grails run-app` will invoke the compilation step, but it doesn't \nhurt anything.\n\nIf you see any errors, run the command again.  \n\n**IMPORTANT** That last line is important.  Because of some quirkiness with the way older versions of Grails resolve \ndependencies and generates config files, you may need to run either of these commands multiple times in order to \nresolve all dependencies and generate the config files.\n\nOnce the dependency resolution phase has completed, all dependencies will be stored in a local ivy cache (usually \nunder `$USER_HOME/.grails/ivy-cache`).  You do not have to worry about this, just know that the dependencies are now \non your machine and Grails will attempt to find them there before it tries to resolve them in a remote repository. \n\n#### 10. Start application in development mode\nThe application can be run in development mode.  This starts the application running in an instance of Tomcat within \nthe Grails console.\nYou may need to run 'grails run-app' several times in order to download all dependencies.\n```\ngrails run-app\n```\n\n#### 11. Open application in Google Chrome \n```\nhttp://localhost:8080/openboxes\n```\n\n#### 12. Log into OpenBoxes \nYou can use the default accounts (manager:password OR admin:password). Once you are logged in as an admin, you can \ncreate own account. Or you can use the signup form to create a new account.\n\n#### 13. React tests\nTo run new frontend (React) tests type:\n```\nnpm test\n```\n\n#### 14. Grails tests\nTo run Grails tests type:\n```\ngrails test-app\n```\n\n#### 15. React documentation\nStart a style guide dev server:\n```\nnpm run styleguide\n```\nView your style guide in the browser:\n```\nhttp://localhost:6060\n```\n\n## Troubleshooting\n\n### How to Debug \n* Run Grails in debug mode\n    ```\n    grails-debug run-app\n    ```\n* In Intellij navigate to Run > Edit Configurations\n* Create a new Remote Debug Configuration\n    * Name: openboxes-debug\n    * Transport: Socket\n    * Debugger mode: Attach\n    * Host: localhost\n    * Port: 5005\n* Command line arguments should look something like this: \n    ```\n    -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005\n    ```\n\n\n### Problem\n```\nCaused by: java.io.FileNotFoundException: Could not open ServletContext resource [/WEB-INF/applicationContext.xml]\n```\n### Solution\nExecute the grails upgrade command in order to generate the files nece\n```\n$ grails upgrade\n```\nSee the following stackoverflow article:\nhttp://stackoverflow.com/questions/24243027/grails-spring-security-sample-application-not-working\n"
 },
 {
  "repo": "hyperledger-labs/sawtooth-healthcare",
  "language": "Python",
  "readme_contents": "# Medical Insurance\n\n# About\n\nThis is blockchain project based on Hyperledger Sawtooth. This project focuses on interaction between Insurer, \nInsured Person (Patient), and Medical Facility. It covers data gathering flow and manages data access based on \nclient\u2019s role.\n\n# Features\n\n## Functional\n\n- Create main participants (like Patient, Doctor, Clinic Desk, Lab and Insurance)\n- Clinic Desk registers/closes claim only if with patient\u2019s consent\n- Doctor updates existing claim only if with patient\u2019s consent\n- Insurance company creates contract with patient/receive an invoice when the claim resolved\n- Patient allows/revokes consent to access his data by Clinic Desk/Doctor\n- Patient adds pulse items from hardware (Android smartphone in our case)\n- Patient adds lab test items\n- Any participant has data access according to granted roles/permissions\n\n## Technical\n\n- Private key to store/read data (every participant uses his own private key to store data, and public key to read data)\n- Private data access management (every participant has a role assigned with corresponding permissions)\n- Docker compliance (every component of this project has separate docker image and fully isolated)\n- Various network representation (blockchain network has few options (1 node/Dev-Mode consensus, 3 nodes/PoET consensus/single VM, 3 nodes/PoET consensus/3 separate VMs)\n- IoT (android client to send data to blockchain and manage consent)\n- Unit tests (automated regression testing)\n- Load tests\n\n# Components\n\n- **Consent/Identity/Authorization Management** smart contract (responsible to operate with identity/permission related data)\n- **Data Management** smart contract (responsible to handle EHR patient\u2019s data)\n- **Insurance/Contract Management** smart contract (responsible to operate with insurance related data)\n- **Finance/Invoice Management** smart contract (responsible to operate with finances/invoices)\n- **REST-API service** (provides interface between client and blockchain network)\n- **Web client** (web page where a participant can operate as one of predefined roles such as doctor, patient etc)\n- **Android client** (application link to Play Market for patient to add pulse items and manage consent for own data)\n- **CLI client** (command line service to perform basic operations)\n\n# Architecture\n\n![Infrastructure](https://github.com/hyperledger-labs/sawtooth-healthcare/blob/master/MedicalInsurance.png)\n\n# Technology stack\n\nPython/Hyperledger Sawtooth/Docker/Docker-Composer/Protobuf/Setuptools/Sanic/Shell/JMeter/Webpack\n\n# How to setup and run infrastructure (1 node/Dev-Mode consensus)\n\n- Go to root project\u2019s directory\n- Clone this repo (if not cloned yet))\n- Ensure all containers stopped: \u201cdocker-compose down --remove-orphans\u201d\n- Get recent data from the repo: \u201cgit pull\u201d\n- Start new containers: \u201cdocker-compose up\u201d\n\n# Demo\n\nTBD\n"
 },
 {
  "repo": "chvlyl/ML_in_Biomed",
  "language": null,
  "readme_contents": "# Machine Learning in Healthcare and Biomedical Applications\n\n* Data driven decision making\n* Questions -> Data -> Models/Tools\n\n# Table of Contents\n1. [Overview](#overview)\n2. [EHR data](#ehr-data)\n3. [Insurance claims data](#claims)\n4. [Clinical notes](#clinical-notes)\n5. [Image data](#image-data)\n6. [Time series data](#time-series-data)\n7. [Genomics data](#genomics-data)\n\n\n\n\n## Overview\n|Data type|Models/Tools|Applications|\n|---|---|---|\n|-EHR data <br/>-Insurance claims data |ML(logistic regression,XGBoost)|Predict outcomes (disease, death, readmission etc.)|\n|-Clinical notes <br/>-Conversation text data|-Rule based approach(regular expression)<br/>-Deep learning apporach|-Extract concepts from clinical notes <br/>-Knowledge graphs<br/>-Chat-bot<br/>-QA system|\n|Medical image data (X-ray, CT, OCR image etc.)|CNN|-Detection: diagnosis of skin cancer lung nodule or diabetic reinopathy<br/>-Segmentation of tumor, histopathology|\n|Time series data (EEG, ECG, vital sign data etc.)|HMM,RNN,CNN|-Heart disease<br/>-Sleep disorder(apnea)<br/>-ICU monitoring|\n|Genomics data|GATK,QIIME|-Cancer mutation identification<br/>-Biomarker identification<br/>-Durg discovery |\n|Other data (hospital operational data)|-ML(regression)<br/>-Queueing model|-Reduce operational cost<br/>-Improve patient experience<br/>-ER wait time and queueing|\n\n## EHR data\n\n\n|Prediction outcomes|Models/Tools|Data type|Sample size|Reference|Year|\n|---|---|---|---|---|---|\n|Review||||[Mining electronic health records: towards better research applications and clinical care](https://www.nature.com/nrg/journal/v13/n6/full/nrg3208.html)|2012|\n|Review||||[Opportunities and challenges in developing risk prediction models with electronic health records data: a systematic review](https://academic.oup.com/jamia/article/24/1/198/2631444/Opportunities-and-challenges-in-developing-risk)|2016|\n|heart failure|-logistic regression<br/>-random forest|longitudinal EHR data|1684 heart failure cases and 13525 matched controls|[Early Detection of Heart Failure Using Electronic Health Records](http://circoutcomes.ahajournals.org/content/9/6/649.long)|2016|\n|heart failure (review)||||[Population Risk Prediction Models for Incident Heart Failure](http://circheartfailure.ahajournals.org/content/8/3/438.long)|2015|\n|Kidney transplant graft failure|Cox regression|10-years EHR data|69,440 kidney transpants|[A comprehensive risk quantification score for deceased donor kidneys: the kidney donor risk index](https://insights.ovid.com/pubmed?pmid=19623019)|2009|\n\n\n## Clinical notes\n|Prediction outcomes|Models/Tools|Data type|Sample size|Reference|Year|\n|---|---|---|---|---|---|\n|Review||||[Realizing the full potential of electronic health records: the role of natural language processing](https://academic.oup.com/jamia/article-lookup/doi/10.1136/amiajnl-2011-000501)|2011|\n|Review||||[Natural language processing: an introduction](https://academic.oup.com/jamia/article-lookup/doi/10.1136/amiajnl-2011-000464)|2011|\n|Negation|Regular expression and rule-based approach|Clinical reports|2060 discharge summaries|[A simple algorithm for identifying negated findings and diseases in discharge summaries](http://www.sciencedirect.com/science/article/pii/S1532046401910299?via%3Dihub)|2001|\n|||||[Using electronic health records to drive discovery in disease genomics](https://www.nature.com/nrg/journal/v12/n6/pdf/nrg2999.pdf)||\n|NER||discharge summaries|826 notes|[A study of machine-learning-based approaches to extract clinical entities and their assertions from discharge summaries](https://academic.oup.com/jamia/article-lookup/doi/10.1136/amiajnl-2011-000163)|2011|\n\n\n\n\n## Image data\n|Prediction outcomes|Models/Tools|Data type|Sample size|Reference|Year|\n|---|---|---|---|---|---|\n|Diabetic retinopathy|CNN|retinal fundus images|128175 retinal images|[Development and Validation of a Deep Learning Algorithm for Detection of Diabetic Retinopathy in Retinal Fundus Photographs](http://jamanetwork.com/journals/jama/fullarticle/2588763)|2016|\n|Skin cancer |CNN|skin images|129,450 skin images|[Dermatologist-level classification of skin cancer with deep neural networks](https://www.nature.com/nature/journal/v542/n7639/full/nature21056.html)|2017|\n|Tumor|CNN|Pathology images|400+110 slides|[Detecting Cancer Metastases on Gigapixel Pathology Images](https://arxiv.org/abs/1703.02442)|2017|\n|||||[Deep Learning Automates the Quantitative Analysis of Individual Cells in Live-Cell Imaging Experiments](http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005177)||\n\n\n\n## Time series data\n|Prediction outcomes|Models/Tools|Data type|Sample size|Reference|Year|\n|---|---|---|---|---|---|\n|sinus rhythm and atrial fibrillation|34-layer convolutional neural network (CNN)|single-lead ECG|-(Train) 64,121 ECG records from 29,163 patients<br/>-(Test) 336 records from 328 unique patients|[Cardiologist-Level Arrhythmia Detection with Convolutional Neural Networks](https://arxiv.org/abs/1707.01836)|2017|\n|Hand movements|CNN|sEMG|67 intact subjects and 11 transradial amputees|[Deep Learning with Convolutional Neural Networks Applied to Electromyography Data: A Resource for the Classification of Movements for Prosthetic Hands](http://journal.frontiersin.org/article/10.3389/fnbot.2016.00009/full)|2016|\n|Review||ICU data||[Machine Learning and Decision Support in Critical Care](http://ieeexplore.ieee.org/document/7390351/?part=1)|2017|\n\n\n\n## Genomics data\n|Prediction outcomes|Models/Tools|Data type|Sample size|Reference|Year|\n|---|---|---|---|---|---|\n|Genetic variants|Exome NGS|NGS&EHR data|50,726 individuals|[Distribution and clinical impact of functional variants in 50,726 whole-exome sequences from the DiscovEHR study](http://science.sciencemag.org/content/354/6319/aaf6814)|2016|\n|Familial hypercholesterolemia|Exome NGS|NGS&EHR data|50,726 individuals|[Genetic identification of familial hypercholesterolemia within a single U.S. health care system](http://science.sciencemag.org/content/354/6319/aaf7000)|2016|\n\n\n## Other\n|Prediction outcomes|Models/Tools|Data type|Sample size|Reference|Year|\n|---|---|---|---|---|---|\n|Drug discovery|LSTM|Assay|12-27 assays|[Low data drug discovery with one-shot learning](http://pubs.acs.org/doi/full/10.1021/acscentsci.6b00367)|2017|\n|Tutorial||Image||[Deep learning models for health care: challenges and solutions](http://www-bcf.usc.edu/~liu32/icml_tutorial.pdf)|2017|\n|Tutorial||Image||[Deep learning in radiology: recent advances, challenges and future trends](https://ulasbagci.wordpress.com/2016/12/10/deep-learning-in-radiology-rsna-2016/)|2016|\n|Tutorial||||[Big data analytics for healthcare](https://www.siam.org/meetings/sdm13/sun.pdf)|2013|\n|Tutorial||Image||[Survey of deep learning in radiology](https://healthcare.ai/survey-of-deep-learning-in-radiology/)|2017|\n|ER wait time||ER visit time||[Accurate ED Wait Time Prediction](https://web.stanford.edu/~bayati/papers/edwait.pdf)|2017|\n\n\n\n\n"
 },
 {
  "repo": "abuanwar072/Production-Ready-Doctor-Consultant-App-UI-",
  "language": "Dart",
  "readme_contents": "# Production-Ready Doctor Consultant App - Flutter UI\n\n## [Watch it on YouTube](https://youtube.com/playlist?list=PLxUBb2A_UUy9rvCoLXopsYQJTTnuW0NIq)\n\n**Packages we are using:**\n\n- flutter_svg: [link](https://pub.dev/packages/flutter_svg)\n\n## [Complete Source code (Patreon)](https://cutt.ly/DmKF5HP)\n\nIn this full series, we will show you how to Building Production-Ready Healthcare/ Doctor Consult Android and iOS app UI using Flutter. This full app contains more than 15 screens like Splash Screen, log in & Sign up page. In episode one we will show you how to create those three screens even show you how to validate the form field on flutter for example email validation, password validation, or username is required.\nThat's not all we also learn how to show custom keyboard like when you are on email field it shows the @ sign, or on phone number text field it only shows numbers.\n\n### Doctor Consultant App Final UI\n\n![Preview](/gif.gif)\n\n![App Full UI](/previews/1.png)\n![Episode 1 - Splash and Auth Page](/previews/2.png)\n\n**List Of Screens:**\n\n- Splash\n- Sign in (With form validation)\n- Sign up (With form validation)\n- Home\n- Appointment \n- BottomNavigationBar \n- Profile\n- List of Doctors\n- Settings"
 },
 {
  "repo": "amanjeetsahu/AI-for-Healthcare-Nanodegree",
  "language": "Jupyter Notebook",
  "readme_contents": "# AI for Healthcare\n\n#### NANODEGREE PROGRAM SYLLABUS\n\n\n## Overview\n\n```\nPlay a critical role in enhancing clinical decision-making with machine learning to build the treatments of\nthe future. Learn to build, evaluate, and integrate predictive models that have the power to transform\npatient outcomes. Begin by classifying and segmenting 2D and 3D medical images to augment diagnosis\nand then move on to modeling patient outcomes with electronic health records to optimize clinical trial\ntesting decisions. Finally, build an algorithm that uses data collected from wearable devices to estimate the\nwearer\u2019s pulse rate in the presence of motion.\n```\n```\nA graduate of this program will be able to:\n```\n- Recommend appropriate imaging modalities for common clinical applications of 2D medical imaging\n- Perform exploratory data analysis (EDA) on 2D medical imaging data to inform model training and\nexplain model performance\n- Establish the appropriate \u2018ground truth\u2019 methodologies for training algorithms to label medical images\n- Extract images from a DICOM dataset\n- Train common CNN architectures to classify 2D medical images\n- Translate outputs of medical imaging models for use by a clinician\n- Plan necessary validations to prepare a medical imaging model for regulatory approval\n- Detect major clinical abnormalities in a DICOM dataset\n- Train machine learning models for classification tasks using real-world 3D medical imaging data\n- Integrate models into a clinician\u2019s workflow and troubleshoot deployments\n- Build machine learning models in a manner that is compliant with U.S. healthcare data security and\nprivacy standards\n- Use the TensorFlow Dataset API to scalably extract, transform, and load datasets that are aggregated\nat the line, encounter, and longitudinal (patient) data levels\n- Analyze EHR datasets to check for common issues (data leakage, statistical properties, missing values,\nhigh cardinality) by performing exploratory data analysis with TensorFlow Data Analysis and Validation\nlibrary\n- Create categorical features from Key Industry Code Sets (ICD, CPT, NDC) and reduce dimensionality for\nhigh cardinality features\n- Use TensorFlow feature columns on both continuous and categorical input features to create derived\nfeatures (bucketing, cross-features, embeddings)\n- Use Shapley values to select features for a model and identify the marginal contribution for each\nselected feature\n- Analyze and determine biases for a model for key demographic groups\n- Use the TensorFlow Probability library to train a model that provides uncertainty range predictions in\norder to allow for risk adjustment/prioritization and triaging of predictions\n- Preprocess data (eliminate \u201cnoise\u201d) collected by IMU, PPG, and ECG sensors based on mechanical,\nphysiology and environmental effects on the signal.\n- Create an activity classification algorithm using signal processing and machine learning techniques\n- Detect QRS complexes using one-dimensional time series processing techniques\n- Evaluate algorithm performance without ground truth labels\n- Generate a pulse rate algorithm that combines information from the PPG and IMU sensor streams\n\n\n```\nPrerequisites :\nIntermediate\nPython, and\nExperience with\nMachine Learning\n```\n**Flexible Learning** :\nSelf-paced, so\nyou can learn on\nthe schedule that\nworks best for you.\n\n**Estimated Time** :\n4 Months at\n15 hours / week\n\n```\nNeed Help?\nudacity.com/advisor\nDiscuss this program\nwith an enrollment\nadvisor.\n```\n\n## Course 1: Applying AI to 2D Medical Imaging\n\n## Data\n\n2D imaging, such as X-ray, is widely used when making critical decisions about patient care and accessible by\nmost healthcare centers around the world. With the advent of deep learning for non-medical imaging data\nover the past half decade, the world has quickly turned its attention to how AI could be specifically applied to\nmedical imaging to improve clinical decision-making and to optimize workflows. Learn the fundamental skills\nneeded to work with 2D medical imaging data and how to use AI to derive clinically-relevant insights from\ndata gathered via different types of 2D medical imaging such as x-ray, mammography, and digital pathology.\nExtract 2D images from DICOM files and apply the appropriate tools to perform exploratory data analysis\non them. Build different AI models for different clinical scenarios that involve 2D images and learn how to\nposition AI tools for regulatory approval.\n\n##### Course Project\n\n##### Pneumonia Detection\n\n##### from Chest X-Rays\n\n```\nChest X-ray exams are one of the most frequent and cost-effective\ntypes of medical imaging examinations. Deriving clinical diagnoses\nfrom chest X-rays can be challenging, however, even by skilled\nradiologists. When it comes to pneumonia, chest X-rays are the best\navailable method for point-of-care diagnosis. More than 1 million\nadults are hospitalized with pneumonia and around 50,000 die\nfrom the disease every year in the US alone. The high prevalence\nof pneumonia makes it a good candidate for the development of a\ndeep learning application for two reasons: 1) Data availability in a\nhigh enough quantity for training deep learning models for image\nclassification 2) Opportunity for clinical aid by providing higher\naccuracy image reads of a difficult-to-diagnose disease and/or reduce\nclinical burnout by performing automated reads of very common\nscans. In this project, you will analyze data from the NIH Chest\nX-ray dataset and train a CNN to classify a given chest X-ray for the\npresence or absence of pneumonia. First, you\u2019ll curate training and\ntesting sets that are appropriate for the clinical question at hand from\na large collection of medical images. Then, you will create a pipeline\nto extract images from DICOM files that can be fed into the CNN for\nmodel training. Lastly, you\u2019ll write an FDA 501(k) validation plan that\nformally describes your model, the data that it was trained on, and a\nvalidation plan that meets FDA criteria in order to obtain clearance of\nthe software being used as a medical device.\n```\n\n###### LEARNING OUTCOMES\n\n###### LESSON ONE\n\n```\nIntroduction to\nAI for 2D Medical\nImaging\n```\n- Explain what AI for 2D medical imaging is and why it is relevant.\n\n###### LESSON TWO\n\n```\nClinical\nFoundations of 2D\nMedical Imaging\n```\n- Learn about different 2D medical imaging modalities and their\nclinical applications\n- Understand how different types of machine learning\nalgorithms can be applied to 2D medical imaging\n- Learn how to statistically assess an algorithm\u2019s performance\n- Understand the key stakeholders in the 2D medical imaging\nspace.\n\n###### LESSON THREE\n\n```\n2D Medical Imaging\nExploratory Data\nAnalysis\n```\n- Learn what the DICOM standard it is and why it exists\n- Use Python tools to explore images extracted from DICOM files\n- Apply Python tools to explore DICOM header data\n- Prepare a DICOM dataset for machine learning\n- Explore a dataset in preparation for machine learning\n\n###### LESSON FOUR\n\n```\nClassification\nModels of 2D\nMedical Images\n```\n- Understand architectures of different machine learning and\ndeep learning models, and the differences between them\n- Split a dataset for training and testing an algorithm\n- Learn how to define a gold standard\n- Apply common image pre-processing and augmentation\ntechniques to data\n- Fine-tune an existing CNN architecture for transfer learning\nwith 2D medical imaging applications\n- Evaluate a model\u2019s performance and optimize its parameters\n\n###### LESSON FIVE\n\n```\nTranslating AI\nAlgorithms for\nClinical Settings\nwith the FDA\n```\n- Learn about the FDA\u2019s risk categorization for medical devices\nand how to define an Intended Use statement\n- Identify and describe algorithmic limitations for the FDA\n- Translate algorithm performance statistics into clinically\nmeaningful information that can trusted by professionals\n- Learn how to create an FDA validation plan\n\n\n## Course 2: Applying AI to 3D Medical Imaging\n\n## Data\n\n3D medical imaging exams such as CT and MRI serve as critical decision-making tools in the clinician\u2019s\neveryday diagnostic armamentarium. These modalities provide a detailed view of the patient\u2019s anatomy and\npotential diseases, and are a challenging though highly promising data type for AI applications. Learn the\nfundamental skills needed to work with 3D medical imaging datasets and frame insights derived from the\ndata in a clinically relevant context. Understand how these images are acquired, stored in clinical archives, and\nsubsequently read and analyzed. Discover how clinicians use 3D medical images in practice and where AI holds\nmost potential in their work with these images. Design and apply machine learning algorithms to solve the\nchallenging problems in 3D medical imaging and how to integrate the algorithms into the clinical workflow.\n\n###### LEARNING OUTCOMES\n\n```\nLESSON ONE Introduction to\nAI for 3D Medical\nImaging\n```\n- Explain what AI for 3D medical imaging is and why it is\nrelevant\n\n##### Course Project\n\n##### Hippocampal Volume\n\n##### Quantification in\n\n##### Alzheimer\u2019s Progression\n\n```\nHippocampus is one of the major structures of the human brain\nwith functions that are primarily connected to learning and\nmemory. The volume of the hippocampus may change over time,\nwith age, or as a result of disease. In order to measure hippocampal\nvolume, a 3D imaging technique with good soft tissue contrast is\nrequired. MRI provides such imaging characteristics, but manual\nvolume measurement still requires careful and time consuming\ndelineation of the hippocampal boundary. In this project, you will\ngo through the steps that will have you create an algorithm that will\nhelp clinicians assess hippocampal volume in an automated way\nand integrate this algorithm into a clinician\u2019s working environment.\nFirst, you\u2019ll prepare a hippocampal image dataset to train the U-net\nbased segmentation model, and capture performance on the test\ndata. Then, you will connect the machine learning execution code\ninto a clinical network, create code that will generate reports based\non the algorithm output, and inspect results in a medical image\nviewer. Lastly, you\u2019ll write up a validation plan that would help\ncollect clinical evidence of the algorithm performance, similar to\nthat required by regulatory authorities.\n```\n\n###### LESSON TWO\n\n```\n3D Medical\nImaging - Clinical\nFundamentals\n```\n- Identify medical imaging modalities that generate 3D images\n- List clinical specialties who use 3D images to influence clinical\ndecision making\n- Describe use cases for 3D medical images\n- Explain the principles of clinical decision making\n- Articulate the basic principles of CT and MR scanner operation\n- Perform some of the common 3D medical image analysis\ntasks such as windowing, MPR and 3D reconstruction\n\n###### LESSON THREE\n\n```\n3D Medical\nImaging\nExploratory Data\nAnalysis\n```\n- Describe and use DICOM and NIFTI representations of 3D\nmedical imaging data\n- Explain specifics of spatial and dimensional encoding of 3D\nmedical images\n- Use Python-based software packages to load and inspect 3D\nmedical imaging volumes\n- Use Python-based software packages to explore datasets\nof 3D medical images and prepare it for machine learning\npipelines\n- Visualize 3D medical images using open software packages\n\n###### LESSON FOUR\n\n```\n3D Medical\nImaging - Deep\nLearning Methods\n```\n- Distinguish between classification and segmentation\nproblems as they apply to 3D imaging\n- Apply 2D, 2.5D and 3D convolutions to a medical imaging\nvolume\n- Apply U-net algorithm to train an automatic segmentation\nmodel of a real-world CT dataset using PyTorch\n- Interpret results of training, measure efficiency using Dice and\nJaccard performance metrics\n\n###### LESSON FIVE\n\n```\nDeploying AI\nAlgorithms in the\nReal World\n```\n- Identify the components of a clinical medical imaging network\nand integration points as well as DICOM protocol for medical\nimage exchange\n- Define the requirements for integration of AI algorithms\n- Use tools for modeling of clinical environments so that\nit is possible to emulate and troubleshoot real-world AI\ndeployments\n- Describe regulatory requirements such as FDA medical device\nframework and HIPAA required for operating AI for clinical\ncare\n- Provide input into regulatory process, as a data scientist\n\n\n## Course 3: Applying AI to EHR Data\n\n```\nWith the transition to electronic health records (EHR) over the last decade, the amount of EHR data has increased\nexponentially, providing an incredible opportunity to unlock this data with AI to benefit the healthcare system.\nLearn the fundamental skills of working with EHR data in order to build and evaluate compliant, interpretable\nmachine learning models that account for bias and uncertainty using cutting-edge libraries and tools including\nTensorFlow Probability, Aequitas, and Shapley. Understand the implications of key data privacy and security\nstandards in healthcare. Apply industry code sets (ICD10-CM, CPT, HCPCS, NDC), transform datasets at different\nEHR data levels, and use TensorFlow to engineer features.\n```\n###### LEARNING OUTCOMES\n\n###### LESSON ONE\n\n```\nEHR Data Security\nand Analysis\n```\n- Understand U.S. healthcare data security and privacy best\npractices (e.g. HIPAA, HITECH) and how they affect utilizing\nprotected health information (PHI) data and building\nmodels\n- Analyze EHR datasets to check for common issues\n(data leakage, statistical properties, missing values, high\ncardinality) by performing exploratory data analysis\n\n```\nLESSON TWO EHR Code Sets\n```\n- Understand the usage and structure of key industry code\nsets (ICD, CPT, NDC).\n- Group and categorize data within EHR datasets using code\nsets.\n\n##### Course Project\n\n##### Patient Selection for\n\n##### Diabetes Drug Testing\n\n```\nEHR data is becoming a key source of real-world evidence (RWE)\nfor the pharmaceutical industry and regulators to make decisions\non clinical trials. In this project, you will act as a data scientist\nfor an exciting unicorn healthcare startup that has created a\ngroundbreaking diabetes drug that is ready for clinical trial\ntesting. Your task will be to build a regression model to predict the\nestimated hospitalization time for a patient in order to help select/\nfilter patients for your study. First, you will perform exploratory\ndata analysis in order to identify the dataset level and perform\nfeature selection. Next, you will build necessary categorical and\nnumerical feature transformations with TensorFlow. Lastly, you will\nbuild a model and apply various analysis frameworks, including\nTensorFlow Probability and Aequitas, to evaluate model bias and\nuncertainty.\n```\n\n###### LESSON THREE\n\n```\nEHR Transformations\n& Feature\nEngineering\n```\n- Use the TensorFlow Dataset API to scalably extract,\ntransform, and load datasets\n- Build datasets aggregated at the line, encounter, and\nlongitudinal(patient) data levels\n- Create derived features (bucketing, cross-features,\nembeddings) utilizing TensorFlow feature columns on both\ncontinuous and categorical input features\n\n###### LESSON FOUR\n\n```\nBuilding, Evaluating,\nand Interpreting\nModels\n```\n- Analyze and determine biases for a model for key\ndemographic groups by evaluating performance metrics\nacross groups by using the Aequitas framework.\n- Train a model that provides an uncertainty range with the\nTensorFlow Probability library\n- Use Shapley values to select features for a model and\nidentify the marginal contribution for each selected feature\n\n\n## Course 4: Applying AI to Wearable Device Data\n\nWearable devices are an emerging source of physical health data. With continuous, unobtrusive monitoring\nthey hold the promise to add richness to a patient\u2019s health information in remarkable ways. Understand the\nfunctional mechanisms of three sensors (IMU, PPG, and ECG) that are common to most wearable devices\nand the foundational signal processing knowledge critical for success in this domain. Attribute physiology\nand environmental context\u2019s effect on the sensor signal. Build algorithms that process the data collected by\nmultiple sensor streams from wearable devices to surface insights about the wearer\u2019s health.\n\n###### LEARNING OUTCOMES\n\n###### LESSON ONE\n\n```\nIntro to Digital\nSampling & Signal\nProcessing\n```\n- Describe how to digitally sample analog signals\n- Apply signal processing techniques (eg. filtering,\nresampling, interpolation) to time series signals.\n- Apply frequency domain techniques (eg. FFT, STFT,\nspectrogram) to time series signals\n- Use matplotlib\u2019s plotting functionality to visualize signals\n\n###### LESSON TWO\n\n```\nIntroduction to\nSensors\n```\n- Describe how sensors convert a physical phenomenon into\nan electrical one.\n- Understand the signal and noise characteristics of the IMU\nand PPG signals\n\n##### Course Project\n\n##### Motion Compensated\n\n##### Pulse Rate Estimation\n\n```\nWearable devices have multiple sensors all collecting information\nabout the same person at the same time. Combining these\ndata streams allows us to accomplish many tasks that would be\nimpossible from a single sensor. In this project, you will build an\nalgorithm which combines information from two of the sensors\nthat are covered in this course -- the IMU and PPG sensors -- that\ncan estimate the wearer\u2019s pulse rate in the presence of motion.\nFirst, you\u2019ll create and evaluate an activity classification algorithm\nby building signal processing features and a random forest model.\nThen, you will build a pulse rate algorithm that uses the activity\nclassifier and frequency domain techniques, and also produces\nan associated confidence metric that estimates the accuracy\nof the pulse rate estimate. Lastly, you will evaluate algorithm\nperformance and iterate on design until the desired accuracy is\nachieved.\n```\n\n**LESSON THREE Activity Classification**\n\n- Perform exploratory data analysis to understand class\nimbalance and subject imbalance\n- Gain an intuitive understanding signal characteristics and\npotential feature performance\n- Write code to implement features from literature\n- Recognize the danger overfitting of technique (esp.\non small datasets), not simply of model parameters or\nhyperparameters\n\n**LESSON FOUR ECG Signal Processing**\n\n- Understand the electrophysiology of the heart at a basic\nlevel\n- Understand the signal and noise characteristics of the ECG\n- Understand how atrial fibrillation manifests in the ECG\n- Build a QRS complex detection algorithm\n- Build an arrhythmia detection algorithm from a wearable\nECG signal\n- Understand how models can be cascaded together to\nachieve higher-order functionality\n\n\n## Our Classroom Experience\n\n###### REAL-WORLD PROJECTS\n\n```\nBuild your skills through industry-relevant projects. Get\npersonalized feedback from our network of 900+ project\nreviewers. Our simple interface makes it easy to submit\nyour projects as often as you need and receive unlimited\nfeedback on your work.\n```\n###### KNOWLEDGE\n\n```\nFind answers to your questions with Knowledge, our\nproprietary wiki. Search questions asked by other students,\nconnect with technical mentors, and discover in real-time\nhow to solve the challenges that you encounter.\n```\n###### STUDENT HUB\n\n```\nLeverage the power of community through a simple, yet\npowerful chat interface built within the classroom. Use\nStudent Hub to connect with your fellow students in your\nExecutive Program.\n```\n###### WORKSPACES\n\n```\nSee your code in action. Check the output and quality of\nyour code by running them on workspaces that are a part\nof our classroom.\n```\n###### QUIZZES\n\n```\nCheck your understanding of concepts learned in the\nprogram by answering simple and auto-graded quizzes.\nEasily go back to the lessons to brush up on concepts\nanytime you get an answer wrong.\n```\n###### CUSTOM STUDY PLANS\n\n```\nPreschedule your study times and save them to your\npersonal calendar to create a custom study plan. Program\nregular reminders to keep track of your progress toward\nyour goals and completion of your program.\n```\n###### PROGRESS TRACKER\n\n```\nStay on track to complete your Nanodegree program with\nuseful milestone reminders.\n```\n\n## Learn with the Best\n\n### Nikhil Bikhchandani\n\n```\nDATA SCIENTIST\nAT VERILY LIFE SCIENCES\nNikhil spent five years working with\nwearable devices at Google and Verily Life\nSciences. His work with wearables spans\nmany domains including cardiovascular\ndisease, neurodegenerative diseases, and\ndiabetes. Before Alphabet, he earned a\nB.S. and M.S. in Electrical Engineering and\nComputer Science at Carnegie Mellon.\n```\n### Mazen Zawaideh\n\n```\nRADIOLOGIST\nAT UNIVERSITY OF WASHINGTON\nMazen Zawaideh is a Neuroradiology\nFellow at the University of Washington,\nwhere he focuses on advanced diagnostic\nimaging and minimally invasive\ntherapeutics. He also served as a Radiology\nConsultant for Microsoft Research for AI\napplications in oncologic imaging.\n```\n### Emily Lindemer\n\n```\nDIRECTOR OF DATA SCIENCE &\nANALYTICS AT WELLFRAME\nEmily is an expert in AI for both medical\nimaging and digital healthcare. She holds\na PhD from Harvard-MIT\u2019s Health Sciences\n& Technology division and founded her\nown digital health company in the opioid\nspace. She now runs the data science\ndivision of a digital healthcare company in\nBoston called Wellframe.\n```\n### Ivan Tarapov\n\n```\nSR. PROGRAM MANAGER\nAT MICROSOFT RESEARCH\nAt Microsoft Research, Ivan works on robust\nauto-segmentation algorithms for MRI and CT\nimages. He has worked with Physio-Control,\nStryker, Medtronic, and Abbott, where he\nhelped develop external and internal cardiac\ndefibrillators, insulin pumps, telemedicine,\nand medical imaging systems.\n```\n\n## Learn with the Best\n\n### Michael Dandrea\n\n```\nPRINCIPAL DATA SCIENTIST\nAT GENENTECH\n```\n```\nMichael is on the Pharma Development\nInformatics team at Genentech (part of\nthe Roche Group), where he works on\nimproving clinical trials and developing\nsafer, personalized treatments with\nclinical and EHR data. Previously, he was\na Lead Data Scientist on the AI team at\nMcKesson\u2019s Change Healthcare.\n```\n\n## All Our Nanodegree Programs Include:\n\n###### EXPERIENCED PROJECT REVIEWERS\n\n```\nREVIEWER SERVICES\n```\n- Personalized feedback & line by line code reviews\n- 1600+ Reviewers with a 4.85/5 average rating\n- 3 hour average project review turnaround time\n- Unlimited submissions and feedback loops\n- Practical tips and industry best practices\n- Additional suggested resources to improve\n\n###### TECHNICAL MENTOR SUPPORT\n\n```\nMENTORSHIP SERVICES\n```\n- Questions answered quickly by our team of\ntechnical mentors\n- 1000+ Mentors with a 4.7/5 average rating\n- Support for all your technical questions\n\n###### PERSONAL CAREER SERVICES\n\n```\nCAREER COACHING\n```\n- Personal assistance in your job search\n- Monthly 1-on-1 calls\n- Personalized feedback and career guidance\n- Interview preparation\n- Resume services\n- Github portfolio review\n- LinkedIn profile optimization\n\n\n## Frequently Asked Questions\n\nPROGRAM OVERVIEW\n\n**WHY SHOULD I ENROLL?**\nArtificial Intelligence has revolutionized many industries in the past decade,\nand healthcare is no exception. In fact, the amount of data in **healthcare has\ngrown 20x in the past 7 years** , causing an expected surge in the Healthcare AI\nmarket from **$2.1 to $36.1 billion by 2025** at an annual growth rate of 50.4%. AI\nin Healthcare is transforming the way patient care is delivered, and is impacting\nall aspects of the medical industry, including early detection, more accurate\ndiagnosis, advanced treatment, health monitoring, robotics, training, research and\nmuch more.\n\nBy leveraging the power of AI, providers can deploy more precise, efficient,\nand impactful interventions at exactly the right moment in a patient\u2019s care. In\nlight of the worldwide COVID-19 pandemic, there has never been a better time\nto understand the possibilities of artificial intelligence within the healthcare\nindustry and learn how you can make an impact to better the world\u2019s healthcare\ninfrastructure.\n\n###### WHAT JOBS WILL THIS PROGRAM PREPARE ME FOR?\n\nThis program will help you apply your Data Science and Machine Learning\nexpertise in roles including Physician Data Scientist; Healthcare Data Scientist;\nHealthcare Data Scientist, Machine Learning; Healthcare Machine Learning\nEngineer, Research Scientist, Machine Learning, and more roles in the healthcare\nand health tech industries that necessitate knowledge of AI and machine learning\ntechniques.\n\n###### HOW DO I KNOW IF THIS PROGRAM IS RIGHT FOR ME?\n\nIf you are interested in applying your data science and machine learning\nexperience in the healthcare industry, then this program is right for you.\n\nAdditional job titles and backgrounds that could be helpful include Data Scientist,\nMachine Learning Engineer, AI Specialist, Deep Learning Research Engineer, and AI\nScientist. This program is also a good fit for Researchers, Scientists, and Engineers\nwho want to make an impact in the medical field.\n\nENROLLMENT AND ADMISSION\n\n###### DO I NEED TO APPLY? WHAT ARE THE ADMISSION CRITERIA?\n\nThere is no application. This Nanodegree program accepts everyone, regardless of\nexperience and specific background.\n\n\n## FAQs Continued\n\n###### WHAT ARE THE PREREQUISITES FOR ENROLLMENT?\n\nTo be best prepared to succeed in this program, students should be able to:\n\nIntermediate Python:\n\n- Read, understand, and write code in Python, including language constructs\nsuch as functions and classes.\n- Read code using vectorized operations with the NumPy library.\n\nMachine Learning:\n\n- Build a machine learning model for a supervised learning problem and\nunderstand basic methods to represent categorical and numerical features\nas inputs for this model\n- Perform simple machine learning tasks, such as classification and\nregression, from a set of features\n- Apply basic knowledge of Python data and machine learning frameworks\n(Pandas, NumPy, TensorFlow, PyTorch) to manipulate and clean data for\nconsumption by different estimators/algorithms (e.g. CNNs, RNNs, tree-\nbased models).\n\n**IF I DO NOT MEET THE REQUIREMENTS TO ENROLL, WHAT SHOULD I DO?**\nTo best prepare for this program, we recommend the **AI Programming with\nPython Nanodegree program** and the **Deep Learning Nanodegree program** or\nthe **Intro to Machine Learning with PyTorch Nanodegree program** or the **Intro\nto Machine Learning with TensorFlow Nanodegree program**.\n\nTUITION AND TERM OF PROGRAM\n\n**HOW IS THIS NANODEGREE PROGRAM STRUCTURED?**\nThe AI for Healthcare Nanodegree program is comprised of content and\ncurriculum to support four projects. Once you subscribe to a Nanodegree\nprogram, you will have access to the content and services for the length of time\nspecified by your subscription. We estimate that students can complete the\nprogram in four months, working 15 hours per week.\n\nEach project will be reviewed by the Udacity reviewer network. Feedback will be\nprovided and if you do not pass the project, you will be asked to resubmit the\nproject until it passes.\n\n**HOW LONG IS THIS NANODEGREE PROGRAM?**\nAccess to this Nanodegree program runs for the length of time specified in\nthe payment card on the Nanodegree program overview page. If you do not\ngraduate within that time period, you will continue learning with month to\nmonth payments. See the **Terms of Use** for other policies around the terms of\naccess to our Nanodegree programs.\n\n\n## FAQs Continued\n\n###### CAN I SWITCH MY START DATE? CAN I GET A REFUND?\n\nPlease see the Udacity Program **Terms of Use** and **FAQs** for policies on\nenrollment in our programs.\n\nSOFTWARE AND HARDWARE\n\n**WHAT SOFTWARE AND VERSIONS WILL I NEED IN THIS PROGRAM?**\nFor this Nanodegree program, you will need a desktop or laptop computer\nrunning recent versions of Windows, Mac OS X, or Linux and an unmetered\nbroadband Internet connection. For an ideal learning experience, a computer\nwith Mac or Linux OS is recommended.\n\nYou will use Python, PyTorch, TensorFlow, and Aequitas in this Nanodegree\nprogram.\n\n\n"
 },
 {
  "repo": "rahulremanan/HIMA",
  "language": "HTML",
  "readme_contents": "\ufeff# HIMA\n(Healthcare Image Analysis)\n\nHIMA is phonetic equivalent of Sanskrit root: \\\u0939\u093f\u092e\\ meaning snow.\n\nAn open-source cloud powered image analytics platform for healthcare imaging data.\n\nBuilt with Jomiraki, an open source development environment for artificial intelligence applications using Python, Tensorflow and Keras, all residing inside a secure linux VM.\n"
 },
 {
  "repo": "GoogleCloudPlatform/healthcare-data-harmonization-dataflow",
  "language": "Java",
  "readme_contents": "# HL7v2 to FHIR Pipeline\n\nThis directory contains a reference Cloud Dataflow pipeline to convert HL7v2 messages to FHIR resources. Please note that additional configurations and hardening are required before processing PHI data with this pipeline.\n\n## Prerequisites\n\n* Have a Linux (Ubuntu & Debian preferred) machine ready.\n  * Install [GCC compiler](https://gcc.gnu.org/install/).\n  * Install [Go tools](https://golang.org/doc/install), versions >= [1.14](https://golang.org/dl/) are recommended.\n  * Install [Gradle](https://gradle.org/install/), version [6.3.0](https://gradle.org/next-steps/?version=6.3&format=bin) is recommended.\n  * Install [Protoc](https://github.com/protocolbuffers/protobuf/releases), version [3.14.0](https://github.com/protocolbuffers/protobuf/releases) is recommended.\n* Add your public key to [GitHub](https://help.github.com/en/github/authenticating-to-github/adding-a-new-ssh-key-to-your-github-account).\n* Install the latest [GCloud SDK](https://cloud.google.com/sdk/install).\n* Create a [project](https://cloud.google.com/resource-manager/docs/creating-managing-projects).\n* Create an [HL7v2 Store](https://cloud.google.com/healthcare/docs/how-tos/hl7v2).\n  * Make sure to use beta endpoints and provide `NotificationConfig`s and a schematized `ParserConfig`.\n* Create a [FHIR Store](https://cloud.google.com/healthcare/docs/how-tos/fhir).\n  * Set [enableUpdateCreate](https://cloud.google.com/healthcare/docs/reference/rest/v1/projects.locations.datasets.fhirStores#FhirStore.FIELDS.enable_update_create) and [disableReferentialIntegrity](https://cloud.google.com/healthcare-api/docs/reference/rest/v1/projects.locations.datasets.fhirStores#FhirStore.FIELDS.disable_referential_integrity) for the FHIR store.\n* Enable [Cloud Dataflow API](https://cloud.google.com/endpoints/docs/openapi/enable-api).\n* (Highly recommended) Enable [audit logging](https://cloud.google.com/logging/docs/audit).\n\n### Permissions\n\nMake sure you have [enough permissions](https://cloud.google.com/dataflow/docs/concepts/access-control#creating_jobs) to run Cloud Dataflow jobs.\n\nThe [Cloud Dataflow Controller Service Account](https://cloud.google.com/dataflow/docs/concepts/security-and-permissions#controller_service_account) needs the following permissions.\n\n* `roles/pubsub.subscriber`.\n  * To listen for PubSub notifications from new messages. The service account only needs the role on the specific PubSub subscription.\n* `roles/healthcare.hl7V2Consumer`.\n  * To access messages in your HL7v2 store. The service account only needs the role on the source HL7v2 Store.\n* `roles/healthcare.fhirResourceEditor`.\n  * To write transformed resources to your FHIR store. The service account only needs this role on the target FHIR Store.\n* `roles/storage.objectAdmin`.\n  * To access mapping and harmonization configurations on GCS. The service account needs this role on all GCS buckets that the mappings reside in.\n\n## How to Run\n\nBuild a fat JAR of the pipeline by running the following from the project directory.\n\n* Please make sure gradle is added to PATH before running the following commands.\n\n```bash\n# Generate wrapper classes.\ngradle wrapper --gradle-version 6.7.1\n./gradlew shadowJar\n```\n\nA JAR file should be generated in `build/libs` folder.\n\nNow run the pipeline with the following command:\n\n```bash\n# Please set the environment variables in the following command.\n\njava -jar build/libs/converter-0.1.0-all.jar --pubSubSubscription=\"projects/${PROJECT?}/subscriptions/${SUBSCRIPTION?}\" \\\n                                             --readErrorPath=\"gs://${ERROR_BUCKET?}/read/\" \\\n                                             --writeErrorPath=\"gs://${ERROR_BUCKET?}/write/\" \\\n                                             --mappingErrorPath=\"gs://${ERROR_BUCKET?}/mapping/\" \\\n                                             --mappingPath=\"gs://${MAPPING_BUCKET?}/mapping.textproto\" \\\n                                             --fhirStore=\"projects/${PROJECT?}/locations/${LOCATION?}/datasets/${DATASET?}/fhirStores/${FHIRSTORE?}\" \\\n                                             --runner=DataflowRunner \\\n                                             --region=${REGION?} \\\n                                             --project=${PROJECT?}\n```\n\nA few notes:\n\n- By default, streaming pipelines do not have autoscaling enabled, please use\neither `--enableStreamingEngine` (recommended) or a combination of `--autoscalingAlgorithm=THROUGHPUT_BASED` and\n`--maxNumWorkers=N` to manually enable it. See [this page](https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#autotuning-features) for more details.\n- For production use, we recommend enabling agent metrics by appending `--experiments=enable_stackdriver_agent_metrics` as an option (you will need to grant `roles/monitoring.metricWriter` to Dataflow controller service account as well), see [this page](https://cloud.google.com/dataflow/docs/guides/using-cloud-monitoring#receive_worker_vm_metrics_from_monitoring_agent) for more details. Additionally, we **highly** recommend limiting the number of threads on each worker, e.g. `--numberOfWorkerHarnessThreads=10`. You can tune the limit based on your workload.\n- To generate a template instead of running the pipeline, add `--stagingLocation=gs://${STAGING_LOCATION} --templateLocation=gs://${TEMPLATE_LOCATION}` to the above command. See [here](https://cloud.google.com/dataflow/docs/guides/templates/creating-templates)\n\nPlease take a look at the `PipelineRunner` class to see the concrete meaning of\neach argument.\n\nYou should be able to verify that a Dataflow pipeline is running from the cloud\nconsole UI. Data should start flowing through the pipeline and arrive at the\nFHIR Store, use the SearchResources API to verify that FHIR Resources are\nwritten correctly.\n\n# DICOM to FHIR Pipeline\n\nThis directory contains a reference Cloud Dataflow pipeline to convert a DICOM Study to a FHIR ImagingStudy resource.\n\n## Prerequisites\n\n* Have a Linux (Ubuntu & Debian preferred) machine ready.\n  * Install [GCC compiler](https://gcc.gnu.org/install/).\n  * Install [Go tools](https://golang.org/doc/install), versions >= [1.14](https://golang.org/dl/) are recommended.\n  * Install [Gradle](https://gradle.org/install/), version [6.3.0](https://gradle.org/next-steps/?version=6.3&format=bin) is recommended.\n  * Install [Protoc](https://github.com/protocolbuffers/protobuf/releases), version [3.14.0](https://github.com/protocolbuffers/protobuf/releases) is recommended.\n* Add your public key to [GitHub](https://help.github.com/en/github/authenticating-to-github/adding-a-new-ssh-key-to-your-github-account).\n* Install the latest [GCloud SDK](https://cloud.google.com/sdk/install).\n* Create a [project](https://cloud.google.com/resource-manager/docs/creating-managing-projects).\n* Create a [DICOM Store](https://cloud.google.com/healthcare/docs/how-tos/dicom).\n* Create an R4 [FHIR Store](https://cloud.google.com/healthcare/docs/how-tos/fhir).\n  * Set [disableReferentialIntegrity](https://cloud.google.com/healthcare-api/docs/reference/rest/v1/projects.locations.datasets.fhirStores#FhirStore.FIELDS.disable_referential_integrity) for the FHIR store.\n* Enable [Cloud Dataflow API](https://cloud.google.com/endpoints/docs/openapi/enable-api).\n\n### Permissions\n\nMake sure you have [enough permissions](https://cloud.google.com/dataflow/docs/concepts/access-control#creating_jobs) to run Cloud Dataflow jobs.\n\nThe [Cloud Dataflow Controller Service Account](https://cloud.google.com/dataflow/docs/concepts/security-and-permissions#controller_service_account) needs the following permissions.\n\n* `roles/pubsub.subscriber`.\n  * To listen for PubSub notifications from new messages. The service account only needs the role on the specific PubSub subscription.\n* `roles/healthcare.dicomEditor`.\n  * To access metadata of DICOM stores.\n* `roles/healthcare.fhirResourceEditor`.\n  * To write transformed resources to your FHIR store. The service account only needs this role on the target FHIR Store.\n* `roles/storage.objectAdmin`.\n  * To access mapping and harmonization configurations on GCS. The service account needs this role on all GCS buckets that the mappings reside in.\n\n## How to Run\n\nBuild a fat JAR of the pipeline by running the following from the project directory.\n\n* Please make sure gradle is added to PATH before running the following commands.\n\n```bash\n# Generate wrapper classes.\ngradle wrapper\n./gradlew shadowJar -PmainClass=com.google.cloud.healthcare.etl.runner.dicomtofhir.DicomToFhirStreamingRunner\n```\n\nA JAR file should be generated in `build/libs` folder.\n\nNow run the pipeline with the following command:\n\n```bash\n# Please set the environment variables in the following command.\n\njava -jar build/libs/converter-0.1.0-all.jar --pubSubSubscription=\"projects/${PROJECT?}/subscriptions/${SUBSCRIPTION?}\" \\\n                                             --readErrorPath=\"gs://${ERROR_BUCKET?}/read/\" \\\n                                             --writeErrorPath=\"gs://${ERROR_BUCKET?}/write/\" \\\n                                             --mappingErrorPath=\"gs://${ERROR_BUCKET?}/mapping/\" \\\n                                             --mappingPath=\"gs://${MAPPING_BUCKET?}/main.textproto\" \\\n                                             --fhirStore=\"projects/${PROJECT?}/locations/${LOCATION}/datasets/${DATASET?}/fhirStores/${FHIRSTORE?}\" \\\n                                             --runner=DataflowRunner \\\n                                             --region=${REGION?} \\\n                                             --project=${PROJECT?}\n```\n\nA few notes:\n\n- By default, streaming pipelines do not have autoscaling enabled, please use\neither `--enableStreamingEngine` (recommended) or a combination of `--autoscalingAlgorithm=THROUGHPUT_BASED` and\n`--maxNumWorkers=N` to manually enable it. See [this page](https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#autotuning-features) for more details.\n- For production use, we recommend enabling agent metrics by appending `--experiments=enable_stackdriver_agent_metrics` as an option (you will need to grant `roles/monitoring.metricWriter` to Dataflow controller service account as well), see [this page](https://cloud.google.com/dataflow/docs/guides/using-cloud-monitoring#receive_worker_vm_metrics_from_monitoring_agent) for more details. Additionally, we **highly** recommend limiting the number of threads on each worker, e.g. `--numberOfWorkerHarnessThreads=10`. You can tune the limit based on your workload.\n- To generate a template instead of running the pipeline, add `--stagingLocation=gs://${STAGING_LOCATION} --templateLocation=gs://${TEMPLATE_LOCATION}` to the above command. See [here](https://cloud.google.com/dataflow/docs/guides/templates/creating-templates)\n- The mappingPath file (main.textproto) configures the mapping library. Ensure that the paths inside the file exist (References the following repository: https://github.com/GoogleCloudPlatform/healthcare-data-harmonization/). The required binaries should be installed by the build JAR command. There is a sample main.textproto at src/main/java/com/google/cloud/healthcare/etl/runner/dicomtofhir/main.textproto, if specifying GCS (non-local) paths use `gcs_location:` instead of `local_path:`.\n- As the mappings do not assign an ID to the mapped FHIR resource, each input creates a new output in the FHIR store. TODO: evaluate maintaining an ID for DICOM Instances.\n\nPlease take a look at the `PipelineRunner` class to see the concrete meaning of\neach argument.\n\nYou should be able to verify that a Dataflow pipeline is running from the cloud\nconsole UI. Data should start flowing through the pipeline and arrive at the\nFHIR Store, use the SearchResources API to verify that FHIR Resources are\nwritten correctly.\n\n# Custom to FHIR Pipeline\n\nThis directory contains a reference Cloud Dataflow pipeline to convert custom/non standard messages to FHIR resources. Please note that additional configurations and hardening are required before processing PHI data with this pipeline.\n\n## Prerequisites\n\n* Have a Linux (Ubuntu & Debian preferred) machine ready.\n  * Install [GCC compiler](https://gcc.gnu.org/install/).\n  * Install [Go tools](https://golang.org/doc/install), versions >= [1.14](https://golang.org/dl/) are recommended.\n  * Install [Gradle](https://gradle.org/install/), version [6.3.0](https://gradle.org/next-steps/?version=6.3&format=bin) is recommended.\n  * Install [Protoc](https://github.com/protocolbuffers/protobuf/releases), version [3.14.0](https://github.com/protocolbuffers/protobuf/releases) is recommended.\n* Add your public key to [GitHub](https://help.github.com/en/github/authenticating-to-github/adding-a-new-ssh-key-to-your-github-account).\n* Install the latest [GCloud SDK](https://cloud.google.com/sdk/install).\n* Create a [project](https://cloud.google.com/resource-manager/docs/creating-managing-projects).\n* Create a [FHIR Store](https://cloud.google.com/healthcare/docs/how-tos/fhir).\n  * Set [enableUpdateCreate](https://cloud.google.com/healthcare/docs/reference/rest/v1/projects.locations.datasets.fhirStores#FhirStore.FIELDS.enable_update_create) and [disableReferentialIntegrity](https://cloud.google.com/healthcare-api/docs/reference/rest/v1/projects.locations.datasets.fhirStores#FhirStore.FIELDS.disable_referential_integrity) for the FHIR store.\n* Enable [Cloud Dataflow API](https://cloud.google.com/endpoints/docs/openapi/enable-api).\n* (Highly recommended) Enable [audit logging](https://cloud.google.com/logging/docs/audit).\n\n### Permissions\n\nMake sure you have [enough permissions](https://cloud.google.com/dataflow/docs/concepts/access-control#creating_jobs) to run Cloud Dataflow jobs.\n\nThe [Cloud Dataflow Controller Service Account](https://cloud.google.com/dataflow/docs/concepts/security-and-permissions#controller_service_account) needs the following permissions.\n\n* `roles/pubsub.subscriber`.\n  * To listen for PubSub notifications from new messages. The service account only needs the role on the specific PubSub subscription.\n* `roles/healthcare.fhirResourceEditor`.\n  * To write transformed resources to your FHIR store. The service account only needs this role on the target FHIR Store.\n* `roles/storage.objectAdmin`.\n  * To access mapping and harmonization configurations on GCS. The service account needs this role on all GCS buckets that the mappings reside in.\n* `roles/pubsub.viewer`.\n  * To access the PubSub subscription.\n* `roles/dataflow.worker`.\n  * To execute the Dataflow job.\n\n## How to Run\n\nBuild a fat JAR of the pipeline by running the following from the project directory.\n\n* Please make sure gradle is added to PATH before running the following commands.\n\n```bash\n# Generate wrapper classes.\ngradle wrapper --gradle-version 6.7.1\n./gradlew shadowJar\n```\n\nA JAR file should be generated in `build/libs` folder.\n\nNow run the pipeline with the following command:\n\n* Edit build.gradle and make the change to ensure the mainClassName is set as thus\n\nshadowJar {\n    mainClassName = project.findProperty('mainClass') ?: 'com.google.cloud.healthcare.etl.runner.customtofhir.CustomToFhirStreamingRunner'\n    dependsOn('buildDeps')\n}\n\n* (Optional) Edit the build.gradle\n Depending on the java environment you might need the change as well for the code to build.\n\n// sourceCompatibility = 11\nsourceCompatibility = 1.8\n\n```bash\n# Please set the environment variables in the following command.\n\njava -jar build/libs/converter-0.1.0-all.jar --pubSubSubscription=\"projects/${PROJECT?}/subscriptions/${SUBSCRIPTION?}\" \\\n                                             --readErrorPath=\"gs://${ERROR_BUCKET?}/read/\" \\\n                                             --writeErrorPath=\"gs://${ERROR_BUCKET?}/write/\" \\\n                                             --mappingErrorPath=\"gs://${ERROR_BUCKET?}/mapping/\" \\\n                                             --mappingPath=\"gs://${MAPPING_BUCKET?}/mapping.textproto\" \\\n                                             --fhirStore=\"projects/${PROJECT?}/locations/${LOCATION?}/datasets/${DATASET?}/fhirStores/${FHIRSTORE?}\" \\\n                                             --runner=DataflowRunner \\\n                                             --region=${REGION?} \\\n                                             --project=${PROJECT?} \\\n                                             --serviceAccount=dataflow-0222@smede-276406.iam.gserviceaccount.com\n```\n\nA few notes:\n\n- By default, streaming pipelines do not have autoscaling enabled, please use\neither `--enableStreamingEngine` (recommended) or a combination of `--autoscalingAlgorithm=THROUGHPUT_BASED` and\n`--maxNumWorkers=N` to manually enable it. See [this page](https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#autotuning-features) for more details.\n- For production use, we recommend enabling agent metrics by appending `--experiments=enable_stackdriver_agent_metrics` as an option (you will need to grant `roles/monitoring.metricWriter` to Dataflow controller service account as well), see [this page](https://cloud.google.com/dataflow/docs/guides/using-cloud-monitoring#receive_worker_vm_metrics_from_monitoring_agent) for more details. Additionally, we **highly** recommend limiting the number of threads on each worker, e.g. `--numberOfWorkerHarnessThreads=10`. You can tune the limit based on your workload.\n- To generate a template instead of running the pipeline, add `--stagingLocation=gs://${STAGING_LOCATION} --templateLocation=gs://${TEMPLATE_LOCATION}` to the above command. See [here](https://cloud.google.com/dataflow/docs/guides/templates/creating-templates)\n\nPlease take a look at the `PipelineRunner` class to see the concrete meaning of\neach argument.\n\nYou should be able to verify that a Dataflow pipeline is running from the cloud\nconsole UI. Data should start flowing through the pipeline and arrive at the\nFHIR Store, use the SearchResources API to verify that FHIR Resources are\nwritten correctly.\n\n## Support\n\nPlease file GitHub issues if you encounter any problems.\n"
 },
 {
  "repo": "IMA-WorldHealth/bhima",
  "language": "JavaScript",
  "readme_contents": "BHIMA\n=================\n\nBHIMA is a free, open source accounting and hospital information management system\n(HIMS) tailored for rural hospitals in Africa.  We are an international team\nbased in the Democratic Republic of the Congo.\n\nBHIMA is an acronym for _basic hospital information management application_.\n\nProject Goals\n--------------------\n\nBHIMA aims to provide a flexible and robust accounting and managerial solution\nfor rural hospitals.  This includes, but is not limited to, basic income/expense\nreporting, budgeting, patient and organisational billing, depreciation,\ninventory and pricing, and purchasing.\n\nAdditionally, BHIMA bundles reports and optional reporting plugins to aid\nhospital administrators, aid organisations, and governmental/non-governmental\nagencies access up to date utilization data.  It targets insitutions that must conform\nto the [OHADA](https://en.wikipedia.org/wiki/OHADA) reporting standards in western\nand central Africa.\n\nFinally, the entire project is designed to scale from a single, low cost device\nin a clinic, to a large multi-hundred bed institution with tens of users\naccessing the server simultaneously.\n\nTechnology\n---------------\n\nThe client-side is written in AngularJS and the server in NodeJS.  Session management\nis enabled by Redis, and the backend is a MySQL database.\n\nContributing\n---------------\nAll contributions are welcome!  If you want to get started hacking on BHIMA, the\n[developer wiki](https://github.com/IMA-WorldHealth/bhima/wiki) contains notes\non our designs and testing infrastructure.  We also have a dedicated documentation\nwebsite https://docs.bhi.ma.  If you have any questions or need help getting started,\nplease [open an issue](https://github.com/IMA-WorldHealth/bhima/issues/new) - chances\nare you are not the only one!\n\nIf you just want to jump into to messing with the software, check out [Getting Up And Running](https://github.com/IMA-WorldHealth/bhima/wiki/Getting-Up-and-Running).\n\nIf you are new to Github, they have an [excellent guide](https://docs.github.com/en/github/getting-started-with-github).\n\nInstallation\n-------------------\nSee the [installation guide](https://docs.bhi.ma/en/for-developers/installing-bhima.html).\n\nLicense\n---------------\nBHIMA is licensed under GPL-2.0.  [Read the License](./LICENSE).\n"
 },
 {
  "repo": "CodeForBaltimore/Healthcare-Rollcall",
  "language": "Vue",
  "readme_contents": "[![Build Status](https://travis-ci.org/CodeForBaltimore/Healthcare-Rollcall.svg?branch=master)](https://travis-ci.org/CodeForBaltimore/Healthcare-Rollcall) [![Netlify Status](https://api.netlify.com/api/v1/badges/83fb49cb-61e1-4c21-8893-03e17e75d972/deploy-status)](https://app.netlify.com/sites/healthcare-rollcall/deploys) [![Language grade: JavaScript](https://img.shields.io/lgtm/grade/javascript/g/CodeForBaltimore/Healthcare-Rollcall.svg?logo=lgtm&logoWidth=18)](https://lgtm.com/projects/g/CodeForBaltimore/Healthcare-Rollcall/context:javascript)\n\n# Healthcare Rollcall\n\nIn the event of a disaster, Baltimore City and the Baltimore City Health Department (BCHD) needs to be able to verify the status of all healthcare providers in the city.\n\n<!-- TOC -->\n\n- [Healthcare Rollcall](#healthcare-rollcall)\n  - [What is this?](#what-is-this)\n  - [Documentation](#documentation)\n- [Project setup](#project-setup)\n  - [Keeping your API up to date](#keeping-your-api-up-to-date)\n  - [Compiles and hot-reloads for development](#compiles-and-hot-reloads-for-development)\n  - [Compiles and minifies for production](#compiles-and-minifies-for-production)\n  - [Lints and fixes files](#lints-and-fixes-files)\n  - [Customize configuration](#customize-configuration)\n- [Using this product](#using-this-product)\n  - [Testing](#testing)\n    - [Using Jest for unit testing](#using-jest-for-unit-testing)\n    - [Using Snyk to check for security vulnerabilities](#using-snyk-to-check-for-security-vulnerabilities)\n- [Sources and Links](#sources-and-links)\n  - [Contributors \u2728](#contributors-)\n\n<!-- /TOC -->\n\n## What is this?\n\nThis system will provide methods for healthcare providers to check-in during disasters, and update their information during non-emergency periods. During an emergency this system will track providers responses to a questionnaire. This questionnaire can be specific to a single disaster, or can be more general. Examples:\n\n- Widespread power blackout\n- Epidemic or Pandemic response (COVID-19)\n- Natural disaster\n\nThis system will make use of digital services and modern methodologies to automate parts of the check-in process to help the city prioritize its call list and response plan. Additionally, the system will validate contact information regularly during non-emergency times to ensure the city has the most up-to-date information for each provider.\n\n## Documentation\n\nMore documentation can be found in the [Docs](/docs) folder.\n\n# Project setup\n\nThe quickest way to get started is using the included `docker-compose` to build a complete local stack (web, api, and database) of the project.\n\nAdd the following to a file named `.env` in your project directory:\n\n```conf\nPORT=3000\nVUE_APP_BASE_API_URL=http://localhost:3001\nVUE_APP_API_VERSION=1\nDATABASE_PASSWORD= # Custom value\nJWT_KEY= # Custom value\n```\n\n- `PORT`: The port the web service will be exposed on the host machine. Default: `3000`\n- `VUE_APP_BASE_API_URL`: The URL to the api service, includes hostname and port. Default: `http://localhost:3001`.\n- `DATABASE_PASSWORD`: The password used to authenticate to the postgres database. For security, use a custom value.\n- `JWT_KEY`: A secret value to generate JSON Web Tokens (JWTs) locally. For security, use a custom value.\n\nYou would then run the docker-compose setup with `docker-compose up -d --build` to run the DB & API, build the front end and stand up all containers.  Once this command completes, wait 5-30 seconds for the db scripts to finish and you'll be able to access your own Healthcare Rollcall app at `https://localhost:3000`.\n\n## Keeping your API up to date\n\nBy default the backend solution will pull the `master` branch of [Bmore-Responsive](https://github.com/CodeForBaltimore/Bmore-Responsive). If you wish to keep this up to date you should run:\n\n```shell\ndocker-compose build\n```\n\nYou can also specify a tagged release by setting the `API_TAG` value in your `.env` file:\n\n```shell\nAPI_TAG=1.3.2\n```\n\nFor more information on valid `API_TAG` values, see: [docker build - Git repositories](https://docs.docker.com/engine/reference/commandline/build/#git-repositories)\n\n## Compiles and hot-reloads for development\n\nUsing `docker-compose` will mount your local `./src` directory into the application, which allows you to continue to make changes and view them within the application.\n\nThe application will be available at [http://localhost:3000/](http://localhost:3000/).\n\n**User Credentials:** To find example user credentials, look to the user.json file in the [Bmore-Responsive repository](https://github.com/CodeForBaltimore/Bmore-Responsive).\n\n**Note:** Depending on the OS you are running `Docker` on your localhost may be mapped to a different IP address. The standard IP address `Docker` is mapped to on Windows is `192.168.99.100` so you would access the application at `192.168.99.100:8080`.\n\n## Compiles and minifies for production\n\n```shell\nnpm run build\n```\n\n## Lints and fixes files\n\n```shell\nnpm run lint\n```\n\n## Customize configuration\n\nSee [Configuration Reference](https://cli.vuejs.org/config/).\n\n# Using this product\n\nHow would someone use this product? Give a few examples here.\n\n## Testing\n\n### Using Jest for unit testing\n\n```shell\n`npm test`\n`yarn test`\n```\n\n### Using Snyk to check for security vulnerabilities\n\n```shell\n`npm install snyk -g`\n`snyk test`\n```\n\n# Sources and Links\n\nWe are also building a back-end API to feed and manage data for this project. To view that project, or to contribute to it, please visit the repo here: https://github.com/CodeForBaltimore/Bmore-Responsive\n\n<p align=\"center\">\n    <img src=\"docs/img/CfB.png\" width=\"400\">\n</p>\n\n## Contributors \u2728\n\nThanks goes to these wonderful people ([emoji key](https://allcontributors.org/docs/en/emoji-key)):\n\n<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->\n<!-- prettier-ignore-start -->\n<!-- markdownlint-disable -->\n<table>\n  <tr>\n    <td align=\"center\"><a href=\"http://www.jasonanton.com\"><img src=\"https://avatars0.githubusercontent.com/u/6391564?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Jason Anton</b></sub></a><br /><a href=\"https://github.com/CodeForBaltimore/Healthcare-Rollcall/commits?author=revjtanton\" title=\"Code\">\ud83d\udcbb</a> <a href=\"https://github.com/CodeForBaltimore/Healthcare-Rollcall/commits?author=revjtanton\" title=\"Documentation\">\ud83d\udcd6</a> <a href=\"#security-revjtanton\" title=\"Security\">\ud83d\udee1\ufe0f</a></td>\n    <td align=\"center\"><a href=\"https://ao10.github.io\"><img src=\"https://avatars3.githubusercontent.com/u/14120224?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Ati Ok</b></sub></a><br /><a href=\"https://github.com/CodeForBaltimore/Healthcare-Rollcall/commits?author=ao10\" title=\"Code\">\ud83d\udcbb</a> <a href=\"https://github.com/CodeForBaltimore/Healthcare-Rollcall/pulls?q=is%3Apr+reviewed-by%3Aao10\" title=\"Reviewed Pull Requests\">\ud83d\udc40</a></td>\n    <td align=\"center\"><a href=\"http://www.restechsys.com\"><img src=\"https://avatars2.githubusercontent.com/u/5619637?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Harry Respass</b></sub></a><br /><a href=\"https://github.com/CodeForBaltimore/Healthcare-Rollcall/commits?author=helro154\" title=\"Code\">\ud83d\udcbb</a> <a href=\"https://github.com/CodeForBaltimore/Healthcare-Rollcall/pulls?q=is%3Apr+reviewed-by%3Ahelro154\" title=\"Reviewed Pull Requests\">\ud83d\udc40</a></td>\n    <td align=\"center\"><a href=\"https://github.com/cmavelis\"><img src=\"https://avatars3.githubusercontent.com/u/16199008?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Cameron Avelis</b></sub></a><br /><a href=\"https://github.com/CodeForBaltimore/Healthcare-Rollcall/commits?author=cmavelis\" title=\"Code\">\ud83d\udcbb</a> <a href=\"https://github.com/CodeForBaltimore/Healthcare-Rollcall/pulls?q=is%3Apr+reviewed-by%3Acmavelis\" title=\"Reviewed Pull Requests\">\ud83d\udc40</a></td>\n    <td align=\"center\"><a href=\"https://github.com/joffutt4\"><img src=\"https://avatars0.githubusercontent.com/u/10181869?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>joffutt4</b></sub></a><br /><a href=\"https://github.com/CodeForBaltimore/Healthcare-Rollcall/commits?author=joffutt4\" title=\"Code\">\ud83d\udcbb</a> <a href=\"https://github.com/CodeForBaltimore/Healthcare-Rollcall/pulls?q=is%3Apr+reviewed-by%3Ajoffutt4\" title=\"Reviewed Pull Requests\">\ud83d\udc40</a></td>\n    <td align=\"center\"><a href=\"https://github.com/MGardner02\"><img src=\"https://avatars0.githubusercontent.com/u/35646560?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>MGardner02</b></sub></a><br /><a href=\"https://github.com/CodeForBaltimore/Healthcare-Rollcall/commits?author=MGardner02\" title=\"Code\">\ud83d\udcbb</a> <a href=\"https://github.com/CodeForBaltimore/Healthcare-Rollcall/pulls?q=is%3Apr+reviewed-by%3AMGardner02\" title=\"Reviewed Pull Requests\">\ud83d\udc40</a></td>\n    <td align=\"center\"><a href=\"https://markadk.in/s\"><img src=\"https://avatars0.githubusercontent.com/u/6365836?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Mark Adkins</b></sub></a><br /><a href=\"https://github.com/CodeForBaltimore/Healthcare-Rollcall/commits?author=funkybunch\" title=\"Code\">\ud83d\udcbb</a> <a href=\"https://github.com/CodeForBaltimore/Healthcare-Rollcall/commits?author=funkybunch\" title=\"Documentation\">\ud83d\udcd6</a> <a href=\"#design-funkybunch\" title=\"Design\">\ud83c\udfa8</a></td>\n  </tr>\n  <tr>\n    <td align=\"center\"><a href=\"https://github.com/charlesw2004\"><img src=\"https://avatars0.githubusercontent.com/u/30778546?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Wilner Charles</b></sub></a><br /><a href=\"https://github.com/CodeForBaltimore/Healthcare-Rollcall/commits?author=charlesw2004\" title=\"Code\">\ud83d\udcbb</a></td>\n    <td align=\"center\"><a href=\"http://jasonbixon.netlify.com\"><img src=\"https://avatars3.githubusercontent.com/u/32110237?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Jason Bixon</b></sub></a><br /><a href=\"https://github.com/CodeForBaltimore/Healthcare-Rollcall/commits?author=jbixon13\" title=\"Code\">\ud83d\udcbb</a> <a href=\"#design-jbixon13\" title=\"Design\">\ud83c\udfa8</a> <a href=\"#infra-jbixon13\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">\ud83d\ude87</a></td>\n    <td align=\"center\"><a href=\"https://snyk.io\"><img src=\"https://avatars2.githubusercontent.com/u/19733683?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Snyk bot</b></sub></a><br /><a href=\"#security-snyk-bot\" title=\"Security\">\ud83d\udee1\ufe0f</a></td>\n    <td align=\"center\"><a href=\"https://dependabot.com\"><img src=\"https://avatars1.githubusercontent.com/u/27347476?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Dependabot</b></sub></a><br /><a href=\"#security-dependabot[bot]\" title=\"Security\">\ud83d\udee1\ufe0f</a></td>\n    <td align=\"center\"><a href=\"http://stephanie.marketing\"><img src=\"https://avatars2.githubusercontent.com/u/47190328?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Stephanie</b></sub></a><br /><a href=\"#content-uxstephanie\" title=\"Content\">\ud83d\udd8b</a></td>\n    <td align=\"center\"><a href=\"https://github.com/c-w-allen\"><img src=\"https://avatars0.githubusercontent.com/u/64177457?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>c-w-allen</b></sub></a><br /><a href=\"https://github.com/CodeForBaltimore/Healthcare-Rollcall/commits?author=c-w-allen\" title=\"Code\">\ud83d\udcbb</a></td>\n    <td align=\"center\"><a href=\"https://github.com/blakenan-bellese\"><img src=\"https://avatars1.githubusercontent.com/u/61432973?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>blakenan-bellese</b></sub></a><br /><a href=\"https://github.com/CodeForBaltimore/Healthcare-Rollcall/commits?author=blakenan-bellese\" title=\"Documentation\">\ud83d\udcd6</a></td>\n  </tr>\n  <tr>\n    <td align=\"center\"><a href=\"http://ianjadams.com\"><img src=\"https://avatars1.githubusercontent.com/u/7966226?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Ian Adams</b></sub></a><br /><a href=\"https://github.com/CodeForBaltimore/Healthcare-Rollcall/commits?author=ijadams\" title=\"Code\">\ud83d\udcbb</a></td>\n    <td align=\"center\"><a href=\"https://www.joshglazer.com\"><img src=\"https://avatars1.githubusercontent.com/u/5789311?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Josh Glazer</b></sub></a><br /><a href=\"https://github.com/CodeForBaltimore/Healthcare-Rollcall/commits?author=joshglazer\" title=\"Code\">\ud83d\udcbb</a></td>\n  </tr>\n</table>\n\n<!-- markdownlint-enable -->\n<!-- prettier-ignore-end -->\n\n<!-- ALL-CONTRIBUTORS-LIST:END -->\n\nThis project follows the [all-contributors](https://github.com/all-contributors/all-contributors) specification. Contributions of any kind welcome!\n"
 },
 {
  "repo": "sample2025nit/HealthCareEx",
  "language": "HTML",
  "readme_contents": "[{\"name\":\".gitignore\",\"path\":\".gitignore\",\"sha\":\"e43b0f988953ae3a84b00331d0ccf5f7d51cb3cf\",\"size\":10,\"url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/.gitignore?ref=master\",\"html_url\":\"https://github.com/wanghaisheng/healthcaredatastandard/blob/master/.gitignore\",\"git_url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/e43b0f988953ae3a84b00331d0ccf5f7d51cb3cf\",\"download_url\":\"https://raw.githubusercontent.com/wanghaisheng/healthcaredatastandard/master/.gitignore\",\"type\":\"file\",\"_links\":{\"self\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/.gitignore?ref=master\",\"git\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/e43b0f988953ae3a84b00331d0ccf5f7d51cb3cf\",\"html\":\"https://github.com/wanghaisheng/healthcaredatastandard/blob/master/.gitignore\"}},{\"name\":\"README.md\",\"path\":\"README.md\",\"sha\":\"fc6bd9a7b0a339af5ee38d7481d24302a18d395c\",\"size\":29010,\"url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/README.md?ref=master\",\"html_url\":\"https://github.com/wanghaisheng/healthcaredatastandard/blob/master/README.md\",\"git_url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/fc6bd9a7b0a339af5ee38d7481d24302a18d395c\",\"download_url\":\"https://raw.githubusercontent.com/wanghaisheng/healthcaredatastandard/master/README.md\",\"type\":\"file\",\"_links\":{\"self\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/README.md?ref=master\",\"git\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/fc6bd9a7b0a339af5ee38d7481d24302a18d395c\",\"html\":\"https://github.com/wanghaisheng/healthcaredatastandard/blob/master/README.md\"}},{\"name\":\"overview.png\",\"path\":\"overview.png\",\"sha\":\"5e49110c0ac25125bf0f277548f85389bd9178da\",\"size\":559586,\"url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/overview.png?ref=master\",\"html_url\":\"https://github.com/wanghaisheng/healthcaredatastandard/blob/master/overview.png\",\"git_url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/5e49110c0ac25125bf0f277548f85389bd9178da\",\"download_url\":\"https://raw.githubusercontent.com/wanghaisheng/healthcaredatastandard/master/overview.png\",\"type\":\"file\",\"_links\":{\"self\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/overview.png?ref=master\",\"git\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/5e49110c0ac25125bf0f277548f85389bd9178da\",\"html\":\"https://github.com/wanghaisheng/healthcaredatastandard/blob/master/overview.png\"}},{\"name\":\"standard number -201506.png\",\"path\":\"standard number -201506.png\",\"sha\":\"10d20f19dadd0de6c6740685c16ad3d98bceb4eb\",\"size\":552959,\"url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/standard%20number%20-201506.png?ref=master\",\"html_url\":\"https://github.com/wanghaisheng/healthcaredatastandard/blob/master/standard%20number%20-201506.png\",\"git_url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/10d20f19dadd0de6c6740685c16ad3d98bceb4eb\",\"download_url\":\"https://raw.githubusercontent.com/wanghaisheng/healthcaredatastandard/master/standard%20number%20-201506.png\",\"type\":\"file\",\"_links\":{\"self\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/standard%20number%20-201506.png?ref=master\",\"git\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/10d20f19dadd0de6c6740685c16ad3d98bceb4eb\",\"html\":\"https://github.com/wanghaisheng/healthcaredatastandard/blob/master/standard%20number%20-201506.png\"}},{\"name\":\"\u57fa\u7840\u7c7b\u6807\u51c6\",\"path\":\"\u57fa\u7840\u7c7b\u6807\u51c6\",\"sha\":\"945a3b3a1831fbad09264b9dea530af3f0fb737a\",\"size\":0,\"url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E5%9F%BA%E7%A1%80%E7%B1%BB%E6%A0%87%E5%87%86?ref=master\",\"html_url\":\"https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E5%9F%BA%E7%A1%80%E7%B1%BB%E6%A0%87%E5%87%86\",\"git_url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/945a3b3a1831fbad09264b9dea530af3f0fb737a\",\"download_url\":null,\"type\":\"dir\",\"_links\":{\"self\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E5%9F%BA%E7%A1%80%E7%B1%BB%E6%A0%87%E5%87%86?ref=master\",\"git\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/945a3b3a1831fbad09264b9dea530af3f0fb737a\",\"html\":\"https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E5%9F%BA%E7%A1%80%E7%B1%BB%E6%A0%87%E5%87%86\"}},{\"name\":\"\u5df2\u6574\u7406\u6750\u6599\",\"path\":\"\u5df2\u6574\u7406\u6750\u6599\",\"sha\":\"e9f14bd3afda272e5e3f310b779e115d0c125d29\",\"size\":0,\"url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E5%B7%B2%E6%95%B4%E7%90%86%E6%9D%90%E6%96%99?ref=master\",\"html_url\":\"https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E5%B7%B2%E6%95%B4%E7%90%86%E6%9D%90%E6%96%99\",\"git_url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/e9f14bd3afda272e5e3f310b779e115d0c125d29\",\"download_url\":null,\"type\":\"dir\",\"_links\":{\"self\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E5%B7%B2%E6%95%B4%E7%90%86%E6%9D%90%E6%96%99?ref=master\",\"git\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/e9f14bd3afda272e5e3f310b779e115d0c125d29\",\"html\":\"https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E5%B7%B2%E6%95%B4%E7%90%86%E6%9D%90%E6%96%99\"}},{\"name\":\"\u6280\u672f\u7c7b\u6807\u51c6\",\"path\":\"\u6280\u672f\u7c7b\u6807\u51c6\",\"sha\":\"de30b9a40cd054b6d7fb7fcebbe6f7e01b5e5770\",\"size\":0,\"url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E6%8A%80%E6%9C%AF%E7%B1%BB%E6%A0%87%E5%87%86?ref=master\",\"html_url\":\"https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E6%8A%80%E6%9C%AF%E7%B1%BB%E6%A0%87%E5%87%86\",\"git_url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/de30b9a40cd054b6d7fb7fcebbe6f7e01b5e5770\",\"download_url\":null,\"type\":\"dir\",\"_links\":{\"self\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E6%8A%80%E6%9C%AF%E7%B1%BB%E6%A0%87%E5%87%86?ref=master\",\"git\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/de30b9a40cd054b6d7fb7fcebbe6f7e01b5e5770\",\"html\":\"https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E6%8A%80%E6%9C%AF%E7%B1%BB%E6%A0%87%E5%87%86\"}},{\"name\":\"\u6570\u636e\u7c7b\u6807\u51c6\",\"path\":\"\u6570\u636e\u7c7b\u6807\u51c6\",\"sha\":\"b07085f5d932d491dc4776309fc799305e1b4838\",\"size\":0,\"url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E6%95%B0%E6%8D%AE%E7%B1%BB%E6%A0%87%E5%87%86?ref=master\",\"html_url\":\"https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E6%95%B0%E6%8D%AE%E7%B1%BB%E6%A0%87%E5%87%86\",\"git_url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/b07085f5d932d491dc4776309fc799305e1b4838\",\"download_url\":null,\"type\":\"dir\",\"_links\":{\"self\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E6%95%B0%E6%8D%AE%E7%B1%BB%E6%A0%87%E5%87%86?ref=master\",\"git\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/b07085f5d932d491dc4776309fc799305e1b4838\",\"html\":\"https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E6%95%B0%E6%8D%AE%E7%B1%BB%E6%A0%87%E5%87%86\"}},{\"name\":\"\u6807\u51c6\u5316\u6d4b\u8bc4\u76f8\u5173\u89c4\u8303\",\"path\":\"\u6807\u51c6\u5316\u6d4b\u8bc4\u76f8\u5173\u89c4\u8303\",\"sha\":\"5bf75d1217960dfa55654ed55bb07f644330a763\",\"size\":0,\"url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E6%A0%87%E5%87%86%E5%8C%96%E6%B5%8B%E8%AF%84%E7%9B%B8%E5%85%B3%E8%A7%84%E8%8C%83?ref=master\",\"html_url\":\"https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E6%A0%87%E5%87%86%E5%8C%96%E6%B5%8B%E8%AF%84%E7%9B%B8%E5%85%B3%E8%A7%84%E8%8C%83\",\"git_url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/5bf75d1217960dfa55654ed55bb07f644330a763\",\"download_url\":null,\"type\":\"dir\",\"_links\":{\"self\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E6%A0%87%E5%87%86%E5%8C%96%E6%B5%8B%E8%AF%84%E7%9B%B8%E5%85%B3%E8%A7%84%E8%8C%83?ref=master\",\"git\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/5bf75d1217960dfa55654ed55bb07f644330a763\",\"html\":\"https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E6%A0%87%E5%87%86%E5%8C%96%E6%B5%8B%E8%AF%84%E7%9B%B8%E5%85%B3%E8%A7%84%E8%8C%83\"}},{\"name\":\"\u7ba1\u7406\u7c7b\u6807\u51c6\",\"path\":\"\u7ba1\u7406\u7c7b\u6807\u51c6\",\"sha\":\"697c02441646c251192f32f1bdf86ea52042e7e4\",\"size\":0,\"url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E7%AE%A1%E7%90%86%E7%B1%BB%E6%A0%87%E5%87%86?ref=master\",\"html_url\":\"https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E7%AE%A1%E7%90%86%E7%B1%BB%E6%A0%87%E5%87%86\",\"git_url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/697c02441646c251192f32f1bdf86ea52042e7e4\",\"download_url\":null,\"type\":\"dir\",\"_links\":{\"self\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E7%AE%A1%E7%90%86%E7%B1%BB%E6%A0%87%E5%87%86?ref=master\",\"git\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/697c02441646c251192f32f1bdf86ea52042e7e4\",\"html\":\"https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E7%AE%A1%E7%90%86%E7%B1%BB%E6%A0%87%E5%87%86\"}}]"
 },
 {
  "repo": "aws-samples/aws-healthcare-lifescience-ai-ml-sample-notebooks",
  "language": "Jupyter Notebook",
  "readme_contents": "# Healthcare and Life Sciences Amazon SageMaker and AI/ML Immersion Day Workshops\n\n## Introduction\n\n[AWS Healthcare Life Sciences (HCLS) Artificial Intelligence/Machine Learning (AI/ML) Immersion Days](https://catalog.workshops.aws/hcls-aiml/en-US) offer an opportunity for AWS customers and those who wish to learn about AWS AI/ML services via a deep, hands on workshop experience. Customers can use Immersion Days to:\n\n* **Engage in hands on workshops to learn about AI/ML services.** We will work in a hands-on fashion with data scientists, machine learning engineers, developers, analysts and anyone else to familiarize the customer with our services. These workshops are hands on -- workshop participants will be provided with temporary AWS account(s) from which they will execute AI/ML workloads in a step-by-step fashion with our HCLS AI/ML Solutions Architects. Please see the Workshops section for available workshops.\n\n* **Gain a deep understanding of AWS AI/ML Services.** We will discuss what our AI/ML services are, how they can be easily brought to bear on numerous workloads, and help enable the customer to approach their own business problems in the context of AI/ML. These conversations can be overviews of AWS services, or technical deep dives into specific components that to enable well-architected AI/ML applications for HCLS business.\n\n* **Understand best practices with AI/ML in the context of HCLS.** We will discuss what are the best practices and procedures for using AI/ML intelligently in HCLS applications. This includes basics of training and testing, MLOps and deployment practices, software development life cycle in the context of AI/ML and many other components.\n\nThe Immersion Day workshops may be used by in the context of [AWS Instructure-Led Labs](https://sagemaker-immersionday.workshop.aws/en/prerequisites/option1.html) or [self-paced labs](https://sagemaker-immersionday.workshop.aws/en/prerequisites/option2.html). Please see [here](https://sagemaker-immersionday.workshop.aws/en/prerequisites.html) for more information.\n\n\n## Related Resources\n\n* The [AWS Healthcare Life Sciences (HCLS) Artificial Intelligence/Machine Learning (AI/ML) Immersion Days](https://catalog.workshops.aws/hcls-aiml/en-US) has overviews of a number of the workshops in this repository and instructions for running them.\n* The [SageMaker Immersion Day](https://github.com/aws-samples/amazon-sagemaker-immersion-day) provides many other useful workshops.\n* The [SageMaker sample code repository](https://github.com/aws/amazon-sagemaker-examples) provides more than 300 code samples for using SageMaker\n\n\n## FAQ\n\n**Do I have to be a machine learning expert to benefit from a workshop?**\n\nAbsolutely not! These workshops can benefit people at all levels, whether they are machine learning experts, developers, managers, or anyone in your organization. [Amazon SageMaker](https://aws.amazon.com/sagemaker/) and Amazon's [many other machine learning services](https://aws.amazon.com/machine-learning/) are designed to remove the heavy lifting from development to quickly enable you to integrate AI/ML into your applications.\n\n**How can I get started?**\n\nYou can peruse this repository for notebooks that are relevant to you. \n\n**What workshops makes the most sense for me and my group?**\n\nThis depends on your teams familiarity with SageMaker. If the team is deeply familiar with ML and SageMaker we recommend picking workshops that best match the business problem(s) you are trying to solve. If your team is not yet deeply familiar with AWS infrastructure and SageMaker, we recommend  at least 1 more basic workshop that focuses on tabular analysis so that the team can get hands-on practice with AWS AI/ML steps (e.g. loading data into S3 for training with AI/ML, deploying models etc.)\n\n**Who should come to the AWS Instructure-led workshops?**\n\nAnyone is welcome to the workshop. We recommend that the customer have at least one developer present who will be actively working on business problems and can take away technical learnings that can be applied for their future work.\n\n\n**How can I get started?**\n\nWhether you are doing an [AWS Instructure-Led Labs](https://sagemaker-immersionday.workshop.aws/en/prerequisites/option1.html) or [self-paced labs](https://sagemaker-immersionday.workshop.aws/en/prerequisites/option2.html), we recommend that you begin by looking at the workshops and executing them to get an understanding of SageMaker and the AI/ML services work in the context of healthcare and life sciences.\n\n**How do I use these workshops?**\n\nThe notebooks provided within these workshops are independent units and may be run on their own. Further instructions are provided within each specific directory. \n\n\n**What is the source of these workshops?**\n\nSome of these workshops have been created by HCLS AI/ML team has written specific workshops that demonstrate key components of using SageMaker. We have also curated resources from the [AWS machine learning blog](https://aws.amazon.com/blogs/machine-learning/) and the Amazon SageMaker [respository](https://github.com/aws/amazon-sagemaker-examples) of sample code for these workshops.\n\n**I am interested in workshops not listed on this repository.**\n\nThe workshops for the HCLS AI/ML listed are generally focused on applications related to Health and Life Sciences. However, there is a wealth of more general information and public facing AWS provided notebooks that use non-HCLS data [here](https://github.com/awslabs/amazon-sagemaker-examples) and [here](https://sagemaker-immersionday.workshop.aws/). \n\n**I think I see a mistake or something I want changed in the repository**.\n\nFeel free to to submit a pull request detailing the issue. Please bear with us in if pull requests take longer than expected or are closed. \n\n**How can I arrange an AWS Instructor-Led Immersion Day?**\n\nIf you are interested in having an Immersion Day for your team, please reach out to your AWS Account Manager.\n\n## Security\n\nSee [CONTRIBUTING](CONTRIBUTING.md#security-issue-notifications) for more information.\n\n## License\n\nThis library is licensed under the MIT-0 License. See the LICENSE file.\n\n"
 },
 {
  "repo": "PacktPublishing/Healthcare-Analytics-Made-Simple",
  "language": "Jupyter Notebook",
  "readme_contents": "\n\n\n# Healthcare Analytics Made Simple\n\n<a href=\"https://www.packtpub.com/big-data-and-business-intelligence/healthcare-analytics-made-simple?utm_source=github&utm_medium=repository&utm_campaign=9781787286702\"><img src=\"https://www.packtpub.com/sites/default/files/B06444.png\" alt=\"Healthcare Analytics Made Simple\" height=\"256px\" align=\"right\"></a>\n\nThis is the code repository for [Healthcare Analytics Made Simple](https://www.packtpub.com/big-data-and-business-intelligence/healthcare-analytics-made-simple?utm_source=github&utm_medium=repository&utm_campaign=9781787286702), published by Packt.\n\n**Techniques in healthcare computing using machine learning and Python**\n\n## What is this book about?\nIn recent years, machine learning technologies and analytics have been widely utilized across the healthcare sector. Healthcare Analytics Made Simple bridges the gap between practising doctors and data scientists. It equips the data scientists\u2019 work with healthcare data and allows them to gain better insight from this data in order to improve healthcare outcomes.\n\nThis book covers the following exciting features:\n* Gain valuable insight into healthcare incentives, finances, and legislation \n* Discover the connection between machine learning and healthcare processes\n* Use SQL and Python to analyze data\n* Measure healthcare quality and provider performance\n* Identify features and attributes to build successful healthcare models \n\nIf you feel this book is for you, get your [copy](https://www.amazon.com/dp/1787286703) today!\n\n<a href=\"https://www.packtpub.com/?utm_source=github&utm_medium=banner&utm_campaign=GitHubBanner\"><img src=\"https://raw.githubusercontent.com/PacktPublishing/GitHub/master/GitHub.png\" \nalt=\"https://www.packtpub.com/\" border=\"5\" /></a>\n\n\n## Instructions and Navigations\nAll of the code is organized into folders. For example, Chapter02.\n\nThe code will look like the following:\n```\nstring_1 = '1'\nstring_2 = '2'\nstring_sum = string_1 + string_2\nprint(string_sum)\n```\n\n**Following is what you need for this book:**\nHealthcare Analytics Made Simple is for you if you are a developer who has a working knowledge of Python or a related programming language, although you are new to healthcare or predictive modeling with healthcare data. Clinicians interested in analytics and healthcare computing will also benefit from this book. This book can also serve as a textbook for students enrolled in an introductory course on machine learning for healthcare.\n\nWith the following software and hardware list you can run all code files present in the book (Chapter 1-9).\n\n### Software and Hardware List\n\n| Chapter  | Software required                      | OS required                          |\n| -------- | ------------------------------------   | ------------------------------------ |\n| 1        | Anaconda: 4.4.0                        |6GB of RAM, i5 Pentium, Windows 10 OS |\n| 4        | Python: 3.6.1                          |6GB of RAM, i5 Pentium, Windows 10 OS |\n| 5        | NumPy: 1.12.1                          |6GB of RAM, i5 Pentium, Windows 10 OS |\n| 6        | pandas: 0.20.1                         |6GB of RAM, i5 Pentium, Windows 10 OS |\n| 7        | scikit-learn: 0.18.1,matplotlib: 2.0.2 |6GB of RAM, i5 Pentium, Windows 10 OS |\n\n\n\nWe also provide a PDF file that has color images of the screenshots/diagrams used in this book. [Click here to download it](http://www.packtpub.com/sites/default/files/downloads/HealthcareAnalyticsMadeSimple_ColorImages.pdf).\n\n### Related products \n* Learning Social Media Analytics with R [[Packt]](https://www.packtpub.com/big-data-and-business-intelligence/learning-social-media-analytics-r?utm_source=github&utm_medium=repository&utm_campaign=9781787127524) [[Amazon]](https://www.amazon.com/dp/1787127524)\n\n* Predictive Analytics with Tensorflow [[Packt]](https://www.packtpub.com/big-data-and-business-intelligence/predictive-analytics-tensorflow?utm_source=github&utm_medium=repository&utm_campaign=9781788398923) [[Amazon]](https://www.amazon.com/dp/1788398920)\n\n## Get to Know the Author\n**Dr. Vikas (Vik) Kumar**\n grew up in the United States in Niskayuna, New York. He earned\nhis MD from the University of Pittsburgh, but shortly afterwards he discovered his true\ncalling of computers and data science. He then earned his MS in the College of Computing\nat Georgia Institute of Technology and has subsequently worked as a data scientist for both\nhealthcare and non-healthcare companies. He currently lives in Atlanta, Georgia.\n\n\n\n\n### Suggestions and Feedback\n[Click here](https://docs.google.com/forms/d/e/1FAIpQLSdy7dATC6QmEL81FIUuymZ0Wy9vH1jHkvpY57OiMeKGqib_Ow/viewform) if you have any feedback or suggestions.\n\n### Download a free PDF\n\n <i>If you have already purchased a print or Kindle version of this book, you can get a DRM-free PDF version at no cost.<br>Simply click on the link to claim your free PDF.</i>\n<p align=\"center\"> <a href=\"https://packt.link/free-ebook/9781787286702\">https://packt.link/free-ebook/9781787286702 </a> </p>"
 },
 {
  "repo": "simpledotorg/simple-android",
  "language": "Kotlin",
  "readme_contents": "![Build Status](https://github.com/simpledotorg/simple-android/workflows/CI/badge.svg)\n\n# Simple\n\nAn Android app for recording blood pressure measurements.\n\n## Pre-requisites\n\nThe application currently requires JDK 17 to build. If you already have JDK 17 installed, skip this step.\n\n**Check if the right JDK is already available**\n\nRun the command `java -version`. If you have the right version of the JDK installed, you should see something like:\n\n```sh\nopenjdk 17.0.7 2023-04-18 LTS\nOpenJDK Runtime Environment Zulu17.42+19-CA (build 17.0.7+7-LTS)\nOpenJDK 64-Bit Server VM Zulu17.42+19-CA (build 17.0.7+7-LTS, mixed mode, sharing)\n```\n\nIf this command has an error, or shows a different version, you can follow the instructions below to install the JDK.\n\n**Install the JDK**\n\nWe recommend using [jEnv](https://www.jenv.be/) to manage your JDK installations. Here are instructions to setup a working JDK 17 installation (macOS\nonly):\n\n1. Setup up [Homebrew](https://brew.sh/).\n\n2. Install `jEnv` using Homebrew.\n\n```sh\nbrew install jenv\n```\n\n3. Add the following lines to your shell configuration file (`~/.bash_profile` if you're using bash, or `~/.zshrc` if you're using zsh).\n\n```sh\nexport PATH=\"$HOME/.jenv/bin:$PATH\"\neval \"$(jenv init -)\"\n```\n\n4. Once this is done, you'll need to restart the terminal or reload the configuration file in order for the `jenv` command to be recognised.\n\n```sh\nsource <path to shell configuration file>\n```\n\n5. Install the JDK using Homebrew.\n\n```sh\nbrew tap mdogan/zulu\nbrew install zulu-jdk17\n```\n\n6. Add the installed JDK to `jEnv`\n\n```sh\njenv add /Library/Java/JavaVirtualMachines/zulu-17.jdk/Contents/Home/\n```\n\n7. Run the command `jenv versions`. You should see something like:\n\n```sh\n  system\n* 17.0\n  17.0.7\n  zulu64-17.0.7\n```\n\n## How to build\n\n**Clone the project using git.**\n\nRun the following command in a terminal.\n\n ```\n $ git clone git@github.com:simpledotorg/simple-android.git\n ```\n\n**Install Android Studio**\n\nDownload and install Android Studio from [their website](https://developer.android.com/studio/).\n\n**Import the project into Android Studio.**\n\nWhen Android Studio starts up, it will prompt you to create a new project or import an existing project. Select the option to import an existing\nproject, navigate to the `simple-android` directory you cloned earlier, and select it.\n\nWhen building for the first time, gradle will download all dependencies so it'll take a few minutes to complete. Subsequent builds will be faster.\n\nIf during the build process you see the message:\n\"Warning: License for package Android SDK Build-Tools 30.0.2 not accepted.\"\nThen you may need to install the Google Play Licensing Library:\n\n* Open the SDK Manager through Tools -> SDK Manager\n* Select Appearance & Behavior -> System Settings -> Android SDK in the left sidebar\n* Select the SDK Tools tab in the main window\n* Activate Google Play Licensing Library and click Apply\n\n## Running locally\n\nThe Simple App can be run locally on an Android emulator using Android Studio. To do this,\n\n**Install the NDK library**\n\nThe NDK library is currently required by the project to enable an SQLite extension. To install it:\n\n* Open the SDK Manager through Tools -> SDK Manager\n* Select Appearance & Behavior -> System Settings -> Android SDK in the left sidebar\n* Select the SDK Tools tab in the main window\n* Activate NDK (Side by Side) and click Apply\n\nNDK will now be installed.\n\n**Create a Run/Debug configuration**\n\n* Open the Run/Debug configurations window through Run -> Edit Configurations ([ref](https://developer.android.com/studio/run/rundebugconfig))\n* Create a new configuration using the `Android App` template\n* Set the module to `app`, and finish creating the configuration\n\n**Create a virtual device**\n\n* Create an Android Virtual Device (AVD) using the AVD Manager, usually found in Tools -> AVD\n  Manager. ([ref](https://developer.android.com/studio/run/managing-avds))\n* Select a device and operating system\n* Note: You will have to download one of the available OS options the first time you create an AVD\n\n**Set the right build variant**\n\n* Open the Build Variants window through View -> Tool Windows -> Build Variants, or clicking the item in the lower left corner of the main window\n* Set the Build Variant of the app module to `qaDebug`\n\n**Run the app**\n\n* Click \"Run\", either through Run -> Run, or the green play button in the top toolbar.\n\n## Code styles\n\nThe code styles which the project uses have been exported as an IntelliJ code style XML file and are saved as\n`quality/code-style.xml`. To import them into Android Studio,\n\n1. Open the Android Studio preferences page, and navigate to Editor -> Code Style.\n1. Click on the gear/settings button next to the \"Scheme\" label.\n1. In the drop-down menu, select \"Import scheme\".\n1. In the file picker, navigate to  `<project>/quality/code-style.xml`.\n1. Import the `Simple` scheme into the IDE and set it as the project code style.\n\n## Tooling\n\nAn Android Studio plugin that provides some quality of life improvements like live templates can be\nfound [HERE](https://github.com/simpledotorg/simple-android-idea-plugin).\n\n## Building an APK with a different build variant\n\nThere are currently 2 ways to build an app pointing to different environments:\n\n1. Changing the `qa` API URL in `gradle.properties` file to point to the environment you want. These builds will be debuggable and require us to clone\n   the project and build it using [Android Studio](https://developer.android.com/studio). [*\n   Warning*: These changes should not be commited back to `master` branch]\n2. Use Bitrise workflows to build APKs of different build variants. These builds will not be debuggable, unless for `build-debuggable-sandbox-apk`.\n\n## Build and deploy Simple Server\n\nSimple Server is in a separate repository, and you should follow\nthe [instructions there](https://github.com/simpledotorg/simple-server/blob/master/README.md).\n\n## Execute SQL Queries\n\nYou can use [Flipper](https://fbflipper.com/) to run SQL queries on Simple:\n\n1. Install Flipper using brew or download from their [website](https://fbflipper.com/).\n\n```sh \nbrew install Flipper\n```\n\n2. Launch Flipper (you might have to allow Flipper to launch from System Preferences > Security > General as it\u2019s from an unknown developer to Apple).\n3. Run the Simple app in an emulator or your physical device(as Flipper loads the data from your device's local database).\n4. In the Plugins section in the sidebar menu click on Disabled and enable the Database plugin.\n5. Click on Databases, select `red-db` and choose whichever table\u2019s data you want to inspect.\n6. Click on SQL at the top to execute SQL queries.\n\n## Resources\n\nCheck out the following documents for more information.\n\n* [Quirks That You Should Probably Be Aware Of](doc/QUIRKS.md)\n* [More Documentation](doc)\n* [Recipes](doc/recipes.md)\n* [Integration Test Heroku Setup](doc/integration-test-suite-setup.md)\n"
 },
 {
  "repo": "katalon-studio-samples/healthcare-tests",
  "language": "Groovy",
  "readme_contents": "# healthcare-tests\n\nNavigate to https://docs.katalon.com/katalon-studio/docs/health-care-prj.html for further details.\n\n## Companion products\n\n### Katalon TestOps\n\n[Katalon TestOps](https://analytics.katalon.com) is a web-based application that provides dynamic perspectives and an insightful look at your automation testing data. You can leverage your automation testing data by transforming and visualizing your data; analyzing test results; seamlessly integrating with such tools as Katalon Studio and Jira; maximizing the testing capacity with remote execution.\n\n* Read our [documentation](https://docs.katalon.com/katalon-analytics/docs/overview.html).\n* Ask a question on [Forum](https://forum.katalon.com/categories/katalon-analytics).\n* Request a new feature on [GitHub](CONTRIBUTING.md).\n* Vote for [Popular Feature Requests](https://github.com/katalon-analytics/katalon-analytics/issues?q=is%3Aopen+is%3Aissue+label%3Afeature-request+sort%3Areactions-%2B1-desc).\n* File a bug in [GitHub Issues](https://github.com/katalon-analytics/katalon-analytics/issues).\n\n### Katalon Studio\n[Katalon Studio](https://www.katalon.com) is a free and complete automation testing solution for Web, Mobile, and API testing with modern methodologies (Data-Driven Testing, TDD/BDD, Page Object Model, etc.) as well as advanced integration (JIRA, qTest, Slack, CI, Katalon TestOps, etc.). Learn more about [Katalon Studio features](https://www.katalon.com/features/).\n"
 },
 {
  "repo": "pras75299/Healthcare-Website",
  "language": "HTML",
  "readme_contents": "# Healthcare-Website\n- Informational Website related to Healthcare, Details and Services provided by different hospitals, Details about them and Inquiry form for foreigners who want to use the facility in India.\n\n## Table of contents\n- [About Healthcare](#about-healthcare)\n- [Responsibility](#responsibility)\n- [Screenshots](#screenshots)\n- [Dependencies](#dependencies)\n\n\n#### About Healthcare\n- Informational Website related to Healthcare, Details and Services provided by different hospitals, Details about them and Inquiry form for foreigners who want to use the facility in India.\n\n##### Responsibility\n- Template Design\n- Bug Fixing\n- Responsive Design Check\n- Cross Browser Compatibility Checking\n- UI Design\n- Front End Development\n- Photoshop Designs\n- Logo Design\n\n\n###### Screenshots\n\n- **Home Page Image** \n<img src=\"https://github.com/pras75299/Healthcare-Website/blob/master/images/home-healthcare.png?raw=true\" width=\"50%\" height=\"50%\"/>\n\n\n###### Dependencies\n- Basically it\u2019s the website for  Information about all major hospital in Delhi/NCR, and anyone can read the information, and see what services provided by each hospital and By submitting an enquiry for availability in hospital.\n\n\n- [Jquery](https://code.jquery.com/jquery-3.2.1.min.js) <br/>\n- [Bootstrap 3.3](https://getbootstrap.com/docs/3.3/) <br/>\n- [Mean Menu For Mobile Devices](https://github.com/meanthemes/meanMenu) <br/>\n- HTML5 <br/>\n- CSS3 <br/>\n- Smooth Scroll <br/> \n- Parallax <br/>\n- Animation <br/>\n"
 },
 {
  "repo": "rajagopal28/healthcare-server",
  "language": "Ruby",
  "readme_contents": "# healthcare-server\nA rubyOnRails based web application with a small concept behind healthcare full proposal here [Proposal](https://github.com/rajagopal28/healthcare-server/blob/master/proposal.md)\nThe related mobile repository can be viewed ==> [Mobile](https://github.com/rajagopal28/Jackie)\n## Problem at hand\nOur major objective is to create an environment that helps us be independent and be healthy. Being independent makes us feel empowered all the time. People tend to forget things more often. But when it comes to health we got to be vigilant. Diabetic people need constant attention and care when it comes to health checks and medications. Level-2 Diabetes often required periodic insulin intake to keep glucose level balanced. They should also maintain a timely and proper diet that goes hand in hand with their medication schedules. We live in a busy world where we cannot be around all the time. With that being said we can deep dive into our proposed solution.\n\n## The proposed solution\nThe proposed solution is to have a multi-platform environment that helps you take care of yourself. We intend to build a personal assistant based ecosystem that helps you keep track of your health by monitoring your body vitals viz., glucose, pressure, pulse and temperature, perform tasks like book appointments, view or remind you about your booked appointments, keep track of you medicine prescriptions, intake and personal medicine inventory management in a more nurturing and enjoyable way.\n\n\n## Proposed architecture\n![Architecture](./images/image00.png)\nThis entire application has 3 essential components\n- The centralized healthcare server which holds patient data such as vital information, medicine intake logs, appointments, prescriptions etc.\n- The mobile app + wearable component - with this combo we can collect user information such as vitals, medicine intake activities, reminders on appointments and medicine intakes etc.\n- The Alexa skill - which is essentially coupled with the data back-end to personally serve people in managing their vitals, appointments and medicine intake.\n\n\n## Backend Schema\n![Schema](./images/image02.png)\n\n\n## Major User cases\nCentralized web applications with ability too\n- view & create doctor appointments\n- view & create vitals\n- monitor and visualize vitals\n- view & create medicines\n- view & create prescriptions and medicines\n- view & create doctor appointments, schedules and reschedules\n- view & create notifications for doctors\n- monitor and visualize medicine availability\n\n## Technical Nuances\nAs we wanted to have to quick backend setup so that we can have some time available to spent on the new technologies that are involved in the component(viz., react native, android, alexa and Aurdino devlopment) we chose Ruby On Rails and it was totally worth it.\n* **Ruby on Rails** is one of the beautiful script based web frameworks, it did all the data management work setup for us with it's scaffolding generation, what a beauty. Just defining the attributes in `` rails generate scaffolding `` command generates everything to manage that particular model, it even gives rest end points in an instant. We were totally carried away by it capability to create a robust and flexible back-end in a short span.\n* **Postgres** is one of the most advanced open source database management system that is as is. We chose rails as we structured the data in a most relational way. Postgres supported quick setup and easy to manage data and their relationship. Of course, rails and it's migrations have a great part as the out of the box postgres support elevated everything to a different level.\n* **Pure CSS** is the best light weight css framework that helped us create a pretty decent looking UI views. Their approach was so simplistic that they provide on demand inclusions of styles that can be included only when needed say forms, grids and layouts , such that the site does not become heavy with elements that will not be used.\n* **Chartkick + highcharts** made us drop our jaws because it is the first ever server side chart rendering framework. It was really smooth as if we are using server side tag libraries to loop through list of data. Credits to rails of cource, gems for everything that we need, really helped us save time. We used some server side capabilities to conditionally choose charts and render data in a synchronous way, really first time we have used a chart library that did not use ajax and rest call.\n* **Heroku** was our first choice as it is well known for its intensive support for rails applications. Its of the box support to postgres as an out of the box add-on made us feel re-assured with our choice on postgres as our database.\n* **GCM server side support** was required as part of the mobile application concept. With an additional inclusion of server side capabilities in capabilities to call external APIs such as RestClient gem helped us big time to integrate this feature in a seamless way.\n\n\n## Major User Flows:\n### Home:\nThis is the simplistic Home UI in PureCSS with nav and everything. I know it looks kind of childish with the images we have chosen but our features are realtime and helpful.\n![Home](./images/image000.png)\n### Users:\n![Users](./images/image001.png)\n### Doctors:\n![Doctors](./images/image002.png)\n### Doctor Appointments:\n![Doctor Appointments](./images/image003.png)\n### Doctors Notifications:\n![Doctors Notifications](./images/image004.png)\n##New doctor appointments\n![Doctor appointments](./images/image009.png)\n### Medicines:\n![Medicines](./images/image006.png)\n### Prescribed Medicines:\nPrescribed Medicines for user\n![Prescribed Medicines](./images/image010.png)\nPrescribed medicines edit view\n![Prescribed Medicines](./images/image017.png)\n### In Patients:\n![In Patients](./images/image005.png)\n### Medicine intake logs:\n![User Vital logs](./images/image013.png)\nMedicine intake logs deletion view\n![Medicine intake logs](./images/image018.png)\n![Medicine intake logs](./images/image019.png)\n### Prescriptions:\n![Prescriptions](./images/image007.png)\n### User Vital logs:\n![User Vital logs](./images/image011.png)\nUser Vital logs with user wise grouping\n![User Vital logs](./images/image012.png)\n### User vitals summary:\n![User vitals summary](./images/image016.png)\n\n\n\n## Key Learnings\n- How to create and publish an alexa skill by leveraging the voice activated technlogies in a smooth and effective way.\n- React native is adaptive, flexible enough to let both native as well as hybrid code and features by binding them together with their coherant data flows and models.\n- Ruby on rails is the quickest script based web application framework that can be developer friendly as well as feature friendly with their ability to scale and balance.\n\n## References\n- http://guides.rubyonrails.org/association_basics.html\n- https://stackoverflow.com/questions/36946498/for-loop-with-select-helper\n- https://www.tutorialspoint.com/ruby-on-rails/rails-scaffolding.htm\n- https://www.digitalocean.com/community/tutorials/how-to-use-postgresql-with-your-ruby-on-rails-application-on-ubuntu-14-04\n- http://mentalized.net/journal/2017/04/22/run-rails-migrations-on-heroku-deploy/\n- https://www.chartkick.com/\n- http://guides.rubyonrails.org/active_record_querying.html\n- https://www.theodinproject.com/courses/ruby-on-rails/lessons/sessions-cookies-and-authentication\n- version/arguments mismatch issue: https://stackoverflow.com/a/69274921\n- Issue `uninitialized class variable @@schemes in URI` : https://stackoverflow.com/a/73583358\n- Release issue with db-migrate: https://stackoverflow.com/a/71192990\n"
 },
 {
  "repo": "blencorp/HealthCare.gov-Open-Source-Release",
  "language": "JavaScript",
  "readme_contents": "HealthCare.gov-Open-Source-Release\n==================================\nThis project includes the source code and content for the healthcare.gov website. For more information, please visit https://www.healthcare.gov/developers\n\n\n==============================================\nLocal Installation Requirements\n==============================================\n\nInstalling the code in this repository should be fairly straight-forward, but there are a few requirements you\u2019ll need to make sure your system has before you start:\n\n- RedHat Enterprise Linux (RHEL) 6.1 or similar\n- Ruby on Rails\n- RubyGems\n- Jekyll\n\n\n==============================================\nLinux Environment\n==============================================\n\nHealthcare.Gov is currently hosted on a RedHat Enterprise Linux (RHEL) environment. Current version is RHEL 6.1 It is advised that local environments try to match this as closely as possible. If RHEL is not available, CentOS linux distribution may be used. \n\nOnce you have setup your local environment, run 'yum update' to ensure that the system has all of the latest updates and is current. \n\n\n==============================================\nRuby on Rails\n==============================================\n\nRuby and Rails will need to be installed after configuration of your local/development environment. Follow the steps below to install Ruby on Rails:\n\nInstall the Ruby Package:\n\n - yum install ruby\n - yum install ruby-devel ruby-irb ruby-rdoc ruby-ri\n - mkdir ~/src\n - cd ~/src\n\n \n==============================================\nInstall rubygems: \n==============================================\n\n - wget http://production.cf.rubygems.org/rubygems/rubygems-1.8.24.tgz\n - Copy the tar file to  the /opt directory\n - Run the following command to untar the file: tar xzvf rubygems-1.8.24.tgz\n\nRemove the rubygem tar file and install RubyGems:\n\n - rm rubygems-1.8.24.tgz \u2013f\n - cd rubygems-1.8.24 and issue the following command to install ruby gems\n - ruby setup.rb\n\nIssue the following command to update the gems:\n\n - gem update\n - gem update --system\n\nInstall gcc compiler: \n\n - yum install gcc gcc-c++ make \u2013y\n - gem install rails \u2013V\n \nIssue the following command to install rails:\n \n - gem install rails\n\nCheck the version of rails:\n - rails --version\n\nTo check the list of gems installed issue the following command:\n- gem list\n\nInstall sqlite\n\n - yum install sqlite-devel\n \nInstall bundle:\n\n - bundle install\n - gem install therubyracer\n - vi Gemfile and uncomment \"gem therubyracer\"\n\nStart the rails server\n\n - rails server\n - Browse to http://localhost:3000 to view the site\n\n \n============================================== \nInstall Jekyll\n==============================================\n\nRuntime Dependencies\n\nThe following Ruby gems are required in order to run Jekyll. These can be installed via the 'gem install <gem name>' command.\n\n - Classifier: Generating related posts (Ruby)\n - Directory Watcher: Auto-regeneration of sites (Ruby)\n - Kramdown: Markdown-superset converter (Ruby)\n - Liquid: Templating system (Ruby)\n - Maruku: Default markdown engine (Ruby)\n\nDeveloper Dependencies\n\nThe following Ruby gems should also be installed to develop for Jekyll. These can be installed via the 'gem install <gem name>' command.\n\n - RDiscount: Discount Markdown Processor (Ruby)\n - RedCloth: Textile support (Ruby)\n - RedGreen: Nicer test output (Ruby)\n - RR: Mocking (Ruby)\n - Shoulda: Test framework (Ruby)\n\n\nInstall Jekyll by issuing the following command:\n\n - gem install Jekyll\n\nChange directory to the following:\n \n - cd /var/www/html\n\nCreate a directory to store the project files\n - mkdir /healthcare.gov\n - cd /healthcare.gov\n\nAfter downloading and unzipping the project files, start the Jekyll Server:\n\n - jekyll serve\n - Browse to http://localhost:4000 to view the site\n \n \n \n\n\n\n\n \n \n \n\n\n\n"
 },
 {
  "repo": "Jianing-Qiu/Awesome-Healthcare-Foundation-Models",
  "language": null,
  "readme_contents": "# Awesome-Healthcare-Foundation-Models \n\n[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)\n\nCurated list of awesome large AI models (LAMs), or foundation models, in healthcare. We organize the current LAMs into four categories: large language models (LLMs), large vision models (LVMs), large audio models (LAudiMs), and large multi-modal models (LMMs). The areas that these LAMs are applied to include but not limited to bioinformatics, medical diagnosis and decision making, medical imaging and vision, medical informatics, medical education, public health, and medical robotics.\n\nWe welcome contributions to this repository to add more resources. Please submit a pull request if you want to contribute!\n\n## News\n\nWe are excited to annouce a *IEEE J-BHI* special issue on **Biomedical and Health Foundation Models**. Please refer to the [call-for-papers](https://www.embs.org/jbhi/wp-content/uploads/sites/18/2023/06/JBHI_Foundation_Models_Call-for-Papers.pdf) for more details. \n\nTopics of interest include but not limited to:\n1) Basic research on new theories, principles, and structures of biomedical and health foundation models\n2) Basic research on the interpretability and explainability of biomedical and health foundation models\n3) Prompt engineering in biomedical and health foundation models\n4) Data engineering in biomedical and health foundation models\n5) Large-scale biomedical and health dataset\n6) Multi-modal learning and alignment for biomedical and health foundation models\n7) Efficient computing for biomedical and health foundation models\n8) Adversarial robustness of biomedical and health foundation models\n9) Applications of foundation models in biomedical and health informatics\n10) New evaluation paradigms for biomedical and health foundation models\n11) New computer systems for biomedical and health foundation models\n12) Decentralised methods for developing and deploying biomedical and health foundation models\n13) Foundation model ethics, safety, privacy, and regulations in biomedicine and healthcare\n\nPlease help spread the word and contribute if you are interested or already working on these topics!\n\n\n## Table of Contents\n* [Survey](#survey)\n* [Large Language Models](#large-language-models)\n* [Large Vision Models](#large-vision-models)\n* [Large Audio Models](#large-audio-models)\n* [Large Multi-modal models](#large-multi-modal-models)\n* [Applications of Large AI Models in Healthcare](#applications-of-large-ai-models-in-healthcare)\n\n\n## Survey\n\nThis repository is largely based on the following paper:\n\n**[Large AI Models in Health Informatics:\nApplications, Challenges, and the Future](https://arxiv.org/pdf/2303.11568v1.pdf)**\n<br /> \nJianing Qiu,\nLin Li, \nJiankai Sun,\nJiachuan Peng,\nPeilun Shi,\nRuiyang Zhang,\nYinzhao Dong,\nKyle Lam,\nFrank P.-W. Lo,\nBo Xiao,\nWu Yuan,\nDong Xu, and\nBenny Lo\n<br />\n\n\nIf you find this repository helpful, please consider citing:\n\n```bibtex\n@article{qiu2023large,\n  title={Large AI Models in Health Informatics: Applications, Challenges, and the Future},\n  author={Qiu, Jianing and Li, Lin and Sun, Jiankai and Peng, Jiachuan and Shi, Peilun and Zhang, Ruiyang and Dong, Yinzhao and Lam, Kyle and Lo, Frank P-W and Xiao, Bo and others},\n  journal={arXiv preprint arXiv:2303.11568},\n  year={2023}\n}\n```\n\n\n\n\n\n\n## Large Language Models\n\n### Healthcare Domain\n\n* KeBioLM: Improving Biomedical Pretrained Language Models with Knowledge [[Paper]](https://arxiv.org/abs/2104.10344)\n* BioELMo: Probing Biomedical Embeddings from Language Models [[Paper]](https://arxiv.org/abs/1904.02181)\n* BioBART: Pretraining and Evaluation of A Biomedical Generative Language Model [[Paper]](https://aclanthology.org/2022.bionlp-1.9.pdf)\n* ClinicalT5: A Generative Language Model for Clinical Text [[Paper]](https://aclanthology.org/2022.findings-emnlp.398.pdf)\n* GatorTron: A Large Clinical Language Model to Unlock Patient Information from Unstructured Electronic Health Records [[Paper]](https://arxiv.org/pdf/2203.03540v2.pdf)\n* ChatCAD: Interactive Computer-Aided Diagnosis on Medical Image using Large Language Models [[Paper]](https://arxiv.org/pdf/2302.07257.pdf)\n* DeID-GPT: Zero-shot Medical Text De-Identification by GPT-4 [[Paper]](https://arxiv.org/pdf/2303.11032.pdf)\n* Capabilities of GPT-4 on Medical Challenge Problems [[Paper]](https://arxiv.org/pdf/2303.13375.pdf)\n* BioBERT: a pre-trained biomedical language representation model for biomedical text mining [[Paper]](https://arxiv.org/pdf/1901.08746.pdf)\n* Publicly Available Clinical BERT Embeddings [[Paper]](https://arxiv.org/pdf/1904.03323.pdf)\n* BioMegatron: Larger Biomedical Domain Language Model [[Paper]](https://arxiv.org/pdf/2010.06060.pdf)\n* Don\u2019t Stop Pretraining: Adapt Language Models to Domains and Tasks [[Paper]](https://aclanthology.org/2020.acl-main.740.pdf)\n* Med-BERT: pretrained contextualized embeddings on large-scale structured electronic health records for disease prediction [[Paper]](https://www.nature.com/articles/s41746-021-00455-y)\n* BioELECTRA:Pretrained Biomedical text Encoder using Discriminators [[Paper]](https://aclanthology.org/2021.bionlp-1.16.pdf)\n* LinkBERT: Pretraining Language Models with Document Links [[Paper]](https://arxiv.org/pdf/2203.15827.pdf)\n* BioGPT: Generative Pre-trained Transformer for Biomedical Text Generation and Mining [[Paper]](https://arxiv.org/pdf/2210.10341.pdf)\n* Large Language Models Encode Clinical Knowledge [[Paper]](https://arxiv.org/pdf/2212.13138.pdf)\n* A large language model for electronic health records [[Paper]](https://www.nature.com/articles/s41746-022-00742-2)\n* Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing [[Paper]](https://arxiv.org/pdf/2007.15779.pdf)\n* BEHRT: Transformer for Electronic Health Records [[Paper]](https://www.nature.com/articles/s41598-020-62922-y)\n* Federated Learning of Medical Concepts Embedding using BEHRT [[Paper]](https://arxiv.org/abs/2305.13052) [[Code]](https://github.com/nadavlab/FederatedBEHRT)\n* RadBERT: Adapting Transformer-based Language Models to Radiology [[paper]](https://pubs.rsna.org/doi/epdf/10.1148/ryai.210258) [[HuggingFace]](https://huggingface.co/UCSD-VA-health/RadBERT-RoBERTa-4m)\n* Highly accurate protein structure prediction with AlphaFold [[Paper]](https://www.nature.com/articles/s41586-021-03819-2) [[Code]](https://github.com/deepmind/alphafold)\n* Accurate prediction of protein structures and interactions using a three-track neural network [[Paper]](https://www.science.org/doi/full/10.1126/science.abj8754?casa_token=tleEHPOOSr8AAAAA%3AT0eToIMPW0oN1jjIGLs8aPyQK8qbcFIByjT1x4k90tvBAj03SZUzpEinCPe_t-g4ECmjJ9wlj8OwQBs)\n* Protein complex prediction with AlphaFold-Multimer [[Paper]](https://www.biorxiv.org/content/10.1101/2021.10.04.463034v2.abstract)\n* FastFold: Reducing AlphaFold Training Time from 11 Days to 67 Hours [[Paper]](https://arxiv.org/abs/2203.00854) [[Code]](https://github.com/hpcaitech/fastfold)\n* HelixFold: An Efficient Implementation of AlphaFold2 using PaddlePaddle [[Paper]](https://arxiv.org/abs/2207.05477) [[Code]](https://github.com/PaddlePaddle/PaddleHelix)\n* Uni-Fold: An Open-Source Platform for Developing Protein Folding Models beyond AlphaFold [[Paper]](https://www.biorxiv.org/content/10.1101/2022.08.04.502811v3.abstract) [[Code]](https://github.com/dptech-corp/Uni-Fold)\n* OpenFold: Retraining AlphaFold2 yields new insights into its learning mechanisms and capacity for generalization [[Paper]](https://www.biorxiv.org/content/10.1101/2022.11.20.517210v2.abstract) [[Code]](https://github.com/aqlaboratory/openfold)\n* ManyFold: an efficient and flexible library for training and validating protein folding models [[Paper]](https://academic.oup.com/bioinformatics/article/39/1/btac773/6887136) [[Code]](https://github.com/instadeepai/manyfold)\n* ColabFold: making protein folding accessible to all [[Paper]](https://www.nature.com/articles/s41592-022-01488-1) [[Code]](https://github.com/sokrypton/ColabFold)\n* Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences [[Paper]](https://www.pnas.org/doi/abs/10.1073/pnas.2016239118) [[Code]](https://github.com/facebookresearch/esm)\n* ProGen: Language Modeling for Protein Generation [[Paper]](https://arxiv.org/abs/2004.03497) [[Code]](https://github.com/lucidrains/progen)\n* ProtTrans: Towards Cracking the Language of Life's Code Through Self-Supervised Deep Learning and High Performance Computing [[Paper]](https://arxiv.org/abs/2007.06225) [[Code]](https://github.com/agemagician/ProtTrans)\n* Evolutionary-scale prediction of atomic level protein structure with a language model [[Paper]](https://www.science.org/doi/full/10.1126/science.ade2574) \n* High-resolution de novo structure prediction from primary sequence [[Paper]](https://www.biorxiv.org/content/10.1101/2022.07.21.500999v1.abstract) [[Code]](https://github.com/HeliXonProtein/OmegaFold)\n* Single-sequence protein structure prediction using a language model and deep learning [[Paper]](https://www.nature.com/articles/s41587-022-01432-w)\n* Improved the Protein Complex Prediction with Protein Language Models [[Paper]](https://www.biorxiv.org/content/10.1101/2022.09.15.508065v2.abstract)\n* MSA Transformer [[Paper]](http://proceedings.mlr.press/v139/rao21a.html) [[Code]](https://github.com/The-AI-Summer/self-attention-cv)\n* Deciphering antibody affinity maturation with language models and weakly supervised learning [[Paper]](https://arxiv.org/abs/2112.07782)\n* xTrimoABFold: De novo Antibody Structure Prediction without MSA [[Paper]](https://arxiv.org/abs/2212.00735)\n* scBERT as a large-scale pretrained deep language model for cell type annotation of single-cell RNA-seq data [[Paper]](https://arxiv.org/abs/2212.00735) [[Code]](https://github.com/TencentAILabHealthcare/scBERT)\n* Interpretable RNA Foundation Model from Unannotated Data for Highly Accurate RNA Structure and Function Predictions [[Paper]](https://www.biorxiv.org/content/10.1101/2022.08.06.503062v2.abstract) [[Code]](https://github.com/ml4bio/rna-fm)\n* E2Efold-3D: End-to-End Deep Learning Method for accurate de novo RNA 3D Structure Prediction [[Paper]](https://www.biorxiv.org/content/10.1101/2022.08.06.503062v2.abstract) [[Code]](https://github.com/ml4bio/rna-fm)\n\n### General Domain\n\n* Chatgpt: Optimizing language models for dialogue [[Blog]](https://openai.com/blog/chatgpt/) \n* LLaMA: Open and Efficient Foundation Language Models [[Paper]](https://arxiv.org/pdf/2302.13971.pdf)\n* Scaling Instruction-Finetuned Language Models [[Paper]](https://arxiv.org/pdf/2210.11416.pdf)\n* PaLM: Scaling Language Modeling with Pathways [[Paper]](https://arxiv.org/pdf/2204.02311.pdf)\n* Training Compute-Optimal Large Language Models [[Paper]](https://arxiv.org/pdf/2203.15556.pdf)\n* Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model [[Paper]](https://arxiv.org/pdf/2201.11990.pdf)\n* BLOOM: A 176B-Parameter Open-Access Multilingual Language Model [[Paper]](https://arxiv.org/pdf/2211.05100.pdf)\n* LaMDA: Language Models for Dialog Applications [[Paper]](https://arxiv.org/pdf/2201.08239.pdf)\n* OPT: Open Pre-trained Transformer Language Models [[Paper]](https://arxiv.org/pdf/2205.01068.pdf)\n* Training language models to follow instructions with human feedback [[Paper]](https://arxiv.org/pdf/2203.02155.pdf)\n* Scaling Language Models: Methods, Analysis & Insights from Training Gopher [[Paper]](https://arxiv.org/pdf/2112.11446.pdf)\n* Multitask prompted training enables zero-shot task generalization [[Paper]](https://arxiv.org/pdf/2110.08207.pdf)\n* Language Models are Few-Shot Learners [[Paper]](https://arxiv.org/pdf/2005.14165.pdf)\n* Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer [[Paper]](https://arxiv.org/pdf/1910.10683.pdf)\n* RoBERTa: A Robustly Optimized BERT Pretraining Approach [[Paper]](https://arxiv.org/pdf/1907.11692.pdf)\n* Language Models are Unsupervised Multitask Learners [[Paper]](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)\n* Improving language models by retrieving from trillions of tokens [[Paper]](https://arxiv.org/pdf/2112.04426.pdf)\n* WebGPT: Browser-assisted question-answering with human feedback [[Paper]](https://arxiv.org/pdf/2112.09332.pdf)\n* Improving alignment of dialogue agents via targeted human judgements [[Paper]](https://arxiv.org/pdf/2209.14375.pdf)\n* Improving Language Understanding by Generative Pre-Training [[Paper]](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf)\n* BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding [[Paper]](https://arxiv.org/pdf/1810.04805.pdf)\n\n\n\n\n\n\n## Large Vision Models\n\n### Healthcare Domain\n\n\n* Med3d: Transfer learning for 3d medical image analysis [[Paper]](https://arxiv.org/abs/1904.00625) [[Code]](https://github.com/Tencent/MedicalNet)\n* Models genesis: Generic autodidactic models for 3d medical image analysis [[Paper]](https://arxiv.org/abs/1908.06912) [[Code]](https://github.com/MrGiovanni/ModelsGenesis)\n* MICLe: Big self-supervised models advance medical image classifications [[Paper]](https://arxiv.org/abs/2101.05224) [[Code]](https://github.com/rjrobben/MICLe_pytorch)\n* C2l: Comparing to Learn: Surpassing ImageNet Pretraining on Radiographs By Comparing Image Representations [[Paper]](https://arxiv.org/abs/2007.07423) [[Code]](https://github.com/funnyzhou/C2L_MICCAI2020)\n* MoCo-CXR: MoCo Pretraining Improves Representation and Transferability of Chest X-ray Models [[Paper]](https://arxiv.org/abs/2010.05352) [[Code]](https://github.com/stanfordmlgroup/MoCo-CXR)\n* Transunet: Transformers make strong encoders for medical image segmentation [[Paper]](https://arxiv.org/abs/2102.04306) [[Code]](https://github.com/Beckschen/TransUNet)\n* Transfuse: Fusing transformers and cnns for medical image segmentation [[Paper]](https://arxiv.org/abs/2102.08005) [[Code]](https://github.com/Rayicer/TransFuse)\n* Medical transformer: Gated axial-attention for medical image segmentation [[Paper]](https://arxiv.org/abs/2102.10662) [[Code]](https://github.com/jeya-maria-jose/Medical-Transformer)\n* UNETR: Transformers for 3D Medical Image Segmentation [[Paper]](https://arxiv.org/abs/2103.10504) [[Code]](https://github.com/Project-MONAI/research-contributions/tree/main/UNETR/BTCV)\n* Cotr: Efficiently bridging cnn and transformer for 3d medical image segmentation [[Paper]](https://arxiv.org/abs/2103.03024) [[Code]](https://github.com/YtongXie/CoTr)\n* Swin-unet: Unet-like pure transformer for medical image segmentation [[Paper]](https://arxiv.org/abs/2105.05537) [[Code]](https://github.com/HuCaoFighting/Swin-Unet)\n* SAM4Med: Generalist Vision Foundation Models for Medical Imaging: A Case Study of Segment Anything Model on Zero-Shot Medical Segmentation [[Paper]](https://arxiv.org/pdf/2304.12637.pdf)\n\n### General Domain\n\n**CNNs**:\n\n* GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism [[paper]](https://proceedings.neurips.cc/paper/2019/hash/093f65e080a295f8076b1c5722a46aa2-Abstract.html)\n* Big Transfer (BiT): General Visual Representation Learning [[paper]](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123500477.pdf)\n* Designing Network Design Spaces [[paper]](https://openaccess.thecvf.com/content_CVPR_2020/html/Radosavovic_Designing_Network_Design_Spaces_CVPR_2020_paper.html)\n* Self-supervised Pretraining of Visual Features in the Wild [[paper]](http://arxiv.org/abs/2103.01988)\n* EfficientNetV2: Smaller Models and Faster Training [[paper]](https://proceedings.mlr.press/v139/tan21a.html)\n* A ConvNet for the 2020s [[paper]](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_A_ConvNet_for_the_2020s_CVPR_2022_paper.pdf)\n* InternImage: Exploring Large-Scale Vision Foundation Models with Deformable Convolutions [[paper]](http://arxiv.org/abs/2211.05778)\n\n**Vision Transformers**:\n\n* Generative Pretraining From Pixels [[paper]](https://proceedings.mlr.press/v119/chen20s.html)\n* An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale [[paper]](https://openreview.net/forum?id=YicbFdNTTy&utm_campaign=f86497ed3a-EMAIL_CAMPAIGN_2019_04_24_03_18_COPY_01&utm_medium=email&utm_source=Deep%20Learning%20Weekly&utm_term=0_384567b42d-f86497ed3a-72965345)\n* Transformer in Transformer [[paper]](https://proceedings.neurips.cc/paper/2021/hash/854d9fca60b4bd07f9bb215d59ef5561-Abstract.html)\n* Swin Transformer: Hierarchical Vision Transformer Using Shifted Windows [[paper]](https://openaccess.thecvf.com/content/ICCV2021/html/Liu_Swin_Transformer_Hierarchical_Vision_Transformer_Using_Shifted_Windows_ICCV_2021_paper.html)\n* Training data-efficient image transformers & distillation through attention [[paper]](https://proceedings.mlr.press/v139/touvron21a.html)\n* Self-supervised Models are Good Teaching Assistants for Vision Transformers [[paper]](https://proceedings.mlr.press/v162/wu22c.html)\n* Scaling Vision with Sparse Mixture of Experts [[paper]](https://proceedings.neurips.cc/paper/2021/hash/48237d9f2dea8c74c2a72126cf63d933-Abstract.html)\n* Going Deeper With Image Transformers [[paper]](https://openaccess.thecvf.com/content/ICCV2021/html/Touvron_Going_Deeper_With_Image_Transformers_ICCV_2021_paper.html)\n* Masked Autoencoders Are Scalable Vision Learners [[paper]](https://openaccess.thecvf.com/content/CVPR2022/html/He_Masked_Autoencoders_Are_Scalable_Vision_Learners_CVPR_2022_paper.html)\n* Swin Transformer V2: Scaling Up Capacity and Resolution [[paper]](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Swin_Transformer_V2_Scaling_Up_Capacity_and_Resolution_CVPR_2022_paper.html)\n* Scaling Vision Transformers [[paper]](https://openaccess.thecvf.com/content/CVPR2022/html/Zhai_Scaling_Vision_Transformers_CVPR_2022_paper.html)\n* Efficient Self-supervised Vision Transformers for Representation Learning [[paper]](https://openreview.net/forum?id=fVu3o-YUGQK)\n* Scaling Vision Transformers to 22 Billion Parameters [[paper]](http://arxiv.org/abs/2302.05442)\n\n**CNNs + ViTs**:\n\n* CoAtNet: Marrying Convolution and Attention for All Data Sizes [[paper]](https://proceedings.neurips.cc/paper/2021/hash/20568692db622456cc42a2e853ca21f8-Abstract.html)\n* LeViT: A Vision Transformer in ConvNet's Clothing for Faster Inference [[paper]](https://openaccess.thecvf.com/content/ICCV2021/html/Graham_LeViT_A_Vision_Transformer_in_ConvNets_Clothing_for_Faster_Inference_ICCV_2021_paper.html)\n* ConViT: Improving Vision Transformers with Soft Convolutional Inductive Biases [[paper]](https://proceedings.mlr.press/v139/d-ascoli21a.html)\n\n\n\n## Large Audio Models\n\n### Healthcare Domain\n\n\n### General Domain\n\n* wav2vec: Unsupervised Pre-training for Speech Recognition [[Paper]](https://arxiv.org/abs/1904.05862) [[Blog]](https://ai.facebook.com/blog/wav2vec-20-learning-the-structure-of-speech-from-raw-audio/)\n* W2v-BERT: Combining Contrastive Learning and Masked Language Modeling for Self-Supervised Speech Pre-Training [[Paper]](https://arxiv.org/abs/2108.06209)\n* AudioLM: a Language Modeling Approach to Audio Generation [[Paper]](https://arxiv.org/abs/2209.03143) [[Project]](https://google-research.github.io/seanet/audiolm/examples/) [[Blog]](https://ai.googleblog.com/2022/10/audiolm-language-modeling-approach-to.html)\n* HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units [[Paper]](https://arxiv.org/abs/2106.07447) [[HuggingFace]](https://huggingface.co/docs/transformers/model_doc/hubert)\n* XLS-R: Self-supervised Cross-lingual Speech Representation Learning at Scale [[Paper]](https://arxiv.org/abs/2111.09296) [[Blog]](https://ai.facebook.com/blog/xls-r-self-supervised-speech-processing-for-128-languages/) [[HuggingFace]](https://huggingface.co/facebook/wav2vec2-xls-r-300m)\n* MusicLM: Generating Music From Text [[Paper]](https://arxiv.org/abs/2301.11325) [[Project]](https://google-research.github.io/seanet/musiclm/examples/) [[Code]](https://github.com/lucidrains/musiclm-pytorch)\n* Diffsound: Discrete Diffusion Model for Text-to-sound Generation [[Paper]](https://arxiv.org/abs/2207.09983) [[Project]](http://dongchaoyang.top/text-to-sound-synthesis-demo/) [[Code]](https://github.com/yangdongchao/Text-to-sound-Synthesis)\n* AudioGen: Textually Guided Audio Generation [[Paper]](https://arxiv.org/abs/2209.15352) [[Project]](https://felixkreuk.github.io/audiogen/)\n* Whisper: Robust Speech Recognition via Large-Scale Weak Supervision [[Paper]](https://arxiv.org/abs/2212.04356) [[Code]](https://github.com/openai/whisper) [[HuggingFace]](https://huggingface.co/openai/whisper-tiny.en)\n* Google USM: Scaling Automatic Speech Recognition Beyond 100 Languages [[Paper]](https://arxiv.org/abs/2303.01037) [[Blog]](https://ai.googleblog.com/2023/03/universal-speech-model-usm-state-of-art.html)\n\n\n## Large Multi-modal Models\n\n### Healthcare Domain\n\n* GPT-4 Technical Report [[Paper]](https://arxiv.org/pdf/2303.08774.pdf)\n* Expert-level detection of pathologies from unannotated chest X-ray images via self-supervised learning [[Paper]](https://www.nature.com/articles/s41551-022-00936-9)\n* Contrastive Learning of Medical Visual Representations from Paired Images and Text [[Paper]](https://arxiv.org/pdf/2010.00747.pdf) [[Code]](https://github.com/edreisMD/ConVIRT-pytorch)\n* Gloria: A multimodal global-local representation learning framework for labelefficient medical image recognition [[Paper]](https://ieeexplore.ieee.org/document/9710099) [[Code]](https://github.com/marshuang80/gloria)\n* RAMM: Retrieval-augmented Biomedical Visual Question Answering with Multi-modal Pre-training [[Paper]](https://arxiv.org/abs/2303.00534)\n\n### General Domain\n\n**Representation learning**:\n\n* Learning Transferable Visual Models From Natural Language Supervision [[paper]](https://proceedings.mlr.press/v139/radford21a.html)\n* Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision [[paper]](https://proceedings.mlr.press/v139/jia21b.html)\n* Florence: A New Foundation Model for Computer Vision [[paper]](http://arxiv.org/abs/2111.11432)\n* Grounded Language-Image Pre-Training [[paper]](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Grounded_Language-Image_Pre-Training_CVPR_2022_paper.html)\n* WenLan: Bridging Vision and Language by Large-Scale Multi-Modal Pre-Training [[paper]](http://arxiv.org/abs/2103.06561)\n* FLAVA: A Foundational Language and Vision Alignment Model [[paper]](https://openaccess.thecvf.com/content/CVPR2022/html/Singh_FLAVA_A_Foundational_Language_and_Vision_Alignment_Model_CVPR_2022_paper.html)\n* SimVLM: Simple Visual Language Model Pretraining with Weak Supervision [[paper]](https://openreview.net/forum?id=GUrhfTuf_3)\n* FILIP: Fine-grained Interactive Language-Image Pre-Training [[paper]](https://openreview.net/forum?id=cpDhcsEDC2)\n* Combined Scaling for Open-Vocabulary Image Classification [[paper]](http://arxiv.org/abs/2111.10050)\n* BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation [[paper]](https://proceedings.mlr.press/v162/li22n.html)\n* PaLI: A Jointly-Scaled Multilingual Language-Image Model [[paper]](http://arxiv.org/abs/2209.06794)\n* Towards All-in-one Pre-training via Maximizing Multi-modal Mutual Information [[paper]](http://arxiv.org/abs/2211.09807)\n* BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models [[paper]](http://arxiv.org/abs/2301.12597)\n* Supervision Exists Everywhere: A Data Efficient Contrastive Language-Image Pre-training Paradigm [[paper]](https://openreview.net/forum?id=zq1iJkNk3uN)\n* Language Is Not All You Need: Aligning Perception with Language Models [[paper]](http://arxiv.org/abs/2302.14045)\n* PaLM-E: An Embodied Multimodal Language Model [[paper]](http://arxiv.org/abs/2303.03378)\n* Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models [[paper]](http://arxiv.org/abs/2303.04671)\n\n**Text-to-image generation**:\n\n* Zero-Shot Text-to-Image Generation [[paper]](https://proceedings.mlr.press/v139/ramesh21a.html)\n* High-Resolution Image Synthesis With Latent Diffusion Models [[paper]](https://openaccess.thecvf.com/content/CVPR2022/html/Rombach_High-Resolution_Image_Synthesis_With_Latent_Diffusion_Models_CVPR_2022_paper.html)\n* Hierarchical Text-Conditional Image Generation with CLIP Latents [[paper]](http://arxiv.org/abs/2204.06125)\n* GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models [[paper]](https://proceedings.mlr.press/v162/nichol22a.html)\n* Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding [[paper]](https://openreview.net/forum?id=08Yk-n5l2Al)\n* Scaling Autoregressive Models for Content-Rich Text-to-Image Generation [[paper]](https://openreview.net/forum?id=AFDcYJKhND)\n\n\n\n## Applications of Large AI Models in Healthcare\n\nNote that some of the following models were not targeted at healthcare applications initially but may have the potential to be transferred to the healthcare domain or inspire future development.\n\n\n### Bioinformatics\n\n* GeneGPT: Augmenting Large Language Models with Domain Tools for Improved Access to Biomedical Information [[Paper]](https://arxiv.org/abs/2304.09667)\n* Highly accurate protein structure prediction with AlphaFold [[Paper]](https://www.nature.com/articles/s41586-021-03819-2) [[Code]](https://github.com/deepmind/alphafold)\n* Accurate prediction of protein structures and interactions using a three-track neural network [[Paper]](https://www.science.org/doi/full/10.1126/science.abj8754?casa_token=tleEHPOOSr8AAAAA%3AT0eToIMPW0oN1jjIGLs8aPyQK8qbcFIByjT1x4k90tvBAj03SZUzpEinCPe_t-g4ECmjJ9wlj8OwQBs)\n* Protein complex prediction with AlphaFold-Multimer [[Paper]](https://www.biorxiv.org/content/10.1101/2021.10.04.463034v2.abstract)\n* FastFold: Reducing AlphaFold Training Time from 11 Days to 67 Hours [[Paper]](https://arxiv.org/abs/2203.00854) [[Code]](https://github.com/hpcaitech/fastfold)\n* HelixFold: An Efficient Implementation of AlphaFold2 using PaddlePaddle [[Paper]](https://arxiv.org/abs/2207.05477) [[Code]](https://github.com/PaddlePaddle/PaddleHelix)\n* Uni-Fold: An Open-Source Platform for Developing Protein Folding Models beyond AlphaFold [[Paper]](https://www.biorxiv.org/content/10.1101/2022.08.04.502811v3.abstract) [[Code]](https://github.com/dptech-corp/Uni-Fold)\n* OpenFold: Retraining AlphaFold2 yields new insights into its learning mechanisms and capacity for generalization [[Paper]](https://www.biorxiv.org/content/10.1101/2022.11.20.517210v2.abstract) [[Code]](https://github.com/aqlaboratory/openfold)\n* ManyFold: an efficient and flexible library for training and validating protein folding models [[Paper]](https://academic.oup.com/bioinformatics/article/39/1/btac773/6887136) [[Code]](https://github.com/instadeepai/manyfold)\n* ColabFold: making protein folding accessible to all [[Paper]](https://www.nature.com/articles/s41592-022-01488-1) [[Code]](https://github.com/sokrypton/ColabFold)\n* Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences [[Paper]](https://www.pnas.org/doi/abs/10.1073/pnas.2016239118) [[Code]](https://github.com/facebookresearch/esm)\n* ProGen: Language Modeling for Protein Generation [[Paper]](https://arxiv.org/abs/2004.03497) [[Code]](https://github.com/lucidrains/progen)\n* ProtTrans: Towards Cracking the Language of Life's Code Through Self-Supervised Deep Learning and High Performance Computing [[Paper]](https://arxiv.org/abs/2007.06225) [[Code]](https://github.com/agemagician/ProtTrans)\n* Evolutionary-scale prediction of atomic level protein structure with a language model [[Paper]](https://www.science.org/doi/full/10.1126/science.ade2574) \n* High-resolution de novo structure prediction from primary sequence [[Paper]](https://www.biorxiv.org/content/10.1101/2022.07.21.500999v1.abstract) [[Code]](https://github.com/HeliXonProtein/OmegaFold)\n* Single-sequence protein structure prediction using a language model and deep learning [[Paper]](https://www.nature.com/articles/s41587-022-01432-w)\n* Improved the Protein Complex Prediction with Protein Language Models [[Paper]](https://www.biorxiv.org/content/10.1101/2022.09.15.508065v2.abstract)\n* MSA Transformer [[Paper]](http://proceedings.mlr.press/v139/rao21a.html) [[Code]](https://github.com/The-AI-Summer/self-attention-cv)\n* Deciphering antibody affinity maturation with language models and weakly supervised learning [[Paper]](https://arxiv.org/abs/2112.07782)\n* xTrimoABFold: De novo Antibody Structure Prediction without MSA [[Paper]](https://arxiv.org/abs/2212.00735)\n* scBERT as a large-scale pretrained deep language model for cell type annotation of single-cell RNA-seq data [[Paper]](https://arxiv.org/abs/2212.00735) [[Code]](https://github.com/TencentAILabHealthcare/scBERT)\n* Interpretable RNA Foundation Model from Unannotated Data for Highly Accurate RNA Structure and Function Predictions [[Paper]](https://www.biorxiv.org/content/10.1101/2022.08.06.503062v2.abstract) [[Code]](https://github.com/ml4bio/rna-fm)\n* E2Efold-3D: End-to-End Deep Learning Method for accurate de novo RNA 3D Structure Prediction [[Paper]](https://www.biorxiv.org/content/10.1101/2022.08.06.503062v2.abstract) [[Code]](https://github.com/ml4bio/rna-fm)\n* SMILES-BERT: large scale unsupervised pre-training for molecular property prediction [[Paper]](https://par.nsf.gov/servlets/purl/10168888) [[Code]](https://github.com/uta-smile/SMILES-BERT)\n* SMILES Transformer: Pre-trained molecular fingerprint for low data drug discovery [[Paper]](https://arxiv.org/abs/1911.04738) [[Code]](https://github.com/DSPsleeporg/smiles-transformer)\n* MolBert: Molecular representation learning with language models and domain-relevant auxiliary tasks [[Paper]](https://arxiv.org/abs/2011.13230) [[Code]](https://github.com/BenevolentAI/MolBERT)\n* AGBT: Algebraic graph-assisted bidirectional transformers for molecular property prediction [[Paper]](https://www.nature.com/articles/s41467-021-23720-w) [[Code]](https://github.com/ChenDdon/AGBTcode)\n* GROVER: Self-supervised graph transformer on large-scale molecular data [[Paper]](https://arxiv.org/abs/2007.02835) [[Code]](https://github.com/tencent-ailab/grover)\n* Molgpt: molecular generation using a transformer-decoder model [[Paper]](https://pubs.acs.org/doi/10.1021/acs.jcim.1c00600) [[Code]](https://github.com/devalab/molgpt)\n* A Model to Search for Synthesizable Molecules [[Paper]](https://arxiv.org/abs/1906.05221) [[Code]](https://github.com/john-bradshaw/molecule-chef)\n* Transformer neural network for protein-specific de novo drug generation as a machine translation problem [[Paper]](https://www.nature.com/articles/s41598-020-79682-4)\n* Deepconv-dti: Prediction of drug-target interactions via deep learning with convolution on protein sequences [[Paper]](https://arxiv.org/abs/1811.02114) [[Code]](https://github.com/GIST-CSBL/DeepConv-DTI)\n* Graphdta: predicting drug\u2013target binding affinity with graph neural networks [[Paper]](https://pubmed.ncbi.nlm.nih.gov/33119053/) [[Code]](https://github.com/thinng/GraphDTA)\n* Moltrans: molecular interaction transformer for drug\u2013target interaction prediction [[Paper]](https://arxiv.org/abs/2004.11424) [[Code]](https://github.com/kexinhuang12345/moltrans)\n* Extracting Predictive Representations from Hundreds of Millions of Molecules [[Paper]](https://pubs.acs.org/doi/10.1021/acs.jpclett.1c03058) [[Code]](https://github.com/WeilabMSU/PretrainModels)\n* ADMETlab 2.0: an integrated online platform for accurate and comprehensive predictions of ADMET properties [[Project]](https://admetmesh.scbdd.com/) [[Paper]](https://pubmed.ncbi.nlm.nih.gov/33893803/)\n* MPG: Learn molecular representations from large-scale unlabeled molecules for drug discovery [[Paper]](https://arxiv.org/abs/2012.11175)\n* MG-BERT: leveraging unsupervised atomic representation learning for molecular property prediction [[Paper]](https://academic.oup.com/bib/article-abstract/22/6/bbab152/6265201?redirectedFrom=fulltext) [[Code]](https://github.com/ParishadBehnam/MG-BERT)\n* PanGu Drug Model: Learn a Molecule Like a Human [[Project]](http://www.pangu-drug.com/) [[Paper]](https://www.biorxiv.org/content/10.1101/2022.03.31.485886v1.full)\n* DrugBAN: Interpretable bilinear attention network with domain adaptation improves drug\u2013target prediction [[Paper]](https://www.nature.com/articles/s42256-022-00605-1) [[Code]](https://github.com/peizhenbai/DrugBAN)\n* DrugOOD: Out-of-Distribution (OOD) Dataset Curator and Benchmark for AI-aided Drug Discovery [[Paper]](https://arxiv.org/abs/2201.09637) [[Code]](https://github.com/tencent-ailab/DrugOOD)\n\n### Medical Diagnosis and Decision-making\n\n* Expert-level detection of pathologies from unannotated chest X-ray images via self-supervised learning [[Paper]](https://www.nature.com/articles/s41551-022-00936-9)\n* ChatCAD: Interactive Computer-Aided Diagnosis on Medical Image using Large Language Models [[Paper]](https://arxiv.org/pdf/2302.07257.pdf)\n* BEHRT: Transformer for Electronic Health Records [[Paper]](https://www.nature.com/articles/s41598-020-62922-y)\n* Federated Learning of Medical Concepts Embedding using BEHRT [[Paper]](https://arxiv.org/abs/2305.13052) [[Code]](https://github.com/nadavlab/FederatedBEHRT)\n* Med-BERT: pretrained contextualized embeddings on large-scale structured electronic health records for disease prediction [[Paper]](https://www.nature.com/articles/s41746-021-00455-y)\n* RadBERT: Adapting Transformer-based Language Models to Radiology [[paper]](https://pubs.rsna.org/doi/epdf/10.1148/ryai.210258) [[HuggingFace]](https://huggingface.co/UCSD-VA-health/RadBERT-RoBERTa-4m)\n\n### Medical Imaging and Vision\n\n* Expert-level detection of pathologies from unannotated chest X-ray images via self-supervised learning [[Paper]](https://www.nature.com/articles/s41551-022-00936-9)\n* Med3d: Transfer learning for 3d medical image analysis [[Paper]](https://arxiv.org/abs/1904.00625) [[Code]](https://github.com/Tencent/MedicalNet)\n* Models genesis: Generic autodidactic models for 3d medical image analysis [[Paper]](https://arxiv.org/abs/1908.06912) [[Code]](https://github.com/MrGiovanni/ModelsGenesis)\n* MICLe: Big self-supervised models advance medical image classifications [[Paper]](https://arxiv.org/abs/2101.05224) [[Code]](https://github.com/rjrobben/MICLe_pytorch)\n* C2l: Comparing to Learn: Surpassing ImageNet Pretraining on Radiographs By Comparing Image Representations [[Paper]](https://arxiv.org/abs/2007.07423) [[Code]](https://github.com/funnyzhou/C2L_MICCAI2020)\n* ConVIRT: Contrastive learning of medical visual representations from paired images and text [[Paper]](https://arxiv.org/pdf/2303.11032.pdf) [[Code]](https://github.com/edreisMD/ConVIRT-pytorch)\n* Gloria: A multimodal global-local representation learning framework for labelefficient medical image recognition [[Paper]](https://ieeexplore.ieee.org/document/9710099) [[Code]](https://github.com/marshuang80/gloria)\n* MoCo-CXR: MoCo Pretraining Improves Representation and Transferability of Chest X-ray Models [[Paper]](https://arxiv.org/abs/2010.05352) [[Code]](https://github.com/stanfordmlgroup/MoCo-CXR)\n* Transunet: Transformers make strong encoders for medical image segmentation [[Paper]](https://arxiv.org/abs/2102.04306) [[Code]](https://github.com/Beckschen/TransUNet)\n* Transfuse: Fusing transformers and cnns for medical image segmentation [[Paper]](https://arxiv.org/abs/2102.08005) [[Code]](https://github.com/Rayicer/TransFuse)\n* Medical transformer: Gated axial-attention for medical image segmentation [[Paper]](https://arxiv.org/abs/2102.10662) [[Code]](https://github.com/jeya-maria-jose/Medical-Transformer)\n* UNETR: Transformers for 3D Medical Image Segmentation [[Paper]](https://arxiv.org/abs/2103.10504) [[Code]](https://github.com/Project-MONAI/research-contributions/tree/main/UNETR/BTCV)\n* Cotr: Efficiently bridging cnn and transformer for 3d medical image segmentation [[Paper]](https://arxiv.org/abs/2103.03024) [[Code]](https://github.com/YtongXie/CoTr)\n* Swin-unet: Unet-like pure transformer for medical image segmentation [[Paper]](https://arxiv.org/abs/2105.05537) [[Code]](https://github.com/HuCaoFighting/Swin-Unet)\n* SAM4Med: Generalist Vision Foundation Models for Medical Imaging: A Case Study of Segment Anything Model on Zero-Shot Medical Segmentation [[Paper]](https://arxiv.org/pdf/2304.12637.pdf)\n\n\n\n\n\n### Medical Informatics\n\n* DeID-GPT: Zero-shot Medical Text De-Identification by GPT-4 [[Paper]](https://arxiv.org/pdf/2303.11032.pdf)\n* Capabilities of GPT-4 on Medical Challenge Problems [[Paper]](https://arxiv.org/pdf/2303.13375.pdf)\n* BioBERT: a pre-trained biomedical language representation model for biomedical text mining [[Paper]](https://arxiv.org/pdf/1901.08746.pdf)\n* Publicly Available Clinical BERT Embeddings [[Paper]](https://arxiv.org/pdf/1904.03323.pdf)\n* BioMegatron: Larger Biomedical Domain Language Model [[Paper]](https://arxiv.org/pdf/2010.06060.pdf)\n* Don\u2019t Stop Pretraining: Adapt Language Models to Domains and Tasks [[Paper]](https://aclanthology.org/2020.acl-main.740.pdf)\n* Med-BERT: pretrained contextualized embeddings on large-scale structured electronic health records for disease prediction [[Paper]](https://www.nature.com/articles/s41746-021-00455-y)\n* BioELECTRA:Pretrained Biomedical text Encoder using Discriminators [[Paper]](https://aclanthology.org/2021.bionlp-1.16.pdf)\n* LinkBERT: Pretraining Language Models with Document Links [[Paper]](https://arxiv.org/pdf/2203.15827.pdf)\n* BioGPT: Generative Pre-trained Transformer for Biomedical Text Generation and Mining [[Paper]](https://arxiv.org/pdf/2210.10341.pdf)\n* Large Language Models Encode Clinical Knowledge [[Paper]](https://arxiv.org/pdf/2212.13138.pdf)\n* A large language model for electronic health records [[Paper]](https://www.nature.com/articles/s41746-022-00742-2)\n* Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing [[Paper]](https://arxiv.org/pdf/2007.15779.pdf)\n* BEHRT: Transformer for Electronic Health Records [[Paper]](https://www.nature.com/articles/s41598-020-62922-y)\n* Federated Learning of Medical Concepts Embedding using BEHRT [[Paper]](https://arxiv.org/abs/2305.13052) [[Code]](https://github.com/nadavlab/FederatedBEHRT)\n\n\n### Medical Education\n\n* GPT-4 Technical Report [[Paper]](https://arxiv.org/pdf/2303.08774.pdf)\n* Empowering Beginners in Bioinformatics with ChatGPT [[Paper]](https://www.biorxiv.org/content/10.1101/2023.03.07.531414v1)\n\n\n### Public Health\n\n* Expert-level detection of pathologies from unannotated chest X-ray images via self-supervised learning [[Paper]](https://www.nature.com/articles/s41551-022-00936-9)\n* Clustering Egocentric Images in Passive Dietary Monitoring with Self-Supervised Learning [[Paper]](https://arxiv.org/pdf/2208.12160.pdf)\n* ClimaX: A foundation model for weather and climate [[Paper]](https://arxiv.org/pdf/2301.10343.pdf)\n\n\n\n###  Medical Robotics\n\n* Decision Transformer: Reinforcement Learning via Sequence Modeling [[Paper]](https://arxiv.org/abs/2106.01345) [[Code]](https://github.com/kzl/decision-transformer)\n* R3M: A Universal Visual Representation for Robot Manipulation [[Paper]](https://arxiv.org/abs/2203.12601) [[Project]](https://sites.google.com/view/robot-r3m/) [[Code]](https://github.com/facebookresearch/r3m)\n* MimicPlay: Long-Horizon Imitation Learning by Watching Human Play [[Paper]](https://arxiv.org/abs/2302.12422) [[Project]](https://mimic-play.github.io/)\n* PaLM-E: An Embodied Multimodal Language Model [[Paper]](https://arxiv.org/abs/2303.03378) [[Project]](https://palm-e.github.io/) [[Blog]](https://ai.googleblog.com/2023/03/palm-e-embodied-multimodal-language.html)\n* A Generalist Agent [[Paper]](https://arxiv.org/abs/2205.06175) [[Blog]](https://www.deepmind.com/blog/a-generalist-agent)\n* CLIPort: What and Where Pathways for Robotic Manipulation [[Paper]](https://arxiv.org/abs/2109.12098) [[Project]](https://cliport.github.io/) [[Code]](https://github.com/cliport/cliport)\n* Perceiver-Actor: A Multi-Task Transformer for Robotic Manipulation [[Paper]](https://arxiv.org/abs/2209.05451) [[Project]](https://peract.github.io/) [[Code]](https://github.com/peract/peract)\n* Do As I Can, Not As I Say: Grounding Language in Robotic Affordances [[Paper]](https://arxiv.org/abs/2204.01691) [[Project]](https://say-can.github.io/) [[Code]](https://github.com/google-research/google-research/tree/master/saycan)\n* VIMA: General Robot Manipulation with Multimodal Prompts [[Paper]](https://arxiv.org/abs/2210.03094) [[Project]](https://vimalabs.github.io/) [[Code]](https://github.com/vimalabs/VIMA)\n* RT-1: Robotics Transformer for Real-World Control at Scale [[Paper]](https://arxiv.org/abs/2212.06817) [[Project]](https://robotics-transformer.github.io/) [[Code]](https://github.com/google-research/robotics_transformer)\n* ChatGPT for Robotics: Design Principles and Model Abilities [[Paper]](https://www.microsoft.com/en-us/research/uploads/prod/2023/02/ChatGPT___Robotics.pdf) [[Blog]](https://www.microsoft.com/en-us/research/group/autonomous-systems-group-robotics/articles/chatgpt-for-robotics/) [[Code]](https://github.com/microsoft/PromptCraft-Robotics)\n"
 },
 {
  "repo": "metriport/metriport",
  "language": "JavaScript",
  "readme_contents": "<p align=\"center\">\n  <a href=\"https://github.com/metriport/metriport\">\n    <img src=\"./assets/logo.png\" alt=\"Logo\">\n  </a>\n\n  <p align=\"center\">\n    Metriport helps digital health companies access and manage health and medical data, through a single open source API.\n    <br />\n    <a href=\"https://metriport.com\" target=\"_blank\"><strong>Learn more \u00bb</strong></a>\n    <br />\n    <br />\n    <a href=\"https://docs.metriport.com/\" target=\"_blank\">Docs</a>\n    \u00b7\n    <a href=\"https://www.npmjs.com/package/@metriport/api\" target=\"_blank\">NPM</a>\n    \u00b7\n    <a href=\"https://dash.metriport.com\" target=\"_blank\">Developer Dashboard</a>\n    \u00b7\n    <a href=\"https://metriport.com\" target=\"_blank\">Website</a>\n\n  </p>\n</p>\n\n<p align=\"center\">\n   <a href=\"https://status.metriport.com/\"><img src=\"https://api.checklyhq.com/v1/badges/checks/38e13035-5922-4b4c-8d94-6fe766a3c4da?style=flat&theme=default\" alt=\"API Status Check\"></a>\n   <a href=\"https://github.com/metriport/metriport/stargazers\"><img src=\"https://img.shields.io/github/stars/metriport/metriport\" alt=\"Github Stars\"></a>\n   <a href=\"https://github.com/metriport/metriport/blob/master/LICENSE\"><img src=\"https://img.shields.io/badge/license-AGPLv3-purple\" alt=\"License\"></a>\n   <a href=\"https://github.com/metriport/metriport/pulse\"><img src=\"https://img.shields.io/github/commit-activity/m/metriport/metriport\" alt=\"Commits-per-month\"></a>\n   <a href=\"https://twitter.com/metriport\"><img src=\"https://img.shields.io/twitter/follow/metriport?style=social\"></a>\n   <a href=\"https://www.linkedin.com/company/metriport\"><img src=\"https://img.shields.io/static/v1?label=LinkedIn&message=Metriport (YC S22)&color=blue\" alt=\"LinkedIn\"></a>\n   <a href=\"https://www.ycombinator.com/companies/metriport\"><img src=\"https://img.shields.io/static/v1?label=Y Combinator&message=Metriport&color=orange\" alt=\"YC\"></a>\n</p>\n\n<div align=\"center\">\n\n#### Support us on [Product Hunt](https://www.producthunt.com/products/metriport-api) and [Launch YC](https://www.ycombinator.com/launches/Ghx-metriport-universal-api-for-healthcare-data)\n\n<a href=\"https://www.producthunt.com/posts/metriport-health-devices-api?utm_source=badge-featured&utm_medium=badge&utm_souce=badge-metriport&#0045;health&#0045;devices&#0045;api\" target=\"_blank\"><img src=\"https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=371762&theme=light\" alt=\"Metriport&#0032;&#0045;&#0032;Health&#0032;Devices&#0032;API - Open&#0045;source&#0032;Plaid&#0032;for&#0032;healthcare&#0032;data | Product Hunt\" style=\"width: 250px; height: 54px;\" width=\"250\" height=\"54\" /></a> <a href='https://www.ycombinator.com/launches/Ghx-metriport-universal-api-for-healthcare-data' target=\"_blank\"><img src='https://www.ycombinator.com/launches/Ghx-metriport-universal-api-for-healthcare-data/upvote_embed.svg' alt='Launch YC: Metriport - Universal API for Healthcare Data'></a>\n\n</div>\n\n## **Overview**\n\n<div align=\"center\">\n   <img width=\"50%\" alt=\"wearables\" src=\"./assets/wearables.svg\">\n</div>\n\n## **Security and Privacy**\n\nMetriport is SOC 2 and HIPAA compliant. [Click here](https://metriport.com/security/) to learn more about our security practices.\n\n<p float=\"left\">\n  <img src=\"./assets/soc2.png\" width=\"20%\" />\n  <img src=\"./assets/hipaa.png\" width=\"30%\" />\n  <img src=\"./assets/soc2-vanta.png\" width=\"20%\" />\n  <img src=\"./assets/hipaa-vanta.png\" width=\"20%\" />\n</p>\n\n### **Health Devices API**\n\nOur [Health Devices API](https://metriport.com/devices), allows you to gain access to your users\u2019 health data from various wearables, RPM devices, and mHealth sources through a single standardized API.\n\nOut of the box, our Health Devices API supports the following integrations:\n\n- Dexcom\n- Fitbit\n- Garmin\n- Oura\n- Whoop\n- Withings\n- Cronometer\n- Apple Health\n- Google Fit\n\n...with many more integrations on the way! If there\u2019s an integration you need that\u2019s not currently on here, feel free to shoot us an [email](mailto:contact@metriport.com) and let us know so we can build it, or feel free to fork our code and add the integration yourself.\n\n<div align=\"center\">\n   <img width=\"50%\" alt=\"wearables\" src=\"./assets/graphic.svg\">\n</div>\n\n### **Medical API (Coming Soon)**\n\nOpen-source with native FHIR support. More info on our Medical API here: https://metriport.com/medical/\n\n## **Getting Started**\n\nCheck out the links below to get started with Metriport in minutes!\n\n### **[Quickstart Guide](https://docs.metriport.com/getting-started/introduction) \ud83d\ude80**\n\n### **[Developer Dashboard](https://dash.metriport.com/) \ud83d\udcbb**\n\n### **[npm package](https://www.npmjs.com/package/@metriport/api)**\n\n## **Repo Rundown**\n\n### **API Server**\n\nBackend for the Metriport API.\n\n- Dir: [`/api`](/api)\n- URL: [https://api.metriport.com/](https://api.metriport.com/)\n- Sandbox URL: [https://api.sandbox.metriport.com/](https://api.sandbox.metriport.com/)\n\n### **Connect Widget**\n\nPre-built app that you can embed your own app! Use it to allow your users to authenticate with various data sources, allowing you to pull their health data from those sources.\n\n<div align=\"left\">\n   <img width=\"50%\" alt=\"connect widget\" src=\"https://i.ibb.co/mNgMwyd/Screenshot-2022-12-20-at-3-51-47-PM.png\">\n</div>\n\n- Dir: [`/connect-widget`](/connect-widget)\n- URL: [https://connect.metriport.com/](https://connect.metriport.com/?token=demo)\n\n### **Infrastructure as Code**\n\nWe use AWS CDK as IaC.\n\n- Dir: [`/infra`](/infra)\n\n### **Docs**\n\nOur beautiful developer documentation, powered by [mintlify](https://mintlify.com/) \u2764\ufe0f.\n\n- Dir: [`/docs`](/docs)\n- URL: [https://docs.metriport.com/](https://docs.metriport.com/getting-started/introduction)\n\n### **Packages**\n\nCheckout our packages in [`/pkgs`](/pkgs) to help you turbocharge your development:\n\n#### **npm**\n\nOur npm packages are available in [`/packages`](/packages):\n\n- [Metriport API](/packages/packages/api/): contains the Metriport data models, and a convenient API client wrapper.\n- [CommonWell JWT Maker](/packages/packages/commonwell-jwt-maker/): CLI to create a JWT for use in [CommonWell](https://www.commonwellalliance.org/) queries.\n- [CommonWell SDK](/packages/packages/commonwell-sdk/): SDK to simplify CommonWell API integration.\n\n#### **iOS**\n\nOur iOS packages are available in our [`iOS repo`](https://github.com/metriport/metriport-ios-sdk):\n\n- [Metriport iOS](https://github.com/metriport/metriport-ios-sdk): SDK to integrate with the Metriport Connect Widget and Apple Health on iOS.\n\n### **Code Examples**\n\nSome example projects that serve as examples for how to integrate with Metriport on various platforms - such as iOS and Android.\n\n- Dir: [`/examples`](/examples)\n\n---\n\n## **Prerequisites**\n\nBefore getting started with the deployment or any development, ensure you have done the following:\n\n1. Install the prerequisite programs:\n   - [The latest LTS Node.js version](https://nodejs.org/en/download/).\n   - [Docker Desktop](https://www.docker.com/products/docker-desktop/).\n   - (Optional) [VS Code](https://code.visualstudio.com/) - recommended IDE.\n   - (Optional) [DBeaver](https://dbeaver.io/) - recommended universal DB tool.\n2. Create an AWS account.\n3. Create an [AWS IAM admin user](https://docs.aws.amazon.com/IAM/latest/UserGuide/getting-started_create-admin-group.html).\n4. Setup AWS `Route 53` to [handle the DNS for your domain, and create a hosted zone](https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/migrate-dns-domain-inactive.html).\n5. Follow modules 1 & 2 of [this guide](https://aws.amazon.com/getting-started/guides/setup-cdk/) for `Typescript` to bootstrap the `AWS CDK` on your local machine.\n6. \ud83e\udd73 \ud83c\udf89 \ud83e\udd73 \ud83c\udf89 \ud83e\udd73 \ud83c\udf89\n\n## **Local Development**\n\n### Monorepo\n\nThis monorepo uses [npm workspaces](https://docs.npmjs.com/cli/v9/using-npm/workspaces) to manage the packages and execute commands globally.\n\nTo setup this repository for local development, issue this command on the root folder:\n\n```shell\n$ npm install # only needs to be run once\n```\n\nUseful commands:\n\n- `npm run typecheck`: it will run `typecheck` on all workspaces, which checks for typescript compilation/syntax issues;\n- `npm run lint-fix`: it will run `lint-fix` on all workspaces, which checks for linting issues and automatically fixes the issues it can;\n- `npm run prettier-fix`: it will run `prettier-fix` on all workspaces, which checks for formatting issues and automatically fixes the issues it can;\n\n### Semantic version\n\nThis repo uses [Semantic Version](https://semver.org/), and we automate the versioning by using [Conventional Commits](https://www.conventionalcommits.org/en/v1.0.0/).\n\nThis means all commit messages must be created following a certain standard:\n\n```\n<type>[optional scope]: <description>\n[optional body]\n[optional footer(s)]\n```\n\nTo enforce commits follow this pattern, we have a Git hook (using [Husky](https://github.com/typicode/husky)) that verifies commit messages according to the Conventional Commits -\nit uses [commitlint](https://github.com/conventional-changelog/commitlint) under the hood ([config](https://github.com/conventional-changelog/commitlint/tree/master/@commitlint/config-conventional)).\n\nAccepted types:\n\n- build\n- chore\n- ci\n- docs\n- feat\n- fix\n- perf\n- refactor\n- revert\n- style\n- test\n\nScope is optional, and we can use one of these, or empty (no scope):\n\n- api\n- widget\n- infra\n\nThe footer should have the ticket number supporting the commit:\n\n```\n...\nRef: #<ticket-number>\n```\n\n#### Commitizen\n\nOne can enter the commit message manually and have `commitlint` check its content, or use [Commitizen](https://github.com/commitizen/cz-cli)'s\nCLI to guide through building the commit message:\n\n```shell\n$ npm run commit\n```\n\nIn case something goes wrong after you prepare the commit message and you want to retry it after fixing the issue, you can issue this command:\n\n```shell\n$ npm run commit -- --retry\n```\n\nCommitizen will retry the last commit message you prepared previously. More about this [here](https://github.com/commitizen/cz-cli#retrying-failed-commits).\n\n### **API Server**\n\nFirst, create a local environment file to define your developer keys, and local dev URLs:\n\n```shell\n$ touch api/app/.env\n$ echo \"LOCAL_ACCOUNT_CXID=<YOUR-TESTING-ACCOUNT-ID>\" >> api/app/.env\n$ echo \"API_URL=http://localhost:8080\" >> api/app/.env\n$ echo \"CONNECT_WIDGET_URL=http://localhost:3001/\" >> api/app/.env\n$ echo \"CRONOMETER_CLIENT_ID=<YOUR-ID>\" >> api/app/.env\n$ echo \"CRONOMETER_CLIENT_SECRET=<YOUR-SECRET>\" >> api/app/.env\n$ echo \"DEXCOM_CLIENT_ID=<YOUR-KEY>\" >> api/app/.env\n$ echo \"DEXCOM_CLIENT_SECRET=<YOUR-SECRET>\" >> api/app/.env\n$ echo \"FITBIT_CLIENT_ID=<YOUR-KEY>\" >> api/app/.env\n$ echo \"FITBIT_CLIENT_SECRET=<YOUR-SECRET>\" >> api/app/.env\n$ echo \"GARMIN_CONSUMER_KEY=<YOUR-KEY>\" >> api/app/.env\n$ echo \"GARMIN_CONSUMER_SECRET=<YOUR-SECRET>\" >> api/app/.env\n$ echo \"GOOGLE_CLIENT_ID=<YOUR-KEY>\" >> api/app/.env\n$ echo \"GOOGLE_CLIENT_SECRET=<YOUR-SECRET>\" >> api/app/.env\n$ echo \"OURA_CLIENT_ID=<YOUR-KEY>\" >> api/app/.env\n$ echo \"OURA_CLIENT_SECRET=<YOUR-SECRET>\" >> api/app/.env\n$ echo \"WHOOP_CLIENT_ID=<YOUR-KEY>\" >> api/app/.env\n$ echo \"WHOOP_CLIENT_SECRET=<YOUR-KEY>\" >> api/app/.env\n$ echo \"WITHINGS_CLIENT_ID=<YOUR-SECRET>\" >> api/app/.env\n$ echo \"WITHINGS_CLIENT_SECRET=<YOUR-SECRET>\" >> api/app/.env\n$ echo \"FHIR_SERVER_URL=<FHIR-SERVER-URL>\" >> api/app/.env # optional\n```\n\nAdditionally, define your System Root [OID](https://en.wikipedia.org/wiki/Object_identifier). This will be the base identifier to represent your system in any medical data you create - such as organizations, facilities, patients, and etc.\n\nYour OID must be registered and assigned by HL7. You can do this [here](http://www.hl7.org/oid/index.cfm).\n\nBy default, OIDs in Metriport are managed according to the [recommended standards outlined by HL7](http://www.hl7.org/documentcenter/private/standards/v3/V3_OIDS_R1_INFORM_2011NOV.pdf).\n\n```shell\n$ echo \"SYSTEM_ROOT_OID=<YOUR-OID>\" >> api/app/.env\n```\n\nThese envs are specific to Commonwell and are necessary in sending requests to their platform.\n\n```shell\n$ echo \"CW_TECHNICAL_CONTACT_NAME=<YOUR-SECRET>\" >> api/app/.env\n$ echo \"CW_TECHNICAL_CONTACT_TITLE=<YOUR-SECRET>\" >> api/app/.env\n$ echo \"CW_TECHNICAL_CONTACT_EMAIL=<YOUR-SECRET>\" >> api/app/.env\n$ echo \"CW_TECHNICAL_CONTACT_PHONE=<YOUR-SECRET>\" >> api/app/.env\n$ echo \"CW_GATEWAY_ENDPOINT=<YOUR-SECRET>\" >> api/app/.env\n$ echo \"CW_GATEWAY_AUTHORIZATION_SERVER_ENDPOINT=<YOUR-SECRET>\" >> api/app/.env\n$ echo \"CW_GATEWAY_AUTHORIZATION_CLIENT_ID=<YOUR-SECRET>\" >> api/app/.env\n$ echo \"CW_GATEWAY_AUTHORIZATION_CLIENT_SECRET=<YOUR-SECRET>\" >> api/app/.env\n$ echo \"CW_MEMBER_NAME=<YOUR-SECRET>\" >> api/app/.env\n$ echo \"CW_MEMBER_OID=<YOUR-SECRET>\" >> api/app/.env\n$ echo \"CW_ORG_MANAGEMENT_PRIVATE_KEY=<YOUR-SECRET>\" >> api/app/.env\n$ echo \"CW_ORG_MANAGEMENT_CERTIFICATE=<YOUR-SECRET>\" >> api/app/.env\n$ echo \"CW_MEMBER_PRIVATE_KEY=<YOUR-SECRET>\" >> api/app/.env\n$ echo \"CW_MEMBER_CERTIFICATE=<YOUR-SECRET>\" >> api/app/.env\n```\n\n#### **Optional analytics reporting**\n\nThe API server reports analytics to [PostHog](https://posthog.com/). This is optional.\n\nIf you want to set it up, add this to the `.env` file:\n\n```shell\n$ echo \"POST_HOG_API_KEY=<YOUR-API-KEY>\" >> api/app/.env\n```\n\n#### **Optional usage report**\n\nThe API server reports endpoint usage to an external service. This is optional.\n\nA reachable service that accepts a `POST` request to the informed URL with the payload below is required:\n\n```json\n{\n  \"cxId\": \"<the account ID>\",\n  \"cxUserId\": \"<the ID of the user who's data is being requested>\"\n}\n```\n\nIf you want to set it up, add this to the `.env` file:\n\n```shell\n$ echo \"USAGE_URL=<YOUR-URL>\" > api/app/.env\n```\n\n#### **Finalizing setting up the API Server**\n\nThen to run the full back-end stack, use docker-compose to lauch a Postgres container, local instance of DynamoDB, and the Node server itself:\n\n```shell\n$ cd api/app\n$ npm run start-docker-compose\n```\n\n...or, from the root folder...\n\n```shell\n$ npm run start-docker-compose -w api\n```\n\nNow, the backend services will be available at:\n\n- API Server: `0.0.0/0:8080`\n- Postgres: `localhost:5432`\n- DynamoDB: `localhost:8000`\n\nAnother option is to have the dependency services running with docker compose and the back-end API running as regular NodeJS process (faster\nto run and restart); this has the benefit of Docker Desktop managing the services and you likely only need to start the dependencies once.\n\n```shell\n$ cd api/app\n$ npm run start-dependencies # might be able run it once\n$ npm run dev\n```\n\n#### **Database Migrations**\n\nThe API Server uses Sequelize as an ORM, and its migration component to update the DB with changes as the application\nevolves. It also uses Umzug for programatic migration execution and typing.\n\nWhen the application runs it automatically executes all migrations located under `src/sequelize/migrations` (in ascending order)\nbefore the code is atually executed.\n\nIf you need to undo/revert a migration manually, you can use the CLI, which is a wrapper to Umzug's CLI (still under heavy\ndevelopment at the time of this writing).\n\nIt requires DB credentials on the environment variable `DB_CREDS` (values from `docker-compose.dev.yml`, update as needed):\n\n```shell\n$ export DB_CREDS='{\"username\":\"admin\",\"password\":\"admin\",\"dbname\":\"db\",\"engine\":\"postgres\",\"host\":\"localhost\",\"port\":5432}'\n```\n\nRun the CLI with:\n\n```shell\n$ npm i -g ts-node # only needs to be run once\n$ cd api/app\n$ ts-node src/sequelize/cli\n```\n\nAlternatively, you can use a shortcut for migrations on local environment:\n\n```shell\n$ npm run db-local -- <cmd>\n```\n\n> Note: the double dash `--` is required so parameters after it go to sequelize cli; without it, parameters go to `npm`\n\nUmzug's CLI is still in development at the time of this writing, so that's how one uses it:\n\n- it will print the commands being sent to the DB\n- followed by the result of the command\n- it won't exit by default, you need to `ctrl+c`\n- the command `up` executes all outstanding migrations\n- the command `down` reverts one migration at a time\n\nTo create new migrations:\n\n1. Duplicate a migration file on `./api/app/src/sequelize/migrations`\n2. Rename the new file so the timestamp is close to the current time - it must be unique, migrations are executed in sorting order\n3. Edit the migration file to perform the changes you want\n   - `up` add changes to the DB (takes it to the new version)\n   - `down` rolls back changes from the DB (goes back to the previous version)\n\n#### **Additional stuff**\n\nTo do basic UI admin operations on the DynamoDB instance, you can do the following:\n\n```shell\n$ npm install -g dynamodb-admin # only needs to be run once\n$ npm run ddb-admin # admin console will be available at http://localhost:8001/\n```\n\nTo kill and clean-up the back-end, hit `CTRL + C` a few times, and run the following from the `api/app` directory:\n\n```shell\n$ docker-compose -f docker-compose.dev.yml down\n```\n\nTo debug the backend, you can attach a debugger to the running Docker container by launching the `Docker: Attach to Node` configuration in VS Code. Note that this will support hot reloads \ud83d\udd25\ud83d\udd25!\n\n### **Connect Widget**\n\nTo run the Connect Widget:\n\n```shell\n$ cd connect-widget/app\n$ npm run start # available on port 3001 by default\n```\n\n...or, from the root folder...\n\n```shell\n$ npm run start -w connect-widget\n```\n\nTo debug the Connect Widget, you can run a Chrome window by launching the `Run Chrome` configuration in VS Code.\n\n### Utils\n\nThe `./utils` folder contains utilities that help with the development of this and other opensource Metriport projects:\n\n- [mock-webhook](https://github.com/metriport/metriport/blob/develop/utils/src/mock-webhook.ts): implements the Metriport webhook protocol, can be used by applications integrating with Metriport API as a reference to the behavior expected from these applications when using the webhook feature.\n- [fhir-uploader](https://github.com/metriport/metriport/blob/develop/utils/src/fhir-uploader.ts): useful to insert synthetic/mock data from [Synthea](https://github.com/synthetichealth/synthea) into [FHIR](https://www.hl7.org/fhir) servers (see https://github.com/metriport/hapi-fhir-jpaserver).\n\nCheck the scripts on the folder's [package.json](https://github.com/metriport/metriport/blob/develop/utils/package.json) to see how to run these.\n\n---\n\n### Tests\n\nUnit tests can be executed with:\n\n```shell\n$ npm run test\n```\n\nTo run integration tests, make sure to check each package/folder README for requirements, but in general they can be\nexecuted with:\n\n```shell\n$ npm run test:e2e\n```\n\n## **Self-Hosted Deployments**\n\n### **API Key Setup**\n\nMost endpoints require an API Gateway [API Key](https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-api-usage-plans.html). You can do it manually on AWS console or programaticaly through AWS CLI or SDK.\n\nTo do it manually:\n\n1. Login to the AWS console;\n1. Go to API Gateway;\n1. Create a Usage Plan if you don't already have one;\n1. Create an API Key;\n   - the `value` field must follow this pattern: base 64 of \"`<KEY>:<UUID>`\", where:\n   - `KEY` is a random key (e.g., generated with `nanoid`); and\n   - `UUID` is the customer ID (more about this on [Initialization](#initialization))\n1. Add the newly created API Key to a Usage Plan.\n\nNow you can make requests to endpoints that require the an API Key by setting the `x-api-key` header.\n\n### **Environment Setup**\n\n1. You'll need to create and configure a deployment config file: `/infra/config/production.ts`. You can see `example.ts` in the same directory for a sample of what the end result should look like. Optionally, you can setup config files for `staging` and `sandbox` deployments, based on your environment needs. Then, proceed with the deployment steps below.\n\n2. Configure the Connect Widget environment variables to the subdomain and domain you'll be hosting the API at in the config file: `connect-widget/app/.env.production`.\n\n### **Deployment Steps**\n\n1. First, deploy the secrets stack. This will setup the secret keys required to run the server using AWS Secrets Manager and create other infra pre-requisites. To deploy it, run the following commands (with `<config.stackName>` replaced with what you've set in your config file):\n\n```shell\n$ ./deploy.sh -e \"production\" -s \"<config.secretsStackName>\"\n```\n\n2. After the previous steps are done, define all of the required keys in the AWS console by navigating to the Secrets Manager.\n\n3. Then, to deploy the back-end execute the following command:\n\n```shell\n$ ./deploy.sh -e \"production\" -s \"<config.stackName>\"\n```\n\nAfter deployment, the API will be available at the configured subdomain + domain.\n\n4. Finally, to self-host the Connect widget, run the following:\n\n```shell\n$ ./deploy.sh -e \"production\" -s \"<config.connectWidget.stackName>\"\n```\n\nNote: if you need help with the `deploy.sh` script at any time, you can run:\n\n```shell\n$ ./deploy.sh -h\n```\n\n### **Initialization**\n\nThe API Server works with the concept of \"Customer\", which is basically a tenant on the API Server DB.\nThere must be at least one customer on the API Server DB - you can think of it as your account in case you're\nplanning to have only one.\n\nEach new Customer on the API Server should be initialized by calling the \"init\" endpoint with said customer ID:\n\n```\nPOST /internal/init?cxId=<customer-id>\n```\n\nThe customer ID must be a UUID.\n\n## License\n\nDistributed under the AGPLv3 License. See `LICENSE` for more information.\n\nCopyright \u00a9 Metriport 2022-present\n"
 },
 {
  "repo": "IBM/Medical-Blockchain",
  "language": "Vue",
  "readme_contents": "# Store private healthcare data off-chain and manage medical data using blockchain\n\nElectronic medical records and data craves the need for innovation. The way patient health records are stored and secured today do not showcase our technological advancement in this area in the past decade, and hospitals continue to use age-old data management systems for patient data. This is partly due to strict regulations around privacy and security of medical data, which has stifled the use of latest technology to make medical data management more transparent and useful for both patients as well as doctors.\n\nThis code pattern showcases a medical data/access management platform built using blockchain. The application shows the platform from the point of view of 4 stakeholders -\n* The solution admin is the admin of a conglomerate of hospitals, and has the highest of access levels in the hierarchy. They have the ability to onboard a new organization (hospital) to the conglomerate and assign/de-assign hospital admins on their dashboard.\n* The organization (hospital) admin is the admin of a particular hospital which is part of the conglomerate/solution. They have the ability to onboard new users with the role of either patient or doctor, or remove a user.\n* The doctor is a user in the organization with the appropriate role and has the ability to upload documents for their patients and download/view documents of their patients to which they have been granted access.\n* The patient is a user in the organization with the appropriate role and has the ability to upload documents on their own, view them, view the document access logs and also manage access to their documents on their dashboard.\n\nThis code pattern is for developers who want to integrate with the Blockchain Solution Manager, Blockchain Document Store and the IBM Blockchain Platform. When you have completed it, you will understand how to:\n\n* Connect the Blockchain Solution Manager and Blockchain Document Store with the IBM Blockchain Platform.\n* Create a VueJS web app that has multiple dashboards on a single page application, which can communicate in realtime with each other.\n* Create a NodeJS server that is deployed to Kubernetes on IBM Cloud, and connected with a Redis database deployed on the IBM Cloud.\n* Store and retrieve data from a Redis datastore for persistent storage through a NodeJS server.\n* Make REST calls to an external service.\n* Use JWT (JSON web token) tokens for user management.\n\n# Architecture flow\n\n![Architecture flow](docs/doc-images/arch-flow.png?raw=true)\n\n### Login flow\n1. All the stakeholders of the application (solution admin, hospital admin, doctor and patient) begin the user flow by logging into their respective dashboards.\n2. Clicking the login button leads to the login portal of the Blockchain Solution Manager, hosted on the IBM cloud.\n3. The login portal uses OpenAPI Connect and allows the user the login through any onboarded identity provider (in our example, we have on-boarded IBMID ad GoogleID). Successful authentication leads to the JWT credentials for the user.\n\n### Admin dashboard\n4. The solution admin flow begins at the admin component, and requires the user to authenticate themselves through the login flow described above.\n5. After successful authentication, the user can access the solution admin dashboard. They are able to view the solution, and add/remove hospitals from the solution using the Admin API's.\n6. All the admin API's connect with the Blockchain Solution Manager through REST to process the user queries.\n7. The Blockchain Solution Manager connects with the IBM Blockchain Platform and updates the ledger appropriately.\n\n### Organization dashboard\n8. The hospital admin flow begins at the organization component, and requires the user to authenticate themselves through the login flow described above.\n9. After successful authentication, the user can access the hospital admin dashboard. They are able to add/remove any user in their respective hospital with the on-boarded roles (patient/doctor in our case) using the organization API's.\n10. All the organization API's connect with the Blockchain Solution Manager through REST to process the user queries.\n11. The Blockchain Solution Manager connects with the IBM Blockchain Platform and updates the ledger appropriately.\n\n### Doctor dashboard\n12. The doctor flow begins at the doctor component, and requires the user to authenticate themselves through the login flow described above.\n13. After successful authentication, the user can access the doctor dashboard. They are able to upload a medical record for a patient who is part of their hospital and download any medical record associated with a patient to which they have access to, using the Doctor API's. The ACL's for all the patient documents is application level and is maintained through the Document ACL flow described below.\n14. All the doctor API's connect with the Blockchain Document Store through REST to process the user queries.\n15. The Blockchain Document Store connects with the IBM Blockchain Platform and updates the ledger appropriately.\n\n### Patient dashboard\n16. The patient flow begins at the patient component, and requires the user to authenticate themselves through the login flow described above.\n17. After successful authentication, the user can access the patient dashboard. They are able to upload a medical record for themselves, download any of their medical records, view the access logs of their documents, and view/manage permissions to their documents, using the Patient API's. The ACL's for all the documents is application level and is maintained through the document ACL flow described below.\n18. All the patient API's connect with the Blockchain Document Store through REST to process the user queries.\n19. The Blockchain Document Store connects with the IBM Blockchain Platform and updates the ledger appropriately.\n\n### Document access control list (ACL) flow\n20. The doctor and patient component are connected with the Redis API's that invoke methods to manage the document level access control across hospitals.\n21. The Redis API's talk to a NodeJS server deployed in a Docker container in a Kubernetes cluster on the IBM Cloud.\n22. The server talks to two Redis databases which hold the access-per-document and access-per-user permissions. \n\n# Included components\n\n+ [IBM Blockchain Platform](https://console.bluemix.net/docs/services/blockchain/howto/ibp-v2-deploy-iks.html#ibp-v2-deploy-iks) gives you total control of your blockchain network with a user interface that can simplify and accelerate your journey to deploy and manage blockchain components on the IBM Cloud Kubernetes Service.\n+ [IBM Blockchain Solution Manager:](https://cloud.ibm.com/docs/services/blockchain-document-store?topic=blockchain-document-store-blockchain-solution-manager-api-acls) The Blockchain Document Store service includes the IBM Blockchain Solution Manager component, which enables organizations to easily manage blockchain networks, solutions, services, and users.\n+ [IBM Blockchain Document Store](https://cloud.ibm.com/docs/services/blockchain-document-store?topic=blockchain-document-store-getting-started#getting-started) is a comprehensive document management service for IBM Blockchain Platform business networks.\n+ [IBM Cloud Kubernetes Service](https://www.ibm.com/cloud/container-service) creates a cluster of compute hosts and deploys highly available containers. A Kubernetes cluster lets you securely manage the resources that you need to quickly deploy, update, and scale applications.\n+ [IBM Cloud Databases for Redis Service:](https://console.bluemix.net/catalog/services/databases-for-redis) Redis is an open source, in-memory data structure store, used as a database, cache and message broker. It supports data structures such as strings, hashes, lists, sets, sorted sets with range queries, bitmaps, hyperloglogs and geospatial indexes with radius queries.\n\n## Featured technologies\n\n* [Nodejs](https://www.nodejs.org/) is an open-source, cross-platform JavaScript run-time environment that executes JavaScript code server-side.\n* [Vuejs](https://vuejs.org/) is a progressive framework for building user interfaces.\n* [Redis](https://redis.io/) is an open source (BSD licensed), in-memory data structure store, used as a database, cache and message broker.\n* [Bootstrap](https://getbootstrap.com/) is a free and open-source front-end Web framework. It contains HTML and CSS-based design templates for typography, forms, buttons, navigation and other interface components, as well as optional JavaScript extensions.\n* [Docker](https://www.docker.com/) is a computer program that performs operating-system-level virtualization, also known as Containerization.\n\n## Prerequisites\n\nWe find that Blockchain can be finicky when it comes to installing Node. We want to share this [StackOverflow response](https://stackoverflow.com/questions/49744276/error-cannot-find-module-api-hyperledger-composer) - because many times the errors you see with Compose are derived in having installed either the wrong Node version or took an approach that is not supported by Compose:\n\n* [IBM Cloud account](https://cloud.ibm.com/registration/?target=%2Fdashboard%2Fapps)\n* [Docker](https://www.docker.com/products) - latest\n* [Docker Compose](https://docs.docker.com/compose/overview/) - latest\n* [NPM](https://www.npmjs.com/get-npm) - latest\n* [nvm]() - latest\n* [Node.js](https://nodejs.org/en/download/) - Node v8.9.x\n* [Git client](https://git-scm.com/downloads) - latest\n\n\n# Running the application\n\n## Manually deploy to local machine\n1. [Set up your machine](#1-set-up-your-machine)\n2. [Create IBM cloud services](#2-create-ibm-cloud-services)\n3. [Create a solution](#3-create-a-solution)\n4. [Clone the repository](#4-clone-the-repository)\n5. [Modify the configuration files](#5-modify-the-configuration-files)\n6. [Run the application](#6-run-the-application)\n\n### 1. Set up your machine\n\nInstall the following dependencies -\n\n- [Docker](https://www.docker.com/): Go to the Docker website and download the installer. After installation, run Docker.\n- [git](https://git-scm.com/): Install `git` which is a free and open source distributed version control system.\n\n### 2. Create IBM cloud services\n\n* Create the [IBM Cloud Kubernetes Service](https://cloud.ibm.com/catalog/infrastructure/containers-kubernetes).  You can find the service in the `Catalog`. For this code pattern, we can use the `Free` cluster, and give it a name.  Note, that the IBM Cloud allows one instance of a free cluster and expires after 30 days.\n\n<br>\n<p align=\"center\">\n  <img src=\"docs/doc-gifs/1.gif\">\n</p>\n<br>\n\n* Create two instances of [Databases for Redis Service](https://cloud.ibm.com/catalog/services/databases-for-redis).  You can find the service in the `Catalog`.\n\n<br>\n<p align=\"center\">\n  <img src=\"docs/doc-gifs/2.gif\">\n</p>\n<br>\n\n  > Note: You can use just one instance of Redis as well. Modify the code in the server repository to allow for this.\n\n* Create the [IBM Blockchain Service](https://cloud.ibm.com/catalog/services/ibm-blockchain-5-prod). You can find the service in the `Catalog`.\n\n<br>\n<p align=\"center\">\n  <img src=\"docs/doc-gifs/3.gif\">\n</p>\n<br>\n\n* Create the `Blockchain document store` and `Blockchain solution manager` services. These services are not currently available publicly on the `IBM cloud catalog`. You can reach out to `Rak-Joon Choi (rak-joon.choi@us.ibm.com)` to provision these services for you. Follow the service [documentation](https://cloud.ibm.com/docs/services/blockchain-document-store?topic=blockchain-document-store-getting-started#getting-started) to connect the `Blockchain document store` to the `Blockchain service`.\n\n<br>\n<p align=\"center\">\n  <img src=\"docs/doc-gifs/4.gif\">\n</p>\n<br>\n\n### 3. Create a solution\n\n* After configuring your services in the previous step, we now move on to creating a solution using our custom swagger url for the `blockchain solution manager` service. Go to the `Patch endpoint (/v1/solutions)` under `Solution` and authorize using the api by going to the `/v1/logins` url in a new tab, logging in as `Administrator`, and getting the JWT. Add the token prepended by `bearer` such that it looks like `bearer <JWT>`. After authorization, click on `try it out` to execute the api, and paste the following JSON in the `on-boarding` section. Give the name `medrec_demo` to the solution.\n\n```\n{\n  \"onboardingdata\": {\n    \"solution\": {\n      \"id\": \"medrec_demo\",\n      \"name\": \"demo for medrec pattern\"\n    },\n    \"roles\": [\n      {\n        \"id\": \"role_patient\",\n        \"name\": \"Patient\",\n        \"solutionId\": \"medrec_demo\",\n        \"isBlockchainRole\": true\n      },\n      {\n        \"id\": \"role_doctor\",\n        \"name\": \"Doctor\",\n        \"solutionId\": \"medrec_demo\",\n        \"isBlockchainRole\": true\n      }\n    ]\n  }\n}\n```\n\n<br>\n<p align=\"center\">\n  <img src=\"docs/doc-gifs/5.gif\">\n</p>\n<br>\n\n* After creating the solution successfully, add yourself as the admin of the solution. Go to the `Post endpoint (/v1/solutions/{solutionId}/administrators)` under `Solution` and authorize using the api by going to the `/v1/logins` url in a new tab, logging in as `Administrator`, and getting the JWT. Add the token prepended by `bearer` such that it looks like `bearer <JWT>`. After authorization, click on `try it out` to execute the api, and type your email id under `solutionAdministrators` in the JSON object. Provide `medrec_demo` as the `solutionId`.\n\n<br>\n<p align=\"center\">\n  <img src=\"docs/doc-gifs/6.gif\">\n</p>\n<br>\n\n### 4. Clone the repository\n\n```\ngit clone https://github.com/IBM/Medical-Blockchain.git\ncd Medical-Blockchain\n```\n\n### 5. Modify the configuration files\n\n* Modify the redis config file:\n  - Go to the previously provisioned redis services on IBM Cloud.\n  - Click on `Service credentials`.\n  - Click on `New credential` button.\n  - Once the new credentials are created, click on `view credentials`.\n  - From the JSON object, extract the URI from `connection.rediss.composed[0]`.\n  - From the JSON object, extract the certificate from `connection.rediss.certificate.certificate_base64`.\n  - Navigate to the `server/config.json` file in the cloned repository.\n  - Replace the URI and certificate values in the marked places.\n  - Repeat the steps for the second provisioned service, and enter it in the second spot in the config file.\n\n<br>\n<p align=\"center\">\n  <img src=\"docs/doc-gifs/7.gif\">\n</p>\n<br>\n\n* Modify the blockchain config file:\n  - Go to the `/v1/logins` url for your blockchain document store service.\n  - Login as administrator.\n  - Extract the `iss` field from the decoded JWT and remove `/onboarding` string from it.\n  - Navigate to the `src/secrets/config.json` file in the cloned repository.\n  - Replace the `iss` field with the extracted value above.\n  - Replace the `blockchain_channel` field with the name of the channel provided during connecting the blockchain service to the document store.\n\n<br>\n<p align=\"center\">\n  <img src=\"docs/doc-gifs/8.gif\">\n</p>\n<br>\n\n### 6. Run the application\n\n* Running the application locally:\n  - To run the application on the local system, execute the `run-application.sh` file.\n  - Go to `localhost:8080` to see the running application.\n\n<br>\n<p align=\"center\">\n  <img src=\"docs/doc-gifs/9.gif\">\n</p>\n<br>\n\n* Running the application on kubernetes:\n  - Navigate to server directory - `cd server`.\n  - Build the docker image for the server - `docker build -t <DOCKERHUB_USERNAME>/medrec-server .`\n  - Replace the image name in `manifest.yml`, where indicated.\n  - Apply the manifest to the previously provisioned kubernetes cluster.\n  - Navigate to `/src/apis/RedisApi.js` and replace the `baseURL` value with the Kubernetes load balancer IP.\n  - Build and run the Vue application by executing the below in the repository home.\n  - Go to `localhost:8080` to see the running application.\n\n```\ndocker build -t medrec-vue .\ndocker run -d --restart always --name medrec-vue -p 8080:8080 medrec-vue\n```\n\n> Note: You can also deploy the Vue App to Kubernetes, by modifying the manifest.yml to support two pods.\n\n# License\n\nThis code pattern is licensed under the Apache Software License, Version 2.  Separate third-party code objects invoked within this code pattern are licensed by their respective providers pursuant to their own separate licenses. Contributions are subject to the [Developer Certificate of Origin, Version 1.1 (DCO)](https://developercertificate.org/) and the [Apache Software License, Version 2](http://www.apache.org/licenses/LICENSE-2.0.txt).\n\n[Apache Software License (ASL) FAQ](http://www.apache.org/foundation/license-faq.html#WhatDoesItMEAN)\n"
 },
 {
  "repo": "ESS-LLP/smarte",
  "language": "Python",
  "readme_contents": "## This repo is no longer maintained\nTo try out the features setup a new bench and install erpnext from https://github.com/ESS-LLP/erpnext-medical\n\n# smarteCare\n\nModules on frappe to suite General Practice, Hospital and Laboratory Management. It is designed to work seamlessly with ERPNext so that healthcare providers can administer their day today operations in a smarter way.\n\n## Installation\nYou will need a frappe site with erpnext installed. Visit https://github.com/frappe/bench\n\n\tbench get-app smarte https://github.com/ESS-LLP/smarte.git\n\tbench new-site site.name\n\tbench --site site.name install-app erpnext\n\tbench --site site.name install-app smarte\n\n## Demo and Website\nVisit [smarteCare](https://smarteHIS.com) to see live demo\n\n## Feature list\n#### General Practice / Clinic Out Patient\n* Appointments scheduling\n* Consultation - Prescriptions, Investigations etc.\n\n#### Laboratory Management\n* Lab Procedures\n* Lab Test Result Templates and Printing / Emailing\n* Sample Collection\n* Configurable workflow - Auto create sample collection task and lab procedure on Invoice submit\n\n#### Hospital / In-patient Management(beta)\n* In-patient admission, facility allotment\n* Infrastructure management - Wards, Rooms, Beds\n* Service Units - Nurses\u2019 stations, Diagnostic test centres, Housekeeping units etc. and user assignment\n* Service Tasks (Tasks for service units)\n* Configurable workflow - Auto create service tasks\n\n#### General\n* Send SMS - automatic / manual\n* Resource Scheduling (Physicians, Service Units etc.)\n\n#### License\nGNU / General Public License v3.\n"
 },
 {
  "repo": "mp2893/retain",
  "language": "Python",
  "readme_contents": "RETAIN\n=========================================\n\nRETAIN is an interpretable predictive model for healthcare applications. Given patient records, it can make predictions while explaining how each medical code (diagnosis codes, medication codes, or procedure codes) at each visit contributes to the prediction. The interpretation is possible due to the use of neural attention mechanism.\n\n[![RETAIN Interpretation Demo](http://mp2893.com/images/thumbnail.png)](https://youtu.be/co3lTOSgFlA?t=1m46s \"RETAIN Interpretation Demo - Click to Watch!\")\nUsing RETAIN, you can calculate how positively/negatively each medical code (diagnosis, medication, or procedure code) at different visits contributes to the final score. In this case, we are predicting whether the given patient will be diagnosed with Heart Failure (HF). You can see that the codes that are highly related to HF makes positive contributions. RETAIN also learns to pay more attention to new information than old information. You can see that Cardiac Dysrythmia (CD) makes a bigger contribution as it occurs in the more recent visit.\n\n#### Relevant Publications\n\nRETAIN implements an algorithm introduced in the following [paper](http://papers.nips.cc/paper/6321-retain-an-interpretable-predictive-model-for-healthcare-using-reverse-time-attention-mechanism):\n\n\tRETAIN: An Interpretable Predictive Model for Healthcare using Reverse Time Attention Mechanism\n\tEdward Choi, Mohammad Taha Bahadori, Joshua A. Kulas, Andy Schuetz, Walter F. Stewart, Jimeng Sun,\n\tNIPS 2016, pp.3504-3512\n\n#### Notice\n\nThe RETAIN paper formulates the model as being able to make prediction at each timestep (e.g. try to predict what diagnoses the patient will receive at each visit), and treats sequence classification (e.g. Given a patient record, will he be diagnosed with heart failure in the future?) as a special case, since sequence classification makes the prediction at the last timestep only.\n\nThis code, however, is implemented to perform the sequence classification task. For example, you can use this code to predict whether the given patient is a heart failure patient or not. Or you can predict whether this patient will be readmitted in the future. The more general version of RETAIN will be released in the future.\n\t\n#### Running RETAIN\n\n**STEP 1: Installation**  \n\n1. Install [python](https://www.python.org/), [Theano](http://deeplearning.net/software/theano/index.html). We use Python 2.7, Theano 0.8. Theano can be easily installed in Ubuntu as suggested [here](http://deeplearning.net/software/theano/install_ubuntu.html#install-ubuntu)\n\n2. If you plan to use GPU computation, install [CUDA](https://developer.nvidia.com/cuda-downloads)\n\n3. Download/clone the RETAIN code  \n\n**STEP 2: Fast way to test RETAIN with MIMIC-III**  \nThis step describes how to train RETAIN, with minimum number of steps using MIMIC-III, to predict patients' mortality using their visit records.\n\n0. You will first need to request access for [MIMIC-III](https://mimic.physionet.org/gettingstarted/access/), a publicly avaiable electronic health records collected from ICU patients over 11 years. \n\n1. You can use \"process_mimic.py\" to process MIMIC-III dataset and generate a suitable training dataset for RETAIN. \nPlace the script to the same location where the MIMIC-III CSV files are located, and run the script.\nThe execution command is `python process_mimic.py ADMISSIONS.csv DIAGNOSES_ICD.csv PATIENTS.csv <output file>`.\n\n2. Run RETAIN using the \".seqs\" and \".morts\" file generated by process_mimic.py. \nThe \".seqs\" file contains the sequence of visits for each patient. Each visit consists of multiple diagnosis codes.\nHowever we recommend using \".3digitICD9.seqs\" file instead, as the results will be much more interpretable.\n(Or you could use [Single-level Clical Classification Software for ICD9](https://www.hcup-us.ahrq.gov/toolssoftware/ccs/ccs.jsp#examples) to decrease the number of codes to a couple of hundreds, which will even more improve the performance)\nThe \".morts\" file contains the sequence of mortality labels for each patient. \nThe command is `python retain.py <3digitICD9.seqs file> 942 <morts file> <output path> --simple_load --n_epochs 100 --keep_prob_context 0.8 --keep_prob_emb 0.5`.\n`942` is the number of the entire 3-digit ICD9 codes used in the dataset.\n\n3. To test the model for interpretation, please refer to Step 6. I personally found that _perinatal jaundice (ICD9 774)_ has high correlation with mortality.\n\n4. The model reaches AUC above 0.8 with the above command, but the interpretations are not super clear. \nYou could tune the hyper-parameters, but I doubt things will dramatically improve. \nAfter all, only 7,500 patients made more than a single hospital visit, and most of them have only two visits.\n\n**STEP 3: How to prepare your own dataset**  \n\n1. RETAIN's training dataset needs to be a Python cPickled list of list of list. The outermost list corresponds to patients, the intermediate to the visit sequence each patient made, and the innermost to the medical codes (e.g. diagnosis codes, medication codes, procedure codes, etc.) that occurred within each visit.\nFirst, medical codes need to be converted to an integer. Then a single visit can be seen as a list of integers. Then a patient can be seen as a list of visits.\nFor example, [5,8,15] means the patient was assigned with code 5, 8, and 15 at a certain visit.\nIf a patient made two visits [1,2,3] and [4,5,6,7], it can be converted to a list of list [[1,2,3], [4,5,6,7]].\nMultiple patients can be represented as [[[1,2,3], [4,5,6,7]], [[2,4], [8,3,1], [3]]], which means there are two patients where the first patient made two visits and the second patient made three visits.\nThis list of list of list needs to be pickled using cPickle. We will refer to this file as the \"visit file\".\n\n2. The total number of unique medical codes is required to run RETAIN.\nFor example, if the dataset is using 14,000 diagnosis codes and 11,000 procedure codes, the total number is 25,000. \n\n3. The label dataset (let us call this \"label file\") needs to be a Python cPickled list. Each element corresponds to the true label of each patient. For example, 1 can be the case patient and 0 can be the control patient. If there are two patients where only the first patient is a case, then we should have [1,0].\n\n4. The \"visit file\" and \"label file\" need to have 3 sets respectively: training set, validation set, and test set.\nThe file extension must be \".train\", \".valid\", and \".test\" respectivley.  \nFor example, if you want to use a file named \"my_visit_sequences\" as the \"visit file\", then RETAIN will try to load \"my_visit_sequences.train\", \"my_visit_sequences.valid\", and \"my_visit_sequences.test\".  \nThis is also true for the \"label file\"\n\n5. You can use the time information regarding the visits as an additional source of information. Let us call this \"time file\".\nNote that the time information could be anything: duration between consecutive visits, cumulative number of days since the first visit, etc.\n\"time file\" needs to be prepared as a Python cPickled list of list. The outermost list corresponds to patients, and the innermost to the time information of each visit.\nFor example, given a \"visit file\" [[[1,2,3], [4,5,6,7]], [[2,4], [8,3,1], [3]]], its corresponding \"time file\" could look like [[0, 15], [0, 45, 23]], if we are using the duration between the consecutive visits. (of course the numbers are fake, and I've set the duration for the first visit to zero.)\nUse `--time_file <path to time file>` option to use \"time file\"\nRemember that the \".train\", \".valid\", \".test\" rule also applies to the \"time file\" as well.\n\n**Additional: Using your own medical code representations**  \nRETAIN internally learns the vector representation of medical codes while training. These vectors are initialized with random values of course.  \nYou can, however, also use your own medical code representations, if you have one. (They can be trained by using Skip-gram like algorithms. Refer to [Med2Vec](http://www.kdd.org/kdd2016/subtopic/view/multi-layer-representation-learning-for-medical-concepts) or [this](http://arxiv.org/abs/1602.03686) for further details.)\nIf you want to provide the medical code representations, it has to be a list of list (basically a matrix) of N rows and M columns where N is the number of unique codes in your \"visit file\" and M is the size of the code representations.\nSpecify the path to your code representation file using `--embed_file <path to embedding file>`.\nAdditionally, even if you use your own medical code representations, you can re-train (a.k.a fine-tune) them as you train RETAIN.\nUse `--embed_finetune` option to do this. If you are not providing your own medical code representations, RETAIN will use randomly initialized one, which obviously requires this fine-tuning process. Since the default is to use the fine-tuning, you do not need to worry about this.\n\n**STEP 4: Running RETAIN**  \n\n1. The minimum input you need to run RETAIN is the \"visit file\", the number of unique medical codes in the \"visit file\", \nthe \"label file\", and the output path. The output path is where the learned weights and the log will be saved.  \n`python retain.py <visit file> <# codes in the visit file> <label file> <output path>`  \n\n2. Specifying `--verbose` option will print training process after each 10 mini-batches.\n\n3. You can specify the size of the embedding W_emb, the size of the hidden layer of the GRU that generates alpha, and the size of the hidden layer of the GRU that generates beta.\nThe respective commands are `--embed_size <integer>`, `--alpha_hidden_dim_size <integer>`, and `--beta_hidden_dim_size <integer>`.\nFor example `--alpha_hidden_dim_size 128` will tell RETAIN to use a GRU with 128-dimensional hidden layer for generating alpha.\n\n4. Dropouts are applied to two places: 1) to the input embedding, 2) to the context vector c_i. The respective dropout rates can be adjusted using `--keep_prob_embed {0.0, 1.0}` and `--keep_prob_context {0.0, 1.0}`. Dropout values affect the performance so it is recommended to tune them for your data.\n\n5. L2 regularizations can be applied to W_emb, w_alpha, W_beta, and w_output.\n\n6. Additional options can be specified such as the size of the batch size, the number of epochs, etc. Detailed information can be accessed by `python retain.py --help`\n\n7. My personal recommendation: use mild regularization (0.0001 ~ 0.001) on all four weights, and use moderate dropout on the context vector only. But this entirely depends on your data, so you should always tune the hyperparameters for yourself.\n\n**STEP 5: Getting your results**  \n\nRETAIN checks the AUC of the validation set after each epoch, and if it is higher than all previous values, it will save the current model. The model file is generated by [numpy.savez_compressed](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.savez_compressed.html).\n\n**Step 6: Testing your model**\n\n1. Using the file \"test_retain.py\", you can calculate the contributions of each medical code at each visit. First you need to have a trained model that was saved by numpy.savez_compressed. Note that you need to know the configuration with which you trained RETAIN (e.g. use of `--time_file`, use of `--use_log_time`.)\n\n2. Again, you need the \"visit file\" and \"label file\" prepared in the same way. This time, however, you do not need to follow the \".train\", \".valid\", \".test\" rule. The testing script will try to load the file name as given.\n\n3. You also need the mapping information between the actual string medical codes and their integer codes. \n(e.g. \"Hypertension\" is mapped to 24) \nThis file (let's call this \"mapping file\") need to be a Python cPickled dictionary where the keys are the string medical codes and the values are the corresponding intergers. \n(e.g. The mapping file generated by process_mimic.py is the \".types\" file)\nThis file is required to print the contributions of each medical code in a user-friendly format. \n\n4. For the additional options such as `--time_file` or `--use_log_time`, you should use exactly the same configuration with which you trained the model. For more detailed information, use \"--help\" option.\n\n5. The minimum input to run the testing script is the \"model file\", \"visit file\", \"label file\", \"mapping file\", and \"output file\". \"output file\" is where the contributions will be stored.\n`python test_retain.py <model file> <visit file> <label file> <mapping file> <output file>`\n"
 },
 {
  "repo": "PacktPublishing/Applied-Machine-Learning-For-Healthcare",
  "language": "HTML",
  "readme_contents": "# Applied-Machine-Learning-For-Healthcare\nApplied Machine Learning For Healthcare, published by Packt\n"
 },
 {
  "repo": "openmrs/openmrs-core",
  "language": "Java",
  "readme_contents": "<img src=\"https://talk.openmrs.org/uploads/default/original/2X/f/f1ec579b0398cb04c80a54c56da219b2440fe249.jpg\" alt=\"OpenMRS\"/>\n\n[![Build Status](https://travis-ci.org/openmrs/openmrs-core.svg?branch=master)](https://travis-ci.org/openmrs/openmrs-core) [![Coverage Status](https://coveralls.io/repos/github/openmrs/openmrs-core/badge.svg?branch=master)](https://coveralls.io/github/openmrs/openmrs-core?branch=master) [![Codacy Badge](https://api.codacy.com/project/badge/Grade/a51303ee46c34775a7c31c8d6016da6b)](https://www.codacy.com/app/openmrs/openmrs-core?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=openmrs/openmrs-core&amp;utm_campaign=Badge_Grade)\n\napi: [![API](https://snyk.io/test/github/openmrs/openmrs-core/badge.svg?targetFile=api%2Fpom.xml)](https://snyk.io/test/github/openmrs/openmrs-core?targetFile=api%2Fpom.xml)\ntest: [![test](https://snyk.io/test/github/openmrs/openmrs-core/badge.svg?targetFile=test%2Fpom.xml)](https://snyk.io/test/github/openmrs/openmrs-core?targetFile=test%2Fpom.xml)\ntools: [![tools](https://snyk.io/test/github/openmrs/openmrs-core/badge.svg?targetFile=tools%2Fpom.xml)](https://snyk.io/test/github/openmrs/openmrs-core?targetFile=tools%2Fpom.xml)\nweb: [![web](https://snyk.io/test/github/openmrs/openmrs-core/badge.svg?targetFile=web%2Fpom.xml)](https://snyk.io/test/github/openmrs/openmrs-core?targetFile=web%2Fpom.xml)\nwebapp: [![webapp](https://snyk.io/test/github/openmrs/openmrs-core/badge.svg?targetFile=webapp%2Fpom.xml)](https://snyk.io/test/github/openmrs/openmrs-core?targetFile=webapp%2Fpom.xml)\n\nOpenMRS is a patient-based medical record system focusing on giving providers a free customizable electronic medical record system (EMR).\n\nThe mission of OpenMRS is to improve health care delivery in resource-constrained environments by coordinating a global community that creates a robust, scalable, user-driven, open source medical record system platform.\n\n#### Table of Contents\n\n1. [Build](#build)\n   1. [Prerequisites](#prerequisites)\n   2. [Build Command](#build-command)\n   3. [Deploy](#deploy)\n2. [Docker build](#docker-build)\n3. [Navigating the repository](#navigating-the-repository)\n4. [Software Development Kit](#software-development-kit)\n5. [Extending OpenMRS with Modules](#extending-openmrs-with-modules)\n6. [Documentation](#documentation)\n   1. [Developer guides](#developer-guides)\n   2. [Wiki](#wiki)\n   3. [Website](#website)\n7. [Contributing](#contributing)\n   1. [Code](#code)\n   2. [Code Reviews](#code-reviews)\n   3. [Translation](#translation)\n8. [Issues](#issues)\n9. [Community](#community)\n10. [Support](#support)\n11. [License](#license)\n\n## Build\n\n### Prerequisites\n\n#### Java\n\nOpenMRS is a Java application which is why you need to install a Java JDK.\n\nIf you want to build the master branch you will need a Java JDK of minimum version 8.\n\n#### Maven\n\nInstall the build tool [Maven](https://maven.apache.org/).\n\nYou need to ensure that Maven uses the Java JDK needed for the branch you want to build.\n\nTo do so execute\n\n```bash\nmvn -version\n```\n\nwhich will tell you what version Maven is using. Refer to the [Maven docs](https://maven.apache.org/configure.html) if you need to configure Maven.\n\n#### Git\n\nInstall the version control tool [git](https://git-scm.com/) and clone this repository with\n\n```bash\ngit clone https://github.com/openmrs/openmrs-core.git\n```\n\n### Build Command\n\nAfter you have taken care of the [Prerequisites](#prerequisites)\n\nExecute the following\n\n```bash\ncd openmrs-core\nmvn clean package\n```\n\nThis will generate the OpenMRS application in `webapp/target/openmrs.war` which you will have to deploy into an application server like for example [tomcat](https://tomcat.apache.org/) or [jetty](http://www.eclipse.org/jetty/).\n\n### Deploy\n\nFor development purposes you can simply deploy the `openmrs.war` into the application server jetty via\n\n```bash\ncd openmrs-core/webapp\nmvn jetty:run\n```\n\nIf all goes well (check the console output) you can access the OpenMRS application at `localhost:8080/openmrs`.\n\nRefer to [Getting Started as a Developer - Maven](https://wiki.openmrs.org/display/docs/Maven) for some more information\non useful Maven commands and build options.\n\n## Docker build\n\nDocker builds are still work in progress. We appreciate any feedback and improvements to the process.\n\nThe only prerequisite needed is Docker. \n\nIn order to build a development version run:\n```bash \ndocker-compose build\n```\nIt calls `mvn install` by default. If you would like to customize mvn build arguments you can do so by running:\n```bash\ndocker-compose build --build-arg MVN_ARGS='install -DskipTests'\n```\nIt is also possible to use the built dev image to run jetty:\n```bash\ndocker-compose up\n```\n\nIn order to build a production version run:\n```bash\ndocker-compose -f docker-compose.yml build\n```\nIt first builds the dev image and then an image with Tomcat and openmrs.war. \nIt has no dev dependencies.\n\nThe production version can be run with:\n```bash\ndocker-compose -f docker-compose.yml up\n```\n\n## Navigating the repository\n\nThe project tree is set up as follows:\n\n<table>\n <tr>\n  <td>api/</td>\n  <td>Java and resource files for building the java api jar file.</td>\n </tr>\n <tr>\n  <td>tools/</td>\n  <td>Meta code used during compiling and testing. Does not go into any released binary (like doclets).</td>\n </tr>\n <tr>\n  <td>web/</td>\n  <td>Java and resource files that are used in the webapp/war file.</td>\n </tr>\n <tr>\n  <td>webapp/</td>\n  <td>files used in building the war file (contains JSP files on older versions).</td>\n </tr>\n <tr>\n  <td>pom.xml</td>\n  <td>The main maven file used to build and package OpenMRS.</td>\n </tr>  \n</table>\n\n## Software Development Kit\n\nFor rapid development of modules and the OpenMRS Platform code check out the\nawesome SDK at\n\nhttps://wiki.openmrs.org/display/docs/OpenMRS+SDK\n\n## Extending OpenMRS with Modules\n\nOpenMRS has a modular architecture that allows developers to extend the OpenMRS core functionality by creating modules that can easily be added or removed to meet the needs of a specific implementation.\n\nBefore creating your own module go to the [OpenMRS Module Repository](https://addons.openmrs.org/) and see if there is already a module for your specific use case. If so deploy and try it and if a functionality is missing join the developers of the module to add a feature.\n\nIf you haven't found what you were looking for refer to the [Module - wiki](https://wiki.openmrs.org/display/docs/Modules) to learn how you can create a new module.\n\n## Documentation\n\n### Developer guides\n\nIf you want to contribute please refer to these resources\n\n* [Getting Started as a Developer](https://wiki.openmrs.org/display/docs/Get+Started+as+a+Developer)\n* [How To Configure Your IDE](https://wiki.openmrs.org/display/docs/How-To+Setup+And+Use+Your+IDE)\n* [How To Make a Pull Request](https://wiki.openmrs.org/display/docs/Pull+Request+Tips)\n\n### Wiki\n\nIf you are looking for detailed guides on how to install, configure, contribute and\nextend OpenMRS visit\n\nhttp://wiki.openmrs.org\n\n### Website\n\nIf you are looking for more information regarding OpenMRS as an organization\ncheck\n\nhttp://openmrs.org\n\n## Contributing\n\nContributions are very welcome, we can definitely use your help!\n\nOpenMRS organizes the privileges of its contributors in developer stages which\nare documented [here](https://wiki.openmrs.org/display/RES/OpenMRS+Developer+Stages).\n\nRead the following sections to find out where you could help.\n\n### Code\n\nCheck out our [contributing guidelines](CONTRIBUTING.md), read through the [Developer guides](#developer-guides).\n\nAfter you've read up :eyeglasses: [grab an introductory issue](https://wiki.openmrs.org/display/docs/Contribute+as+a+Developer#ContributeasaDeveloper-Workonanissue) that is `Ready For Work`.\n\n### Code Reviews\n\nYou might not have the time to develop yourself but enough experience with\nOpenMRS and/or reviewing code, your help on code reviews will be much\nappreciated!\n\nRead\n\nhttps://wiki.openmrs.org/display/docs/Code+Review\n\nand get started with re-:eyes: pull requests!\n\n### Translation\n\nWe use\n\nhttps://www.transifex.com/openmrs/OpenMRS/\n\nto manage our translations.\n\nThe `messages.properties` file in this repository is our single source of\ntruth. It contains key, value pairs for the English language which is the\ndefault.\n\nTransifex fetches updates to this file every night which can then be translated\nby you and me on transifex website itself. At any time we can pull new translations from transifex\nback into this repository. Other languages like for ex. Spanish will then be in\nthe `messages_es.properties` file.\n\nIf you would like to know how to help with translations see\n\nhttp://openmrs.org/join-the-community/translate/\n\n## Issues\n\nIf you want help fix existing issues or you found a bug and want to tell us please go to\n\nhttps://issues.openmrs.org\n\n## Community\n\n[![OpenMRS Talk](https://omrs-shields.psbrandt.io/custom/openmrs/talk/F26522?logo=openmrs)](http://talk.openmrs.org)\n[![OpenMRS IRC](https://img.shields.io/badge/openmrs-irc-EEA616.svg?logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI2MTIiIGhlaWdodD0iNjEyIiB2aWV3Qm94PSIwIDAgNjEyIDYxMiI%2BPHBhdGggZD0iTTE1MyAyMjkuNWMtMjEuMTMzIDAtMzguMjUgMTcuMTE3LTM4LjI1IDM4LjI1UzEzMS44NjcgMzA2IDE1MyAzMDZjMjEuMTE0IDAgMzguMjUtMTcuMTE3IDM4LjI1LTM4LjI1UzE3NC4xMzMgMjI5LjUgMTUzIDIyOS41em0xNTMgMGMtMjEuMTMzIDAtMzguMjUgMTcuMTE3LTM4LjI1IDM4LjI1UzI4NC44NjcgMzA2IDMwNiAzMDZjMjEuMTE0IDAgMzguMjUtMTcuMTE3IDM4LjI1LTM4LjI1UzMyNy4xMzMgMjI5LjUgMzA2IDIyOS41em0xNTMgMGMtMjEuMTMzIDAtMzguMjUgMTcuMTE3LTM4LjI1IDM4LjI1UzQzNy44NjcgMzA2IDQ1OSAzMDZzMzguMjUtMTcuMTE3IDM4LjI1LTM4LjI1UzQ4MC4xMzMgMjI5LjUgNDU5IDIyOS41ek0zMDYgMEMxMzcuMDEyIDAgMCAxMTkuODc1IDAgMjY3Ljc1YzAgODQuNTE0IDQ0Ljg0OCAxNTkuNzUgMTE0Ljc1IDIwOC44MjZWNjEybDEzNC4wNDctODEuMzRjMTguNTUyIDMuMDYyIDM3LjYzOCA0Ljg0IDU3LjIwMyA0Ljg0IDE2OS4wMDggMCAzMDYtMTE5Ljg3NSAzMDYtMjY3Ljc1UzQ3NS4wMDggMCAzMDYgMHptMCA0OTcuMjVjLTIyLjMzOCAwLTQzLjkxLTIuNi02NC42NDMtNy4wMmwtOTAuMDQgNTQuMTI0IDEuMjA0LTg4LjdDODMuNSA0MTQuMTMzIDM4LjI1IDM0NS41MTMgMzguMjUgMjY3Ljc1YzAtMTI2Ljc0IDExOS44NzUtMjI5LjUgMjY3Ljc1LTIyOS41czI2Ny43NSAxMDIuNzYgMjY3Ljc1IDIyOS41UzQ1My44NzUgNDk3LjI1IDMwNiA0OTcuMjV6IiBmaWxsPSIjZmZmIi8%2BPC9zdmc%2B)](http://irc.openmrs.org)\n[![OpenMRS Telegram](https://img.shields.io/badge/openmrs-telegram-009384.svg?logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNDAgMjQwIj48ZGVmcz48bGluZWFyR3JhZGllbnQgaWQ9ImEiIHgxPSIuNjY3IiB5MT0iLjE2NyIgeDI9Ii40MTciIHkyPSIuNzUiPjxzdG9wIHN0b3AtY29sb3I9IiMzN2FlZTIiIG9mZnNldD0iMCIvPjxzdG9wIHN0b3AtY29sb3I9IiMxZTk2YzgiIG9mZnNldD0iMSIvPjwvbGluZWFyR3JhZGllbnQ%2BPGxpbmVhckdyYWRpZW50IGlkPSJiIiB4MT0iLjY2IiB5MT0iLjQzNyIgeDI9Ii44NTEiIHkyPSIuODAyIj48c3RvcCBzdG9wLWNvbG9yPSIjZWZmN2ZjIiBvZmZzZXQ9IjAiLz48c3RvcCBzdG9wLWNvbG9yPSIjZmZmIiBvZmZzZXQ9IjEiLz48L2xpbmVhckdyYWRpZW50PjwvZGVmcz48Y2lyY2xlIGN4PSIxMjAiIGN5PSIxMjAiIHI9IjEyMCIgZmlsbD0idXJsKCNhKSIvPjxwYXRoIGZpbGw9IiNjOGRhZWEiIGQ9Ik05OCAxNzVjLTMuODg4IDAtMy4yMjctMS40NjgtNC41NjgtNS4xN0w4MiAxMzIuMjA3IDE3MCA4MCIvPjxwYXRoIGZpbGw9IiNhOWM5ZGQiIGQ9Ik05OCAxNzVjMyAwIDQuMzI1LTEuMzcyIDYtM2wxNi0xNS41NTgtMTkuOTU4LTEyLjAzNSIvPjxwYXRoIGZpbGw9InVybCgjYikiIGQ9Ik0xMDAuMDQgMTQ0LjQxbDQ4LjM2IDM1LjczYzUuNTIgMy4wNDQgOS41IDEuNDY3IDEwLjg3Ni01LjEyNGwxOS42ODUtOTIuNzYzYzIuMDE2LTguMDgtMy4wOC0xMS43NDYtOC4zNTgtOS4zNWwtMTE1LjU5IDQ0LjU3MmMtNy44OSAzLjE2NS03Ljg0NCA3LjU2Ny0xLjQ0IDkuNTI4bDI5LjY2NCA5LjI2IDY4LjY3My00My4zMjZjMy4yNC0xLjk2NiA2LjIxNy0uOTEgMy43NzUgMS4yNTgiLz48L3N2Zz4%3D)](https://telegram.me/openmrs)\n[![OpenMRS Wiki](https://img.shields.io/badge/openmrs-wiki-5B57A6.svg?logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNjAiIGhlaWdodD0iMTQyIiB2aWV3Qm94PSIwIDAgMTYwIDE0MiI%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%3D%3D)](https://wiki.openmrs.org)\n\n## Support\n\nTalk to us on [OpenMRS Talk](https://talk.openmrs.org/)\n\n## License\n\n[MPL 2.0 w/ HD](http://openmrs.org/license/) \u00a9 [OpenMRS Inc.](http://www.openmrs.org/)\n\n"
 },
 {
  "repo": "informatici/openhospital-core",
  "language": "Java",
  "readme_contents": "# Open Hospital - Core\n[![Java CI](https://github.com/informatici/openhospital-core/workflows/Java%20CI%20with%20Maven/badge.svg)](https://github.com/informatici/openhospital-core/actions?query=workflow%3A%22Java+CI+with+Maven%22)\n\nThis is the Core component of [Open Hospital][openhospital]: it contains the business logic and the data abstraction layer.  \nThe Core component is used by the [Java Swing desktop GUI][openhospital-gui], and by the [web UI][openhospital-ui] (through the [API component][openhospital-api]).\n\n## How to build\n\nAfter having installed Java JDK 8+ and Maven, to build this project issue:  \n\n    mvn package\n\nTo use the Core component in the other projects, you'll need to install it locally with:\n\n    mvn install\n    \nTo run the tests simply issue:\n\n    mvn test\n\nTests are run against an in-memory database (H2).  \nTo test the application against MySQL, you can change [`database.properties`][database.prop] and run the Docker container in the root folder with:\n\n    # clean previous build\n    docker compose rm --stop --volumes --force\n    docker-compose up\n\n\n## How to run Open Hospital\n\nTo run Open Hospital, you'll need a user interface, which is provided in the [GUI][openhospital-gui] and in the [UI][openhospital-ui] projects.  \nPlease follow the instructions in the documentation of those repositories.\n\n## How to contribute\n\nYou can find the contribution guidelines in the [Open Hospital wiki][contribution-guide].  \nA list of open issues is available on [Jira][jira].\n\n## Community\n\nYou can reach out to the community of contributors by joining \nour [Slack workspace][slack] or by subscribing to our [mailing list][ml].\n\n## Code style\n\nThis project uses a consistent code style and provides definitions for use in both IntelliJ and Eclipse IDEs.\n\n<details><summary>IntelliJ IDEA instructions</summary>\n\nFor IntelliJ IDEA the process for importing the code style is:\n\n* Select *Settings* in the *File* menu\n* Select *Editor*\n* Select *Code Style*\n* Expand the menu item and select *Java*\n* Go to *Scheme* at the top, click on the setting button by the side of the drop-down list\n* Select *Import Scheme*\n* Select *IntelliJ IDE code style XML*\n* Navigate to the location of the file which relative to the project root is:  `.ide-settings/idea/OpenHospital-code-style-configuration.xml`\n* Select *OK* \n* At this point the code style is stored as part of the IDE and is used for **all** projects opened in the editor.  To restrict the settings to just this project again select the setting button by the side of the *Scheme* list and select *Copy to Project...*. If successful a notice appears in the window that reads: *For current project*.\n\n</details>\n\n<details><summary>Eclipse instructions</summary>\n\nFor Eclipse the process requires loading the formatting style and the import order separately.\n\n* Select *Preferences* in the *Window* menu\n* Select *Java*\n* Select *Code Style* and expand the menu\n* Select *Formatter*\n* Select the *Import...* button\n* Navigate to the location of the file which relative to the project root is:  `.ide-settings/eclipse/OpenHospital-Java-CodeStyle-Formatter.xml`\n* Select *Open*\n* At this point the code style is stored and is applicable to all projects opened in the IDE.  To restrict the settings just to this project select *Configure Project Specific Settings...* in the upper right.  In the next dialog select the *openhospital* repository and select *OK*.  In the next dialog select the *Enable project specific settings* checkbox.  Finally select *Apply and Close*.\n* Back in the *Code Style* menu area, select *Organize Imports*\n* Select *Import...*\n* Navigate to the location of the file which relative to the project root is:  `.ide-settings/eclipse/OpenHospital.importorder`\n* Select *Open*\n* As with the formatting styles the import order is applicable to all projects.  In order to change it just for this project repeat the same steps as above for *Configure Project Specific Settings...*\n \n</details> \n\n [openhospital]: https://www.open-hospital.org/\n [openhospital-gui]: https://github.com/informatici/openhospital-gui\n [openhospital-ui]: https://github.com/informatici/openhospital-ui\n [openhospital-api]: https://github.com/informatici/openhospital-api\n [contribution-guide]: https://openhospital.atlassian.net/wiki/display/OH/Contribution+Guidelines\n [jira]: https://openhospital.atlassian.net/jira/software/c/projects/OP/issues/\n [database.prop]: https://github.com/informatici/openhospital-core/blob/develop/src/test/resources/database.properties\n [slack]: https://join.slack.com/t/openhospitalworkspace/shared_invite/enQtOTc1Nzc0MzE2NjQ0LWIyMzRlZTU5NmNlMjE2MDcwM2FhMjRkNmM4YzI0MTAzYTA0YTI3NjZiOTVhMDZlNWUwNWEzMjE5ZDgzNWQ1YzE\n [ml]: https://sourceforge.net/projects/openhospital/lists/openhospital-devel\n"
 },
 {
  "repo": "opensource-emr/hospital-management-emr",
  "language": "JavaScript",
  "readme_contents": "\nIf you have any issues please send us mail at shiv_koirala@yahoo.com  more than happy to help you in understanding and installing. You can also <a href=\"https://www.ehospitalmanagementsystem.com/\" target=\"_new\">\n Chat with us here.\n</a> \n <br>\n If you wish to see demo <a href=\"http://202.51.74.168:175/\" target=\"_blank\">\n Click here\n</a> Username  : admin / Password  : pass123 <br>\nAlso please do read down for more details of how to install and configure.\n\nIntroduction\n==============\nDanphe EMR is a enterprise web-based application which covers all day to day aspects of Hospital management end to end. Its currently live 50 plus hospitals in Asia(India,Nepal and Bangladesh). \n\n![danphelogin](https://user-images.githubusercontent.com/48054642/159859670-05cbe026-f0eb-43cf-811a-0404a36a76f7.jpg) ![danphepatientregistration](https://user-images.githubusercontent.com/48054642/159859505-84b59b71-d271-4e33-b504-1c15ecba3580.jpg)\n\nModules in Danphe EMR\n==============\nIt has around 40 modules and below are important ones listed.\n\n+ Registration/Patient \n+ Appointment \n+ Billing Module \n+ Accounting Module \n+ Inventory Management \n+ Pharmacy Module \n+ Laboratory Management \n+ User Module \n+ Admission Discharge and Transfer (ADT) \n+ Nursing Module \n+ Sub-store Module \n+ Radiology Management \n+ Medical Record \n+ Emergency \n+ Reporting and Dashboard \n+ Doctors \n\n`and more...`\n\nDemo of Danphe EMR\n==============\nIf you have any issues please sen us mail at shiv_koirala@yahoo.com \n\nClick on below demo link and check out live application\n\n<a href=\"http://202.51.74.168:175/\" target=\"_blank\">\n  Danphe EMR Live Application\n</a>\n\nUse below `credentials` for login\n\n```\n   Username  : admin\n   Password  : pass123\n```   \n\nNeed help?\n==============\nIf you have any issues please send us mail at shiv_koirala@yahoo.com  more than happy to help you in understanding and installing.\n\nInstallation & Setup\n======================\nGetting start with **DanpheEMR** Please visit <a href=\"https://opensource-emr.github.io/hospital-management-emr//#setup\" target=\"_blank\">\n    :point_right: Page\n</a>  and read it carefully. \nHere you have details about requirements, configuration and setup.\n\n\n#### Development Setup\n\n+ This details for `developers` who wants to `clone DanpheEMR`, Use it and `help` us for improvements.\n+ We have all details like software and tools `requirements`\n+ Step by step guide for `build and run` project\n+ Database creation \n`and more..`\n\n\n<a href=\"https://opensource-emr.github.io/hospital-management-emr/#setup\" target=\"_blank\">\n    :point_right: docs\n</a>\n\nCredits\n========\n\n## Sponsors\nAll sponsors are here. Thanks all sponsors for your contributions.\n\n<a href=\"https://www.imarkdigital.com/\" target=\"_blank\">\n  <img src=\"https://user-images.githubusercontent.com/48054642/161473176-51fcb05f-e87f-4229-8673-887bf5060fe0.png\" />\n</a>\n\n## Contributors\nThanks all contributors. \n\n<a href=\"https://github.com/opensource-emr/hospital-management-emr/graphs/contributors\" target=\"_blank\">\n  <img src=\"https://contrib.rocks/image?repo=opensource-emr/hospital-management-emr\" />\n</a> <br><br>\n\n\nLicense\n==============\n\nSee the [LICENSE](https://github.com/opensource-emr/hospital-management-emr/blob/master/LICENSE) file.\n\n"
 },
 {
  "repo": "clinical-meteor/meteor-on-fhir",
  "language": "Objective-C",
  "readme_contents": "# Meteor on FHIR\nFor my Masters of Science in Biomedical Informatics, we are required to create a Capstone Project.  So I decided to write a Health Information Exchange infrastructure.  The technical infrastructure uses MongoDB (a modern hierarchical database, similar to the MUMPS/Cache database what Epic uses), a full-stack isomorphic javascript framework called [Meteor](https://www.meteor.com/), and Facebook's user interface layer React.  The HIE uses a wordpress business model, and is intended to be a distributed and federated peer-to-peer network.  We use [HL7 Fast Healthcare Interoperability Resources (FHIR)](https://www.hl7.org/fhir/) for data exchange and interoperability.  \n\n> NOTE: We have recently refactored the codebase.  We removed a ton of clutter, stale prototypes, dead code, and binary files that were tying Meteor on FHIR to Mac/Linux.  Meteor on FHIR should now run on Azure, and is configured as a community build by default.  You may notice some missing functionality, such as theming, geomapping, timelines, and other features.  Please contact demos@symptomatic.io if you need access to those features.  \n\n[![CircleCI](https://circleci.com/gh/clinical-meteor/meteor-on-fhir/tree/master.svg?style=svg)](https://circleci.com/gh/clinical-meteor/meteor-on-fhir/tree/master)  \n\n\n![https://github.com/clinical-meteor/meteor-on-fhir/blob/master/media/screenshot-1.png](https://github.com/clinical-meteor/meteor-on-fhir/blob/master/media/screenshot-1.png)\n\nYes, the above is a live screenshot of the app, which supports a theming engine and an augmented reality interface.\n\n#### A. Installation  \n\n```sh\n# get the application\ngit clone http://github.com/clinical-meteor/meteor-on-fhir\n\n# move into the webapp directory\ncd meteor-on-fhir/webapp\n\n# clone the example plugin\ngit clone http://github.com/clinical-meteor/example-plugin packages/example-plugin\n\n# install the example plugin\nmeteor add clinical:example-plugin\n\n# install the app\nmeteor npm install\n```\n\n\n#### B. Running Local\n\n```sh\n## general development\nmeteor --settings configs/settings.blank.canvas.json\n```\n\n\n#### C. Install Test Data\n\n```sh\n# install sample doctors and nurses\nmeteor add clinical:accounts-housemd\n\n# run with initialization variables\nINITIALIZE=true Patients=true Practitioners=true meteor\n```\n\n\n#### D. Theme and Remove Licensed Media Assets\nEdit the `settings.dev.json` file, and update:\n```\n{\n  \"public\": {\n    \"title\": \"Rainbow's End Nursing Home Health Exchange\",\n    \"theme\": {\n      \"backgroundImagePath\": \"/backgrounds/medical/Gradient.jpg\",\n      \"backgroundColor\": \"#34B6C2\",\n      \"palette\": {\n        \"colorA\": \"#34B6C2\",\n        \"colorB\": \"#177AB9\",\n        \"colorC\": \"#31323C\",\n        \"colorD\": \"#710A4A\",\n        \"colorE\": \"#FFFFFF\"\n      }\n    },\n    \"meshNetwork\": {\n      \"upstreamSync\": \"http://meteor-on-fhir.meteorapp.com/fhir-3.0.0\", \n      \"autosync\": false\n    }    \n  },\n  \"private\": {\n    \"practitionerAccessCode\": \"practitionerAccessCode\",\n    \"sysadminAccessCode\": \"sysadminAccessCode\"\n  },\n  \"galaxy.meteor.com\": {\n    \"env\": {\n      \"MONGO_URL\": \"mongodb://username:password@mlab.com:25389/my-org-exchange-db\",\n      \"NODE_ENV\": \"production\"\n    }\n  }  \n}\n```\n\nRun the script to remove restricted media assets:\n```\nscripts/remove_restricted_media_assets.sh\n```\n\n \n\n#### E. Desktop Build   \n\n```bash\n # build the executables and add them into the /public directory\nmeteor add-platform ios\nmeteor add omega:meteor-desktop-watcher@=0.11.1 omega:meteor-desktop-bundler@=0.11.1 omega:meteor-desktop-localstorage@=0.0.11\n\n# install meteor-desktop / electron\nmeteor npm install --save meteor-desktop\n\n# add the .desktop directory, which has files needed by omega:meteor-desktop\nnpm run desktop -- init\n\n# if there is already a desktop directory, move it to the .desktop dir\n# this will override the previous step\nmv webapp/desktop webapp/.desktop\n\n\n# run the app server locally, as if you were doing a mobile build\n# (you may be able to just use the running mobile build server)\nNODE_ENV=dev meteor --mobile-server http://localhost:3000 --settings configs/settings.galaxy.json\n\n# then to run the desktop app locally...\n# npm run desktop\n\n# or try the shortcut script\n# meteor npm run-script desktop\n\n# If you want to build a production release, that connects to the main server, you'll need to specify a different URL\n# meteor --mobile-server http://www.symptomatic.io --settings configs/settings.galaxy.json\n# npm run desktop -- build-installer http://www.symptomatic.io\n\nmeteor --mobile-server https://meteor-on-fhir.meteorapp.com --settings packages/landing-page/configs/settings.symptomatic.io.json\nmeteor npm run desktop -- build-installer http://meteor-on-fhir.meteorapp.com\n\n```    \n\n\n#### F. Deploy to Galaxy  \n\n```sh\n# remove the desktop pipeline before building for Galaxy\nmv webapp/.desktop webapp/desktop\ngit commit -a -m 'desktop' \n\nmeteor reset\nmeteor remove-platform ios\nmeteor remove omega:meteor-desktop-watcher omega:meteor-desktop-bundler omega:meteor-desktop-localstorage\nmeteor npm remove meteor-desktop\nrm -rf node_modules\nrm -rf .desktop-installer\nmeteor npm install\n\n# upload to Galaxy\nTIMEOUT_SCALE_FACTOR=10 DEPLOY_HOSTNAME=us-east-1.galaxy-deploy.meteor.com meteor deploy --settings configs/settings.galaxy.json meteor-on-fhir.meteorapp.com\n```   \n\n#### G. Azure Configuration  \n\n```sh\naz webapp deployment user set --user-name admin --password password\naz appservice list-locations\naz group create --name appName --location 'Central US'\naz appservice plan create --name appServicePlan --resource-group appName --sku S1 \naz webapp create --resource-group appResourceGroup --plan appServicePlan --name appname \n```    \n\n#### H. Azure Deployment \n\n```sh\n# prepare environment variables\nexport METEOR_SETTINGS=\"$(cat ../../webapp/packages/example-plugin/configs/settings.blank.json )\"\nexport ROOT_URL=https://appname.azurewebsites.net\nexport MONGO_URL=mongodb://user:password@cosmodb.documents.azure.com:10255/?ssl=true\n\n# Now that Azure is configured, go to application\ncd webapp/packages\ngit clone https://github.com/clinical-meteor/example-plugin\ncd webapp\n\n# stringify the settings.json file; and add to Azure METEOR_SETTINGS\ncat packages/example-plugin/configs/settings.json | tr -d ' ' | tr -d '\\n'\n\n# add required packages\nmeteor add clinical:example-plugin\n\n# remove unnecessary packages\nmeteor remove-platform ios\n\n# run local production build\nnpm install\nnode start\n\n# meteor-azure\nmeteor-azure --settings packages/example-plugin/configs/settings.blank.json\n\n# debugging\ncurl -u admin https://appname.scm.azurewebsites.net/api/logstream\ncurl -u admin https://appname.scm.azurewebsites.net/api/logstream\ncurl -u admin https://appname.scm.azurewebsites.net/api/logstream/application\ncurl -u admin https://appname.scm.azurewebsites.net/api/logstream/kudu/deployment\n```\n\n\n#### I. Synchronizing With Other Datalakes  \n\nTo enable network synchronizing, you'll need to specify an upstream sync partner in your `settings.json` file.  Afterwards, you can enable manual synchronization in the **Data Management* page.  \n\n```javascript\n{\n  \"public\": {\n    \"meshNetwork\": {\n      \"upstreamSync\": \"http://meteor-on-fhir.meteorapp.com/fhir-3.0.0\", \n      \"autosync\": false\n    },\n  }\n}\n```\n\n\n#### J. Connect to an External EMR   \n[HL7 v2 to FHIR Interface Mapping](https://medium.com/@awatson1978/hl7-v2-to-fhir-interface-mapping-f83c6ecf6bee)  \n\n\n\n#### Trouble Shooting\n```sh\n# Browser ERROR: 404 \"/example-route\" does not exist\n# A quick fix is edit the \"route\" to \"/hello-world\" in the webapp/packages/example-plugin/configs/settings.example.json \n# \"defaults\": {\n#       \"route\": \"/hello-world\",\n#       ...\n#       }\n\n# ERROR: Failed to connect to 127.0.0.1:27017\n# You may need to restart mongod with the correct dbpath. Example:  \nmongod --dbpath ~/meteor-on-fhir/webapp/packages/example-plugin/data\n\n\n```\n\n#### Miscellaneous References    \n[Supporting Interoperability \u2013 Terminology, Subsets and Other Resources from Natl. Library of Medicine](https://www.nlm.nih.gov/hit_interoperability.html)  \n[Health IT Standards for Health Information Management Practices](http://ihe.net/uploadedFiles/Documents/ITI/IHE_ITI_WP_HITStdsforHIMPratices_Rev1.1_2015-09-18.pdf)  \n"
 },
 {
  "repo": "digital-asset/ex-healthcare-claims-processing",
  "language": "Haskell",
  "readme_contents": "# Reference Application: Healthcare Claims Processing\n\n## Overview\n\nThis application simulates processing a healthcare claim, starting with the referral from the Primary Care Provider (PCP) and including the creation of an appointment with the radiologist, checking in the patient on the date of the appointment, checking out the patient after service delivery, generation of the claim, and finally, payment for the procedure.\n\n## Getting Started\n\n### Installing\n\n**Disclaimer:** This reference application is intended to demonstrate the capabilities of Daml. You are recommended to consider other non-functional aspects, like security, resiliency, recoverability, etc prior to production use.\n\n#### Prerequisites\n\nBe sure you have the following installed.\n- [Daml SDK](https://docs.daml.com/)\n- Java 8 or higher\n- Make\n- Node v14.16.0 or higher\n- NPM v7.14.0 or higher\n- [Python Pipenv](https://pipenv.pypa.io/)\n\n### Starting the App\n\n1. Build the App. Type:\n    ```shell\n    make build\n    ```\n    **Note:** If you change the Daml models locally, you need to re-run this command before starting the application.\n\n2. Use **separate terminals** to launch the individual components:\n\n    ```shell\n    launchers/sandbox+populate\n    launchers/automation\n    launchers/ui\n    ```\n\n### Stopping the App\n\n1. Stop each running command by pressing **Ctrl+C**.\n\n## Working with Daml Hub\n\n**Note**: The custom UI does not work on Daml Hub yet, but you can use Daml Hub's live explorer to interact with the contracts by following the instructions below.\n\n1. As a first step, build the whole project\n    ```shell\n    make clean build\n    ```\n2. Create a project and a ledger in Daml Hub\n3. Upload the DARs\n4. Add the parties to the ledger\n   - PrimaryCareProvider\n   - Radiologist\n   - Patient1\n   - Operator\n   - InsuranceCompany\n5. Download `participants.json` from the ledger settings\n6. Create the `ledger-setup.json` file manually or by running\n    ```shell\n    node scripts/create-ledger-setup.js participants.json ledger-setup.json\n    ```\n\n    The resulting file should like this:\n    ```json\n    {\n      \"parties\": {\n        \"payer1\": \"ledger-party-92d3fc64-a589-4a18-9e47-30541fdc7824\",\n        \"operator\": \"ledger-party-01328c4d-a7b1-49d4-92cc-400badcb46c2\",\n        \"patient1\": \"ledger-party-841214e1-cb38-42fa-88a9-08710592f74d\",\n        \"provider1\": \"ledger-party-5292e717-bbd6-43d5-8cdc-67b463427ee9\",\n        \"provider2\": \"ledger-party-bd952624-9142-412d-ae39-f6025cd94ac8\"\n      }\n    }\n    ```\n\n    The following table contains the necessary name mapping:\n\n    | Daml Hub name (in `participants.json`) | Ledger Setup name |\n    | :------------------------------------: | :---------------: |\n    |          primaryCareProvider           |     provider1     |\n    |              radiologist               |     provider2     |\n    |                patient1                |     patient1      |\n    |                operator                |     operator      |\n    |            insuranceCompany            |      payer1       |\n7. Run the ledger setup\n    ```shell\n    daml script \\\n      --participant-config participants.json \\\n      --json-api \\\n      --dar models.dar \\\n      --script-name DemoOnboardScenario.StartScript:setupLedger \\\n      --input-file ledger-setup.json\n    ```\n8. Run the triggers from the Daml Hub UI\n\n   | Party            | Trigger                                                                        |\n   | :--------------- | :----------------------------------------------------------------------------- |\n   | InsuranceCompany | Triggers.AcceptClaimTrigger:acceptClaimTrigger                                 |\n   | InsuranceCompany | Triggers.AcknowledgeAppointmentTrigger:acknowledgeAppointmentTrigger           |\n   | Radiologist      | Triggers.EvaluateReferralTrigger:evaluateReferralTrigger                       |\n   | Radiologist      | Triggers.UpdateReferralDetailsTrigger:updateReferralDetailsTrigger             |\n   | Patient1         | Triggers.AcknowledgeAndDiscloseTrigger:acknowledgeAndDiscloseTrigger           |\n   | Patient1         | Triggers.AcceptPatientPaymentRequestTrigger:acceptPatientPaymentRequestTrigger |\n\n## User Guide\n\nThis User Guide will take you step-by-step through healthcare claims processing, executing one successful claim.\n\n**Note:** This demo is designed to show successful processing of a claim without exceptions or error conditions. A full production implementation would include additional features, handle errors and exceptions, and incorporate appropriate security controls.\n\n\n## Workflow\n\n**Roles and Responsibilities**\n\n\n<table>\n<thead>\n  <tr>\n    <th>Role</th>\n    <th>Responsibility</th>\n  </tr>\n</thead>\n<tbody>\n  <tr>\n    <td>Primary Care Provider</td>\n    <td>A physician, who creates a referral for a Patient to a Radiologist</td>\n  </tr>\n  <tr>\n    <td>Patient</td>\n    <td>Visits the Primary Care Provider and is referred to a Radiologist<br>Pays their portion of the Bill/Claim after the Radiologist submits a Claim</td>\n  </tr>\n  <tr>\n    <td>Radiologist</td>\n    <td>Checks Referrals and schedules an Appointment for a Patient<br>On the Appointment date they Check-In the Patient in and perform a treatment <br>Marks the Treatment as Completed which creates a Claim for the Insurance Company</td>\n  </tr>\n  <tr>\n    <td>Insurance Company</td>\n    <td>Pays their portion of the Claim/Bill after the Radiologist submits a Claim</td>\n  </tr>\n</tbody>\n</table>\n\n\n**Steps**\n\nThe Healthcare Process workflow involves these steps:\n\n\n\n1. **Referral**\n\n    The Primary Care Provider creates a referral for \"John Doe\" in the system, sending the patient to a radiology lab (Radiologist) for an x-ray of a possible fracture. The system checks to verify that the patient is eligible for treatment under their insurance and calculates the cost of the procedure for this patient.\n\n\n    Checks include:\n\n    *   Validity of the patient\u2019s insurance policy (in good standing, not expired)\n    *   Network status of the radiologist (whether in or out of the insurance company\u2019s approved provider list)\n    *   Verification of eligibility and pre-authorization for the treatment\n\n2. **Appointment**\n\n    The Radiologist now creates an appointment for the patient in the system. The system ensures that the treatment is appropriate for the diagnosis and that any necessary pre-authorization has been done. It checks again to ensure that the patient insurance status has not changed since the referral was created.\n\n3. **Check-In**\n\n    The patient goes to the lab and is checked in. Again the system reruns all the previous checks to determine if any parameter has changed, for example, whether the patient has satisfied more of their deductible before this date.\n\n4. **Treatment Completion and Claim Creation**\n\n    The x-ray is done. The treatment is completed, and the claim is automatically created. The system creates an obligation for the patient to pay their portion of the cost (if any) and for the insurance company to pay its portion.\n\n5. **Payment**\n\n    The insurance company now pays the claim to the lab. The patient pays any required amount as well. The amounts paid are the verified amount established in first steps of the process.\n\n\n\n## Running the Application\n\n\n### Choosing and Changing Roles\n\nWhen you launch the application, you will see a login screen with the option to choose your Role.\n\nTo switch from one Role to another click on \"Change Roles\" in the lower left hand corner of the screen.\n\nNote: In this application each Role is represented by a different Party, this is a simplified design for demonstration purposes.\n\n\n## Refer the Patient (\"John Doe\") to the Radiologist\n\nThe workflow begins with the patient visiting their Primary Care Provider physician (PCP) for treatment. The PCP decides the patient needs an X-Ray and creates a referral to a Radiologist.\n\n### Create a Referral\n\n1. Log in as the Primary Care Provider Role\n1. Go to **Patients** tab\n1. Click on the Patient \"John Doe\"\n1. Select \"Refer Patient\"\n1. Fill out the \"Create Referral\" screen and click \"Create Referral.\n    * You can select the \"Policy\", \"Diagnosis Code\", and \"Procedure Code\" from their respective dropdowns\n    * Receiver must be \"Radiologist\" (without quotes)\n    * All other fields can contain any text\n\n\n## Schedule an Appointment for the Patient as the Radiologist\n\nThe next step is scheduling the appointment for the x-ray.\n\n### Schedule the Patient\n\n\n1. Log in as the Radiologist\n1. Choose the **Referrals** tab\n1. Click on the referral for \"John Doe\" that you just created\n4. Choose **Schedule Appointment**\n5. Select the date and time for the appointment on the New Appointment pane and click the **Schedule Appointment** button.\n    * You'll typically want to leave this as the current date and time, otherwise the system won't let you check in \"John Doe\" until the scheduled appointment time has passed.\n    * This new appointment is now visible to the Radiologist and \"John Doe\".\n\n    * The various checks are run again, and the payment requirements are displayed, showing now what payment the lab will receive and what the patient will owe.\n    \n    * The Primary Care Provider cannot see this part of the workflow, as the appointment scheduling is only disclosed to the Patient, the Radiologist, and the Insurance Company.\n\n## Check-In the Patient as the Radiologist\n\nThe next step is for the patient to arrive at the lab for the x-ray and be checked in.\n\n### Check-In\n\n1. Choose the **Appointments** tab as the Radiologist\n1. Click on \"John Doe\"s appointment\n1. Click \"Check In Patient\" and confirm in the dialog window\n\n    The various checks are run again to confirm that the patient is still eligible and to recalculate the payments to account for any changes, such as a situation where the patient has satisfied part of their deductible.\n\n\n## Complete Treatment and Create the Claim as the Radiologist\n\nAfter the x-ray is done, the patient is checked out from the facility, and the claim is created.\n\n### Complete Treatment\n\n1. Choose the **Treatments** tab as the Radiologist\n1. On the Treatments tab, click on the treatment with \"John Doe\"s name and click **Complete Treatment** and confirm in the dialog window\n    * You can see the pending unpaid claim by locating it on the Claims tab. It will show both the Patient and Insurance Company's payment responsibilities.\n\n\n## Make Payments from Insurance Company and Patient\n\nThe last step of this workflow is for payment to be made to the lab by both the Insurance Company and the Patient\n\n### Make Payment\n\n1. Log in as Insurance Company and choose the **Claims** tab\n1. On the Claims list screen, click on the claim made from the Radiologist to the Insurance Company\n\n    * Details of this claim will be displayed.\n\n1. Click the **Pay Claim** button, and confirm in the dialog window\n\n1. Log in as the Patient and choose the **Bills** tab\n\n    * In a production system, the patient would likely log in through a patient portal rather than through this application.\n\n1. Click on the open claim from the Radiologist, click the **Pay Bill** button and confirm on the dialog window\n\n\nAnd that's the whole workflow! You've just worked through a complicated but typical workflow involving 4 separate parties with their respective privacy preserved throughout and information disclosed only where necessary.\n\n\nCONFIDENTIAL \u00a9 2019 Digital Asset (Switzerland) GmbH and/or its affiliates. All rights reserved.\nAny unauthorized use, duplication or distribution is strictly prohibited.\n"
 },
 {
  "repo": "TheDesignMedium/healthcare-website",
  "language": "HTML",
  "readme_contents": "[{\"name\":\".gitignore\",\"path\":\".gitignore\",\"sha\":\"e43b0f988953ae3a84b00331d0ccf5f7d51cb3cf\",\"size\":10,\"url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/.gitignore?ref=master\",\"html_url\":\"https://github.com/wanghaisheng/healthcaredatastandard/blob/master/.gitignore\",\"git_url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/e43b0f988953ae3a84b00331d0ccf5f7d51cb3cf\",\"download_url\":\"https://raw.githubusercontent.com/wanghaisheng/healthcaredatastandard/master/.gitignore\",\"type\":\"file\",\"_links\":{\"self\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/.gitignore?ref=master\",\"git\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/e43b0f988953ae3a84b00331d0ccf5f7d51cb3cf\",\"html\":\"https://github.com/wanghaisheng/healthcaredatastandard/blob/master/.gitignore\"}},{\"name\":\"README.md\",\"path\":\"README.md\",\"sha\":\"fc6bd9a7b0a339af5ee38d7481d24302a18d395c\",\"size\":29010,\"url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/README.md?ref=master\",\"html_url\":\"https://github.com/wanghaisheng/healthcaredatastandard/blob/master/README.md\",\"git_url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/fc6bd9a7b0a339af5ee38d7481d24302a18d395c\",\"download_url\":\"https://raw.githubusercontent.com/wanghaisheng/healthcaredatastandard/master/README.md\",\"type\":\"file\",\"_links\":{\"self\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/README.md?ref=master\",\"git\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/fc6bd9a7b0a339af5ee38d7481d24302a18d395c\",\"html\":\"https://github.com/wanghaisheng/healthcaredatastandard/blob/master/README.md\"}},{\"name\":\"overview.png\",\"path\":\"overview.png\",\"sha\":\"5e49110c0ac25125bf0f277548f85389bd9178da\",\"size\":559586,\"url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/overview.png?ref=master\",\"html_url\":\"https://github.com/wanghaisheng/healthcaredatastandard/blob/master/overview.png\",\"git_url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/5e49110c0ac25125bf0f277548f85389bd9178da\",\"download_url\":\"https://raw.githubusercontent.com/wanghaisheng/healthcaredatastandard/master/overview.png\",\"type\":\"file\",\"_links\":{\"self\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/overview.png?ref=master\",\"git\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/5e49110c0ac25125bf0f277548f85389bd9178da\",\"html\":\"https://github.com/wanghaisheng/healthcaredatastandard/blob/master/overview.png\"}},{\"name\":\"standard number -201506.png\",\"path\":\"standard number -201506.png\",\"sha\":\"10d20f19dadd0de6c6740685c16ad3d98bceb4eb\",\"size\":552959,\"url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/standard%20number%20-201506.png?ref=master\",\"html_url\":\"https://github.com/wanghaisheng/healthcaredatastandard/blob/master/standard%20number%20-201506.png\",\"git_url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/10d20f19dadd0de6c6740685c16ad3d98bceb4eb\",\"download_url\":\"https://raw.githubusercontent.com/wanghaisheng/healthcaredatastandard/master/standard%20number%20-201506.png\",\"type\":\"file\",\"_links\":{\"self\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/standard%20number%20-201506.png?ref=master\",\"git\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/blobs/10d20f19dadd0de6c6740685c16ad3d98bceb4eb\",\"html\":\"https://github.com/wanghaisheng/healthcaredatastandard/blob/master/standard%20number%20-201506.png\"}},{\"name\":\"\u57fa\u7840\u7c7b\u6807\u51c6\",\"path\":\"\u57fa\u7840\u7c7b\u6807\u51c6\",\"sha\":\"945a3b3a1831fbad09264b9dea530af3f0fb737a\",\"size\":0,\"url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E5%9F%BA%E7%A1%80%E7%B1%BB%E6%A0%87%E5%87%86?ref=master\",\"html_url\":\"https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E5%9F%BA%E7%A1%80%E7%B1%BB%E6%A0%87%E5%87%86\",\"git_url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/945a3b3a1831fbad09264b9dea530af3f0fb737a\",\"download_url\":null,\"type\":\"dir\",\"_links\":{\"self\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E5%9F%BA%E7%A1%80%E7%B1%BB%E6%A0%87%E5%87%86?ref=master\",\"git\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/945a3b3a1831fbad09264b9dea530af3f0fb737a\",\"html\":\"https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E5%9F%BA%E7%A1%80%E7%B1%BB%E6%A0%87%E5%87%86\"}},{\"name\":\"\u5df2\u6574\u7406\u6750\u6599\",\"path\":\"\u5df2\u6574\u7406\u6750\u6599\",\"sha\":\"e9f14bd3afda272e5e3f310b779e115d0c125d29\",\"size\":0,\"url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E5%B7%B2%E6%95%B4%E7%90%86%E6%9D%90%E6%96%99?ref=master\",\"html_url\":\"https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E5%B7%B2%E6%95%B4%E7%90%86%E6%9D%90%E6%96%99\",\"git_url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/e9f14bd3afda272e5e3f310b779e115d0c125d29\",\"download_url\":null,\"type\":\"dir\",\"_links\":{\"self\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E5%B7%B2%E6%95%B4%E7%90%86%E6%9D%90%E6%96%99?ref=master\",\"git\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/e9f14bd3afda272e5e3f310b779e115d0c125d29\",\"html\":\"https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E5%B7%B2%E6%95%B4%E7%90%86%E6%9D%90%E6%96%99\"}},{\"name\":\"\u6280\u672f\u7c7b\u6807\u51c6\",\"path\":\"\u6280\u672f\u7c7b\u6807\u51c6\",\"sha\":\"de30b9a40cd054b6d7fb7fcebbe6f7e01b5e5770\",\"size\":0,\"url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E6%8A%80%E6%9C%AF%E7%B1%BB%E6%A0%87%E5%87%86?ref=master\",\"html_url\":\"https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E6%8A%80%E6%9C%AF%E7%B1%BB%E6%A0%87%E5%87%86\",\"git_url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/de30b9a40cd054b6d7fb7fcebbe6f7e01b5e5770\",\"download_url\":null,\"type\":\"dir\",\"_links\":{\"self\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E6%8A%80%E6%9C%AF%E7%B1%BB%E6%A0%87%E5%87%86?ref=master\",\"git\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/de30b9a40cd054b6d7fb7fcebbe6f7e01b5e5770\",\"html\":\"https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E6%8A%80%E6%9C%AF%E7%B1%BB%E6%A0%87%E5%87%86\"}},{\"name\":\"\u6570\u636e\u7c7b\u6807\u51c6\",\"path\":\"\u6570\u636e\u7c7b\u6807\u51c6\",\"sha\":\"b07085f5d932d491dc4776309fc799305e1b4838\",\"size\":0,\"url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E6%95%B0%E6%8D%AE%E7%B1%BB%E6%A0%87%E5%87%86?ref=master\",\"html_url\":\"https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E6%95%B0%E6%8D%AE%E7%B1%BB%E6%A0%87%E5%87%86\",\"git_url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/b07085f5d932d491dc4776309fc799305e1b4838\",\"download_url\":null,\"type\":\"dir\",\"_links\":{\"self\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E6%95%B0%E6%8D%AE%E7%B1%BB%E6%A0%87%E5%87%86?ref=master\",\"git\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/b07085f5d932d491dc4776309fc799305e1b4838\",\"html\":\"https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E6%95%B0%E6%8D%AE%E7%B1%BB%E6%A0%87%E5%87%86\"}},{\"name\":\"\u6807\u51c6\u5316\u6d4b\u8bc4\u76f8\u5173\u89c4\u8303\",\"path\":\"\u6807\u51c6\u5316\u6d4b\u8bc4\u76f8\u5173\u89c4\u8303\",\"sha\":\"5bf75d1217960dfa55654ed55bb07f644330a763\",\"size\":0,\"url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E6%A0%87%E5%87%86%E5%8C%96%E6%B5%8B%E8%AF%84%E7%9B%B8%E5%85%B3%E8%A7%84%E8%8C%83?ref=master\",\"html_url\":\"https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E6%A0%87%E5%87%86%E5%8C%96%E6%B5%8B%E8%AF%84%E7%9B%B8%E5%85%B3%E8%A7%84%E8%8C%83\",\"git_url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/5bf75d1217960dfa55654ed55bb07f644330a763\",\"download_url\":null,\"type\":\"dir\",\"_links\":{\"self\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E6%A0%87%E5%87%86%E5%8C%96%E6%B5%8B%E8%AF%84%E7%9B%B8%E5%85%B3%E8%A7%84%E8%8C%83?ref=master\",\"git\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/5bf75d1217960dfa55654ed55bb07f644330a763\",\"html\":\"https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E6%A0%87%E5%87%86%E5%8C%96%E6%B5%8B%E8%AF%84%E7%9B%B8%E5%85%B3%E8%A7%84%E8%8C%83\"}},{\"name\":\"\u7ba1\u7406\u7c7b\u6807\u51c6\",\"path\":\"\u7ba1\u7406\u7c7b\u6807\u51c6\",\"sha\":\"697c02441646c251192f32f1bdf86ea52042e7e4\",\"size\":0,\"url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E7%AE%A1%E7%90%86%E7%B1%BB%E6%A0%87%E5%87%86?ref=master\",\"html_url\":\"https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E7%AE%A1%E7%90%86%E7%B1%BB%E6%A0%87%E5%87%86\",\"git_url\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/697c02441646c251192f32f1bdf86ea52042e7e4\",\"download_url\":null,\"type\":\"dir\",\"_links\":{\"self\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/contents/%E7%AE%A1%E7%90%86%E7%B1%BB%E6%A0%87%E5%87%86?ref=master\",\"git\":\"https://api.github.com/repos/wanghaisheng/healthcaredatastandard/git/trees/697c02441646c251192f32f1bdf86ea52042e7e4\",\"html\":\"https://github.com/wanghaisheng/healthcaredatastandard/tree/master/%E7%AE%A1%E7%90%86%E7%B1%BB%E6%A0%87%E5%87%86\"}}]"
 },
 {
  "repo": "Ivanzgj/HealthCare",
  "language": "Java",
  "readme_contents": "# HealthCare\n\u6bd5\u8bbe\uff1a\u4e00\u4e2a\u8840\u538b\u5b9e\u65f6\u76d1\u63a7app\uff0c\u8be5app\u4e3b\u8981\u529f\u80fd\u4e3a\u4e0e\u6d4b\u91cf\u8bbe\u5907\u8fdb\u884c\u901a\u4fe1\uff0c\u83b7\u53d6\u6d4b\u91cf\u6570\u636e\u5e76\u5728\u5ba2\u6237\u7aef\u8fdb\u884c\u5904\u7406\uff0c\u7531\u670d\u52a1\u5668\u8fdb\u884c\u6570\u636e\u5206\u6790\uff0c\u4e3a\u7528\u6237\u63d0\u4f9b\u5065\u5eb7\u8bc4\u4f30\u53ca\u5efa\u8bae\u3002\n\n## \u76ee\u6807\n##### \u5b9e\u73b0\u4e0e\u84dd\u7259\u8bbe\u5907\u901a\u4fe1\uff0c\u83b7\u53d6\u4f7f\u7528\u8005\u7684\u5fc3\u7387\u6570\u636e\u548c\u8840\u538b\u6570\u636e\n##### \u5b9e\u73b0\u6570\u636e\u53ef\u89c6\u5316\n##### \u5b9e\u73b0\u5c06\u6570\u636e\u4e0a\u4f20\u5230\u670d\u52a1\u5668\uff0c\u5e76\u8fdb\u884c\u8fdb\u4e00\u6b65\u5206\u6790\n##### \u5b9e\u73b0\u5176\u5b83\u8f85\u52a9\u6027\u529f\u80fd\uff1a\u4e2a\u4eba\u4fe1\u606f\uff0c\u8bbe\u7f6e\u7b49\n##### \u5728\u5b8c\u6210\u4e0a\u8ff0\u529f\u80fd\u4e4b\u540e\uff0c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u5b9e\u73b0\u5176\u5b83\u529f\u80fd\uff0c\u4f8b\u5982\u6d4b\u91cf\u5149\u7167\uff0c\u6e29\u5ea6\uff0c\u632f\u52a8\u7b49\u6570\u636e\n\n## \u5df2\u5b8c\u6210\u529f\u80fd\n### \u84dd\u7259\u529f\u80fd\n\u53ef\u4ee5\u6253\u5f00\u84dd\u7259\u5e76\u8fde\u63a5\u5230\u6307\u5b9a\u8bbe\u5907\u83b7\u53d6\u6570\u636e\u6d41\u3002\n### \u6570\u636e\u56fe\u8868\n\u5df2\u5b8c\u6210\u56fe\u8868UI\u8bbe\u8ba1\u4ee5\u53ca\u6a21\u5757\u529f\u80fd\u642d\u5efa\uff0c\u5df2\u5b9e\u73b0\u56fe\u8868\u6570\u636e\u7684\u6570\u636e\u5e93\u8bfb\u53d6\u529f\u80fd\u3002\n### \u4e2a\u4eba\u8bbe\u7f6e\n\u5df2\u642d\u5efa\u597dUI\uff0c\u5b8c\u6210\u4e2a\u4eba\u4fe1\u606f\u9875\u9762\u5168\u90e8\u529f\u80fd\u3002\u5df2\u5b8c\u6210\u5168\u90e8\u7f51\u7edc\u901a\u4fe1\u63a5\u53e3\u3002\n### \u642d\u5efa\u597d\u6570\u636e\u5e93\u6a21\u5757\u4ee5\u53ca\u7f51\u7edc\u901a\u4fe1\u6a21\u5757\n\u6570\u636e\u5e93\u529f\u80fd\u5df2\u7ecf\u5b9e\u73b0\u5e76\u62bd\u8c61\uff0c\u7f51\u7edc\u901a\u4fe1\u529f\u80fd\u4e5f\u5df2\u5b9e\u73b0\u5e76\u62bd\u8c61\uff0c\u670d\u52a1\u5668\u521d\u6b65\u642d\u5efa\u4e86\u6846\u67b6\u3002\n\u670d\u52a1\u5668\u548c\u5ba2\u6237\u7aef\u5df2\u5b8c\u6210\u4e86\u5173\u4e8eUser\u6570\u636e\u548c\u6d4b\u91cf\u6570\u636e\u7684\u4e0a\u4f20\u4e0b\u8f7d\u4ee5\u53ca\u6e05\u7a7a\u7b49\u4e00\u7cfb\u5217\u64cd\u4f5c\uff0c\u672c\u673a\u5df2\u901a\u8fc7\u82b1\u751f\u58f3\u6620\u5c04\u5230\u5916\u7f51\u4f5c\u4e3a\u6d4b\u8bd5\u670d\u52a1\u5668\u3002\n\u670d\u52a1\u5668\u5df2\u6709\u6bd4\u8f83\u7b80\u5355\u7684UI\u53ef\u4f9b\u67e5\u8be2\u6307\u5b9a\u7528\u6237\u7684\u6d4b\u91cf\u6570\u636e\u3002\n### \u72b6\u6001\u8ba1\u7b97\n\u6839\u636e\u76d1\u63a7\u6570\u636e\uff08\u632f\u52a8\uff0c\u5c4f\u5e55\u63a7\u5236\uff09\u8ba1\u7b97\u7528\u6237\u72b6\u6001\uff0c\u5ba2\u6237\u7aef\u7b97\u6cd5\u5df2\u521d\u6b65\u5b8c\u6210\u3002\n### \u4e00\u4e9b\u9644\u52a0\u529f\u80fd\n\u5df2\u5b8c\u6210\u76d1\u542c\u52a0\u901f\u5ea6\u8ba1\u83b7\u53d6\u632f\u52a8\u6570\u636e\uff1b\u5df2\u5b8c\u6210\u76d1\u542c\u5c4f\u5e55\u4eae\u706d\u89e3\u9501\u529f\u80fd\uff1b\u5df2\u5b8c\u6210\u4e0a\u8ff0\u4e24\u79cd\u6570\u636e\u7684\u6570\u636e\u5e93\u8bfb\u5199\u4ee5\u53ca\u56fe\u8868\u5448\u73b0\u529f\u80fd\u3002\n### \u670d\u52a1\u5668\n\u670d\u52a1\u5668\u5df2\u5b8c\u6210\u6240\u6709\u4e0e\u5ba2\u6237\u7aef\u901a\u4fe1\u7684\u529f\u80fd\uff0c\u5df2\u521d\u6b65\u6784\u5efa\u4e86\u4e00\u4e2a\u53ef\u89c6\u5316\u7684\u7f51\u9875\u5bf9\u6570\u636e\u8fdb\u884c\u521d\u6b65\u7684\u67e5\u8be2\u548c\u4fee\u6539\u64cd\u4f5c\u3002\u5e94\u7528eCharts\u5c06\u6570\u636e\u4ee5\u56fe\u8868\u5f62\u5f0f\u663e\u793a\u51fa\u6765\u3002\n\n## PHP\u670d\u52a1\u5668\u7aef\u4ee3\u7801\u6258\u7ba1\u5730\u5740\nhttps://github.com/Ivanzgj/HealthCare_PHP\n"
 },
 {
  "repo": "cevheri/healthcare",
  "language": "Java",
  "readme_contents": "# healthcare\n\nThis application was generated using JHipster 6.8.0, you can find documentation and help at [https://www.jhipster.tech/documentation-archive/v6.8.0](https://www.jhipster.tech/documentation-archive/v6.8.0).\n\n## Development\n\nBefore you can build this project, you must install and configure the following dependencies on your machine:\n\n1. [Node.js][]: We use Node to run a development web server and build the project.\n   Depending on your system, you can install Node either from source or as a pre-packaged bundle.\n\nAfter installing Node, you should be able to run the following command to install development tools.\nYou will only need to run this command when dependencies change in [package.json](package.json).\n\n    npm install\n\nWe use npm scripts and [Webpack][] as our build system.\n\nRun the following commands in two separate terminals to create a blissful development experience where your browser\nauto-refreshes when files change on your hard drive.\n\n    ./mvnw\n    npm start\n\nNpm is also used to manage CSS and JavaScript dependencies used in this application. You can upgrade dependencies by\nspecifying a newer version in [package.json](package.json). You can also run `npm update` and `npm install` to manage dependencies.\nAdd the `help` flag on any command to see how you can use it. For example, `npm help update`.\n\nThe `npm run` command will list all of the scripts available to run for this project.\n\n### PWA Support\n\nJHipster ships with PWA (Progressive Web App) support, and it's turned off by default. One of the main components of a PWA is a service worker.\n\nThe service worker initialization code is commented out by default. To enable it, uncomment the following code in `src/main/webapp/index.html`:\n\n```html\n<script>\n  if ('serviceWorker' in navigator) {\n    navigator.serviceWorker.register('./service-worker.js').then(function() {\n      console.log('Service Worker Registered');\n    });\n  }\n</script>\n```\n\nNote: [Workbox](https://developers.google.com/web/tools/workbox/) powers JHipster's service worker. It dynamically generates the `service-worker.js` file.\n\n### Managing dependencies\n\nFor example, to add [Leaflet][] library as a runtime dependency of your application, you would run following command:\n\n    npm install --save --save-exact leaflet\n\nTo benefit from TypeScript type definitions from [DefinitelyTyped][] repository in development, you would run following command:\n\n    npm install --save-dev --save-exact @types/leaflet\n\nThen you would import the JS and CSS files specified in library's installation instructions so that [Webpack][] knows about them:\nEdit [src/main/webapp/app/vendor.ts](src/main/webapp/app/vendor.ts) file:\n\n```\nimport 'leaflet/dist/leaflet.js';\n```\n\nEdit [src/main/webapp/content/scss/vendor.scss](src/main/webapp/content/scss/vendor.scss) file:\n\n```\n@import '~leaflet/dist/leaflet.css';\n```\n\nNote: There are still a few other things remaining to do for Leaflet that we won't detail here.\n\nFor further instructions on how to develop with JHipster, have a look at [Using JHipster in development][].\n\n### Using Angular CLI\n\nYou can also use [Angular CLI][] to generate some custom client code.\n\nFor example, the following command:\n\n    ng generate component my-component\n\nwill generate few files:\n\n    create src/main/webapp/app/my-component/my-component.component.html\n    create src/main/webapp/app/my-component/my-component.component.ts\n    update src/main/webapp/app/app.module.ts\n\n## Building for production\n\n### Packaging as jar\n\nTo build the final jar and optimize the healthcare application for production, run:\n\n    ./mvnw -Pprod clean verify\n\nThis will concatenate and minify the client CSS and JavaScript files. It will also modify `index.html` so it references these new files.\nTo ensure everything worked, run:\n\n    java -jar target/*.jar\n\nThen navigate to [http://localhost:8080](http://localhost:8080) in your browser.\n\nRefer to [Using JHipster in production][] for more details.\n\n### Packaging as war\n\nTo package your application as a war in order to deploy it to an application server, run:\n\n    ./mvnw -Pprod,war clean verify\n\n## Testing\n\nTo launch your application's tests, run:\n\n    ./mvnw verify\n\n### Client tests\n\nUnit tests are run by [Jest][] and written with [Jasmine][]. They're located in [src/test/javascript/](src/test/javascript/) and can be run with:\n\n    npm test\n\nFor more information, refer to the [Running tests page][].\n\n### Code quality\n\nSonar is used to analyse code quality. You can start a local Sonar server (accessible on http://localhost:9001) with:\n\n```\ndocker-compose -f src/main/docker/sonar.yml up -d\n```\n\nYou can run a Sonar analysis with using the [sonar-scanner](https://docs.sonarqube.org/display/SCAN/Analyzing+with+SonarQube+Scanner) or by using the maven plugin.\n\nThen, run a Sonar analysis:\n\n```\n./mvnw -Pprod clean verify sonar:sonar\n```\n\nIf you need to re-run the Sonar phase, please be sure to specify at least the `initialize` phase since Sonar properties are loaded from the sonar-project.properties file.\n\n```\n./mvnw initialize sonar:sonar\n```\n\nor\n\nFor more information, refer to the [Code quality page][].\n\n## Using Docker to simplify development (optional)\n\nYou can use Docker to improve your JHipster development experience. A number of docker-compose configuration are available in the [src/main/docker](src/main/docker) folder to launch required third party services.\n\nFor example, to start a postgresql database in a docker container, run:\n\n    docker-compose -f src/main/docker/postgresql.yml up -d\n\nTo stop it and remove the container, run:\n\n    docker-compose -f src/main/docker/postgresql.yml down\n\nYou can also fully dockerize your application and all the services that it depends on.\nTo achieve this, first build a docker image of your app by running:\n\n    ./mvnw -Pprod verify jib:dockerBuild\n\nThen run:\n\n    docker-compose -f src/main/docker/app.yml up -d\n\nFor more information refer to [Using Docker and Docker-Compose][], this page also contains information on the docker-compose sub-generator (`jhipster docker-compose`), which is able to generate docker configurations for one or several JHipster applications.\n\n## Continuous Integration (optional)\n\nTo configure CI for your project, run the ci-cd sub-generator (`jhipster ci-cd`), this will let you generate configuration files for a number of Continuous Integration systems. Consult the [Setting up Continuous Integration][] page for more information.\n\n[jhipster homepage and latest documentation]: https://www.jhipster.tech\n[jhipster 6.8.0 archive]: https://www.jhipster.tech/documentation-archive/v6.8.0\n[using jhipster in development]: https://www.jhipster.tech/documentation-archive/v6.8.0/development/\n[using docker and docker-compose]: https://www.jhipster.tech/documentation-archive/v6.8.0/docker-compose\n[using jhipster in production]: https://www.jhipster.tech/documentation-archive/v6.8.0/production/\n[running tests page]: https://www.jhipster.tech/documentation-archive/v6.8.0/running-tests/\n[code quality page]: https://www.jhipster.tech/documentation-archive/v6.8.0/code-quality/\n[setting up continuous integration]: https://www.jhipster.tech/documentation-archive/v6.8.0/setting-up-ci/\n[node.js]: https://nodejs.org/\n[yarn]: https://yarnpkg.org/\n[webpack]: https://webpack.github.io/\n[angular cli]: https://cli.angular.io/\n[browsersync]: https://www.browsersync.io/\n[jest]: https://facebook.github.io/jest/\n[jasmine]: https://jasmine.github.io/2.0/introduction.html\n[protractor]: https://angular.github.io/protractor/\n[leaflet]: https://leafletjs.com/\n[definitelytyped]: https://definitelytyped.org/\n"
 },
 {
  "repo": "wso2/open-healthcare-docs",
  "language": "CSS",
  "readme_contents": "# WSO2 Open Healthcare Documentation\n\nThis is the source documentation of WSO2 Open Healthcare.\n\n## Prerequisites\n\nTo run the project locally, it requires [python](https://www.python.org/downloads/) & [pip](https://pypi.org/project/pip/).\n\n### Install Python\n\nCheck if you already have Python installed by running the following command.\n\n```bash\n$ python --version\nPython 2.7.10\n```\n\nIf you receive a response similar to the one shown above, `Python 2.7.10` is your default version.\n\nYou should also check if you have Python 3 installed. \n\n```bash\n$ python3 --version\nPython 3.8.0\n```\n\nIf you don't seem to have `Python` installed, grab the latest release from the [official downloads page](https://www.python.org/downloads/).\n\n### Install pip\n\npip is already installed if you are using Python 2 >=2.7.9 or Python 3 >=3.4 downloaded from [python.org](https://www.python.org/) or if you are working in a [Virtual Environment](https://packaging.python.org/tutorials/installing-packages/#creating-and-using-virtual-environments) created by [virtualenv](https://packaging.python.org/key_projects/#virtualenv) or [pyvenv](https://packaging.python.org/key_projects/#venv). Just make sure to [upgrade pip](https://pip.pypa.io/en/stable/installing/#upgrading-pip).\n\n#### Installing with get-pip.py\n\nTo install pip with `curl`, execute the following command. Alternatively you can download `get-pip.py` by clicking [here](https://bootstrap.pypa.io/get-pip.py). \n\n```bash\n$ curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\n```\n\nThen run the following command in the folder where you have downloaded get-pip.py\n\n```bash\n$ python get-pip.py\n```\n\n## Run project locally (Dev Mode)\n\n**Clone the repo**\n\n```bash\n$ git clone https://github.com/wso2/open-healthcare-docs.git\n```\n\n**Install the dependencies**\n\n```bash\n$ cd open-healthcare-docs && pip install -r requirements.txt\n```\n\n**Run mkdocs**\n\nExecute the following command from inside the `<Lang folder>`.\n\n```bash\n$ cd en && mkdocs serve\n```\n\n## License\n\nLicenses this source under the Apache License, Version 2.0 ([LICENSE](LICENSE)), You may not use this file except in compliance with the License.\n"
 },
 {
  "repo": "OmRajpurkar/Healthcare-Chatbot",
  "language": "PHP",
  "readme_contents": "# Healthcare-Chatbot\nHealthcare is essential in daily life. Unfortunately, consultation with a doctor can be difficult to obtain, especially if we need advice on non-life threatening problems. The proposed idea is to create a system with Dialog Flow that can meet the patients requirements. Healthcare chatbot is built with medical applications having the potential to reduce healthcare cost and improves accessibility to medical knowledge by a simple chat through method. Chatbots are useful for patients and for those who want to learn more about health. The real benefit of the chatbot is to provide advice and information for an healthy life. A text-to-text diagnosis engages patients in conversation about their medical issues and provides a personalized diagnosis based on their symptoms and also sets appointment for the user. Hence, people will have an idea about their health and have the right protection and prevention.\n\n\n**Start Page**\n\n![](Healthcare%20Chatbot%20Start%20Page.png)\n\n\n**Login Page (Screenshot of Errors When Directly Clicked the 'Sign In' Button)**\n\n![](Healthcare%20Chatbot%20Login%20Page.png)\n\n\n**Registration Page**\n\n![](Healthcare%20Chatbot%20Register.png)\n\n\n**Chat Page**\n\n![](Healthcare%20Chatbot%20Chat.png)\n"
 },
 {
  "repo": "AmitXShukla/Healthcare-Management-App-Flutter_Firebase",
  "language": "Dart",
  "readme_contents": "# Flutter FireBase Healthcare Management App\nComplete Healthcare Management (Patient, OPD, IPD, Rx, Lab) in Flutter Firebase App for iOS Android and Web\n\n```diff\n- If you like this project, please consider giving it a star (*) and follow me at GitHub & YouTube.\n```\n[<img src=\"https://github.com/AmitXShukla/AmitXShukla.github.io/blob/master/assets/icons/youtube.svg\" width=40 height=50>](https://youtube.com/AmitShukla_AI)\n[<img src=\"https://github.com/AmitXShukla/AmitXShukla.github.io/blob/master/assets/icons/github.svg\" width=40 height=50>](https://github.com/AmitXShukla)\n[<img src=\"https://github.com/AmitXShukla/AmitXShukla.github.io/blob/master/assets/icons/medium.svg\" width=40 height=50>](https://medium.com/@Amit_Shukla)\n[<img src=\"https://github.com/AmitXShukla/AmitXShukla.github.io/blob/master/assets/icons/twitter_1.svg\" width=40 height=50>](https://twitter.com/ashuklax)\n\n# Elish HMS\n\nElish Healthcare Management System App\n\n## Objective \nManage OPD, IPD, Pathology, WebMD, Rx, Patient Appointments<br/><br/>\n\n<i>Due to current Covid-19 situation,<br/>\nPatient's private data is not stored in app and location tracing functionality is not available with out government/authorities approval.</i>\n## Getting Started\n\nThis project is a community version and is absolutely free for private use.<br/>\n<a href=\"https://www.youtube.com/playlist?list=PLp0TENYyY8lHcc8mZiYG83sbsCea2xd3r\">click here for Demo & Video tutorials</a>\n\n## Technologies\n```sbtshell)\nFrontend: Flutter\nBackend:Google Firestore/Firebase\nMessages: LOOM SDK\nWebView: loom-app (using Angular version\n``` \n\n## Related Apps\n<ul>\n<li><a href=\"https://getcovidvaccine.web.app/\">Vaccine Distribution App</a></li>\n<li><a href=\"https://www.youtube.com/watch?v=MkV413X2Kmw&list=PLp0TENYyY8lHL-G7jGbhpJBhVb2UdTOhQ&index=1&t=698s\">Pandemic Contact Tracing, Visitor Management, Mobile Assets/Employee Attendance App</a></li>\n</ul>\n\n## Features\n<ul>\n<li>Store millions of records with lightening fast data retrieval</li>\n<li>hands free /voice activated typing</li>\n<li>Secured App (Role based access with Admin panel)</li>\n<li>Local dictionary based auto-completion</li>\n<li>Global dictionary based auto-completion/auto-sync (Pro)</li>\n<li>GBs of pictures, documents, Lab reports, Receipts (Pro)</li>\n<li>Self learning (auto complete) data entry (Pro)</li>\n<li>Social authentication (Pro)</li>\n<li>SMS, EMAIL, WhatsAPP API (Pro)</li>\n</ul>\n<i>send email to info@elishcosulting.com for Pro version enquiries.</i>\n\n## Product Images\n\n![Pic 1](./images/hms_pic_1.png)\n![Pic 2](./images/hms_pic_2.png)\n![Pic 3](./images/hms_pic_3.png)\n![Pic 4](./images/hms_pic_4.png)\n\n\n\n## How to Install\n\n<ul>\n    <li>Install Flutter environment</li>\n    <li>Download This GitHub repository</li>\n    <li>install Flutter packages *pub get) and Flutter web -> Flutter create .</li>\n    <li>Setup firebase account/project</li>\n    <li>Copy Firebase Project Config settings and replace variable firebaseConfig at src/web/index.html</li>\n    <li>enable Firebase social authentications</li>\n    <li>update Firebase Rules</li>\n\n```sbtshell\n    rules_version = '2';\n    service cloud.firestore {\n    match /databases/{database}/documents {\n    match /{document=**} {\n      allow read, write: if false;\n    }\n    match /roles/{document} {\n    // fix this, anyone who is logged in, can read these document & passwords\n    //  allow read: if isSignedIn();\n  \tallow read, write: if false;\n    }\n    \n    match /users/{document} {\n    allow create: if true;\n    allow read : if isSignedIn() && (isDocOwner() || isAdmin());\n    allow update: if isSignedIn() && isDocOwner() && onlyContentChanged();\n    allow update, delete: if isAdmin();\n    }\n    \n    match /person/{document=**} {\n    allow create: if true;\n    allow read, update : if isSignedIn() && (isDocOwner() || isAdmin());\n    allow delete : if isSignedIn() && isAdmin();\n    }\n    \n    match /person/{document}/Vaccine/{doc=**} {\n    allow create: if true;\n    // allow read, update : if isSignedIn() && (isDocOwner() || isAdmin());\n    // fix this later\n    allow read, update : if true;\n    allow delete : if isSignedIn() && isAdmin();\n    }\n    \n    match /person/{document}/OPD/{doc} {\n    allow create: if true;\n    // allow read, update : if isSignedIn() && (isDocOwner() || isAdmin());\n    // fix this later\n    allow read, update : if true;\n    allow delete : if isSignedIn() && isAdmin();\n    }\n    \n    match /person/{document}/Lab/{doc} {\n    allow create: if true;\n    // allow read, update : if isSignedIn() && (isDocOwner() || isAdmin());\n    // fix this later\n    allow read, update : if true;allow read, update : if isSignedIn() && (isDocOwner() || isAdmin());\n    allow delete : if isSignedIn() && isAdmin();\n    }\n    \n    match /person/{document}/Rx/{doc} {\n    allow create: if true;\n    // allow read, update : if isSignedIn() && (isDocOwner() || isAdmin());\n    // fix this later\n    allow read, update : if true;\n    allow delete : if isSignedIn() && isAdmin();\n    }\n    \n    match /person/{document}/Messages/{doc} {\n    allow create: if true;\n    // allow read, update : if isSignedIn() && (isDocOwner() || isAdmin());\n    // fix this later\n    allow read, update : if true;\n    allow delete : if isSignedIn() && isAdmin();\n    }\n    \n    match /appointments/{document} {\n    allow create: if true;\n    allow read, update : if isSignedIn() && (isDocOwner() || isAdmin());\n    allow delete : if isSignedIn() && isAdmin();\n    }\n    \n    match /records/{document} {\n    allow create: if true;\n    allow read, update : if isSignedIn() && (isDocOwner() || isAdmin());\n    }\n    \n    match /vaccine/{document} {\n    allow create: if true;\n    allow read, update : if isSignedIn() && (isDocOwner() || isAdmin());\n    }\n    \n    match /purchase/{document} {\n    allow create: if true;\n    allow read, update : if isSignedIn() && (isDocOwner() || isAdmin());\n    allow delete : if isSignedIn() && isAdmin();\n    }\n    \n\t\tmatch /msr/{document} {\n    allow create: if true;\n    allow read, update : if isSignedIn() && (isDocOwner() || isAdmin());\n    allow delete : if isSignedIn() && isAdmin();\n    }\n    \n    match /vendor/{document} {\n    allow create: if true;\n    allow read, update : if isSignedIn() && (isDocOwner() || isAdmin());\n    allow delete : if isSignedIn() && isAdmin();\n    }\n    \n    match /warehouse/{document} {\n    allow create: if true;\n    allow read: if isSignedIn()\n    allow update : if isSignedIn() && (isDocOwner() || isAdmin());\n    allow delete : if isSignedIn() && isAdmin();\n    }\n    match /item/{document} {\n    allow create: if true;\n    allow read: if isSignedIn()\n    allow update : if isSignedIn() && (isDocOwner() || isAdmin());\n    allow delete : if isSignedIn() && isAdmin();\n    }\n    \n    // helper functions\n    function isSignedIn() {\n    return request.auth.uid != null;\n    }\n    \n    function onlyContentChanged() {\n    return request.resource.data.role == resource.data.role;\n    // make sure user is not signing in with any role or changin his role during update\n    }\n    function isDocOwner() {\n    return request.auth.uid == resource.data.author;\n    }\n    // function isDocCreater() {\n    // return request.auth.uid == request.resource.data.author;\n    // }\n    function isAdmin() {\n    return get(/databases/$(database)/documents/users/$(request.auth.uid)).data.role == \"admin\";\n    }\n    // function isEmployee() {\n    // return get(/databases/$(database)/documents/settings/$(request.auth.uid)).data.role == \"employee\";\n    // }\n    }\n    }\n```\n</ul>\n\n![Pic 4](./images/env_variable.png)\n![Pic 4](./images/social_auth.png)\n![Pic 4](./images/rules.png)"
 },
 {
  "repo": "IRCAD/sight",
  "language": "C++",
  "readme_contents": "# Sight\n\n| Branch |    Status |\n|--------|-----------|\n| Dev    | [![pipeline status](https://git.ircad.fr/Sight/sight/badges/dev/pipeline.svg)](https://git.ircad.fr/Sight/sight/commits/dev) |\n| Master | [![pipeline status](https://git.ircad.fr/Sight/sight/badges/master/pipeline.svg)](https://git.ircad.fr/Sight/sight/commits/master) |\n\n## Description\n[//]: # (cspell: disable)\n**Sight**, the **S**urgical **I**mage **G**uidance and **H**ealthcare **T**oolkit aims to ease the creation of\napplications based on medical imaging.\n[//]: # (cspell: enable)\n\nIt includes various functionalities such as 2D and 3D digital image processing, visualization, augmented reality and\nmedical interaction simulation. It runs on Microsoft Windows and Linux, is written in C++, and features rapid interface\ndesign using XML files. It is freely available under the LGPL.\n\n**Sight** is mainly developed by the Surgical Data Sciences Team of [IRCAD France](https://www.ircad.fr), where it is\nused everyday to develop innovative applications for the operating room and medical research centers.\n\nMany **tutorials** and **examples**, which can help you to learn smoothly how to use **Sight**, are located in the\n`tutorials` and `examples` directories.\nDetailed steps are described [here](https://sight.pages.ircad.fr/sight-doc/Tutorials/index.html).\n\n### Features\n\n- 2D/3D visualization of medical images, meshes, and many widgets.\n- Import / export medical data from various formats (DICOM, [VTK](https://www.vtk.org/), ...) and sources\n  (files, devices, PACS, ...).\n- Playing, recording, processing videos (webcams, network streams, Intel RealSense devices, ...).\n- Easy GUI configuration and customization (XML description and stylesheets support).\n- Timeline, allowing to store various data (video, matrices, markers, etc...) and synchronize these data across time.\n- Mono and stereo camera calibration,\n- [ArUco](https://sourceforge.net/projects/aruco/) optical markers tracking,\n- [openIGTLink](http://openigtlink.org/) support through client and server services,\n- Advanced memory management to support large data. Unused data can be offloaded to disk, saving memory for foreground\n  tasks.\n- Work session or any part of it, can be saved and restored on disk. The data itself can be encrypted using AES256 to\n  ensure a high level of security and privacy\n\n\n### Hardware / Operating System / Compiler support\n\n**Sight** is written in standard C++17 and use [CMake](https://cmake.org/) as its build system, which means that Sight\nshould at least compile on any operating system that provide support for a decent C++17 compiler, CMake, **AND** Sight's\ndependencies (see [Install](#install) for a list of dependencies for Linux platform). However, we currently have access\nto a limited set of hardware/OS/compiler combinations where the code is actually tested on a regular basis.\n\nSuch combination includes:\n-  [Debian 11 stable on AMD64 with GCC 10.2.1](https://www.debian.org/ports/amd64)\n-  [Ubuntu 21.04 on AMD64 with GCC 10.3.0 or CLang 12](https://releases.ubuntu.com/21.04/)\n-  [Microsoft Windows 10 on AMD64 with VisualStudio 2019](https://www.microsoft.com/windows/)\n\n> If your platform is not listed, that *doesn't* mean **Sight** will not work, just we cannot guarantee that it is well\n> tested. If you are on this kind of platform and are able to build and use **Sight**, feel free to share with us your\n> success !\n\n> We use some fine tuned compiler flags (like `/arch:AVX2`) to optimize and generate code specifically for CPUs that\n> were released around 2013 and later. It means, if your CPU is too old, **Sight** will crash at runtime because some\n> CPU instructions are not implemented. In such situation, you can modify hidden cmake variable `SIGHT_ARCH` at\n> configuring time or modify the default compiler flag directly in **Sight** CMake code.\n\n## Applications\n\n### SightViewer\n\n**SightViewer** is a full featured medical image and mesh viewer with advanced rendering features such as volume\nrendering. It supports most medical image formats, and can also retrieve DICOM files from a PACS. It demonstrates many\nuseful features of Sight.\n\n<div align=center style=\"text-align: center; display: flex; flex-flow: row wrap; justify-content: space-around;\">\n<figure>\n    <img src=\"https://git.ircad.fr/sight/sight-doc/-/raw/dev/Introduction/media/SightViewer01.gif\">\n    <figcaption>\n        <b><i>MPR view of a medical 3D image with additional volume rendering</i></b>\n    </figcaption>\n</figure>\n<figure>\n    <img src=\"https://git.ircad.fr/sight/sight-doc/-/raw/dev/Introduction/media/SightViewer02.gif\">\n    <figcaption>\n        <b><i>Volume rendering and transfer function tuning</i></b>\n    </figcaption>\n</figure>\n<figure>\n    <img src=\"https://git.ircad.fr/sight/sight-doc/-/raw/dev/Introduction/media/mixed_vr_reconstructions.gif\">\n    <figcaption>\n        <b><i>Volume rendering mixed with 3D surfacic meshes</i></b>\n    </figcaption>\n</figure>\n</div>\n\n### DicomXplorer\n\n**DicomXplorer** is a simple medical image viewer that can connect to a PACS to retrieve DICOM data. It supports CT-scan\nand MRI images.\n\n<div align=center style=\"text-align: center; display: flex; flex-flow: row wrap; justify-content: space-around;\">\n<figure>\n    <img src=\"https://git.ircad.fr/sight/sight-doc/-/raw/dev/Introduction/media/DicomXplorer01.gif\">\n    <figcaption>\n        <b><i>DICOM and medical image files navigation</i></b>\n    </figcaption>\n</figure>\n<figure>\n    <img src=\"https://git.ircad.fr/sight/sight-doc/-/raw/dev/Introduction/media/DicomXplorer02.gif\">\n    <figcaption>\n        <b><i>MPR view of a medical 3D image</i></b>\n    </figcaption>\n</figure>\n</div>\n\n### SightCalibrator\n\n**SightCalibrator** is a user-friendly application to calibrate mono and stereo cameras.\nThis software is a must-have since camera calibration is a mandatory step in any AR application.\n\n<div align=center style=\"text-align: center; display: flex; flex-flow: row wrap; justify-content: space-around;\">\n<figure style=\"\">\n    <img src=\"https://git.ircad.fr/sight/sight-doc/-/raw/dev/Introduction/media/SightCalibrator01.gif\">\n    <figcaption>\n        <b><i>Intrinsic & extrinsic calibration of mono/stereo cameras with live reprojection error display</i></b>\n    </figcaption>\n</figure>\n</div>\n\n## Install\n\nSee [detailed install instructions](https://sight.pages.ircad.fr/sight-doc/Installation/index.html) for Windows and\nLinux.\n\n## Documentation\n\n* [Documentation](https://sight.pages.ircad.fr/sight-doc)\n* [Tutorials](https://sight.pages.ircad.fr/sight-doc/Tutorials/index.html)\n* [Doxygen](https://sight.pages.ircad.fr/sight)\n\n## Support\n\nPlease note that our GitLab is currently only available in read-only access for external developers and users. This is a\nrestriction because of the licensing model of GitLab. Since we use an EE version, we would be forced to pay for every\ncommunity user, and unfortunately we cannot afford it. This licensing model might change in the future\nhttps://gitlab.com/gitlab-org/gitlab-ee/issues/4382 though.\n\nUntil then, we gently ask our community users to use our GitHub mirror to\n[report any issues](https://github.com/IRCAD/sight/issues) or propose\n[contributions](https://github.com/IRCAD/sight/pulls).\n\nYou can also get live community support on the [gitter chat room](https://gitter.im/IRCAD-IHU/sight-support).\n\n"
 },
 {
  "repo": "hasyed/HealthCareApp",
  "language": "Java",
  "readme_contents": "HealthCareApp\n=============\n\nThe Mobile Solution to maintain consumption of daily use edibles and calorie balance with interactive user interfaces, Chart and Nutrition labels calculated in such a way that are readable to user.\n\nThis app takes an image of  nutrition chart of the product which user wants to intake. OpenCV is used to clean the captured image. Then the image goes to OCR(Optical Character Recognation) which extract the information from the image and added them to user database that he has consumed it, the information  includes Calories, Total Fats and other Nutritions. \n\nIf user want to gain or reduce weight, the formula in the main of the app helps user to input in how many days he want to reduce the weight and how much he wants to reduce. This will give him the Calories he wanted to take take everyday.\nUser can manually add products or exercise too. Products that he intake increase the calories and exercise that he do reduces the calories.\n\nThere is a chart that helps user to see his previouse performance regards calories as well.\n\nI have forked [android-ocr](https://github.com/rmtheis/android-ocr/tree/master/android/src) with some changes for openCV for cleansing the image for my help. \n##Requires\n[tess-two](https://github.com/rmtheis/tess-two/tree/master/tess-two)\n\n[OpenCV for android](http://opencv.org/)\n\n\n"
 },
 {
  "repo": "Qingbao/HealthCareStepCounter",
  "language": "Java",
  "readme_contents": "HealthCareStepCounter\n=====================\n\nComing soon: rewritten with React Native\n\n"
 },
 {
  "repo": "arvindsis11/Ai-Healthcare-Chatbot",
  "language": "CSS",
  "readme_contents": "# flask-chatbot\nBuilt on python 3.6\nFlask==0.11\nchatterbot==0.8.4\nSQLAlchemy==1.1.11\n\n#### A web implementation of [ChatterBot](https://github.com/gunthercox/ChatterBot) using Flask.\n\n## Local Setup:\n 1. Open command prompt and locate folder. run 'pip install -r requirements.txt'\n 2. Run *train.py*\n 3. Run *run.py*\n 4. Demo will be live at http://localhost:5000/\n \n ## Git push cmd- for reference\n ```java\n echo \"# MyRestApi all crud operations using spring boot framework\" >> README.md\ngit init\ngit add .\ngit commit -m \"initial commit\"\ngit branch -M main\ngit remote add origin https://github.com/arvindsis11/MyRestApi.git\ngit push -u origin main\ngit rm -r --cached .\n////////////////////////////////////////\nor push an existing repository from the command line\ngit remote add origin https://github.com/arvindsis11/springJPAdemo.git\ngit branch -M main\ngit push -u origin main\nhttps://github.com/arvindsis11/angular-todomanagement-app.git\n/////////////////////////////////////\ncommon git error:\nuse this:\ngit pull --rebase origin main\ngit push origin main\nurl:https://stackoverflow.com/questions/24114676/git-error-failed-to-push-some-refs-to-remote\n ```\n\n## License\nThis source is free to use, but ChatterBot does have a license which still applies and can be found on the [LICENSE](https://github.com/gunthercox/ChatterBot/blob/master/LICENSE) page.\n"
 },
 {
  "repo": "microsoft/Healthcare-Blockchain-Solution-Accelerator",
  "language": "C#",
  "readme_contents": "# Blockchain Healthcare Solution Accelerator Guide\r\n\r\n## About this repository\r\nThis accelerator was built to provide developers with all of the resources needed to quickly build an initial Hyperledger Fabric Healthcare data transactionary solution. Use this accelerator to jump start your development efforts with Hyperledger and Azure.\r\n\r\nThis repository contains the steps, scripts, code, and tools to create a Hyperledger Fabric blockchain application. 00_Resource_Deployment will create the necessary supporting resources in Azure (Storage, Kubernetes, and Cosmos DB). 01_Hyperledger_Fabric_Deployment will configure and deploy a Hyperledger Fabric blockchain network using Helm Packages and Kubernetes. 02_Hyperledger_Fabric_Client will install the necessary chaincode. Finally 03_Application_Deployment will deploy and host your application either locally or in your subscription.\r\n\r\n## Prerequisites\r\nIn order to successfully complete your solution, you will need to have access to and or provisioned the following:\r\n1. Access to an Azure subscription\r\n2. Visual Studio 2017 or 2019\r\n3. Kubectl, Helm, and Docker Command Line Tools installed\r\n4. Service Fabric\r\n\r\nOptional\r\n1. Intellij CE\r\n\r\n## Azure and Blockchain\r\nThe directions provided for this repository assume fundemental working knowledge of Azure, Cosmos DB, Azure Storage, Hyperledger Fabric, Service Fabric, and Kubernetes.  \r\n\r\nFor additional training and support, please see:\r\n 1. [Kubernetes](https://kubernetes.io/)\r\n 2. [Hyperledger Fabric](https://hyperledger-fabric.readthedocs.io/en/release-1.4/)\r\n 3. [Service Fabric](https://azure.microsoft.com/en-us/services/service-fabric/)\r\n 4. [Cosmos DB](https://docs.microsoft.com/en-us/azure/cosmos-db/introduction)\r\n\r\n## Getting Started and Process Overview\r\nClone/download this repo onto your computer and then walk through each of these folders in order, following the steps outlined in each of the README files.  After completion of all steps, you will have a working end-to-end solution with the following architecture:\r\n\r\n![Microservices Architecture](./References/architecture.JPG)\r\n\r\n\r\n### [00 - Resource Deployment](./00_Resource_Deployment)\r\nThe resources in this folder can be used to deploy the required resources into your Azure Subscription. This can be done either via the [Azure Portal](https://portal.azure.com) or by using the [PowerShell script](./00_Resource_Deployment/deploy.ps1) included in the resource deployment folder.\r\n\r\nAfter deployed, you will have a Cosmos DB account and database, Azure storage, and Kubernetes cluster deployed in your specified resource group.\r\n\r\n### [01 - Hyperledger Fabric Deployment](./01_Hyperledger_Fabric_Deployment)\r\nThis folder contains the Hyperledger Fabric Deployment configuration files. To prepare the environment and deploy the infrastructer run the [deploy script](./01_Hyperledger_Fabric_Deployment/deploy.ps1).\r\n\r\nRunning this script will deploy a basic fabric network consisting of two organizations: one peer organization and one orderer organization. To read more about hyperledger reference the [Hyperledger Fabric Documentation](https://hyperledger-fabric.readthedocs.io/en/release-1.4/).\r\n\r\n### [02 - Hyperledger Fabric Client](./02_Hyperledger_Fabric_Client)\r\nThis folder contains the Kotlin Chaincode and Hyperledger Fabric server used to communicate with the blockchain network. The script in this folder will pull the Fabric Chaincode, Client, and gRPC server. This image will install the chaincode and allow the application to execute against the Blockchain network. Follow the provided instructions.\r\n\r\n### [03 - Application Deployment](./03_Application_Deployment)\r\nThis folder contains the .net services for the proof content storage service, transaction tracker, transaction indexer, and gRPC Fabric Client. The Angular web application is also started and hosted with these services. Service Fabric is used to host this application.\r\n\r\n## Links\r\nHosted Site: [Healthcare Blockchain Solution](http://healthcare-apphosting.southcentralus.cloudapp.azure.com/login)\r\n\r\n*Use income less than 11000 and a NY Zip Code for a profile to qualify*\r\n\r\nVideo: [Healthcare Blockchain Solution Video](https://msit.microsoftstream.com/video/7f62ce8c-39e1-40d6-8adb-cbf298f31dfe)\r\n\r\n*Or download [Healthcare Blockchain Solution Video](healthcare_solution_video.mp4)*\r\n\r\n\r\n## License\r\nCopyright (c) Microsoft Corporation\r\n\r\nAll rights reserved.\r\n\r\nMIT License\r\n\r\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"\"Software\"\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\r\n\r\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\r\n\r\nTHE SOFTWARE IS PROVIDED AS IS, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE\r\n\r\n## Contributing\r\n\r\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\r\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\r\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\r\n\r\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\r\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\r\nprovided by the bot. You will only need to do this once across all repos using our CLA.\r\n\r\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\r\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\r\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\r\n"
 },
 {
  "repo": "openmrs/openmrs-module-radiology",
  "language": "Java",
  "readme_contents": "# openmrs-module-radiology\n\n[![Build Status](https://travis-ci.org/openmrs/openmrs-module-radiology.svg?branch=master)](https://travis-ci.org/openmrs/openmrs-module-radiology) [![Coverage Status](https://coveralls.io/repos/openmrs/openmrs-module-radiology/badge.svg?branch=master&service=github)](https://coveralls.io/github/openmrs/openmrs-module-radiology?branch=master) [![Codacy Badge](https://api.codacy.com/project/badge/grade/5e0137f0c916494eaa3ba7de43149ef7)](https://www.codacy.com/app/teleivo/openmrs-module-radiology_2) [![Dependency Status](https://www.versioneye.com/user/projects/57a194fb3d8eb6002f560778/badge.svg?style=flat)](https://www.versioneye.com/user/projects/57a194fb3d8eb6002f560778)\n\n####Table of Contents\n\n1. [Overview](#overview)\n2. [Build](#build)\n3. [Install](#install)\n  * [Docker](#docker-whale)\n  * [Demo data](#demo-data)\n4. [Documentation](#documentation)\n  * [Website](#website)\n  * [Developer guides](#developer-guides)\n  * [Wiki](#wiki)\n5. [Contributing](#contributing)\n  * [Code](#code)\n  * [Translation](#translation)\n6. [Issues](#issues)\n7. [Limitations](#limitations)\n8. [Community](#community)\n9. [Support](#support)\n10. [License](#license)\n\n## Overview\n\nOpenMRS module radiology (previously called radiologydcm4chee) is a module adding capabilities of a Radiology\nInformation System (RIS) onto OpenMRS.\n\n## Build\n\n### Prerequisites\n\nYou need to have installed\n\n* a Java JDK 8\n* the build tool [Maven](https://maven.apache.org/)\n\nYou need to configure Maven to use the JAVA JDK 8\n\n```bash\nmvn -version\n```\n\nShould tell you what version Maven is using.\n\nYou need to clone this repository:\n\n```bash\ngit clone https://github.com/openmrs/openmrs-module-radiology.git\n```\n\n### Command\n\nAfter you have taken care of the [Prerequisites](#prerequisites)\n\nExecute the following command:\n\n```bash\ncd openmrs-module-radiology\nmvn clean package\n```\n\nThis will generate the radiology module in `omod/target/radiology-{VERSION}.omod` which you will have to deploy into OpenMRS.\n\n## Install\n\nThe easiest way to install the module is to use [Docker](https://www.docker.com/).\n\n### Docker :whale:\n\nThis module can be baked into a Docker image so you can easily run and test it.\n\n#### Prerequisites\n\nAfter you have taken care of the [Build Prerequisites](#prerequisites)\n\nMake sure you have [Docker](https://docs.docker.com/) installed.\n\n#### Build\n\nBuild the Radiology Module and its Docker image:\n\n```bash\ncd openmrs-module-radiology\nmvn clean package docker:build\n```\n\n#### Run\n\nTo run an instance of the OpenMRS Radiology Module execute (assumes you have\ncreated a Docker image):\n\n```bash\ncd openmrs-module-radiology\nmvn docker:start\n```\n\nOpenMRS will be accessible at `http://<IP ADDRESS>:8080/openmrs`\n\n**NOTE: The IP address varies depending on your setup.**\n\nIf you are using [Docker machine](https://docs.docker.com/machine/) refer to its documentation on how to get the IP address.\nIf you are on Linux it will probably be will be `localhost`.\n\n#### Documentation\n\nPlease read the corresponding [DOCKER.md](docs/DOCKER.md) for more detailed\nexplanations on using Docker with the Radiology Module.\n\n### Demo data\n\nYou can import the demo data set [demo-data.sql](acceptanceTest/resources/demo-data.sql) into\nyour database which enables you to try out the modules features or test your\nchanges.\n\nPlease read the corresponding [DEMO-DATA.md](docs/DEMO-DATA.md).\n\n## Documentation\n\n### Website\n\nFor a detailed guide on ways to install and configure this module see\n\nhttp://teleivo.github.io/docs-openmrs-module-radiology/\n\n### Developer guides\n\nPlease check out the readme files at [docs](docs/).\n\n### Wiki\n\nFor some more background informations on the module see\n\nhttps://wiki.openmrs.org/display/docs/Radiology+Module\n\n## Contributing\n\nContributions are very welcome, we can definitely use your help!\n\n### Code\n\nCheck out our [contributing guidelines](CONTRIBUTING.md), read through the [Developer guides](#developer-guides).\n\nAfter you've read up :eyeglasses: [grab an issue](https://issues.openmrs.org/browse/RAD) that is `Ready For Development`.\n\n### Translation\n\nWe use\n\nhttps://www.transifex.com/openmrs/OpenMRS/radiology-module/\n\nto manage our translations.\n\nThe `messages.properties` file in this repository is our single source of\ntruth. It contains key, value pairs for the English language which is the\ndefault.\n\nTransifex fetches updates to this file every night which can then be translated\nby you and me on transifex website itself. At any time we can pull new translations from transifex\nback into this repository. Other languages like for ex. Spanish will then be in\nthe `messages_es.properties` file.\n\nIf you would like to know more about transifex from the coding side read\n\nhttps://wiki.openmrs.org/display/docs/Maintaining+OpenMRS+Module+Translations+via+Transifex\n\n## Issues\n\nTo file new issues or help to fix existing ones please check out\n\nhttps://issues.openmrs.org/browse/RAD\n\n## Limitations\n\nThis module is not yet officially released to the [openmrs modules](https://modules.openmrs.org/#/).\n\nThe API and UI are not yet stable and subject to frequent changes.\n\n:exclamation: ATTENTION :exclamation: radiology orders created via the module will not be sent to the PACS\nas HL7 order messages. This has previously been done in a hacky/synchronous way which was not fit for\nproduction and only messy code which had to be removed. A message queue which takes care of sending HL7\norder messages to the PACS once orders are created is needed. Such a queue would retry sending the order message\nin case the PACS is currently down. Unfortunately, OpenMRS does not provide such a message queue for outgoing HL7 messages.\nThis is THE big missing piece in the puzzle of the radiology module which until\nnow has been bridged with communication servers such as mirth.\n\nThe module depends on [OpenMRS Version 2.0.0](https://github.com/openmrs/openmrs-core) so it cannot\nrun on any version lower than that.\n\nThe module currently depends on [OpenMRS Legacy UI](https://github.com/openmrs/openmrs-module-legacyui)\nwhich provides the UI but it is [planned](https://issues.openmrs.org/browse/RAD-341)\nto extract the UI into a separate module so this module only provides the Java and\nREST API without forcing a specific UI onto anyone.\n\n## Community\n\n[![OpenMRS Talk](https://omrs-shields.psbrandt.io/custom/openmrs/talk/F26522?logo=openmrs)](http://talk.openmrs.org)\n[![OpenMRS IRC](https://img.shields.io/badge/openmrs-irc-EEA616.svg?logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI2MTIiIGhlaWdodD0iNjEyIiB2aWV3Qm94PSIwIDAgNjEyIDYxMiI%2BPHBhdGggZD0iTTE1MyAyMjkuNWMtMjEuMTMzIDAtMzguMjUgMTcuMTE3LTM4LjI1IDM4LjI1UzEzMS44NjcgMzA2IDE1MyAzMDZjMjEuMTE0IDAgMzguMjUtMTcuMTE3IDM4LjI1LTM4LjI1UzE3NC4xMzMgMjI5LjUgMTUzIDIyOS41em0xNTMgMGMtMjEuMTMzIDAtMzguMjUgMTcuMTE3LTM4LjI1IDM4LjI1UzI4NC44NjcgMzA2IDMwNiAzMDZjMjEuMTE0IDAgMzguMjUtMTcuMTE3IDM4LjI1LTM4LjI1UzMyNy4xMzMgMjI5LjUgMzA2IDIyOS41em0xNTMgMGMtMjEuMTMzIDAtMzguMjUgMTcuMTE3LTM4LjI1IDM4LjI1UzQzNy44NjcgMzA2IDQ1OSAzMDZzMzguMjUtMTcuMTE3IDM4LjI1LTM4LjI1UzQ4MC4xMzMgMjI5LjUgNDU5IDIyOS41ek0zMDYgMEMxMzcuMDEyIDAgMCAxMTkuODc1IDAgMjY3Ljc1YzAgODQuNTE0IDQ0Ljg0OCAxNTkuNzUgMTE0Ljc1IDIwOC44MjZWNjEybDEzNC4wNDctODEuMzRjMTguNTUyIDMuMDYyIDM3LjYzOCA0Ljg0IDU3LjIwMyA0Ljg0IDE2OS4wMDggMCAzMDYtMTE5Ljg3NSAzMDYtMjY3Ljc1UzQ3NS4wMDggMCAzMDYgMHptMCA0OTcuMjVjLTIyLjMzOCAwLTQzLjkxLTIuNi02NC42NDMtNy4wMmwtOTAuMDQgNTQuMTI0IDEuMjA0LTg4LjdDODMuNSA0MTQuMTMzIDM4LjI1IDM0NS41MTMgMzguMjUgMjY3Ljc1YzAtMTI2Ljc0IDExOS44NzUtMjI5LjUgMjY3Ljc1LTIyOS41czI2Ny43NSAxMDIuNzYgMjY3Ljc1IDIyOS41UzQ1My44NzUgNDk3LjI1IDMwNiA0OTcuMjV6IiBmaWxsPSIjZmZmIi8%2BPC9zdmc%2B)](http://irc.openmrs.org)\n[![OpenMRS Telegram](https://img.shields.io/badge/openmrs-telegram-009384.svg?logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNDAgMjQwIj48ZGVmcz48bGluZWFyR3JhZGllbnQgaWQ9ImEiIHgxPSIuNjY3IiB5MT0iLjE2NyIgeDI9Ii40MTciIHkyPSIuNzUiPjxzdG9wIHN0b3AtY29sb3I9IiMzN2FlZTIiIG9mZnNldD0iMCIvPjxzdG9wIHN0b3AtY29sb3I9IiMxZTk2YzgiIG9mZnNldD0iMSIvPjwvbGluZWFyR3JhZGllbnQ%2BPGxpbmVhckdyYWRpZW50IGlkPSJiIiB4MT0iLjY2IiB5MT0iLjQzNyIgeDI9Ii44NTEiIHkyPSIuODAyIj48c3RvcCBzdG9wLWNvbG9yPSIjZWZmN2ZjIiBvZmZzZXQ9IjAiLz48c3RvcCBzdG9wLWNvbG9yPSIjZmZmIiBvZmZzZXQ9IjEiLz48L2xpbmVhckdyYWRpZW50PjwvZGVmcz48Y2lyY2xlIGN4PSIxMjAiIGN5PSIxMjAiIHI9IjEyMCIgZmlsbD0idXJsKCNhKSIvPjxwYXRoIGZpbGw9IiNjOGRhZWEiIGQ9Ik05OCAxNzVjLTMuODg4IDAtMy4yMjctMS40NjgtNC41NjgtNS4xN0w4MiAxMzIuMjA3IDE3MCA4MCIvPjxwYXRoIGZpbGw9IiNhOWM5ZGQiIGQ9Ik05OCAxNzVjMyAwIDQuMzI1LTEuMzcyIDYtM2wxNi0xNS41NTgtMTkuOTU4LTEyLjAzNSIvPjxwYXRoIGZpbGw9InVybCgjYikiIGQ9Ik0xMDAuMDQgMTQ0LjQxbDQ4LjM2IDM1LjczYzUuNTIgMy4wNDQgOS41IDEuNDY3IDEwLjg3Ni01LjEyNGwxOS42ODUtOTIuNzYzYzIuMDE2LTguMDgtMy4wOC0xMS43NDYtOC4zNTgtOS4zNWwtMTE1LjU5IDQ0LjU3MmMtNy44OSAzLjE2NS03Ljg0NCA3LjU2Ny0xLjQ0IDkuNTI4bDI5LjY2NCA5LjI2IDY4LjY3My00My4zMjZjMy4yNC0xLjk2NiA2LjIxNy0uOTEgMy43NzUgMS4yNTgiLz48L3N2Zz4%3D)](https://telegram.me/openmrs)\n[![OpenMRS Radiology Wiki](https://img.shields.io/badge/openmrs-wiki-5B57A6.svg?logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNjAiIGhlaWdodD0iMTQyIiB2aWV3Qm94PSIwIDAgMTYwIDE0MiI%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%3D%3D)](https://wiki.openmrs.org/display/docs/Radiology+Module)\n\n## Support\n\nAsk questions on [OpenMRS Talk](https://talk.openmrs.org/).\n\n## License\n\n[MPL 2.0 w/ HD](http://openmrs.org/license/) \u00a9 [OpenMRS Inc.](http://www.openmrs.org/)\n"
 },
 {
  "repo": "VectorInstitute/cyclops",
  "language": "Python",
  "readme_contents": "![cyclops Logo](https://github.com/VectorInstitute/cyclops/blob/main/docs/source/theme/static/cyclops_logo-dark.png?raw=true)\n\n--------------------------------------------------------------------------------\n\n[![PyPI](https://img.shields.io/pypi/v/pycyclops)](https://pypi.org/project/pycyclops)\n[![code checks](https://github.com/VectorInstitute/cyclops/actions/workflows/code_checks.yml/badge.svg)](https://github.com/VectorInstitute/cyclops/actions/workflows/code_checks.yml)\n[![integration tests](https://github.com/VectorInstitute/cyclops/actions/workflows/integration_tests.yml/badge.svg)](https://github.com/VectorInstitute/cyclops/actions/workflows/integration_tests.yml)\n[![docs](https://github.com/VectorInstitute/cyclops/actions/workflows/docs_deploy.yml/badge.svg)](https://github.com/VectorInstitute/cyclops/actions/workflows/docs_deploy.yml)\n[![codecov](https://codecov.io/gh/VectorInstitute/cyclops/branch/main/graph/badge.svg)](https://codecov.io/gh/VectorInstitute/cyclops)\n[![license](https://img.shields.io/github/license/VectorInstitute/cyclops.svg)](https://github.com/VectorInstitute/cyclops/blob/main/LICENSE)\n\n``cyclops`` is a framework for facilitating research and deployment of ML models\nin the health (or clinical) setting. It provides a few high-level APIs namely:\n\n\n* `query` - Querying EHR databases (such as MIMIC-IV)\n* `process` - Process static and temporal EHR data\n* `evaluate` - Evaluate models on clinical prediction tasks\n* `monitor` - Detect data drift relevant for clinical use cases\n\n``cyclops`` also provides a library of use-cases on clinical datasets. The implemented\nuse cases include:\n\n* Mortality decompensation prediction\n\n\n## \ud83d\udc23 Getting Started\n\n### Installing cyclops using pip\n\n```bash\npython3 -m pip install pycyclops\n```\n\nThe core package only includes support for the `process` API. To install support for\n`query`, `evaluate` and `monitor` APIs, install them as extra dependency installs.\n\nTo install with `query` API support,\n\n```bash\npython3 -m pip install 'pycyclops[query]'\n```\n\nTo install with `evaluate` API support,\n\n```bash\npython3 -m pip install 'pycyclops[evaluate]'\n```\n\nTo install with `monitor` API support,\n\n```bash\npython3 -m pip install 'pycyclops[monitor]'\n```\n\nMultiple extras could also be combined, for example to install with both `query` and\n`evaluate` API support:\n\n```bash\npython3 -m pip install 'pycyclops[query,evaluate]'\n```\n\n\n## \ud83e\uddd1\ud83c\udfff\u200d\ud83d\udcbb Developing\n\nThe development environment has been tested on ``python = 3.9``.\n\nThe python virtual environment can be set up using\n[poetry](https://python-poetry.org/docs/#installation). Hence, make sure it is\ninstalled and then run:\n\n```bash\npython3 -m poetry install\nsource $(poetry env info --path)/bin/activate\n```\n\nAPI documentation is built using [Sphinx](https://www.sphinx-doc.org/en/master/) and\ncan be locally built by:\n\n```bash\ncd docs\nmake html SPHINXOPTS=\"-D nbsphinx_allow_errors=True\"\n```\n\n### Contributing\nContributing to cyclops is welcomed.\nSee [Contributing](https://vectorinstitute.github.io/cyclops/api/intro.html) for\nguidelines.\n\n\n## \ud83d\udcda [Documentation](https://vectorinstitute.github.io/cyclops/)\n\n## \ud83d\udcd3 Notebooks\n\nTo use jupyter notebooks, the python virtual environment can be installed and\nused inside an IPython kernel. After activating the virtual environment, run:\n\n```bash\npython3 -m ipykernel install --user --name <name_of_kernel>\n```\n\nNow, you can navigate to the notebook's ``Kernel`` tab and set it as\n``<name_of_kernel>``.\n\n## \ud83c\udf93 Citation\nReference to cite when you use CyclOps in a project or a research paper:\n```\n@article {Krishnan2022.12.02.22283021,\n\tauthor = {Krishnan, Amrit and Subasri, Vallijah and McKeen, Kaden and Kore, Ali and Ogidi, Franklin and Alinoori, Mahshid and Lalani, Nadim and Dhalla, Azra and Verma, Amol and Razak, Fahad and Pandya, Deval and Dolatabadi, Elham},\n\ttitle = {CyclOps: Cyclical development towards operationalizing ML models for health},\n\telocation-id = {2022.12.02.22283021},\n\tyear = {2022},\n\tdoi = {10.1101/2022.12.02.22283021},\n\tpublisher = {Cold Spring Harbor Laboratory Press},\n\tURL = {https://www.medrxiv.org/content/early/2022/12/08/2022.12.02.22283021},\n\tjournal = {medRxiv}\n}\n```\n"
 },
 {
  "repo": "hapifhir/hapi-fhir",
  "language": "Java",
  "readme_contents": "HAPI FHIR\n=========\n\nHAPI FHIR - Java API for HL7 FHIR Clients and Servers\n\n[![License][Badge-License]][Link-License]\n\n## CI/CD\n| CI Status (master) | SNAPSHOT Pipeline | Current Release |\n| :---: | :---: | :---: |\n| [![Build Status][Badge-AzurePipelineMaster]][Link-AzurePipelinesMaster] | [![Build Status][Badge-AzureReleaseSnapshot]][Link-AzurePipelinesSnapshot] | [![Release Artifacts][Badge-MavenCentral]][Link-MavenCentral] |\n\n## Coverage and Quality\n\n[![codecov][Badge-CodeCov]][Link-CodeCov]\n[![Language grade: Java](https://img.shields.io/lgtm/grade/java/g/hapifhir/hapi-fhir.svg?logo=lgtm&logoWidth=18)](https://lgtm.com/projects/g/hapifhir/hapi-fhir/context:java)\n\n## Documentation and wiki\n\nComplete project documentation is available here:\nhttp://hapifhir.io\n\nA demonstration of this project is available here:\nhttp://hapi.fhir.org/\n\nThis project is Open Source, licensed under the Apache Software License 2.0.\n\nPlease see [this wiki page][Link-wiki] for information on where to get help with HAPI FHIR. \n\nPlease see [Smile CDR][Link-SmileCDR] for information on commercial support.\n\n[Link-AzurePipelines]: https://dev.azure.com/hapifhir/HAPI%20FHIR/_build\n[Link-AzurePipelinesMaster]: https://dev.azure.com/hapifhir/HAPI%20FHIR/_build?definitionId=2\n[Link-AzurePipelinesSnapshot]: https://dev.azure.com/hapifhir/HAPI%20FHIR/_build?definitionId=3\n[Link-MavenCentral]: http://search.maven.org/#search|ga|1|ca.uhn.hapi.fhir\n[Link-CodeCov]: https://codecov.io/gh/hapifhir/hapi-fhir\n[Link-wiki]: https://github.com/hapifhir/hapi-fhir/wiki/Getting-Help\n[Link-SmileCDR]: https://smilecdr.com\n[Link-License]: https://hapifhir.io/hapi-fhir/license.html\n\n[Badge-AzurePipelineMaster]: https://dev.azure.com/hapifhir/HAPI%20FHIR/_apis/build/status/hapifhir.hapi-fhir?branchName=refs%2Fpull%2F2319%2Fmerge\n[Badge-AzureReleaseSnapshot]: https://dev.azure.com/hapifhir/HAPI%20FHIR/_apis/build/status/SNAPSHOT%20pipeline?branchName=master\n[Badge-MavenCentral]: https://maven-badges.herokuapp.com/maven-central/ca.uhn.hapi.fhir/hapi-fhir-base/badge.svg\n[Badge-CodeCov]: https://codecov.io/gh/hapifhir/hapi-fhir/branch/master/graph/badge.svg?token=zHfnKfQB9X\n[Badge-License]: https://img.shields.io/badge/license-apache%202.0-60C060.svg\n\n\n"
 },
 {
  "repo": "aws-samples/amazon-sagemaker-healthcare-fraud-detection",
  "language": "Jupyter Notebook",
  "readme_contents": "\n\n# Introduction\n\nIDC study states that 40% of Enteprises in year 2019 will be working to include AI/ML as a part of their transformative strategy. Today, AI/ML is beyond the hype cycle and there are usecases that are providing real business value. \n\nIn this workshop, we will work on a healthcare insurance fraud identification usecase. We will apply machine learning to identify anomalous claims that require further investigation. The technique used in the workshop is broadly applicable to multiple problems fraud, abuse and waste.\n\n## **Launch an Amazon SageMaker Jupyter Notebook**\n\n### Prerequisites and assumptions\n1. To run this Jupyter Notebook, you need an personal Laptop and an AWS account that provides access to AWS services.\n\n### Steps\n1. Sign In to the [AWS Console](https://aws.amazon.com/)\n2. Click Services, search for **Amazon SageMaker** and Click **Amazon SageMaker** in the dropdown![Find SageMaker](./images/find-sagemaker.png)\n3. After you land on Amazon SageMaker console, click on **Notebook Instances**![SageMaker Console](./images/sagemaker-console.png)\n4. Click **Create Notebook**![Create Notebook](./images/create-notebook.png)\n5. Give Notebook a name you can remember and fill out configuration details as suggested in the screenshots below.![Create Notebook Instance](./images/create-notebook-instance.png)\n6. Select IAM Role if one already exists in the dropdown![Select Existing Role](./images/select-role.png)\n7. Create a new role if one doesn't exist. ![Create new role](./images/create-role.png)\n8. Provide  a path to clone public git repo that we will use today for our workshop to download data dictionary and Jupyter IPython Notebook ![Select Git Repo](./images/select-gitrepo.png) \n9. Provide the path of [Git repo](https://github.com/aws-samples/amazon-sagemaker-healthcare-fraud-detection.git)\n![Provide Git url](./images/clone-gitrepo.png) \n6. Click **Create Notebook Instance**\n8. In the Amazon SageMaker Console-->Notebook Instances, wait for your notebook instance to start. Observe change from Pending to In Service status.![Creation pending](./images/creation-pending.png)![Notebook In Service](./images/notebook-inservice.png)\n9. Remember the name of your notebook instance and Click **Open Jupyter** for your notebook.![Notebook In Service](./images/notebook-inservice.png)\n10. Validate your data and notebook cloned from Git Repo![Validate Git Clone](./images/validate-git-clone.png)\n\n## **Finish your Lab in Jupyter Notebook**\n1. Click on **healthcare-fraud-identification-using-PCA-anomaly-detection.ipynb** and start working. From here onwards all the instruction will be in the Jupyter Notebook. Come back after you have completed all the steps in the Jupyter Notebook and finish rest of the steps as suggested below.\n\n\n## Finish\n1. **Congratulations!** \n2. Please make sure to delete all resources as mentioned in the section below.\n\n\n## Cleanup Resources\n1. Go to Amazon SageMaker console to shutdown your Amazon SageMaker Jupyter Notebook Instance, select your instance from the list.Select **Stop** from the **Actions** drop down menu.\n![Stop Notebook Instance](./images/stop-notebook.png)\n2. After your notebook instance is completely **Stopped**, select **Delete** fron the **Actions** drop down menu to **delete** your notebook instance.![Delete Notebook Instance](./images/delete-notebook.png)\n4. Navigate to Amazon S3 Console. \n![S3 Console](./images/s3-console.png)\n5. Find Amazon S3 bucket created for training and click to list objects in the bucket.![Find Bucket](./images/search-s3-bucket.png)\n6. Navigate to the **model-tar.gz** and delete it by using **Actions** menu.![Delete Model](./images/delete-model.png) \n6. Navigate to the training data file **healthcare_fraud_identification_feature_store** and delete it by using **Actions** menu.![Delete Training Data](./images/delete-training-data.png)\n7. After all the objects are deleted in the bucket. Go ahead and delete the bucket using the Actions menu.![Delete Bucket](./images/delete-bucket.png)\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n\n"
 }
]